Directory structure:
â””â”€â”€ leonai-do-openspec/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ AGENTS.md
    â”œâ”€â”€ build.js
    â”œâ”€â”€ CHANGELOG.md
    â”œâ”€â”€ eslint.config.js
    â”œâ”€â”€ flake.lock
    â”œâ”€â”€ flake.nix
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ MAINTAINERS.md
    â”œâ”€â”€ openspec-parallel-merge-plan.md
    â”œâ”€â”€ package.json
    â”œâ”€â”€ tsconfig.json
    â”œâ”€â”€ vitest.config.ts
    â”œâ”€â”€ vitest.setup.ts
    â”œâ”€â”€ .actrc
    â”œâ”€â”€ .coderabbit.yaml
    â”œâ”€â”€ docs/
    â”‚   â”œâ”€â”€ artifact_poc.md
    â”‚   â”œâ”€â”€ experimental-release-plan.md
    â”‚   â”œâ”€â”€ experimental-workflow.md
    â”‚   â”œâ”€â”€ project-config-demo.md
    â”‚   â”œâ”€â”€ schema-customization.md
    â”‚   â””â”€â”€ schema-workflow-gaps.md
    â”œâ”€â”€ openspec/
    â”‚   â”œâ”€â”€ AGENTS.md
    â”‚   â”œâ”€â”€ config.yaml
    â”‚   â”œâ”€â”€ project.md
    â”‚   â”œâ”€â”€ changes/
    â”‚   â”‚   â”œâ”€â”€ IMPLEMENTATION_ORDER.md
    â”‚   â”‚   â”œâ”€â”€ add-feedback-command/
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚       â””â”€â”€ cli-feedback/
    â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ add-verify-skill/
    â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚       â””â”€â”€ opsx-verify-skill/
    â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ archive/
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-01-11-add-update-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-01-13-add-list-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-list/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-05-initialize-typescript-project/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-06-add-init-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-06-adopt-future-state-storage/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ openspec-conventions/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-11-add-complexity-guidelines/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ openspec-docs/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ README.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-13-add-archive-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-archive/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-13-add-diff-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-diff/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-add-change-commands/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-change/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-list/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-add-interactive-show-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-change/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-show/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-spec/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-add-skip-specs-archive-option/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-archive/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-add-spec-commands/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-spec/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-add-zod-validation/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-archive/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-diff/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-adopt-delta-based-changes/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-archive/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-diff/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ openspec-conventions/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-adopt-verb-noun-cli-structure/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-list/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ openspec-conventions/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-bulk-validation-interactive-selection/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-change/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-spec/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-validate/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-fix-update-tool-selection/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-improve-validate-error-messages/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-validate/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-08-19-structured-spec-format/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ openspec-conventions/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-12-add-view-dashboard-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-view/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-add-agents-md-config/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-add-multi-agent-init/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-add-slash-command-support/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-improve-cli-e2e-plan/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-improve-deterministic-tests/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-improve-init-onboarding/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-remove-diff-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-sort-active-changes-by-progress/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-view/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-update-agent-file-name/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ openspec-conventions/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-update-agent-instructions/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-09-29-update-markdown-parser-crlf/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-validate/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-add-codex-slash-command-support/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-add-github-copilot-prompts/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-add-kilocode-workflows/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-add-non-interactive-init-options/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-add-windsurf-workflows/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-enhance-validation-error-messages/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-validate/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-improve-agent-instruction-usability/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ docs-agent-instructions/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-slim-root-agents-file/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-update-cli-init-enter-selection/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-update-cli-init-root-agents/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-14-update-release-automation/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-22-add-archive-command-arguments/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-22-add-cline-support/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-22-add-crush-support/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-10-22-add-factory-slash-commands/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-11-06-add-shell-completions/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-completion/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-20-add-global-config-dir/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ global-config/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-21-add-config-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-config/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-23-extend-shell-completions/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-completion/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-24-add-artifact-graph-core/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ artifact-graph/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-25-add-change-manager/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ change-creation/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-28-add-artifact-workflow-cli/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-artifact-workflow/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-28-add-instruction-loader/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ instruction-loader/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-28-restructure-schema-directories/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ artifact-graph/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-29-unify-change-state-model/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-artifact-workflow/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-view/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-30-add-antigravity-support/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-12-30-fix-cline-workflows-implementation/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-06-add-agent-schema-selection/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-06-add-per-change-schema-metadata/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-artifact-workflow/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-06-add-specs-apply-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ specs-sync-skill/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-06-make-apply-instructions-schema-aware/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-artifact-workflow/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-06-opsx-archive-command/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ opsx-archive-skill/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-07-add-nix-flake-support/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ nix-flake-support/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-09-add-flake-update-script/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ flake-update-script/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-09-add-posthog-analytics/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ global-config/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ telemetry/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ 2026-01-09-fix-codebuddy-frontmatter-fields/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â”‚       â””â”€â”€ cli-update/
    â”‚   â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”‚   â””â”€â”€ 2026-01-15-add-nix-ci-validation/
    â”‚   â”‚   â”‚       â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚       â””â”€â”€ specs/
    â”‚   â”‚   â”‚           â””â”€â”€ ci-nix-validation/
    â”‚   â”‚   â”‚               â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ merge-init-experimental/
    â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚       â”œâ”€â”€ cli-init/
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚       â””â”€â”€ legacy-cleanup/
    â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ multi-provider-skill-generation/
    â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚       â”œâ”€â”€ ai-tool-paths/
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ cli-artifact-workflow/
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚       â””â”€â”€ command-generation/
    â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ project-config/
    â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚       â”œâ”€â”€ config-loading/
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ context-injection/
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚       â”œâ”€â”€ rules-injection/
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ spec.md
    â”‚   â”‚   â”‚       â””â”€â”€ schema-resolution/
    â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ project-local-schemas/
    â”‚   â”‚   â”‚   â”œâ”€â”€ design.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚   â”‚   â””â”€â”€ specs/
    â”‚   â”‚   â”‚       â””â”€â”€ schema-resolution/
    â”‚   â”‚   â”‚           â””â”€â”€ spec.md
    â”‚   â”‚   â”œâ”€â”€ schema-alias-support/
    â”‚   â”‚   â”‚   â”œâ”€â”€ proposal.md
    â”‚   â”‚   â”‚   â””â”€â”€ .openspec.yaml
    â”‚   â”‚   â””â”€â”€ schema-management-cli/
    â”‚   â”‚       â”œâ”€â”€ design.md
    â”‚   â”‚       â”œâ”€â”€ proposal.md
    â”‚   â”‚       â”œâ”€â”€ tasks.md
    â”‚   â”‚       â”œâ”€â”€ .openspec.yaml
    â”‚   â”‚       â””â”€â”€ specs/
    â”‚   â”‚           â”œâ”€â”€ schema-fork-command/
    â”‚   â”‚           â”‚   â””â”€â”€ spec.md
    â”‚   â”‚           â”œâ”€â”€ schema-init-command/
    â”‚   â”‚           â”‚   â””â”€â”€ spec.md
    â”‚   â”‚           â”œâ”€â”€ schema-validate-command/
    â”‚   â”‚           â”‚   â””â”€â”€ spec.md
    â”‚   â”‚           â””â”€â”€ schema-which-command/
    â”‚   â”‚               â””â”€â”€ spec.md
    â”‚   â””â”€â”€ specs/
    â”‚       â”œâ”€â”€ artifact-graph/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ change-creation/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ ci-nix-validation/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-archive/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-artifact-workflow/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-change/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-completion/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-config/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-init/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-list/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-show/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-spec/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-update/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-validate/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ cli-view/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ docs-agent-instructions/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ global-config/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ instruction-loader/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ openspec-conventions/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ opsx-archive-skill/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â”œâ”€â”€ specs-sync-skill/
    â”‚       â”‚   â””â”€â”€ spec.md
    â”‚       â””â”€â”€ telemetry/
    â”‚           â””â”€â”€ spec.md
    â”œâ”€â”€ schemas/
    â”‚   â”œâ”€â”€ spec-driven/
    â”‚   â”‚   â”œâ”€â”€ schema.yaml
    â”‚   â”‚   â””â”€â”€ templates/
    â”‚   â”‚       â”œâ”€â”€ design.md
    â”‚   â”‚       â”œâ”€â”€ proposal.md
    â”‚   â”‚       â”œâ”€â”€ spec.md
    â”‚   â”‚       â””â”€â”€ tasks.md
    â”‚   â””â”€â”€ tdd/
    â”‚       â”œâ”€â”€ schema.yaml
    â”‚       â””â”€â”€ templates/
    â”‚           â”œâ”€â”€ docs.md
    â”‚           â”œâ”€â”€ implementation.md
    â”‚           â”œâ”€â”€ spec.md
    â”‚           â””â”€â”€ test.md
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ pack-version-check.mjs
    â”‚   â”œâ”€â”€ postinstall.js
    â”‚   â”œâ”€â”€ test-postinstall.sh
    â”‚   â””â”€â”€ update-flake.sh
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ index.ts
    â”‚   â”œâ”€â”€ cli/
    â”‚   â”‚   â””â”€â”€ index.ts
    â”‚   â”œâ”€â”€ commands/
    â”‚   â”‚   â”œâ”€â”€ change.ts
    â”‚   â”‚   â”œâ”€â”€ completion.ts
    â”‚   â”‚   â”œâ”€â”€ config.ts
    â”‚   â”‚   â”œâ”€â”€ feedback.ts
    â”‚   â”‚   â”œâ”€â”€ schema.ts
    â”‚   â”‚   â”œâ”€â”€ show.ts
    â”‚   â”‚   â”œâ”€â”€ spec.ts
    â”‚   â”‚   â”œâ”€â”€ validate.ts
    â”‚   â”‚   â””â”€â”€ experimental/
    â”‚   â”‚       â”œâ”€â”€ index.ts
    â”‚   â”‚       â”œâ”€â”€ instructions.ts
    â”‚   â”‚       â”œâ”€â”€ new-change.ts
    â”‚   â”‚       â”œâ”€â”€ schemas.ts
    â”‚   â”‚       â”œâ”€â”€ setup.ts
    â”‚   â”‚       â”œâ”€â”€ shared.ts
    â”‚   â”‚       â”œâ”€â”€ status.ts
    â”‚   â”‚       â””â”€â”€ templates.ts
    â”‚   â”œâ”€â”€ core/
    â”‚   â”‚   â”œâ”€â”€ archive.ts
    â”‚   â”‚   â”œâ”€â”€ config-prompts.ts
    â”‚   â”‚   â”œâ”€â”€ config-schema.ts
    â”‚   â”‚   â”œâ”€â”€ config.ts
    â”‚   â”‚   â”œâ”€â”€ global-config.ts
    â”‚   â”‚   â”œâ”€â”€ index.ts
    â”‚   â”‚   â”œâ”€â”€ init.ts
    â”‚   â”‚   â”œâ”€â”€ list.ts
    â”‚   â”‚   â”œâ”€â”€ project-config.ts
    â”‚   â”‚   â”œâ”€â”€ specs-apply.ts
    â”‚   â”‚   â”œâ”€â”€ update.ts
    â”‚   â”‚   â”œâ”€â”€ view.ts
    â”‚   â”‚   â”œâ”€â”€ artifact-graph/
    â”‚   â”‚   â”‚   â”œâ”€â”€ graph.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ instruction-loader.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ resolver.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ schema.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ state.ts
    â”‚   â”‚   â”‚   â””â”€â”€ types.ts
    â”‚   â”‚   â”œâ”€â”€ command-generation/
    â”‚   â”‚   â”‚   â”œâ”€â”€ generator.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ registry.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts
    â”‚   â”‚   â”‚   â””â”€â”€ adapters/
    â”‚   â”‚   â”‚       â”œâ”€â”€ amazon-q.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ antigravity.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ auggie.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ claude.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ cline.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ codebuddy.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ codex.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ continue.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ costrict.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ crush.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ cursor.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ factory.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ gemini.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ github-copilot.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ iflow.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ index.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ kilocode.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ opencode.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ qoder.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ qwen.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ roocode.ts
    â”‚   â”‚   â”‚       â””â”€â”€ windsurf.ts
    â”‚   â”‚   â”œâ”€â”€ completions/
    â”‚   â”‚   â”‚   â”œâ”€â”€ command-registry.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ completion-provider.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ factory.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ generators/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bash-generator.ts
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fish-generator.ts
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ powershell-generator.ts
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ zsh-generator.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ installers/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bash-installer.ts
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fish-installer.ts
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ powershell-installer.ts
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ zsh-installer.ts
    â”‚   â”‚   â”‚   â””â”€â”€ templates/
    â”‚   â”‚   â”‚       â”œâ”€â”€ bash-templates.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ fish-templates.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ powershell-templates.ts
    â”‚   â”‚   â”‚       â””â”€â”€ zsh-templates.ts
    â”‚   â”‚   â”œâ”€â”€ configurators/
    â”‚   â”‚   â”‚   â”œâ”€â”€ agents.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ base.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ claude.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ cline.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ codebuddy.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ costrict.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ iflow.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ qoder.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ qwen.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ registry.ts
    â”‚   â”‚   â”‚   â””â”€â”€ slash/
    â”‚   â”‚   â”‚       â”œâ”€â”€ amazon-q.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ antigravity.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ auggie.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ base.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ claude.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ cline.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ codebuddy.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ codex.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ continue.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ costrict.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ crush.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ cursor.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ factory.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ gemini.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ github-copilot.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ iflow.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ kilocode.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ opencode.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ qoder.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ qwen.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ registry.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ roocode.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ toml-base.ts
    â”‚   â”‚   â”‚       â””â”€â”€ windsurf.ts
    â”‚   â”‚   â”œâ”€â”€ converters/
    â”‚   â”‚   â”‚   â””â”€â”€ json-converter.ts
    â”‚   â”‚   â”œâ”€â”€ init/
    â”‚   â”‚   â”‚   â””â”€â”€ wizard.ts
    â”‚   â”‚   â”œâ”€â”€ parsers/
    â”‚   â”‚   â”‚   â”œâ”€â”€ change-parser.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ markdown-parser.ts
    â”‚   â”‚   â”‚   â””â”€â”€ requirement-blocks.ts
    â”‚   â”‚   â”œâ”€â”€ schemas/
    â”‚   â”‚   â”‚   â”œâ”€â”€ base.schema.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ change.schema.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
    â”‚   â”‚   â”‚   â””â”€â”€ spec.schema.ts
    â”‚   â”‚   â”œâ”€â”€ styles/
    â”‚   â”‚   â”‚   â””â”€â”€ palette.ts
    â”‚   â”‚   â”œâ”€â”€ templates/
    â”‚   â”‚   â”‚   â”œâ”€â”€ agents-root-stub.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ agents-template.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ claude-template.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ cline-template.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ costrict-template.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ project-template.ts
    â”‚   â”‚   â”‚   â””â”€â”€ slash-command-templates.ts
    â”‚   â”‚   â””â”€â”€ validation/
    â”‚   â”‚       â”œâ”€â”€ constants.ts
    â”‚   â”‚       â”œâ”€â”€ types.ts
    â”‚   â”‚       â””â”€â”€ validator.ts
    â”‚   â”œâ”€â”€ prompts/
    â”‚   â”‚   â””â”€â”€ searchable-multi-select.ts
    â”‚   â”œâ”€â”€ telemetry/
    â”‚   â”‚   â”œâ”€â”€ config.ts
    â”‚   â”‚   â””â”€â”€ index.ts
    â”‚   â”œâ”€â”€ ui/
    â”‚   â”‚   â”œâ”€â”€ ascii-patterns.ts
    â”‚   â”‚   â””â”€â”€ welcome-screen.ts
    â”‚   â””â”€â”€ utils/
    â”‚       â”œâ”€â”€ change-metadata.ts
    â”‚       â”œâ”€â”€ change-utils.ts
    â”‚       â”œâ”€â”€ file-system.ts
    â”‚       â”œâ”€â”€ index.ts
    â”‚       â”œâ”€â”€ interactive.ts
    â”‚       â”œâ”€â”€ item-discovery.ts
    â”‚       â”œâ”€â”€ match.ts
    â”‚       â”œâ”€â”€ shell-detection.ts
    â”‚       â””â”€â”€ task-progress.ts
    â”œâ”€â”€ test/
    â”‚   â”œâ”€â”€ cli-e2e/
    â”‚   â”‚   â””â”€â”€ basic.test.ts
    â”‚   â”œâ”€â”€ commands/
    â”‚   â”‚   â”œâ”€â”€ artifact-workflow.test.ts
    â”‚   â”‚   â”œâ”€â”€ change.interactive-show.test.ts
    â”‚   â”‚   â”œâ”€â”€ change.interactive-validate.test.ts
    â”‚   â”‚   â”œâ”€â”€ completion.test.ts
    â”‚   â”‚   â”œâ”€â”€ config.test.ts
    â”‚   â”‚   â”œâ”€â”€ feedback.test.ts
    â”‚   â”‚   â”œâ”€â”€ schema.test.ts
    â”‚   â”‚   â”œâ”€â”€ show.test.ts
    â”‚   â”‚   â”œâ”€â”€ spec.interactive-show.test.ts
    â”‚   â”‚   â”œâ”€â”€ spec.interactive-validate.test.ts
    â”‚   â”‚   â”œâ”€â”€ spec.test.ts
    â”‚   â”‚   â”œâ”€â”€ validate.enriched-output.test.ts
    â”‚   â”‚   â””â”€â”€ validate.test.ts
    â”‚   â”œâ”€â”€ core/
    â”‚   â”‚   â”œâ”€â”€ archive.test.ts
    â”‚   â”‚   â”œâ”€â”€ config-schema.test.ts
    â”‚   â”‚   â”œâ”€â”€ global-config.test.ts
    â”‚   â”‚   â”œâ”€â”€ list.test.ts
    â”‚   â”‚   â”œâ”€â”€ project-config.test.ts
    â”‚   â”‚   â”œâ”€â”€ validation.enriched-messages.test.ts
    â”‚   â”‚   â”œâ”€â”€ validation.test.ts
    â”‚   â”‚   â”œâ”€â”€ view.test.ts
    â”‚   â”‚   â”œâ”€â”€ artifact-graph/
    â”‚   â”‚   â”‚   â”œâ”€â”€ graph.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ instruction-loader.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ resolver.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ schema.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ state.test.ts
    â”‚   â”‚   â”‚   â””â”€â”€ workflow.integration.test.ts
    â”‚   â”‚   â”œâ”€â”€ command-generation/
    â”‚   â”‚   â”‚   â”œâ”€â”€ adapters.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ generator.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ registry.test.ts
    â”‚   â”‚   â”‚   â””â”€â”€ types.test.ts
    â”‚   â”‚   â”œâ”€â”€ commands/
    â”‚   â”‚   â”‚   â”œâ”€â”€ change-command.list.test.ts
    â”‚   â”‚   â”‚   â””â”€â”€ change-command.show-validate.test.ts
    â”‚   â”‚   â”œâ”€â”€ completions/
    â”‚   â”‚   â”‚   â”œâ”€â”€ completion-provider.test.ts
    â”‚   â”‚   â”‚   â”œâ”€â”€ generators/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bash-generator.test.ts
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fish-generator.test.ts
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ powershell-generator.test.ts
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ zsh-generator.test.ts
    â”‚   â”‚   â”‚   â””â”€â”€ installers/
    â”‚   â”‚   â”‚       â”œâ”€â”€ bash-installer.test.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ fish-installer.test.ts
    â”‚   â”‚   â”‚       â”œâ”€â”€ powershell-installer.test.ts
    â”‚   â”‚   â”‚       â””â”€â”€ zsh-installer.test.ts
    â”‚   â”‚   â”œâ”€â”€ converters/
    â”‚   â”‚   â”‚   â””â”€â”€ json-converter.test.ts
    â”‚   â”‚   â””â”€â”€ parsers/
    â”‚   â”‚       â”œâ”€â”€ change-parser.test.ts
    â”‚   â”‚       â””â”€â”€ markdown-parser.test.ts
    â”‚   â”œâ”€â”€ fixtures/
    â”‚   â”‚   â””â”€â”€ tmp-init/
    â”‚   â”‚       â””â”€â”€ openspec/
    â”‚   â”‚           â”œâ”€â”€ changes/
    â”‚   â”‚           â”‚   â””â”€â”€ c1/
    â”‚   â”‚           â”‚       â”œâ”€â”€ proposal.md
    â”‚   â”‚           â”‚       â””â”€â”€ specs/
    â”‚   â”‚           â”‚           â””â”€â”€ alpha/
    â”‚   â”‚           â”‚               â””â”€â”€ spec.md
    â”‚   â”‚           â””â”€â”€ specs/
    â”‚   â”‚               â””â”€â”€ alpha/
    â”‚   â”‚                   â””â”€â”€ spec.md
    â”‚   â”œâ”€â”€ helpers/
    â”‚   â”‚   â””â”€â”€ run-cli.ts
    â”‚   â”œâ”€â”€ telemetry/
    â”‚   â”‚   â”œâ”€â”€ config.test.ts
    â”‚   â”‚   â””â”€â”€ index.test.ts
    â”‚   â””â”€â”€ utils/
    â”‚       â”œâ”€â”€ change-metadata.test.ts
    â”‚       â”œâ”€â”€ change-utils.test.ts
    â”‚       â”œâ”€â”€ file-system.test.ts
    â”‚       â”œâ”€â”€ interactive.test.ts
    â”‚       â”œâ”€â”€ marker-updates.test.ts
    â”‚       â””â”€â”€ shell-detection.test.ts
    â”œâ”€â”€ .changeset/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â””â”€â”€ config.json
    â”œâ”€â”€ .devcontainer/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â””â”€â”€ devcontainer.json
    â””â”€â”€ .github/
        â”œâ”€â”€ CODEOWNERS
        â””â”€â”€ workflows/
            â”œâ”€â”€ README.md
            â”œâ”€â”€ ci.yml
            â”œâ”€â”€ polish-release-notes.yml
            â””â”€â”€ release-prepare.yml

================================================
FILE: README.md
================================================
<p align="center">
  <a href="https://github.com/Fission-AI/OpenSpec">
    <picture>
      <source srcset="assets/openspec_pixel_dark.svg" media="(prefers-color-scheme: dark)">
      <source srcset="assets/openspec_pixel_light.svg" media="(prefers-color-scheme: light)">
      <img src="assets/openspec_pixel_light.svg" alt="OpenSpec logo" height="64">
    </picture>
  </a>
  
</p>
<p align="center">Spec-driven development for AI coding assistants.</p>
<p align="center">
  <a href="https://github.com/Fission-AI/OpenSpec/actions/workflows/ci.yml"><img alt="CI" src="https://github.com/Fission-AI/OpenSpec/actions/workflows/ci.yml/badge.svg" /></a>
  <a href="https://www.npmjs.com/package/@fission-ai/openspec"><img alt="npm version" src="https://img.shields.io/npm/v/@fission-ai/openspec?style=flat-square" /></a>
  <a href="https://nodejs.org/"><img alt="node version" src="https://img.shields.io/node/v/@fission-ai/openspec?style=flat-square" /></a>
  <a href="./LICENSE"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square" /></a>
  <a href="https://conventionalcommits.org"><img alt="Conventional Commits" src="https://img.shields.io/badge/Conventional%20Commits-1.0.0-yellow.svg?style=flat-square" /></a>
  <a href="https://discord.gg/YctCnvvshC"><img alt="Discord" src="https://img.shields.io/badge/Discord-Join%20the%20community-5865F2?logo=discord&logoColor=white&style=flat-square" /></a>
</p>

<p align="center">
  <img src="assets/openspec_dashboard.png" alt="OpenSpec dashboard preview" width="90%">
</p>

<p align="center">
  Follow <a href="https://x.com/0xTab">@0xTab on X</a> for updates Â· Join the <a href="https://discord.gg/YctCnvvshC">OpenSpec Discord</a> for help and questions.
</p>

<p align="center">
  <sub>ğŸ§ª <strong>New:</strong> <a href="docs/experimental-workflow.md">Experimental Workflow (OPSX)</a> â€” schema-driven, hackable, fluid. Iterate on workflows without code changes.</sub>
</p>

# OpenSpec

OpenSpec aligns humans and AI coding assistants with spec-driven development so you agree on what to build before any code is written. **No API keys required.**

## Why OpenSpec?

AI coding assistants are powerful but unpredictable when requirements live in chat history. OpenSpec adds a lightweight specification workflow that locks intent before implementation, giving you deterministic, reviewable outputs.

Key outcomes:
- Human and AI stakeholders agree on specs before work begins.
- Structured change folders (proposals, tasks, and spec updates) keep scope explicit and auditable.
- Shared visibility into what's proposed, active, or archived.
- Works with the AI tools you already use: custom slash commands where supported, context rules everywhere else.

## How OpenSpec compares (at a glance)

- **Lightweight**: simple workflow, no API keys, minimal setup.
- **Brownfield-first**: works great beyond 0â†’1. OpenSpec separates the source of truth from proposals: `openspec/specs/` (current truth) and `openspec/changes/` (proposed updates). This keeps diffs explicit and manageable across features.
- **Change tracking**: proposals, tasks, and spec deltas live together; archiving merges the approved updates back into specs.
- **Compared to spec-kit & Kiro**: those shine for brand-new features (0â†’1). OpenSpec also excels when modifying existing behavior (1â†’n), especially when updates span multiple specs.

See the full comparison in [How OpenSpec Compares](#how-openspec-compares).

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Draft Change       â”‚
â”‚ Proposal           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ share intent with your AI
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Review & Align     â”‚
â”‚ (edit specs/tasks) â”‚â—€â”€â”€â”€â”€ feedback loop â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
         â”‚ approved plan                        â”‚
         â–¼                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚ Implement Tasks    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ (AI writes code)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ship the change
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Archive & Update   â”‚
â”‚ Specs (source)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Draft a change proposal that captures the spec updates you want.
2. Review the proposal with your AI assistant until everyone agrees.
3. Implement tasks that reference the agreed specs.
4. Archive the change to merge the approved updates back into the source-of-truth specs.
```

## Getting Started

### Supported AI Tools

<details>
<summary><strong>Native Slash Commands</strong> (click to expand)</summary>

These tools have built-in OpenSpec commands. Select the OpenSpec integration when prompted.

| Tool | Commands |
|------|----------|
| **Amazon Q Developer** | `@openspec-proposal`, `@openspec-apply`, `@openspec-archive` (`.amazonq/prompts/`) |
| **Antigravity** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.agent/workflows/`) |
| **Auggie (Augment CLI)** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.augment/commands/`) |
| **Claude Code** | `/openspec:proposal`, `/openspec:apply`, `/openspec:archive` |
| **Cline** | Workflows in `.clinerules/workflows/` directory (`.clinerules/workflows/openspec-*.md`) |
| **CodeBuddy Code (CLI)** | `/openspec:proposal`, `/openspec:apply`, `/openspec:archive` (`.codebuddy/commands/`) â€” see [docs](https://www.codebuddy.ai/cli) |
| **Codex** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (global: `~/.codex/prompts`, auto-installed) |
| **Continue** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.continue/prompts/`) |
| **CoStrict** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.cospec/openspec/commands/`) â€” see [docs](https://costrict.ai)|
| **Crush** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.crush/commands/openspec/`) |
| **Cursor** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` |
| **Factory Droid** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.factory/commands/`) |
| **Gemini CLI** | `/openspec:proposal`, `/openspec:apply`, `/openspec:archive` (`.gemini/commands/openspec/`) |
| **GitHub Copilot** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.github/prompts/`) |
| **iFlow (iflow-cli)** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.iflow/commands/`) |
| **Kilo Code** | `/openspec-proposal.md`, `/openspec-apply.md`, `/openspec-archive.md` (`.kilocode/workflows/`) |
| **OpenCode** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` |
| **Qoder** | `/openspec:proposal`, `/openspec:apply`, `/openspec:archive` (`.qoder/commands/openspec/`) â€” see [docs](https://qoder.com) |
| **Qwen Code** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.qwen/commands/`) |
| **RooCode** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.roo/commands/`) |
| **Windsurf** | `/openspec-proposal`, `/openspec-apply`, `/openspec-archive` (`.windsurf/workflows/`) |

Kilo Code discovers team workflows automatically. Save the generated files under `.kilocode/workflows/` and trigger them from the command palette with `/openspec-proposal.md`, `/openspec-apply.md`, or `/openspec-archive.md`.

</details>

<details>
<summary><strong>AGENTS.md Compatible</strong> (click to expand)</summary>

These tools automatically read workflow instructions from `openspec/AGENTS.md`. Ask them to follow the OpenSpec workflow if they need a reminder. Learn more about the [AGENTS.md convention](https://agents.md/).

| Tools |
|-------|
| Amp â€¢ Jules â€¢ Others |

</details>

### Install & Initialize

#### Prerequisites
- **Node.js >= 20.19.0** - Check your version with `node --version`

#### Step 1: Install the CLI globally

**Option A: Using npm**

```bash
npm install -g @fission-ai/openspec@latest
```

Verify installation:
```bash
openspec --version
```

**Option B: Using Nix (NixOS and Nix package manager)**

Run OpenSpec directly without installation:
```bash
nix run github:Fission-AI/OpenSpec -- init
```

Or install to your profile:
```bash
nix profile install github:Fission-AI/OpenSpec
```

Or add to your development environment in `flake.nix`:
```nix
{
  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
    openspec.url = "github:Fission-AI/OpenSpec";
  };

  outputs = { nixpkgs, openspec, ... }: {
    devShells.x86_64-linux.default = nixpkgs.legacyPackages.x86_64-linux.mkShell {
      buildInputs = [ openspec.packages.x86_64-linux.default ];
    };
  };
}
```

Verify installation:
```bash
openspec --version
```

#### Step 2: Initialize OpenSpec in your project

Navigate to your project directory:
```bash
cd my-project
```

Run the initialization:
```bash
openspec init
```

**What happens during initialization:**
- You'll be prompted to pick any natively supported AI tools (Claude Code, CodeBuddy, Cursor, OpenCode, Qoder,etc.); other assistants always rely on the shared `AGENTS.md` stub
- OpenSpec automatically configures slash commands for the tools you choose and always writes a managed `AGENTS.md` hand-off at the project root
- A new `openspec/` directory structure is created in your project

**After setup:**
- Primary AI tools can trigger `/openspec` workflows without additional configuration
- Run `openspec list` to verify the setup and view any active changes
- If your coding assistant doesn't surface the new slash commands right away, restart it. Slash commands are loaded at startup,
  so a fresh launch ensures they appear

### Optional: Populate Project Context

After `openspec init` completes, you'll receive a suggested prompt to help populate your project context:

```text
Populate your project context:
"Please read openspec/project.md and help me fill it out with details about my project, tech stack, and conventions"
```

Use `openspec/project.md` to define project-level conventions, standards, architectural patterns, and other guidelines that should be followed across all changes.

### Create Your First Change

Here's a real example showing the complete OpenSpec workflow. This works with any AI tool. Those with native slash commands will recognize the shortcuts automatically.

#### 1. Draft the Proposal
Start by asking your AI to create a change proposal:

```text
You: Create an OpenSpec change proposal for adding profile search filters by role and team
     (Shortcut for tools with slash commands: /openspec:proposal Add profile search filters)

AI:  I'll create an OpenSpec change proposal for profile filters.
     *Scaffolds openspec/changes/add-profile-filters/ with proposal.md, tasks.md, spec deltas.*
```

#### 2. Verify & Review
Check that the change was created correctly and review the proposal:

```bash
$ openspec list                             # Confirm the change folder exists
$ openspec validate add-profile-filters     # Validate spec formatting
$ openspec show add-profile-filters         # Review proposal, tasks, and spec delta
```

#### 3. Refine the Specs
Iterate on the specifications until they match your needs:

```text
You: Can you add acceptance criteria for the role and team filters?

AI:  I'll update the spec delta with scenarios for role and team filters.
     *Edits openspec/changes/add-profile-filters/specs/profile/spec.md and tasks.md.*
```

#### 4. Implement the Change
Once specs look good, start implementation:

```text
You: The specs look good. Let's implement this change.
     (Shortcut for tools with slash commands: /openspec:apply add-profile-filters)

AI:  I'll work through the tasks in the add-profile-filters change.
     *Implements tasks from openspec/changes/add-profile-filters/tasks.md*
     *Marks tasks complete: Task 1.1 âœ“, Task 1.2 âœ“, Task 2.1 âœ“...*
```

#### 5. Archive the Completed Change
After implementation is complete, archive the change:

```text
AI:  All tasks are complete. The implementation is ready.

You: Please archive the change
     (Shortcut for tools with slash commands: /openspec:archive add-profile-filters)

AI:  I'll archive the add-profile-filters change.
    *Runs: openspec archive add-profile-filters --yes*
     âœ“ Change archived successfully. Specs updated. Ready for the next feature!
```

Or run the command yourself in terminal:
```bash
$ openspec archive add-profile-filters --yes  # Archive the completed change without prompts
```

**Note:** Tools with native slash commands (Claude Code, CodeBuddy, Cursor, Codex, Qoder, RooCode) can use the shortcuts shown. All other tools work with natural language requests to "create an OpenSpec proposal", "apply the OpenSpec change", or "archive the change".

## Command Reference

```bash
openspec list               # View active change folders
openspec view               # Interactive dashboard of specs and changes
openspec show <change>      # Display change details (proposal, tasks, spec updates)
openspec validate <change>  # Check spec formatting and structure
openspec archive <change> [--yes|-y]   # Move a completed change into archive/ (non-interactive with --yes)
```

## Example: How AI Creates OpenSpec Files

When you ask your AI assistant to "add two-factor authentication", it creates:

```
openspec/
â”œâ”€â”€ specs/
â”‚   â””â”€â”€ auth/
â”‚       â””â”€â”€ spec.md           # Current auth spec (if exists)
â””â”€â”€ changes/
    â””â”€â”€ add-2fa/              # AI creates this entire structure
        â”œâ”€â”€ proposal.md       # Why and what changes
        â”œâ”€â”€ tasks.md          # Implementation checklist
        â”œâ”€â”€ design.md         # Technical decisions (optional)
        â””â”€â”€ specs/
            â””â”€â”€ auth/
                â””â”€â”€ spec.md   # Delta showing additions
```

### AI-Generated Spec (created in `openspec/specs/auth/spec.md`):

```markdown
# Auth Specification

## Purpose
Authentication and session management.

## Requirements
### Requirement: User Authentication
The system SHALL issue a JWT on successful login.

#### Scenario: Valid credentials
- WHEN a user submits valid credentials
- THEN a JWT is returned
```

### AI-Generated Change Delta (created in `openspec/changes/add-2fa/specs/auth/spec.md`):

```markdown
# Delta for Auth

## ADDED Requirements
### Requirement: Two-Factor Authentication
The system MUST require a second factor during login.

#### Scenario: OTP required
- WHEN a user submits valid credentials
- THEN an OTP challenge is required
```

### AI-Generated Tasks (created in `openspec/changes/add-2fa/tasks.md`):

```markdown
## 1. Database Setup
- [ ] 1.1 Add OTP secret column to users table
- [ ] 1.2 Create OTP verification logs table

## 2. Backend Implementation  
- [ ] 2.1 Add OTP generation endpoint
- [ ] 2.2 Modify login flow to require OTP
- [ ] 2.3 Add OTP verification endpoint

## 3. Frontend Updates
- [ ] 3.1 Create OTP input component
- [ ] 3.2 Update login flow UI
```

**Important:** You don't create these files manually. Your AI assistant generates them based on your requirements and the existing codebase.

## Understanding OpenSpec Files

### Delta Format

Deltas are "patches" that show how specs change:

- **`## ADDED Requirements`** - New capabilities
- **`## MODIFIED Requirements`** - Changed behavior (include complete updated text)
- **`## REMOVED Requirements`** - Deprecated features

**Format requirements:**
- Use `### Requirement: <name>` for headers
- Every requirement needs at least one `#### Scenario:` block
- Use SHALL/MUST in requirement text

## How OpenSpec Compares

### vs. spec-kit
OpenSpecâ€™s two-folder model (`openspec/specs/` for the current truth, `openspec/changes/` for proposed updates) keeps state and diffs separate. This scales when you modify existing features or touch multiple specs. spec-kit is strong for greenfield/0â†’1 but provides less structure for cross-spec updates and evolving features.

### vs. Kiro.dev
OpenSpec groups every change for a feature in one folder (`openspec/changes/feature-name/`), making it easy to track related specs, tasks, and designs together. Kiro spreads updates across multiple spec folders, which can make feature tracking harder.

### vs. No Specs
Without specs, AI coding assistants generate code from vague prompts, often missing requirements or adding unwanted features. OpenSpec brings predictability by agreeing on the desired behavior before any code is written.

## Team Adoption

1. **Initialize OpenSpec** â€“ Run `openspec init` in your repo.
2. **Start with new features** â€“ Ask your AI to capture upcoming work as change proposals.
3. **Grow incrementally** â€“ Each change archives into living specs that document your system.
4. **Stay flexible** â€“ Different teammates can use Claude Code, CodeBuddy, Cursor, or any AGENTS.md-compatible tool while sharing the same specs.

Run `openspec update` whenever someone switches tools so your agents pick up the latest instructions and slash-command bindings.

## Updating OpenSpec

1. **Upgrade the package**
   ```bash
   npm install -g @fission-ai/openspec@latest
   ```
2. **Refresh agent instructions**
   - Run `openspec update` inside each project to regenerate AI guidance and ensure the latest slash commands are active.

## Experimental Features

<details>
<summary><strong>ğŸ§ª OPSX: Fluid, Iterative Workflow</strong> (Claude Code only)</summary>

**Why this exists:**
- Standard workflow is locked down â€” you can't tweak instructions or customize
- When AI output is bad, you can't improve the prompts yourself
- Same workflow for everyone, no way to match how your team works

**What's different:**
- **Hackable** â€” edit templates and schemas yourself, test immediately, no rebuild
- **Granular** â€” each artifact has its own instructions, test and tweak individually
- **Customizable** â€” define your own workflows, artifacts, and dependencies
- **Fluid** â€” no phase gates, update any artifact anytime

```
You can always go back:

  proposal â”€â”€â†’ specs â”€â”€â†’ design â”€â”€â†’ tasks â”€â”€â†’ implement
     â–²           â–²          â–²                    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Command | What it does |
|---------|--------------|
| `/opsx:new` | Start a new change |
| `/opsx:continue` | Create the next artifact (based on what's ready) |
| `/opsx:ff` | Fast-forward (all planning artifacts at once) |
| `/opsx:apply` | Implement tasks, updating artifacts as needed |
| `/opsx:archive` | Archive when done |

**Setup:** `openspec experimental`

[Full documentation â†’](docs/experimental-workflow.md)

</details>

<details>
<summary><strong>Telemetry</strong> â€“ OpenSpec collects anonymous usage stats (opt-out: <code>OPENSPEC_TELEMETRY=0</code>)</summary>

We collect only command names and version to understand usage patterns. No arguments, paths, content, or PII. Automatically disabled in CI.

**Opt-out:** `export OPENSPEC_TELEMETRY=0` or `export DO_NOT_TRACK=1`

</details>

## Contributing

- Install dependencies: `pnpm install`
- Build: `pnpm run build`
- Test: `pnpm test`
- Develop CLI locally: `pnpm run dev` or `pnpm run dev:cli`
- Conventional commits (one-line): `type(scope): subject`

<details>
<summary><strong>Maintainers & Advisors</strong></summary>

See [MAINTAINERS.md](MAINTAINERS.md) for the list of core maintainers and advisors who help guide the project.

</details>

## License

MIT



================================================
FILE: AGENTS.md
================================================
<!-- OPENSPEC:START -->
# OpenSpec Instructions

These instructions are for AI assistants working in this project.

Always open `@/openspec/AGENTS.md` when the request:
- Mentions planning or proposals (words like proposal, spec, change, plan)
- Introduces new capabilities, breaking changes, architecture shifts, or big performance/security work
- Sounds ambiguous and you need the authoritative spec before coding

Use `@/openspec/AGENTS.md` to learn:
- How to create and apply change proposals
- Spec format and conventions
- Project structure and guidelines

Keep this managed block so 'openspec update' can refresh the instructions.

<!-- OPENSPEC:END -->



================================================
FILE: build.js
================================================
#!/usr/bin/env node

import { execFileSync } from 'child_process';
import { existsSync, rmSync } from 'fs';
import { createRequire } from 'module';

const require = createRequire(import.meta.url);

const runTsc = (args = []) => {
  const tscPath = require.resolve('typescript/bin/tsc');
  execFileSync(process.execPath, [tscPath, ...args], { stdio: 'inherit' });
};

console.log('ğŸ”¨ Building OpenSpec...\n');

// Clean dist directory
if (existsSync('dist')) {
  console.log('Cleaning dist directory...');
  rmSync('dist', { recursive: true, force: true });
}

// Run TypeScript compiler (use local version explicitly)
console.log('Compiling TypeScript...');
try {
  runTsc(['--version']);
  runTsc();
  console.log('\nâœ… Build completed successfully!');
} catch (error) {
  console.error('\nâŒ Build failed!');
  process.exit(1);
}



================================================
FILE: CHANGELOG.md
================================================
# @fission-ai/openspec

## 0.23.0

### Minor Changes

- [#540](https://github.com/Fission-AI/OpenSpec/pull/540) [`c4cfdc7`](https://github.com/Fission-AI/OpenSpec/commit/c4cfdc7c499daef30d8a218f5f59b8d9e5adb754) Thanks [@TabishB](https://github.com/TabishB)! - ### New Features

  - **Bulk archive skill** â€” Archive multiple completed changes in a single operation with `/opsx:bulk-archive`. Includes batch validation, spec conflict detection, and consolidated confirmation

  ### Other

  - **Simplified setup** â€” Config creation now uses sensible defaults with helpful comments instead of interactive prompts

## 0.22.0

### Minor Changes

- [#530](https://github.com/Fission-AI/OpenSpec/pull/530) [`33466b1`](https://github.com/Fission-AI/OpenSpec/commit/33466b1e2a6798bdd6d0e19149173585b0612e6f) Thanks [@TabishB](https://github.com/TabishB)! - Add project-level configuration, project-local schemas, and schema management commands

  **New Features**

  - **Project-level configuration** â€” Configure OpenSpec behavior per-project via `openspec/config.yaml`, including custom rules injection, context files, and schema resolution settings
  - **Project-local schemas** â€” Define custom artifact schemas within your project's `openspec/schemas/` directory for project-specific workflows
  - **Schema management commands** â€” New `openspec schema` commands (`list`, `show`, `export`, `validate`) for inspecting and managing artifact schemas (experimental)

  **Bug Fixes**

  - Fixed config loading to handle null `rules` field in project configuration

## 0.21.0

### Minor Changes

- [#516](https://github.com/Fission-AI/OpenSpec/pull/516) [`b5a8847`](https://github.com/Fission-AI/OpenSpec/commit/b5a884748be6156a7bb140b4941cfec4f20a9fc8) Thanks [@TabishB](https://github.com/TabishB)! - Add feedback command and Nix flake support

  **New Features**

  - **Feedback command** â€” Submit feedback directly from the CLI with `openspec feedback`, which creates GitHub Issues with automatic metadata inclusion and graceful fallback for manual submission
  - **Nix flake support** â€” Install and develop openspec using Nix with the new `flake.nix`, including automated flake maintenance and CI validation

  **Bug Fixes**

  - **Explore mode guardrails** â€” Explore mode now explicitly prevents implementation, keeping the focus on thinking and discovery while still allowing artifact creation

  **Other**

  - Improved change inference in `opsx apply` â€” automatically detects the target change from conversation context or prompts when ambiguous
  - Streamlined archive sync assessment with clearer delta spec location guidance

## 0.20.0

### Minor Changes

- [#502](https://github.com/Fission-AI/OpenSpec/pull/502) [`9db74aa`](https://github.com/Fission-AI/OpenSpec/commit/9db74aa5ac6547efadaed795217cfa17444f2004) Thanks [@TabishB](https://github.com/TabishB)! - Add `/opsx:verify` command and fix vitest process storms

  **New Features**

  - **`/opsx:verify` command** â€” Validate that change implementations match their specifications

  **Bug Fixes**

  - Fixed vitest process storms by capping worker parallelism
  - Fixed agent workflows to use non-interactive mode for validation commands
  - Fixed PowerShell completions generator to remove trailing commas

## 0.19.0

### Minor Changes

- eb152eb: Add Continue IDE support, shell completions, and `/opsx:explore` command

  **New Features**

  - **Continue IDE support** â€“ OpenSpec now generates slash commands for [Continue](https://continue.dev/), expanding editor integration options alongside Cursor, Windsurf, Claude Code, and others
  - **Shell completions for Bash, Fish, and PowerShell** â€“ Run `openspec completion install` to set up tab completion in your preferred shell
  - **`/opsx:explore` command** â€“ A new thinking partner mode for exploring ideas and investigating problems before committing to changes
  - **Codebuddy slash command improvements** â€“ Updated frontmatter format for better compatibility

  **Bug Fixes**

  - Shell completions now correctly offer parent-level flags (like `--help`) when a command has subcommands
  - Fixed Windows compatibility issues in tests

  **Other**

  - Added optional anonymous usage statistics to help understand how OpenSpec is used. This is **opt-out** by default â€“ set `OPENSPEC_TELEMETRY=0` or `DO_NOT_TRACK=1` to disable. Only command names and version are collected; no arguments, file paths, or content. Automatically disabled in CI environments.

## 0.18.0

### Minor Changes

- 8dfd824: Add OPSX experimental workflow commands and enhanced artifact system

  **New Commands:**

  - `/opsx:ff` - Fast-forward through artifact creation, generating all needed artifacts in one go
  - `/opsx:sync` - Sync delta specs from a change to main specs
  - `/opsx:archive` - Archive completed changes with smart sync check

  **Artifact Workflow Enhancements:**

  - Schema-aware apply instructions with inline guidance and XML output
  - Agent schema selection for experimental artifact workflow
  - Per-change schema metadata via `.openspec.yaml` files
  - Agent Skills for experimental artifact workflow
  - Instruction loader for template loading and change context
  - Restructured schemas as directories with templates

  **Improvements:**

  - Enhanced list command with last modified timestamps and sorting
  - Change creation utilities for better workflow support

  **Fixes:**

  - Normalize paths for cross-platform glob compatibility
  - Allow REMOVED requirements when creating new spec files

## 0.17.2

### Patch Changes

- 455c65f: Fix `--no-interactive` flag in validate command to properly disable spinner, preventing hangs in pre-commit hooks and CI environments

## 0.17.1

### Patch Changes

- a2757e7: Fix pre-commit hook hang issue in config command by using dynamic import for @inquirer/prompts

  The config command was causing pre-commit hooks to hang indefinitely due to stdin event listeners being registered at module load time. This fix converts the static import to a dynamic import that only loads inquirer when the `config reset` command is actually used interactively.

  Also adds ESLint with a rule to prevent static @inquirer imports, avoiding future regressions.

## 0.17.0

### Minor Changes

- 2e71835: Add `openspec config` command and Oh-my-zsh completions

  **New Features**

  - Add `openspec config` command for managing global configuration settings
  - Implement global config directory with XDG Base Directory specification support
  - Add Oh-my-zsh shell completions support for enhanced CLI experience

  **Bug Fixes**

  - Fix hang in pre-commit hooks by using dynamic imports
  - Respect XDG_CONFIG_HOME environment variable on all platforms
  - Resolve Windows compatibility issues in zsh-installer tests
  - Align cli-completion spec with implementation
  - Remove hardcoded agent field from slash commands

  **Documentation**

  - Alphabetize AI tools list in README and make it collapsible

## 0.16.0

### Minor Changes

- c08fbc1: Add new AI tool integrations and enhancements:

  - **feat(iflow-cli)**: Add iFlow-cli integration with slash command support and documentation
  - **feat(init)**: Add IDE restart instruction after init to inform users about slash command availability
    **feat(antigravity)**: Add Antigravity slash command support
  - **fix**: Generate TOML commands for Qwen Code (fixes #293)
  - Clarify scaffold proposal documentation and enhance proposal guidelines
  - Update proposal guidelines to emphasize design-first approach before implementation

## Unreleased

### Minor Changes

- Add Continue slash command support so `openspec init` can generate `.continue/prompts/openspec-*.prompt` files with MARKDOWN frontmatter and `$ARGUMENTS` placeholder, and refresh them on `openspec update`.

- Add Antigravity slash command support so `openspec init` can generate `.agent/workflows/openspec-*.md` files with description-only frontmatter and `openspec update` refreshes existing workflows alongside Windsurf.

## 0.15.0

### Minor Changes

- 4758c5c: Add support for new AI tools with native slash command integration

  - **Gemini CLI**: Add native TOML-based slash command support for Gemini CLI with `.gemini/commands/openspec/` integration
  - **RooCode**: Add RooCode integration with configurator, slash commands, and templates
  - **Cline**: Fix Cline to use workflows instead of rules for slash commands (`.clinerules/workflows/` paths)
  - **Documentation**: Update documentation to reflect new integrations and workflow changes

## 0.14.0

### Minor Changes

- 8386b91: Add support for new AI assistants and configuration improvements

  - feat: add Qwen Code support with slash command integration
  - feat: add $ARGUMENTS support to apply slash command for dynamic variable passing
  - feat: add Qoder CLI support to configuration and documentation
  - feat: add CoStrict AI assistant support
  - fix: recreate missing openspec template files in extend mode
  - fix: prevent false 'already configured' detection for tools
  - fix: use change-id as fallback title instead of "Untitled Change"
  - docs: add guidance for populating project-level context
  - docs: add Crush to supported AI tools in README

## 0.13.0

### Minor Changes

- 668a125: Add support for multiple AI assistants and improve validation

  This release adds support for several new AI coding assistants:

  - CodeBuddy Code - AI-powered coding assistant
  - CodeRabbit - AI code review assistant
  - Cline - Claude-powered CLI assistant
  - Crush AI - AI assistant platform
  - Auggie (Augment CLI) - Code augmentation tool

  New features:

  - Archive slash command now supports arguments for more flexible workflows

  Bug fixes:

  - Delta spec validation now handles case-insensitive headers and properly detects empty sections
  - Archive validation now correctly honors --no-validate flag and ignores metadata

  Documentation improvements:

  - Added VS Code dev container configuration for easier development setup
  - Updated AGENTS.md with explicit change-id notation
  - Enhanced slash commands documentation with restart notes

## 0.12.0

### Minor Changes

- 082abb4: Add factory function support for slash commands and non-interactive init options

  This release includes two new features:

  - **Factory function support for slash commands**: Slash commands can now be defined as functions that return command objects, enabling dynamic command configuration
  - **Non-interactive init options**: Added `--tools`, `--all-tools`, and `--skip-tools` CLI flags to `openspec init` for automated initialization in CI/CD pipelines while maintaining backward compatibility with interactive mode

## 0.11.0

### Minor Changes

- 312e1d6: Add Amazon Q Developer CLI integration. OpenSpec now supports Amazon Q Developer with automatic prompt generation in `.amazonq/prompts/` directory, allowing you to use OpenSpec slash commands with Amazon Q's @-syntax.

## 0.10.0

### Minor Changes

- d7e0ce8: Improve init wizard Enter key behavior to allow proceeding through prompts more naturally

## 0.9.2

### Patch Changes

- 2ae0484: Fix cross-platform path handling issues. This release includes fixes for joinPath behavior and slash command path resolution to ensure OpenSpec works correctly across all platforms.

## 0.9.1

### Patch Changes

- 8210970: Fix OpenSpec not working on Windows when Codex integration is selected. This release includes fixes for cross-platform path handling and normalization to ensure OpenSpec works correctly on Windows systems.

## 0.9.0

### Minor Changes

- efbbf3b: Add support for Codex and GitHub Copilot slash commands with YAML frontmatter and $ARGUMENTS

## Unreleased

### Minor Changes

- Add GitHub Copilot slash command support. OpenSpec now writes prompts to `.github/prompts/openspec-{proposal,apply,archive}.prompt.md` with YAML frontmatter and `$ARGUMENTS` placeholder, and refreshes them on `openspec update`.

## 0.8.1

### Patch Changes

- d070d08: Fix CLI version mismatch and add a release guard that validates the packed tarball prints the same version as package.json via `openspec --version`.

## 0.8.0

### Minor Changes

- c29b06d: Add Windsurf support.
- Add Codex slash command support. OpenSpec now writes prompts directly to Codex's global directory (`~/.codex/prompts` or `$CODEX_HOME/prompts`) and refreshes them on `openspec update`.

## 0.7.0

### Minor Changes

- Add native Kilo Code workflow integration so `openspec init` and `openspec update` manage `.kilocode/workflows/openspec-*.md` files.
- Always scaffold the managed root `AGENTS.md` hand-off stub and regroup the AI tool prompts during init/update to keep instructions consistent.

## 0.6.0

### Minor Changes

- Slim the generated root agent instructions down to a managed hand-off stub and update the init/update flows to refresh it safely.

## 0.5.0

### Minor Changes

- feat: implement Phase 1 E2E testing with cross-platform CI matrix

  - Add shared runCLI helper in test/helpers/run-cli.ts for spawn testing
  - Create test/cli-e2e/basic.test.ts covering help, version, validate flows
  - Migrate existing CLI exec tests to use runCLI helper
  - Extend CI matrix to bash (Linux/macOS) and pwsh (Windows)
  - Split PR and main workflows for optimized feedback

### Patch Changes

- Make apply instructions more specific

  Improve agent templates and slash command templates with more specific and actionable apply instructions.

- docs: improve documentation and cleanup

  - Document non-interactive flag for archive command
  - Replace discord badge in README
  - Archive completed changes for better organization

## 0.4.0

### Minor Changes

- Add OpenSpec change proposals for CLI improvements and enhanced user experience
- Add Opencode slash commands support for AI-driven development workflows

### Patch Changes

- Add documentation improvements including --yes flag for archive command template and Discord badge
- Fix normalize line endings in markdown parser to handle CRLF files properly

## 0.3.0

### Minor Changes

- Enhance `openspec init` with extend mode, multi-tool selection, and an interactive `AGENTS.md` configurator.

## 0.2.0

### Minor Changes

- ce5cead: - Add an `openspec view` dashboard that rolls up spec counts and change progress at a glance
  - Generate and update AI slash commands alongside the renamed `openspec/AGENTS.md` instructions file
  - Remove the deprecated `openspec diff` command and direct users to `openspec show`

## 0.1.0

### Minor Changes

- 24b4866: Initial release



================================================
FILE: eslint.config.js
================================================
import tseslint from 'typescript-eslint';

export default tseslint.config(
  {
    files: ['src/**/*.ts'],
    extends: [...tseslint.configs.recommended],
    rules: {
      // Prevent static imports of @inquirer modules to avoid pre-commit hook hangs.
      // These modules have side effects that can keep the Node.js event loop alive
      // when stdin is piped. Use dynamic import() instead.
      // See: https://github.com/Fission-AI/OpenSpec/issues/367
      'no-restricted-imports': [
        'error',
        {
          patterns: [
            {
              group: ['@inquirer/*'],
              message:
                'Use dynamic import() for @inquirer modules to prevent pre-commit hook hangs. See #367.',
            },
          ],
        },
      ],
      // Disable rules that need broader cleanup - focus on critical issues only
      '@typescript-eslint/no-explicit-any': 'off',
      '@typescript-eslint/no-unused-vars': 'off',
      'no-empty': 'off',
      'prefer-const': 'off',
    },
  },
  {
    // init.ts is dynamically imported from cli/index.ts, so static @inquirer
    // imports there are safe - they won't be loaded at CLI startup
    files: ['src/core/init.ts'],
    rules: {
      'no-restricted-imports': 'off',
    },
  },
  {
    ignores: ['dist/**', 'node_modules/**', '*.js', '*.mjs'],
  }
);



================================================
FILE: flake.lock
================================================
{
  "nodes": {
    "nixpkgs": {
      "locked": {
        "lastModified": 1767640445,
        "narHash": "sha256-UWYqmD7JFBEDBHWYcqE6s6c77pWdcU/i+bwD6XxMb8A=",
        "owner": "NixOS",
        "repo": "nixpkgs",
        "rev": "9f0c42f8bc7151b8e7e5840fb3bd454ad850d8c5",
        "type": "github"
      },
      "original": {
        "owner": "NixOS",
        "ref": "nixos-unstable",
        "repo": "nixpkgs",
        "type": "github"
      }
    },
    "root": {
      "inputs": {
        "nixpkgs": "nixpkgs"
      }
    }
  },
  "root": "root",
  "version": 7
}



================================================
FILE: flake.nix
================================================
{
  description = "OpenSpec - AI-native system for spec-driven development";

  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
  };

  outputs = { self, nixpkgs }:
    let
      supportedSystems = [ "x86_64-linux" "aarch64-linux" "x86_64-darwin" "aarch64-darwin" ];

      forAllSystems = f: nixpkgs.lib.genAttrs supportedSystems (system: f system);
    in
    {
      packages = forAllSystems (system:
        let
          pkgs = nixpkgs.legacyPackages.${system};
        in
        {
          default = pkgs.stdenv.mkDerivation (finalAttrs: {
            pname = "openspec";
            version = "0.23.0";

            src = ./.;

            pnpmDeps = pkgs.fetchPnpmDeps {
              inherit (finalAttrs) pname version src;
              pnpm = pkgs.pnpm_9;
              fetcherVersion = 3;
              hash = "sha256-9s2kdvd7svK4hofnD66HkDc86WTQeayfF5y7L2dmjNg=";
            };

            nativeBuildInputs = with pkgs; [
              nodejs_20
              npmHooks.npmInstallHook
              pnpmConfigHook
              pnpm_9
            ];

            buildPhase = ''
              runHook preBuild

              pnpm run build

              runHook postBuild
            '';

            dontNpmPrune = true;

            meta = with pkgs.lib; {
              description = "AI-native system for spec-driven development";
              homepage = "https://github.com/Fission-AI/OpenSpec";
              license = licenses.mit;
              maintainers = [ ];
              mainProgram = "openspec";
            };
          });
        });

      apps = forAllSystems (system: {
        default = {
          type = "app";
          program = "${self.packages.${system}.default}/bin/openspec";
        };
      });

      devShells = forAllSystems (system:
        let
          pkgs = nixpkgs.legacyPackages.${system};
        in
        {
          default = pkgs.mkShell {
            buildInputs = with pkgs; [
              nodejs_20
              pnpm_9
            ];

            shellHook = ''
              echo "OpenSpec development environment"
              echo "Node version: $(node --version)"
              echo "pnpm version: $(pnpm --version)"
              echo "Run 'pnpm install' to install dependencies"
            '';
          };
        });
    };
}



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2024 OpenSpec Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.




================================================
FILE: MAINTAINERS.md
================================================
# Maintainers

People who maintain and guide OpenSpec.

## Core Maintainers

| Name | GitHub | Role |
|------|--------|------|
| Tabish Bidiwale | [@TabishB](https://github.com/TabishB) | Lead maintainer |

## Advisors

Advisors help shape technical direction and provide guidance to the project.

| Name | GitHub | Focus |
|------|--------|-------|
| Hari Krishnan | [@harikrishnan83](https://github.com/harikrishnan83) | Technical direction |



================================================
FILE: openspec-parallel-merge-plan.md
================================================
# OpenSpec Parallel Delta Remediation Plan

## Problem Summary
- Active changes apply requirement-level replacements when archiving. When two changes touch the same requirement, the second archive overwrites the first and silently drops scenarios (e.g., Windsurf vs. Kilo Code slash command updates).
- The archive workflow (`src/core/archive.ts:191` and `src/core/archive.ts:501`) rebuilds main specs by replacing entire requirement blocks with the content contained in the change delta. The delta format (`src/core/parsers/requirement-blocks.ts:113`) has no notion of base versions or scenario-level operations.
- The tooling cannot detect divergence between the change authorâ€™s starting point and the live spec, so parallel development corrupts the source of truth without warning.

## Observed Failure Mode
- Change A (`add-windsurf-workflows`) adds a Windsurf scenario under `Slash Command Configuration`.
- Change B (`add-kilocode-workflows`) adds a Kilo Code scenario to the same requirement, starting from the pre-Windsurf spec.
- After Change A archives, the main spec contains both scenarios.
- When Change B archives, `buildUpdatedSpec` sees a `MODIFIED` block for `Slash Command Configuration` and replaces the requirement with the four-scenario variant shipped in that change. Because that file never learned about Windsurf, the Windsurf scenario disappears.
- There is no warning, diff, or conflict indicatorâ€”the archive completes successfully, and the source-of-truth spec now omits a shipped scenario.

## Root Causes
1. **Replace-only semantics.** `buildUpdatedSpec` performs hash-map substitution of requirement blocks and cannot merge or compare individual scenarios (`src/core/archive.ts:455`-`src/core/archive.ts:526`).
2. **Missing base fingerprint.** Changes do not persist the requirement content they were authored against, so the archive step cannot tell if the live spec diverged.
3. **Single-level granularity.** The delta language only understands requirements. Even if we introduced scenario-level parsing, we would still lose sibling edits without an accompanying merge strategy.
4. **Lack of conflict UX.** The CLI never forces contributors to reconcile parallel updates. There is no equivalent of `git merge`, `git rebase`, or conflict markers.

## Design Objectives
- Preserve every approved scenario regardless of archive order.
- Detect and block speculative archives when the live spec diverges from the authorâ€™s base.
- Provide a deterministic, reviewable conflict resolution flow that mirrors source-control best practices.
- Keep the authoring experience ergonomic: deltas should remain human-editable markdown.
- Support incremental adoption so existing repositories can roll forward without breaking active work.

## Proposed Fix: Layered Remediation

### Phase 0 â€“ Stop the Bleeding (Detection & Guardrails)
1. **Persist requirement fingerprints alongside each change.**
   - When scaffolding or validating a change, capture the current requirement body for every `MODIFIED`/`REMOVED`/`RENAMED` entry and write it to `changes/<id>/meta.json`.
   - Store a stable hash (e.g., SHA-256) of the base requirement content and the raw text itself for later merges.
2. **Validate fingerprints during archive.**
   - Before `buildUpdatedSpec` mutates specs, recompute the requirement hash from the live spec.
   - If the hash differs from the stored base, abort and instruct the user to rebase. This makes the destructive path impossible.
3. **Surface intent in CLI output.**
   - Show which requirements are stale, when they diverged, and which change last touched them.
4. **Document interim manual mitigation.**
   - Update `openspec/AGENTS.md` and docs so contributors know to rerun `openspec change sync` (see Phase 1) whenever another change lands.

_Outcome:_ We prevent data loss immediately while we work on a richer merge story.

### Phase 1 â€“ Add a Rebase Workflow (Author-Side Merge)
1. **Introduce `openspec change sync <id>` (or `rebase`).**
   - Reads the stored base snapshot, the current spec, and the authorâ€™s delta.
   - Performs a 3-way merge per requirement. A naive diff3 on markdown lines is acceptable initially because we already operate on requirement-sized chunks.
   - If the merge is clean, rewrite the `MODIFIED` block with the merged text and refresh the stored fingerprint.
   - On conflict, write conflict markers inside the change delta (similar to Git) and require the author to hand-edit before re-running validation.
2. **Enrich validator messages.**
   - `openspec validate` should flag unresolved conflict markers or fingerprint mismatches so errors appear early in the workflow.
3. **Optional:** Offer a `--rewrite-scenarios` helper that merges bullet lists of scenarios to reduce manual editing noise.

_Outcome:_ Contributors can safely reconcile their work with the latest spec before archiving, restoring true parallel development.

### Phase 2 â€“ Increase Delta Granularity
1. **Extend the delta language with scenario-level directives.**
   - Allow `## MODIFIED Requirements` + `## ADDED Scenarios` / `## MODIFIED Scenarios` sections nested under the requirement header.
   - Backed by stable scenario identifiers (explicit IDs or generated hashes) stored in `meta.json`. This lets the system reason about individual scenarios.
2. **Teach the parser to understand nested operations.**
   - Update `parseDeltaSpec` to emit scenario-level operations in addition to requirement blocks.
   - Update `buildUpdatedSpec` (or its replacement) to merge scenario lists, preserving order while inserting new entries in a deterministic fashion.
3. **Automate migration.**
   - Provide a one-time command that inspects each existing spec, injects scenario IDs, and rewrites in-flight change deltas into the richer format.
4. **Continue to rely on the Phase 1 rebase flow for conflicts when two changes edit the same scenario body or description.**

_Outcome:_ Most concurrent updates become commutative, drastically reducing the odds of human merges.

### Phase 3 â€“ Structured Spec Graph (Long-Term)
1. **Define stable requirement IDs.**
   - Embed `Requirement ID: <uuid>` markers in specs so renames and moves are trackable.
   - This enables future features like cross-capability references and better diff visualizations.
2. **Model spec edits as operations over an AST.**
   - Build an intermediate representation (IR) for requirements/scenarios/metadata.
   - Use operational transforms or CRDT-like techniques to guarantee merge associativity.
3. **Integrate with Git directly.**
   - Offer optional `openspec branch` scaffolding that aligns spec changes with Git branches, letting teams leverage Gitâ€™s conflict editor for the markdown IR.

_Outcome:_ OpenSpec graduates from replace-based updates to a resilient, intent-preserving spec management platform.

## Migration & Product Impacts
- **Backfill metadata:** add hashes for all active changes and the current main specs during the initial rollout.
- **CLI UX:** new commands (`change sync`, enhanced `archive`) require documentation, help text, and release notes.
- **Docs & AGENTS updates:** reinforce the rebase workflow and explain conflict resolution to AI assistants.
- **Testing:** introduce fixtures covering divergent requirement fingerprints and merge resolution logic.
- **Telemetry (optional):** log fingerprint mismatches so we can see how often teams hit conflicts after the rollout.

## Open Questions / Risks
- How should we order scenarios when multiple changes insert at different points? (Consider optional `position` metadata or deterministic alphabetical fallbacks.)
- What is the graceful failure mode if contributors delete the `meta.json` file? (CLI should recreate fingerprints on demand.)
- Do we need to support offline authors who cannot easily re-run the sync command before archiving? (Potential `--accept-outdated` escape hatch for emergencies.)
- How will archived historical changes be handled? We may need a migration script to embed fingerprints retroactively so re-validation succeeds.

## Immediate Next Steps
1. Prototype fingerprint capture during `openspec change validate` and block archive on mismatches.
2. Ship `openspec change sync` with line-based diff3 merging and conflict markers.
3. Update contributor docs and AI instructions to mandate running `sync` before archiving.
4. Plan the scenario-level delta extension and migration path as a follow-up RFC.



================================================
FILE: package.json
================================================
{
  "name": "@fission-ai/openspec",
  "version": "0.23.0",
  "description": "AI-native system for spec-driven development",
  "keywords": [
    "openspec",
    "specs",
    "cli",
    "ai",
    "development"
  ],
  "homepage": "https://github.com/Fission-AI/OpenSpec",
  "repository": {
    "type": "git",
    "url": "https://github.com/Fission-AI/OpenSpec"
  },
  "license": "MIT",
  "author": "OpenSpec Contributors",
  "type": "module",
  "publishConfig": {
    "access": "public"
  },
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "default": "./dist/index.js"
    }
  },
  "bin": {
    "openspec": "./bin/openspec.js"
  },
  "files": [
    "dist",
    "bin",
    "schemas",
    "scripts/postinstall.js",
    "!dist/**/*.test.js",
    "!dist/**/__tests__",
    "!dist/**/*.map"
  ],
  "scripts": {
    "lint": "eslint src/",
    "build": "node build.js",
    "dev": "tsc --watch",
    "dev:cli": "pnpm build && node bin/openspec.js",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:ui": "vitest --ui",
    "test:coverage": "vitest --coverage",
    "test:postinstall": "node scripts/postinstall.js",
    "prepare": "pnpm run build",
    "prepublishOnly": "pnpm run build",
    "postinstall": "node scripts/postinstall.js",
    "check:pack-version": "node scripts/pack-version-check.mjs",
    "release": "pnpm run release:ci",
    "release:ci": "pnpm run check:pack-version && pnpm exec changeset publish",
    "changeset": "changeset"
  },
  "engines": {
    "node": ">=20.19.0"
  },
  "devDependencies": {
    "@changesets/changelog-github": "^0.5.2",
    "@changesets/cli": "^2.27.7",
    "@types/node": "^24.2.0",
    "@vitest/ui": "^3.2.4",
    "eslint": "^9.39.2",
    "typescript": "^5.9.3",
    "typescript-eslint": "^8.50.1",
    "vitest": "^3.2.4"
  },
  "dependencies": {
    "@inquirer/core": "^10.2.2",
    "@inquirer/prompts": "^7.8.0",
    "chalk": "^5.5.0",
    "commander": "^14.0.0",
    "fast-glob": "^3.3.3",
    "ora": "^8.2.0",
    "posthog-node": "^5.20.0",
    "yaml": "^2.8.2",
    "zod": "^4.0.17"
  }
}



================================================
FILE: tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "lib": ["ES2022"],
    "moduleResolution": "NodeNext",
    "rootDir": "./src",
    "outDir": "./dist",
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "skipLibCheck": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "resolveJsonModule": true,
    "allowSyntheticDefaultImports": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "test"]
}


================================================
FILE: vitest.config.ts
================================================
import { defineConfig } from 'vitest/config';
import os from 'node:os';

function resolveMaxWorkers(): number | undefined {
  // Allow callers (CI/agents) to override without editing config.
  const raw = process.env.VITEST_MAX_WORKERS;
  if (raw) {
    const parsed = Number(raw);
    if (Number.isFinite(parsed) && parsed > 0) {
      return parsed;
    }
  }

  // Vitest v3 defaults to `pool: "forks"` and scales worker processes with CPU.
  // This repo's tests can spawn many Node processes (CLI invocations, temp FS),
  // so cap parallelism to avoid runaway CPU/memory usage in automation.
  const cpuCount = typeof os.availableParallelism === 'function'
    ? os.availableParallelism()
    : os.cpus().length;
  return Math.min(4, Math.max(1, cpuCount));
}

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    globalSetup: './vitest.setup.ts',
    // Tests rely on per-file process isolation (e.g., `process.cwd()` assumptions).
    pool: 'forks',
    maxWorkers: resolveMaxWorkers(),
    include: ['test/**/*.test.ts'],
    coverage: {
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'dist/',
        'bin/',
        '*.config.ts',
        'build.js',
        'test/**'
      ]
    },
    testTimeout: 10000,
    hookTimeout: 10000,
    teardownTimeout: 3000
  }
});



================================================
FILE: vitest.setup.ts
================================================
import { ensureCliBuilt } from './test/helpers/run-cli.js';

// Ensure the CLI bundle exists before tests execute
export async function setup() {
  await ensureCliBuilt();
}

// Global teardown to ensure clean exit
export async function teardown() {
  // Force exit after a short grace period if the process hasn't exited cleanly.
  // This handles cases where child processes or open handles keep the worker alive.
  setTimeout(() => {
    process.exit(0);
  }, 1000).unref();
}



================================================
FILE: .actrc
================================================
-P ubuntu-latest=catthehacker/ubuntu:act-latest



================================================
FILE: .coderabbit.yaml
================================================
# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json
# Minimal configuration for getting started
language: "en-US"
reviews:
  profile: "chill"
  high_level_summary: true
  auto_review:
    enabled: true
    drafts: false
    base_branches:
      - ".*"


================================================
FILE: docs/artifact_poc.md
================================================
# POC-OpenSpec-Core Analysis

---

## Design Decisions & Terminology

### Philosophy: Not a Workflow System

This system is **not** a workflow engine. It's an **artifact tracker with dependency awareness**.

| What it's NOT | What it IS |
|---------------|------------|
| Linear step-by-step progression | Exploratory, iterative planning |
| Bureaucratic checkpoints | Enablers that unlock possibilities |
| "You must complete step 1 first" | "Here's what you could create now" |
| Form-filling | Fluid document creation |

**Key insight:** Dependencies are *enablers*, not *gates*. You can't meaningfully write a design document if there's no proposal to design from - that's not bureaucracy, it's logic.

### Terminology

| Term | Definition | Example |
|------|------------|---------|
| **Change** | A unit of work being planned (feature, refactor, migration) | `openspec/changes/add-auth/` |
| **Schema** | An artifact graph definition (what artifacts exist, their dependencies) | `spec-driven.yaml` |
| **Artifact** | A node in the graph (a document to create) | `proposal`, `design`, `specs` |
| **Template** | Instructions/guidance for creating an artifact | `templates/proposal.md` |

### Hierarchy

```
Schema (defines) â”€â”€â†’ Artifacts (guided by) â”€â”€â†’ Templates
```

- **Schema** = the artifact graph (what exists, dependencies)
- **Artifact** = a document to produce
- **Template** = instructions for creating that artifact

### Schema Variations

Schemas can vary across multiple dimensions:

| Dimension | Examples |
|-----------|----------|
| Philosophy | `spec-driven`, `tdd`, `prototype-first` |
| Version | `v1`, `v2`, `v3` |
| Language | `en`, `zh`, `es` |
| Custom | `team-alpha`, `experimental` |

### Schema Resolution (XDG Standard)

Schemas follow the XDG Base Directory Specification with a 2-level resolution:

```
1. ${XDG_DATA_HOME}/openspec/schemas/<name>/schema.yaml   # Global user override
2. <package>/schemas/<name>/schema.yaml                    # Built-in defaults
```

**Platform-specific paths:**
- Unix/macOS: `~/.local/share/openspec/schemas/`
- Windows: `%LOCALAPPDATA%/openspec/schemas/`
- All platforms: `$XDG_DATA_HOME/openspec/schemas/` (when set)

**Why XDG?**
- Schemas are workflow definitions (data), not user preferences (config)
- Built-ins baked into package, never auto-copied
- Users customize by creating files in global data dir
- Consistent with modern CLI tooling standards

### Template Inheritance (2 Levels Max)

Templates are co-located with schemas in a `templates/` subdirectory:

```
1. ${XDG_DATA_HOME}/openspec/schemas/<schema>/templates/<artifact>.md  # User override
2. <package>/schemas/<schema>/templates/<artifact>.md                   # Built-in
```

**Rules:**
- User overrides take precedence over package built-ins
- A CLI command shows resolved paths (no guessing)
- No inheritance between schemas (copy if you need to diverge)
- Templates are always co-located with their schema

**Why this matters:**
- Avoids "where does this come from?" debugging
- No implicit magic that works until it doesn't
- Schema + templates form a cohesive unit

---

## Executive Summary

This is an **artifact tracker with dependency awareness** that guides iterative development through a structured artifact pipeline. The core innovation is using the **filesystem as a database** - artifact completion is detected by file existence, making the system stateless and version-control friendly.

The system answers:
- "What artifacts exist for this change?"
- "What could I create next?" (not "what must I create")
- "What's blocking X?" (informational, not prescriptive)

---

## Core Components

### 1. ArtifactGraph (Slice 1 - COMPLETE)

The dependency graph engine with XDG-compliant schema resolution.

| Responsibility | Approach |
|----------------|----------|
| Model artifacts as a DAG | Artifact with `requires: string[]` |
| Track completion state | `Set<string>` for completed artifacts |
| Calculate build order | Kahn's algorithm (topological sort) |
| Find ready artifacts | Check if all dependencies are in `completed` set |
| Resolve schemas | XDG global â†’ package built-ins |

**Key Data Structures (Zod-validated):**

```typescript
// Zod schemas define types + validation
const ArtifactSchema = z.object({
  id: z.string().min(1),
  generates: z.string().min(1),      // e.g., "proposal.md" or "specs/*.md"
  description: z.string(),
  template: z.string(),              // path to template file
  requires: z.array(z.string()).default([]),
});

const SchemaYamlSchema = z.object({
  name: z.string().min(1),
  version: z.number().int().positive(),
  description: z.string().optional(),
  artifacts: z.array(ArtifactSchema).min(1),
});

// Derived types
type Artifact = z.infer<typeof ArtifactSchema>;
type SchemaYaml = z.infer<typeof SchemaYamlSchema>;
```

**Key Methods:**
- `resolveSchema(name)` - Load schema with XDG fallback
- `ArtifactGraph.fromSchema(schema)` - Build graph from schema
- `detectState(graph, changeDir)` - Scan filesystem for completion
- `getNextArtifacts(graph, completed)` - Find artifacts ready to create
- `getBuildOrder(graph)` - Topological sort of all artifacts
- `getBlocked(graph, completed)` - Artifacts with unmet dependencies

---

### 2. Change Utilities (Slice 2)

Simple utility functions for programmatic change creation. No class, no abstraction layer.

| Responsibility | Approach |
|----------------|----------|
| Create changes | Create dirs under `openspec/changes/<name>/` with README |
| Name validation | Enforce kebab-case naming |

**Key Paths:**

```
openspec/changes/<name>/   â†’ Change instances with artifacts (project-level)
```

**Key Functions** (`src/utils/change-utils.ts`):
- `createChange(projectRoot, name, description?)` - Create new change directory + README
- `validateChangeName(name)` - Validate kebab-case naming, returns `{ valid, error? }`

**Note:** Existing CLI commands (`ListCommand`, `ChangeCommand`) already handle listing, path resolution, and existence checks. No need to extract that logic - it works fine as-is.

---

### 3. InstructionLoader (Slice 3)

Template resolution and instruction enrichment.

| Responsibility | Approach |
|----------------|----------|
| Resolve templates | XDG 2-level fallback (schema-specific â†’ shared â†’ built-in) |
| Build dynamic context | Gather dependency status, change info |
| Enrich templates | Inject context into base templates |
| Generate status reports | Formatted markdown with progress |

**Key Class - ChangeState:**

```
ChangeState {
  changeName: string
  changeDir: string
  graph: ArtifactGraph
  completed: Set<string>

  // Methods
  getNextSteps(): string[]
  getStatus(artifactId): ArtifactStatus
  isComplete(): boolean
}
```

**Key Functions:**
- `getTemplatePath(artifactId, schemaName?)` - Resolve with 2-level fallback
- `getEnrichedInstructions(artifactId, projectRoot, changeName?)` - Main entry point
- `getChangeStatus(projectRoot, changeName?)` - Formatted status report

---

### 4. CLI (Slice 4)

User interface layer. **All commands are deterministic** - require explicit `--change` parameter.

| Command | Function | Status |
|---------|----------|--------|
| `status --change <id>` | Show change progress (artifact graph) | **NEW** |
| `next --change <id>` | Show artifacts ready to create | **NEW** |
| `instructions <artifact> --change <id>` | Get enriched instructions for artifact | **NEW** |
| `list` | List all changes | EXISTS (`openspec change list`) |
| `new <name>` | Create change | **NEW** (uses `createChange()`) |
| `init` | Initialize structure | EXISTS (`openspec init`) |
| `templates --change <id>` | Show resolved template paths | **NEW** |

**Note:** Commands that operate on a change require `--change`. Missing parameter â†’ error with list of available changes. Agent infers the change from conversation and passes it explicitly.

**Existing CLI commands** (not part of this slice):
- `openspec change list` / `openspec change show <id>` / `openspec change validate <id>`
- `openspec list --changes` / `openspec list --specs`
- `openspec view` (dashboard)
- `openspec init` / `openspec archive <change>`

---

### 5. Claude Commands

Integration layer for Claude Code. **Operational commands only** - artifact creation via natural language.

| Command | Purpose |
|---------|---------|
| `/status` | Show change progress |
| `/next` | Show what's ready to create |
| `/run [artifact]` | Execute a specific step (power users) |
| `/list` | List all changes |
| `/new <name>` | Create a new change |
| `/init` | Initialize structure |

**Artifact creation:** Users say "create the proposal" or "write the tests" in natural language. The agent:
1. Infers change from conversation (confirms if uncertain)
2. Infers artifact from request
3. Calls CLI with explicit `--change` parameter
4. Creates artifact following instructions

This works for ANY artifact in ANY schema - no new slash commands needed when schemas change.

**Note:** Legacy commands (`/openspec-proposal`, `/openspec-apply`, `/openspec-archive`) exist in the main project for backward compatibility but are separate from this architecture.

---

## Component Dependency Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PRESENTATION LAYER                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     CLI      â”‚ â†â”€shell execâ”€â”€â”€â”€â”€â”€â”€â”‚ Claude Commands    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ imports
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATION LAYER                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ InstructionLoader  â”‚        â”‚  change-utils (Slice 2)  â”‚ â”‚
â”‚  â”‚    (Slice 3)       â”‚        â”‚  createChange()          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  validateChangeName()    â”‚ â”‚
â”‚            â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ uses
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CORE LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚               ArtifactGraph (Slice 1)                â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  Schema Resolution (XDG) â”€â”€â†’ Graph â”€â”€â†’ State Detectionâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²
             â”‚ reads from
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PERSISTENCE LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  XDG Schemas     â”‚   â”‚  Project Artifacts             â”‚  â”‚
â”‚  â”‚  ~/.local/share/ â”‚   â”‚  openspec/changes/<name>/      â”‚  â”‚
â”‚  â”‚  openspec/       â”‚   â”‚  - proposal.md, design.md      â”‚  â”‚
â”‚  â”‚  schemas/        â”‚   â”‚  - specs/*.md, tasks.md        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Design Patterns

### 1. Filesystem as Database

No SQLite, no JSON state files. The existence of `proposal.md` means proposal is complete.

```
// State detection is just file existence checking
if (exists(artifactPath)) {
  completed.add(artifactId)
}
```

### 2. Deterministic CLI, Inferring Agent

**CLI layer:** Always deterministic - requires explicit `--change` parameter.

```
openspec status --change add-auth     # explicit, works
openspec status                        # error: "No change specified"
```

**Agent layer:** Infers from conversation, confirms if uncertain, passes explicit `--change`.

This separation means:
- CLI is pure, testable, no state to corrupt
- Agent handles all "smartness"
- No config.yaml tracking of "active change"

### 3. XDG-Compliant Schema Resolution

```
${XDG_DATA_HOME}/openspec/schemas/<name>/schema.yaml   # User override
    â†“ (not found)
<package>/schemas/<name>/schema.yaml                    # Built-in
    â†“ (not found)
Error (schema not found)
```

### 4. Two-Level Template Fallback

```
${XDG_DATA_HOME}/openspec/schemas/<schema>/templates/<artifact>.md  # User override
    â†“ (not found)
<package>/schemas/<schema>/templates/<artifact>.md                   # Built-in
    â†“ (not found)
Error (no silent fallback to avoid confusion)
```

### 5. Glob Pattern Support

`specs/*.md` allows multiple files to satisfy a single artifact:

```
if (artifact.generates.includes("*")) {
  const parentDir = changeDir / patternParts[0]
  if (exists(parentDir) && hasFiles(parentDir)) {
    completed.add(artifactId)
  }
}
```

### 6. Stateless State Detection

Every command re-scans the filesystem. No cached state to corrupt.

---

## Artifact Pipeline (Default Schema)

The default `spec-driven` schema:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ proposal â”‚  (no dependencies)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  specs   â”‚  (requires: proposal)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  design  â”‚   â”‚          â”‚
â”‚          â”‚â—„â”€â”€â”¤ proposal â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚         (requires: proposal, specs)
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  tasks   â”‚  (requires: design)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Other schemas (TDD, prototype-first) would have different graphs.

---

## Implementation Order

Structured as **vertical slices** - each slice is independently testable.

---

### Slice 1: "What's Ready?" (Core Query) âœ… COMPLETE

**Delivers:** Types + Graph + State Detection + Schema Resolution

**Implementation:** `src/core/artifact-graph/`
- `types.ts` - Zod schemas and derived TypeScript types
- `schema.ts` - YAML parsing with Zod validation
- `graph.ts` - ArtifactGraph class with topological sort
- `state.ts` - Filesystem-based state detection
- `resolver.ts` - XDG-compliant schema resolution
- `builtin-schemas.ts` - Package-bundled default schemas

**Key decisions made:**
- Zod for schema validation (consistent with project)
- XDG for global schema overrides
- `Set<string>` for completion state (immutable, functional)
- `inProgress` and `failed` states deferred (require external tracking)

---

### Slice 2: "Change Creation Utilities"

**Delivers:** Utility functions for programmatic change creation

**Scope:**
- `createChange(projectRoot, name, description?)` â†’ creates directory + README
- `validateChangeName(name)` â†’ kebab-case pattern enforcement

**Not in scope (already exists in CLI commands):**
- `listChanges()` â†’ exists in `ListCommand` and `ChangeCommand.getActiveChanges()`
- `getChangePath()` â†’ simple `path.join()` inline
- `changeExists()` â†’ simple `fs.access()` inline
- `isInitialized()` â†’ simple directory check inline

**Why simplified:** Extracting existing CLI logic into a class would require similar refactoring of `SpecCommand` for consistency. The existing code works fine (~15 lines each). Only truly new functionality is `createChange()` + name validation.

---

### Slice 3: "Get Instructions" (Enrichment)

**Delivers:** Template resolution + context injection

**Testable behaviors:**
- Template fallback: schema-specific â†’ shared â†’ built-in â†’ error
- Context injection: completed deps show âœ“, missing show âœ—
- Output path shown correctly based on change directory

---

### Slice 4: "CLI + Integration"

**Delivers:** New artifact graph commands (builds on existing CLI)

**New commands:**
- `status --change <id>` - Show artifact completion state
- `next --change <id>` - Show ready-to-create artifacts
- `instructions <artifact> --change <id>` - Get enriched template
- `templates --change <id>` - Show resolved paths
- `new <name>` - Create change (wrapper for `createChange()`)

**Already exists (not in scope):**
- `openspec change list/show/validate` - change management
- `openspec list --changes/--specs` - listing
- `openspec view` - dashboard
- `openspec init` - initialization

**Testable behaviors:**
- Each new command produces expected output
- Commands compose correctly (status â†’ next â†’ instructions flow)
- Error handling for missing changes, invalid artifacts, etc.

---

## Directory Structure

```
# Global (XDG paths - user overrides)
~/.local/share/openspec/           # Unix/macOS ($XDG_DATA_HOME/openspec/)
%LOCALAPPDATA%/openspec/           # Windows
â””â”€â”€ schemas/                       # Schema overrides
    â””â”€â”€ custom-workflow/           # User-defined schema directory
        â”œâ”€â”€ schema.yaml            # Schema definition
        â””â”€â”€ templates/             # Co-located templates
            â””â”€â”€ proposal.md

# Package (built-in defaults)
<package>/
â””â”€â”€ schemas/                       # Built-in schema definitions
    â”œâ”€â”€ spec-driven/               # Default: proposal â†’ specs â†’ design â†’ tasks
    â”‚   â”œâ”€â”€ schema.yaml
    â”‚   â””â”€â”€ templates/
    â”‚       â”œâ”€â”€ proposal.md
    â”‚       â”œâ”€â”€ design.md
    â”‚       â”œâ”€â”€ spec.md
    â”‚       â””â”€â”€ tasks.md
    â””â”€â”€ tdd/                       # TDD: tests â†’ implementation â†’ docs
        â”œâ”€â”€ schema.yaml
        â””â”€â”€ templates/
            â”œâ”€â”€ test.md
            â”œâ”€â”€ implementation.md
            â”œâ”€â”€ spec.md
            â””â”€â”€ docs.md

# Project (change instances)
openspec/
â””â”€â”€ changes/                       # Change instances
    â”œâ”€â”€ add-auth/
    â”‚   â”œâ”€â”€ README.md              # Auto-generated on creation
    â”‚   â”œâ”€â”€ proposal.md            # Created artifacts
    â”‚   â”œâ”€â”€ design.md
    â”‚   â””â”€â”€ specs/
    â”‚       â””â”€â”€ *.md
    â”œâ”€â”€ refactor-db/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ archive/                   # Completed changes
        â””â”€â”€ 2025-01-01-add-auth/

.claude/
â”œâ”€â”€ settings.local.json            # Permissions
â””â”€â”€ commands/                      # Slash commands
    â””â”€â”€ *.md
```

---

## Schema YAML Format

```yaml
# Built-in: <package>/schemas/spec-driven/schema.yaml
# Or user override: ~/.local/share/openspec/schemas/spec-driven/schema.yaml
name: spec-driven
version: 1
description: Specification-driven development

artifacts:
  - id: proposal
    generates: "proposal.md"
    description: "Create project proposal document"
    template: "proposal.md"          # resolves from co-located templates/ directory
    requires: []

  - id: specs
    generates: "specs/*.md"          # glob pattern
    description: "Create technical specification documents"
    template: "specs.md"
    requires:
      - proposal

  - id: design
    generates: "design.md"
    description: "Create design document"
    template: "design.md"
    requires:
      - proposal
      - specs

  - id: tasks
    generates: "tasks.md"
    description: "Create tasks breakdown document"
    template: "tasks.md"
    requires:
      - design
```

---

## Summary

| Layer | Component | Responsibility | Status |
|-------|-----------|----------------|--------|
| Core | ArtifactGraph | Pure dependency logic + XDG schema resolution | âœ… Slice 1 COMPLETE |
| Utils | change-utils | Change creation + name validation only | Slice 2 (new functionality only) |
| Core | InstructionLoader | Template resolution + enrichment | Slice 3 (all new) |
| Presentation | CLI | New artifact graph commands | Slice 4 (new commands only) |
| Integration | Claude Commands | AI assistant glue | Slice 4 |

**What already exists (not in this proposal):**
- `getActiveChangeIds()` in `src/utils/item-discovery.ts` - list changes
- `ChangeCommand.list/show/validate()` in `src/commands/change.ts`
- `ListCommand.execute()` in `src/core/list.ts`
- `ViewCommand.execute()` in `src/core/view.ts` - dashboard
- `src/core/init.ts` - initialization
- `src/core/archive.ts` - archiving

**Key Principles:**
- **Filesystem IS the database** - stateless, version-control friendly
- **Dependencies are enablers** - show what's possible, don't force order
- **Deterministic CLI, inferring agent** - CLI requires explicit `--change`, agent infers from context
- **XDG-compliant paths** - schemas and templates use standard user data directories
- **2-level inheritance** - user override â†’ package built-in (no deeper)
- **Schemas are versioned** - support variations by philosophy, version, language



================================================
FILE: docs/experimental-release-plan.md
================================================
# OpenSpec Experimental Release Plan

This document outlines the plan to release the experimental artifact workflow system for user testing.

## Overview

The goal is to allow users to test the new artifact-driven workflow system alongside the existing OpenSpec commands. This experimental system (`opsx`) provides a more granular, step-by-step approach to creating change artifacts.

## Three Workflow Modes

### 1. Old Workflow (Current Production)
- **Commands**: `/openspec:proposal`, `/openspec:apply`, `/openspec:archive`
- **Behavior**: Hardcoded slash commands that generate all artifacts in one command
- **Status**: Production, unchanged

### 2. New Artifact System - Batch Mode (Future)
- **Commands**: Refactored `/openspec:proposal` using schemas
- **Behavior**: Schema-driven but generates all artifacts at once (like legacy)
- **Status**: Not in scope for this experimental release
- **Note**: This is a future refactor to unify the old system with schemas

### 3. New Artifact System - Granular Mode (Experimental)
- **Commands**: `/opsx:new`, `/opsx:continue`
- **Behavior**: One artifact at a time, dependency-driven, iterative
- **Status**: Target for this experimental release

---

## Work Items

### 1. Rename AWF to OPSX

**Current State:**
- Commands: `/awf:start`, `/awf:continue`
- Files: `.claude/commands/awf/start.md`, `.claude/commands/awf/continue.md`

**Target State:**
- Commands: `/opsx:new`, `/opsx:continue`
- Files: `.claude/commands/opsx/new.md`, `.claude/commands/opsx/continue.md`

**Tasks:**
- [x] Create `.claude/commands/opsx/` directory
- [x] Rename `start.md` â†’ `new.md` and update content
- [x] Copy `continue.md` with updated references
- [x] Update all references from "awf" to "opsx" in command content
- [x] Update frontmatter (name, description) to use "opsx" naming
- [x] Remove `.claude/commands/awf/` directory

**CLI Commands:**
The underlying CLI commands (`openspec status`, `openspec instructions`, etc.) remain unchanged. Only the slash command names change.

---

### 2. Remove WF Skill Files

**Current State:**
- `.claude/commands/wf/start.md` - References non-existent `openspec wf` commands
- `.claude/commands/wf/continue.md` - References non-existent `openspec wf` commands

**Target State:**
- Directory and files removed

**Tasks:**
- [x] Delete `.claude/commands/wf/start.md`
- [x] Delete `.claude/commands/wf/continue.md`
- [x] Delete `.claude/commands/wf/` directory

---

### 3. Add Agent Skills for Experimental Workflow

**Purpose:**
Generate experimental workflow skills using the [Agent Skills](https://agentskills.io/specification) open standard.

**Why Skills Instead of Slash Commands:**
- **Cross-editor compatibility**: Skills work in Claude Code, Cursor, Windsurf, and other compatible editors automatically
- **Simpler implementation**: Single directory (`.claude/skills/`) instead of 18+ editor-specific configurators
- **Standard format**: Open standard with simple YAML frontmatter + markdown
- **User invocation**: Users explicitly invoke skills when they want to use them

**Behavior:**
1. Create `.claude/skills/` directory if it doesn't exist
2. Generate two skills using the Agent Skills specification:
   - `openspec-new-change/SKILL.md` - Start a new change with artifact workflow
   - `openspec-continue-change/SKILL.md` - Continue working on a change (create next artifact)
3. Skills are added **alongside** existing `/openspec:*` commands (not replacing)

**Supported Editors:**
- Claude Code (native support)
- Cursor (native support via Settings â†’ Rules â†’ Import Settings)
- Windsurf (imports `.claude` configs)
- Cline, Codex, and other Agent Skills-compatible editors

**Tasks:**
- [x] Create skill template content for `openspec-new-change` (based on current opsx:new)
- [x] Create skill template content for `openspec-continue-change` (based on current opsx:continue)
- [x] Add temporary `artifact-experimental-setup` command to CLI
- [x] Implement skill file generation (YAML frontmatter + markdown body)
- [x] Add success message with usage instructions

**Note:** The `artifact-experimental-setup` command is temporary and will be merged into `openspec init` once the experimental workflow is promoted to stable.

**Skill Format:**
Each skill is a directory with a `SKILL.md` file:
```
.claude/skills/
â”œâ”€â”€ openspec-new-change/
â”‚   â””â”€â”€ SKILL.md          # name, description, instructions
â”œâ”€â”€ openspec-continue-change/
â”‚   â””â”€â”€ SKILL.md          # name, description, instructions
â””â”€â”€ openspec-apply-change/
    â””â”€â”€ SKILL.md          # name, description, instructions
```

**CLI Interface:**
```bash
openspec artifact-experimental-setup

# Output:
# ğŸ§ª Experimental Artifact Workflow Skills Created
#
#   âœ“ .claude/skills/openspec-new-change/SKILL.md
#   âœ“ .claude/skills/openspec-continue-change/SKILL.md
#   âœ“ .claude/skills/openspec-apply-change/SKILL.md
#
# ğŸ“– Usage:
#
#   Skills work automatically in compatible editors:
#   â€¢ Claude Code - Auto-detected, ready to use
#   â€¢ Cursor - Enable in Settings â†’ Rules â†’ Import Settings
#   â€¢ Windsurf - Auto-imports from .claude directory
#
#   Ask Claude naturally:
#   â€¢ "I want to start a new OpenSpec change to add <feature>"
#   â€¢ "Continue working on this change"
#
#   Claude will automatically use the appropriate skill.
#
# ğŸ’¡ This is an experimental feature.
#    Feedback welcome at: https://github.com/Fission-AI/OpenSpec/issues
```

**Implementation Notes:**
- Simple file writing: Create directories and write templated `SKILL.md` files (no complex logic)
- Use existing `FileSystemUtils.writeFile()` pattern like slash command configurators
- Template structure: YAML frontmatter + markdown body
- Keep existing `/opsx:*` slash commands for now (manual cleanup later)
- Skills use invocation model (user explicitly asks Claude to use them)
- Skill `description` field guides when Claude suggests using the skill
- Each `SKILL.md` has required fields: `name` (matches directory) and `description`

---

### 4. Update `/opsx:new` Command Content

**Current Behavior (awf:start):**
1. Ask user what they want to build (if no input)
2. Create change directory
3. Show artifact status
4. Show what's ready
5. Get instructions for proposal
6. STOP and wait

**New Behavior (opsx:new):**
Same flow but with updated naming:
- References to "awf" â†’ "opsx"
- References to `/awf:continue` â†’ `/opsx:continue`
- Update frontmatter name/description

**Tasks:**
- [x] Update all "awf" references to "opsx"
- [x] Update command references in prompt text
- [x] Verify CLI commands still work (they use `openspec`, not `awf`)

---

### 5. Update `/opsx:continue` Command Content

**Current Behavior (awf:continue):**
1. Prompt for change selection (if not provided)
2. Check current status
3. Create ONE artifact based on what's ready
4. Show progress and what's unlocked
5. STOP

**New Behavior (opsx:continue):**
Same flow with updated naming.

**Tasks:**
- [x] Update all "awf" references to "opsx"
- [x] Update command references in prompt text

---

### 6. End-to-End Testing

**Objective:**
Run through a complete workflow with Claude using the new skills to create a real feature, validating the entire flow works.

**Test Scenario:**
Use a real OpenSpec feature as the test case (dog-fooding).

**Test Flow:**
1. Run `openspec artifact-experimental-setup` to create skills
2. Verify `.claude/skills/openspec-new-change/SKILL.md` created
3. Verify `.claude/skills/openspec-continue-change/SKILL.md` created
4. Verify `.claude/skills/openspec-apply-change/SKILL.md` created
5. Ask Claude: "I want to start a new OpenSpec change to add feature X"
6. Verify Claude invokes the `openspec-new-change` skill
7. Verify change directory created at `openspec/changes/add-feature-x/`
8. Verify proposal template shown
9. Ask Claude: "Continue working on this change"
10. Verify Claude invokes the `openspec-continue-change` skill
11. Verify `proposal.md` created with content
12. Ask Claude: "Continue" (create specs)
13. Verify `specs/*.md` created
14. Ask Claude: "Continue" (create design)
15. Verify `design.md` created
16. Ask Claude: "Continue" (create tasks)
17. Verify `tasks.md` created
18. Verify status shows 4/4 complete
19. Implement the feature based on tasks
20. Run `/openspec:archive` to archive the change

**Validation Checklist:**
- [ ] `openspec artifact-experimental-setup` creates correct directory structure
- [ ] Skills are auto-detected in Claude Code
- [ ] Skill descriptions trigger appropriate invocations
- [ ] Skills create change directory and show proposal template
- [ ] Skills correctly identify ready artifacts
- [ ] Skills create artifacts with meaningful content
- [ ] Dependency detection works (specs requires proposal, etc.)
- [ ] Progress tracking is accurate
- [ ] Template content is useful and well-structured
- [ ] Error handling works (invalid names, missing changes, etc.)
- [ ] Works with different schemas (spec-driven, tdd)
- [ ] Test in Cursor (Settings â†’ Rules â†’ Import Settings)

**Document Results:**
- Create test log documenting what worked and what didn't
- Note any friction points or confusing UX
- Identify bugs or improvements needed before user release

---

### 7. Documentation for Users

**Create user-facing documentation explaining:**

1. **What is the experimental workflow?**
   - A new way to create OpenSpec changes step-by-step using Agent Skills
   - One artifact at a time with dependency tracking
   - More interactive and iterative than the batch approach
   - Works across Claude Code, Cursor, Windsurf, and other compatible editors

2. **How to set up experimental workflow**
   ```bash
   openspec artifact-experimental-setup
   ```

   Note: This is a temporary command that will be integrated into `openspec init` once promoted to stable.

3. **Available skills**
   - `openspec-new-change` - Start a new change with artifact workflow
   - `openspec-continue-change` - Continue working (create next artifact)

4. **How to use**
   - **Claude Code**: Skills are auto-detected, just ask Claude naturally
     - "I want to start a new OpenSpec change to add X"
     - "Continue working on this change"
   - **Cursor**: Enable in Settings â†’ Rules â†’ Import Settings
   - **Windsurf**: Auto-imports `.claude` directory

5. **Example workflow**
   - Step-by-step walkthrough with natural language interactions
   - Show how Claude invokes skills based on user requests

6. **Feedback mechanism**
   - GitHub issue template for feedback
   - What to report (bugs, UX issues, suggestions)

**Tasks:**
- [ ] Create `docs/experimental-workflow.md` user guide
- [ ] Add GitHub issue template for experimental feedback
- [ ] Update README with mention of experimental features

---

## Dependency Graph

```
1. Remove WF skill files
   â””â”€â”€ (no dependencies)

2. Rename AWF to OPSX
   â””â”€â”€ (no dependencies)

3. Add Agent Skills
   â””â”€â”€ Depends on: Rename AWF to OPSX (uses opsx content as templates)

4. Update opsx:new content
   â””â”€â”€ Depends on: Rename AWF to OPSX

5. Update opsx:continue content
   â””â”€â”€ Depends on: Rename AWF to OPSX

6. E2E Testing
   â””â”€â”€ Depends on: Add Agent Skills (tests the skills workflow)

7. User Documentation
   â””â”€â”€ Depends on: E2E Testing (need to know final behavior)
```

---

## Out of Scope

The following are explicitly NOT part of this experimental release:

1. **Batch mode refactor** - Making legacy `/openspec:proposal` use schemas
2. **New schemas** - Only shipping with existing `spec-driven` and `tdd`
3. **Schema customization UI** - No `openspec schema list` or similar
4. **Multiple editor support in CLI** - Skills work cross-editor automatically via `.claude/skills/`
5. **Replacing existing commands** - Skills are additive, not replacing `/openspec:*` or `/opsx:*`

---

## Success Criteria

The experimental release is ready when:

1. `openspec-new-change`, `openspec-continue-change`, and `openspec-apply-change` skills work end-to-end
2. `openspec artifact-experimental-setup` creates skills in `.claude/skills/`
3. Skills work in Claude Code and are compatible with Cursor/Windsurf
4. At least one complete workflow has been tested manually
5. User documentation exists explaining how to generate and use skills
6. Feedback mechanism is in place
7. WF skill files are removed
8. No references to "awf" remain in user-facing content

---

## Open Questions

1. **Schema selection** - Should `opsx:new` allow selecting a schema, or always use `spec-driven`?
   - Current: Always uses `spec-driven` as default
   - Consider: Add `--schema tdd` option or prompt

2. **Namespace in CLI** - Should experimental CLI commands be namespaced?
   - Current: `openspec status`, `openspec instructions` (no namespace)
   - Alternative: `openspec opsx status` (explicit experimental namespace)
   - Recommendation: Keep current, less typing for users

3. **Deprecation path** - If opsx becomes the default, how do we migrate?
   - Not needed for experimental release
   - Document that command names may change

---

## Estimated Work Breakdown

| Item | Complexity | Notes |
|------|------------|-------|
| Remove WF files | Trivial | Just delete 2 files + directory |
| Rename AWF â†’ OPSX | Low | File renames + content updates |
| Add Agent Skills | **Low** | **Simple: 3-4 files, single output directory, standard format** |
| Update opsx:new content | Low | Text replacements |
| Update opsx:continue content | Low | Text replacements |
| E2E Testing | Medium | Manual testing, documenting results |
| User Documentation | Medium | New docs, issue template |

**Key Improvement:** Switching to Agent Skills reduces complexity significantly:
- **Before:** 20+ files (type definitions, 18+ editor configurators, editor selection UI)
- **After:** 3-4 files (skill templates, simple CLI command)
- **Cross-editor:** Works automatically in Claude Code, Cursor, Windsurf without extra code

---

## User Feedback from E2E Testing

### What Worked Well

1. **Clear dependency graph** â­ HIGH PRIORITY - KEEP
   - The status command showing blocked/unblocked artifacts was intuitive:
     ```
     [x] proposal
     [ ] design
     [-] tasks (blocked by: design, specs)
     ```
   - Users always knew what they could work on next
   - **Relevance**: Core UX strength to preserve

2. **Structured instructions output** â­ HIGH PRIORITY - KEEP
   - `openspec instructions <artifact>` gave templates, output paths, and context in one call
   - Very helpful for understanding what to create
   - **Relevance**: Essential for agent-driven workflow

3. **Simple scaffolding** âœ… WORKS WELL
   - `openspec new change "name"` just worked - created directory structure without fuss
   - **Relevance**: Good baseline, room for improvement (see pain points)

---

### Pain Points & Confusion

1. **Redundant CLI calls** âš ï¸ MEDIUM PRIORITY
   - Users called both `status` AND `next` every time, but they overlap significantly
   - `status` already shows what's blocked
   - **Recommendation**: Consider merging or making `next` give actionable guidance beyond just listing names
   - **Relevance**: Reduces friction in iterative workflow

2. **Specs directory structure was ambiguous** ğŸ”¥ HIGH PRIORITY - FIX
   - Instructions said: `Write to: .../specs/**/*.md`
   - Users had to guess: `specs/spec.md`? `specs/game/spec.md`? `specs/tic-tac-toe/spec.md`?
   - Users ended up doing manual `mkdir -p .../specs/tic-tac-toe` then writing `spec.md` inside
   - **Recommendation**: CLI should scaffold this directory structure automatically
   - **Relevance**: Critical agent UX - ambiguous paths cause workflow friction

3. **Repetitive --change flag** âš ï¸ MEDIUM PRIORITY
   - Every command needed `--change "tic-tac-toe-game"`
   - After 10+ calls, this felt verbose
   - **Recommendation**: `openspec use "tic-tac-toe-game"` to set context, then subsequent commands assume that change
   - **Relevance**: Quality of life improvement for iterative sessions

4. **No validation feedback** ğŸ”¥ HIGH PRIORITY - ADD
   - After writing each artifact, users just ran `status` hoping it would show `[x]`
   - Questions raised:
     - How did it know the artifact was "done"? File existence?
     - What if spec format was wrong (e.g., wrong heading levels)?
   - **Recommendation**: Add `openspec validate --change "name"` to check content quality
   - **Relevance**: Critical for user confidence and catching errors early

5. **Query-heavy, action-light CLI** ğŸ”¥ HIGH PRIORITY - ENHANCE
   - Most commands retrieve info. The only "action" is `new change`
   - Artifact creation is manual Write to guessed paths
   - **Recommendation**: `openspec create proposal --change "name"` could scaffold the file with template pre-filled, then user just edits
   - **Relevance**: Directly impacts agent productivity - reduce manual file writing

6. **Instructions output was verbose** âš ï¸ LOW PRIORITY
   - XML-style output (`<artifact>`, `<template>`, `<instruction>`) was parseable but long
   - Key info (output path, template) was buried in ~50 lines
   - **Recommendation**: Add compact mode or structured JSON output for agents
   - **Relevance**: Nice-to-have for agent parsing efficiency

---

### Workflow Friction

1. **Mandatory "STOP and wait" after showing proposal template** âš ï¸ MEDIUM PRIORITY
   - The skill said "STOP and wait" after showing the proposal template
   - This felt overly cautious when user had already provided enough context (e.g., "tic tac toe, single player vs AI, minimal aesthetics")
   - **Recommendation**: Make the pause optional or conditional based on context clarity
   - **Relevance**: Reduces unnecessary round-trips in agent conversations

2. **No connection to implementation** ğŸ”¥ HIGH PRIORITY - ROADMAP ITEM
   - After 4/4 artifacts complete, then what? The workflow ends at planning
   - No `openspec apply` or guidance on how to execute the tasks
   - User asked "would you like me to implement?" but that's outside OpenSpec's scope currently
   - **Recommendation**: Add implementation bridge - either:
     - `openspec apply` command to start execution phase
     - Clear handoff to existing `/openspec:apply` workflow
     - Documentation on next steps after planning completes
   - **Relevance**: Critical missing piece - users expect end-to-end workflow

---

### Priority Summary

**MUST FIX (High Priority):**
1. Specs directory structure ambiguity (#2)
2. Add validation feedback (#4)
3. Make CLI more action-oriented (#5)
4. Bridge to implementation phase (#2 in Workflow Friction)
5. Keep clear dependency graph (#1 in What Worked)
6. Keep structured instructions (#2 in What Worked)

**SHOULD FIX (Medium Priority):**
1. Reduce redundant CLI calls (#1)
2. Repetitive `--change` flag (#3)
3. Mandatory STOP behavior (#1 in Workflow Friction)

**NICE TO HAVE (Low Priority):**
1. Compact instructions output mode (#6)

---

## Design Decisions (from E2E Testing Feedback)

Based on dev testing and analysis of agent workflow friction, we identified three blockers for experimental release and made the following decisions.

### Blockers Identified

From the pain points in E2E testing, three issues are blocking the experimental release:

1. **Specs directory ambiguity** - Agents don't know where to write spec files or how to name capabilities
2. **CLI is query-heavy** - Most commands retrieve info, artifact creation is manual
3. **Apply integration missing** - After 4/4 artifacts complete, no guidance on implementation phase

### Decision 1: Capability Discovery in Proposal (RESOLVED)

**Problem:** The specs artifact instruction says "Create one spec file per capability in `specs/<name>/spec.md`" but:
- Agent doesn't know what `<name>` should be
- Capability identification requires research (existing specs, codebase)
- Proposal template asks for "Affected specs" but doesn't structure it
- Research happens implicitly, output isn't captured

**Decision:** Enrich the proposal template to explicitly capture capability discovery.

**Current proposal template:**
```markdown
## Why
## What Changes
## Impact
- Affected specs: List capabilities...  â† vague, easy to skip
- Affected code: ...
```

**New proposal template:**
```markdown
## Why
## What Changes
## Capabilities

### New Capabilities
<!-- Capabilities being introduced (will create new specs/<name>/spec.md) -->
- `<name>`: <brief description of what this capability covers>

### Modified Capabilities
<!-- Existing capabilities being changed (will update existing specs) -->
- `<existing-name>`: <what's changing>

## Impact
<!-- Affected code, APIs, dependencies, systems -->
```

**Rationale:**
- Proposal already asks for capabilities (just poorly) - this makes it explicit
- Captured output is reviewable (vs implicit research that can't be verified)
- Creates clear contract between proposal and specs phases
- Distinguishes NEW vs MODIFIED upfront (critical for specs phase)
- Agent can't skip research - it's part of the deliverable

**Implementation:**
- Update `schemas/spec-driven/templates/proposal.md`
- Update proposal instruction in `schemas/spec-driven/schema.yaml`
- Update skill instructions to guide capability discovery

### Decision 2: CLI Action Commands (IN PROGRESS)

**Problem:** CLI is mostly query-oriented. Agents run `openspec status`, `openspec next`, `openspec instructions` but then must manually write files.

#### Decision 2a: Remove `openspec next` command (RESOLVED)

**Problem:** The `next` command is redundant. It only shows which artifacts are ready, but `status` already shows this information (artifacts with status "ready" vs "blocked" vs "done").

**Current behavior:**
```bash
openspec status --change "X"  # Shows: proposal (done), specs (ready), design (blocked), tasks (blocked)
openspec next --change "X"    # Shows: ["specs"]  â† redundant
```

**Decision:** Remove the `next` command. Agents should use `status` which provides the same info plus more context.

**Implementation:**
- Remove `next` command from CLI
- Update skill instructions to use `status` instead of `next`
- Update AGENTS.md references

#### Decision 2b: CLI Scaffolding (RESOLVED - NO)

**Problem:** After getting instructions, agents manually write files. Should CLI scaffold artifacts instead?

**Options considered:**
- Add `openspec create <artifact>` commands that scaffold files with templates
- Keep current approach where agent writes files directly from instructions
- Hybrid: CLI can scaffold, agent can also write directly

**Decision:** Keep current flow. No scaffolding commands.

**Rationale (from agent ergonomics perspective):**
- One Write is better than multiple Edits - agent composes full content atomically
- `instructions` already provides template in context - scaffolding just moves it to a file
- Fewer tool calls: `instructions` + Write (2) vs `create` + `instructions` + Read + EditÃ—N (4+)
- Scaffolding doesn't solve the real problem (not knowing WHAT to write)
- Real problem solved by proposal template change (capability discovery)

**For multi-file artifacts (specs):** Scaffolding can't help because CLI doesn't know capability names until proposal is complete. The capability discovery in proposal solves this.

### Decision 3: Apply Integration (RESOLVED)

**Original problem:** After planning completes (4/4 artifacts), the experimental workflow ends. No guidance on implementation.

**Key insight: No phases, just actions.**

Through discussion, we realized phases (planning â†’ implementation â†’ archive) are an artificial constraint. Work is fluid:
- You might start implementing, realize the design is wrong â†’ update design.md
- You're halfway through tasks, discover a new requirement â†’ update specs
- You bounce between "planning" and "implementing" constantly

**The better model: Actions on a Change**

A change is a thing (with artifacts). Actions are verbs you perform on a change. Actions aren't phases - they're fluid operations you can perform anytime.

| Action | What it does | Skill | CLI Command |
|--------|--------------|-------|-------------|
| `new` | Create a change (scaffold directory) | `opsx:new` | `openspec new change` |
| `continue` | Create next artifact (dependency-aware) | `opsx:continue` | `openspec instructions` |
| `apply` | Implement tasks (execute, check off) | `opsx:apply` (NEW) | TBD |
| `update` | Refresh/update artifacts based on learnings | `opsx:update` (NEW) | TBD |
| `explore` | Research, ask questions, understand | `opsx:explore` (NEW) | TBD |
| `validate` | Check artifacts are correct/complete | TBD | `openspec validate` |
| `archive` | Finalize and move to archive | existing | `openspec archive` |

**Key principles:**
- Actions are modeled as skills (primary interface for agents)
- Some skills have matching CLI commands for convenience
- Skills and CLI commands are decoupled - not everything needs both
- Actions can be performed in any order (with soft prerequisites)
- No linear phase gates

**What the schema defines:**
- Artifacts (what they are, where they go)
- Dependencies (what must exist first)
- Required vs optional
- Templates + instructions

**What the schema does NOT define:**
- Phases
- When you can modify things
- Linear workflow

**Progress tracking:**
- tasks.md checkboxes = implementation progress
- Artifact existence = planning progress
- Archive readiness = user decides (or all tasks done)

**For experimental release:**
- Create `opsx:apply` skill (guidance for implementing tasks)
- Document the "actions on a change" model
- Other actions (update, explore) can come later

---

### Design: `openspec-apply-change` Skill

#### Overview

The apply skill guides agents through implementing tasks from a completed (or in-progress) change. Unlike the old `/openspec:apply` command, this skill:
- Is **fluid** - can be invoked anytime, not just after all artifacts are done
- Allows **artifact updates** - if implementation reveals issues, update design/specs
- Works **until done** - keeps going through tasks until complete or blocked
- Tracks **progress via checkboxes** - tasks.md is the source of truth

#### Skill Metadata

```yaml
name: openspec-apply-change
description: Implement tasks from an OpenSpec change. Use when the user wants to start implementing, continue implementation, or work through tasks.
```

#### When to Invoke

The skill should be invoked when:
- User says "implement this change" or "start implementing"
- User says "work on the tasks" or "do the next task"
- User says "apply this change"
- All artifacts are complete and user wants to proceed
- User wants to continue implementation after a break

#### Input

- Optionally: change name
- Optionally: specific task number to work on
- If omitted: prompt for change selection (same pattern as continue-change)

#### Steps

```markdown
**Steps**

1. **If no change name provided, prompt for selection**

   Run `openspec list --json` to get available changes. Use **AskUserQuestion** to let user select.

   Show changes that have tasks.md (implementation-ready).
   Mark changes with incomplete tasks as "(In Progress)".

2. **Get apply instructions**

   ```bash
   openspec instructions apply --change "<name>" --json
   ```

   This returns:
   - Context file paths (proposal, specs, design, tasks)
   - Progress (total, complete, remaining)
   - Task list with status
   - Dynamic instruction based on current state

   **Handle states:**
   - If blocked (missing artifacts): show message, suggest `openspec-continue-change`
   - If all done: congratulate, suggest archive
   - Otherwise: proceed to implementation

3. **Read context files**

   Read the files listed in the instructions:
   - `proposal.md` - why and what
   - `specs/*.md` - requirements and scenarios
   - `design.md` - technical approach (if exists)
   - `tasks.md` - the implementation checklist

4. **Show current progress**

   Display:
   - Progress: "N/M tasks complete"
   - Remaining tasks overview
   - Dynamic instruction from CLI

5. **Implement tasks (loop until done or blocked)**

   For each pending task:
   - Show which task is being worked on
   - Make the code changes required
   - Keep changes minimal and focused
   - Mark task complete in tasks.md: `- [ ]` â†’ `- [x]`
   - Continue to next task

   **Pause if:**
   - Task is unclear â†’ ask for clarification
   - Implementation reveals a design issue â†’ suggest updating artifacts
   - Error or blocker encountered â†’ report and wait for guidance
   - User interrupts

6. **On completion or pause, show status**

   Display:
   - Tasks completed this session
   - Overall progress: "N/M tasks complete"
   - If all done: suggest archive
   - If paused: explain why and wait for guidance
```

#### Output Format

**During implementation:**
```
## Implementing: add-user-auth

Working on task 3/7: Create UserAuth service class
[...implementation happening...]
âœ“ Task complete

Working on task 4/7: Add login endpoint to AuthController
[...implementation happening...]
âœ“ Task complete

Working on task 5/7: Add JWT token generation
[...implementation happening...]
```

**On completion:**
```
## Implementation Complete

**Change:** add-user-auth
**Progress:** 7/7 tasks complete âœ“

### Completed This Session
- [x] Create UserAuth service class
- [x] Add login endpoint to AuthController
- [x] Add JWT token generation
- [x] Add logout endpoint
- [x] Add auth middleware
- [x] Write unit tests
- [x] Update API documentation

All tasks complete! Ready to archive this change.
```

**On pause (issue encountered):**
```
## Implementation Paused

**Change:** add-user-auth
**Progress:** 4/7 tasks complete

### Issue Encountered
Task 5 "Add JWT token generation" - the design specifies using RS256 but
the existing auth library only supports HS256.

**Options:**
1. Update design.md to use HS256 instead
2. Add a new JWT library that supports RS256
3. Other approach

What would you like to do?
```

#### Guardrails

- Keep going through tasks until done or blocked
- Always read context before starting (specs, design)
- If task is ambiguous, pause and ask before implementing
- If implementation reveals issues, pause and suggest artifact updates
- Keep code changes minimal and scoped to each task
- Update task checkbox immediately after completing each task
- Pause on errors, blockers, or unclear requirements - don't guess

#### Fluid Workflow Integration

The apply skill supports the "actions on a change" model:

**Can be invoked anytime:**
- Before all artifacts are done (if tasks.md exists)
- After partial implementation
- Interleaved with other actions (update, continue)

**Allows artifact updates:**
- If implementation reveals design issues â†’ suggest `opsx:update` or manual edit
- If requirements need clarification â†’ suggest updating specs
- Not phase-locked - work fluidly

**Example fluid workflow:**
```
User: "Implement add-user-auth"
â†’ openspec-apply-change: implements tasks 1, 2, 3, 4...
â†’ Pauses at task 5: "Design says RS256 but library only supports HS256"

User: "Let's use HS256 instead, update the design"
â†’ User edits design.md (or uses opsx:update in future)

User: "Continue implementing"
â†’ openspec-apply-change: implements tasks 5, 6, 7
â†’ "All tasks complete! Ready to archive."
```

#### CLI Commands Used

```bash
openspec list --json                        # List changes for selection
openspec status --change "<name>"           # Check artifact completion
openspec instructions apply --change "<name>" # Get apply instructions (NEW)
# File reads via Read tool for proposal, specs, design, tasks
# File edits via Edit tool for checking off tasks
```

#### New CLI Command: `openspec instructions apply`

For consistency with artifact instructions.

**Usage:**
```bash
openspec instructions apply --change "<name>" [--json]
```

**Output (Markdown format):**
```markdown
## Apply: add-user-auth

### Context Files
- proposal: openspec/changes/add-user-auth/proposal.md
- specs: openspec/changes/add-user-auth/specs/**/*.md
- design: openspec/changes/add-user-auth/design.md
- tasks: openspec/changes/add-user-auth/tasks.md

### Progress
2/7 complete

### Tasks
- [x] Create UserAuth service class
- [x] Add login endpoint
- [ ] Add JWT token generation
- [ ] Add logout endpoint
- [ ] Add auth middleware
- [ ] Write unit tests
- [ ] Update API documentation

### Instruction
Read context files, work through pending tasks, mark complete as you go.
Pause if you hit blockers or need clarification.
```

**Benefits of CLI command:**
- **Consistency** - same pattern as `openspec instructions <artifact>`
- **Structured output** - progress, tasks, context paths in one call
- **Clean format** - markdown is readable and compact (vs verbose XML)
- **Extensibility** - can add more sections later if needed
- **JSON option** - `--json` flag available for programmatic use

#### Differences from Old `/openspec:apply`

| Aspect | Old `/openspec:apply` | New `openspec-apply-change` |
|--------|----------------------|----------------------------|
| Invocation | After all artifacts done | Anytime (if tasks.md exists) |
| Granularity | All tasks at once | All tasks, but pauses on issues |
| Artifact updates | Not mentioned | Encouraged when needed |
| Progress tracking | Update all at end | Update after each task |
| Flow control | Push through everything | Pause on blockers, resume after |
| Context loading | Read once at start | Read context, reference as needed |
| Issue handling | Not specified | Pause, present options, wait for guidance |

#### Implementation Notes

1. **Add CLI command**: Add `openspec instructions apply` to artifact-workflow.ts
   - Parse tasks.md for progress (count done/pending)
   - Return context paths, progress, task list, simple instruction
2. **Add to skill-templates.ts**: Create `getApplyChangeSkillTemplate()` function
3. **Update artifact-experimental-setup**: Generate this skill alongside new/continue
4. **Update skills list**: Add to `.claude/skills/` directory
5. **Test the flow**: Verify it works with existing changes that have tasks.md

---

## Next Steps

1. ~~Review this plan and confirm scope~~ (Done - blockers identified)
2. ~~Design decisions~~ (Done - all 3 blockers resolved)
3. ~~Design apply skill~~ (Done - documented above)
4. ~~Implement proposal template change (Decision 1 - capability discovery)~~ (Done)
5. ~~Remove `openspec next` command (Decision 2a)~~ (Done)
6. ~~Add `openspec instructions apply` CLI command~~ (Done)
7. ~~Create `openspec-apply-change` skill~~ (Done)
8. Conduct E2E testing with updated workflow
9. Write user docs (document "actions on a change" model)
10. Release to test users



================================================
FILE: docs/experimental-workflow.md
================================================
# Experimental Workflow (OPSX)

> **Status:** Experimental. Things might break. Feedback welcome on [Discord](https://discord.gg/YctCnvvshC).
>
> **Compatibility:** Claude Code only (for now)

## What Is It?

OPSX is a **fluid, iterative workflow** for OpenSpec changes. No more rigid phases â€” just actions you can take anytime.

## Why This Exists

The standard OpenSpec workflow works, but it's **locked down**:

- **Instructions are hardcoded** â€” buried in TypeScript, you can't change them
- **All-or-nothing** â€” one big command creates everything, can't test individual pieces
- **Fixed structure** â€” same workflow for everyone, no customization
- **Black box** â€” when AI output is bad, you can't tweak the prompts

**OPSX opens it up.** Now anyone can:

1. **Experiment with instructions** â€” edit a template, see if the AI does better
2. **Test granularly** â€” validate each artifact's instructions independently
3. **Customize workflows** â€” define your own artifacts and dependencies
4. **Iterate quickly** â€” change a template, test immediately, no rebuild

```
Standard workflow:                    OPSX:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hardcoded in package  â”‚           â”‚  schema.yaml           â”‚â—„â”€â”€ You edit this
â”‚  (can't change)        â”‚           â”‚  templates/*.md        â”‚â—„â”€â”€ Or this
â”‚        â†“               â”‚           â”‚        â†“               â”‚
â”‚  Wait for new release  â”‚           â”‚  Instant effect        â”‚
â”‚        â†“               â”‚           â”‚        â†“               â”‚
â”‚  Hope it's better      â”‚           â”‚  Test it yourself      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**This is for everyone:**
- **Teams** â€” create workflows that match how you actually work
- **Power users** â€” tweak prompts to get better AI outputs for your codebase
- **OpenSpec contributors** â€” experiment with new approaches without releases

We're all still learning what works best. OPSX lets us learn together.

## The User Experience

**The problem with linear workflows:**
You're "in planning phase", then "in implementation phase", then "done". But real work doesn't work that way. You implement something, realize your design was wrong, need to update specs, continue implementing. Linear phases fight against how work actually happens.

**OPSX approach:**
- **Actions, not phases** â€” create, implement, update, archive â€” do any of them anytime
- **Dependencies are enablers** â€” they show what's possible, not what's required next
- **Update as you learn** â€” halfway through implementation? Go back and fix the design. That's normal.

```
You can always go back:

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                    â”‚
     â–¼                                    â”‚
  proposal â”€â”€â†’ specs â”€â”€â†’ design â”€â”€â†’ tasks â”€â”€â†’ implement
     â–²           â–²          â–²               â”‚
     â”‚           â”‚          â”‚               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              update as you learn
```

## Setup

```bash
# 1. Make sure you have openspec installed and initialized
openspec init

# 2. Generate the experimental skills
openspec experimental
```

This creates skills in `.claude/skills/` that Claude Code auto-detects.

During setup, you'll be prompted to create a **project config** (`openspec/config.yaml`). This is optional but recommended.

## Project Configuration

Project config lets you set defaults and inject project-specific context into all artifacts.

### Creating Config

Config is created during `experimental`, or manually:

```yaml
# openspec/config.yaml
schema: spec-driven

context: |
  Tech stack: TypeScript, React, Node.js
  API conventions: RESTful, JSON responses
  Testing: Vitest for unit tests, Playwright for e2e
  Style: ESLint with Prettier, strict TypeScript

rules:
  proposal:
    - Include rollback plan
    - Identify affected teams
  specs:
    - Use Given/When/Then format for scenarios
  design:
    - Include sequence diagrams for complex flows
```

### Config Fields

| Field | Type | Description |
|-------|------|-------------|
| `schema` | string | Default schema for new changes (e.g., `spec-driven`, `tdd`) |
| `context` | string | Project context injected into all artifact instructions |
| `rules` | object | Per-artifact rules, keyed by artifact ID |

### How It Works

**Schema precedence** (highest to lowest):
1. CLI flag (`--schema tdd`)
2. Change metadata (`.openspec.yaml` in change directory)
3. Project config (`openspec/config.yaml`)
4. Default (`spec-driven`)

**Context injection:**
- Context is prepended to every artifact's instructions
- Wrapped in `<context>...</context>` tags
- Helps AI understand your project's conventions

**Rules injection:**
- Rules are only injected for matching artifacts
- Wrapped in `<rules>...</rules>` tags
- Appear after context, before the template

### Artifact IDs by Schema

**spec-driven** (default):
- `proposal` â€” Change proposal
- `specs` â€” Specifications
- `design` â€” Technical design
- `tasks` â€” Implementation tasks

**tdd**:
- `spec` â€” Feature specification
- `tests` â€” Test file
- `implementation` â€” Implementation code
- `docs` â€” Documentation

### Config Validation

- Unknown artifact IDs in `rules` generate warnings
- Schema names are validated against available schemas
- Context has a 50KB size limit
- Invalid YAML is reported with line numbers

### Troubleshooting

**"Unknown artifact ID in rules: X"**
- Check artifact IDs match your schema (see list above)
- Run `openspec schemas --json` to see artifact IDs for each schema

**Config not being applied:**
- Ensure file is at `openspec/config.yaml` (not `.yml`)
- Check YAML syntax with a validator
- Config changes take effect immediately (no restart needed)

**Context too large:**
- Context is limited to 50KB
- Summarize or link to external docs instead

## Commands

| Command | What it does |
|---------|--------------|
| `/opsx:explore` | Think through ideas, investigate problems, clarify requirements |
| `/opsx:new` | Start a new change |
| `/opsx:continue` | Create the next artifact (based on what's ready) |
| `/opsx:ff` | Fast-forward â€” create all planning artifacts at once |
| `/opsx:apply` | Implement tasks, updating artifacts as needed |
| `/opsx:sync` | Sync delta specs to main specs |
| `/opsx:archive` | Archive when done |

## Usage

### Explore an idea
```
/opsx:explore
```
Think through ideas, investigate problems, compare options. No structure required - just a thinking partner. When insights crystallize, transition to `/opsx:new` or `/opsx:ff`.

### Start a new change
```
/opsx:new
```
You'll be asked what you want to build and which workflow schema to use.

### Create artifacts
```
/opsx:continue
```
Shows what's ready to create based on dependencies, then creates one artifact. Use repeatedly to build up your change incrementally.

```
/opsx:ff add-dark-mode
```
Creates all planning artifacts at once. Use when you have a clear picture of what you're building.

### Implement (the fluid part)
```
/opsx:apply
```
Works through tasks, checking them off as you go. **Key difference:** if you discover issues during implementation, you can update your specs, design, or tasks â€” then continue. No phase gates. If you're juggling multiple changes, you can run `/opsx:apply <name>`; otherwise it should infer from the conversation and prompt you to choose if it canâ€™t tell.

### Finish up
```
/opsx:sync      # Update main specs with your delta specs
/opsx:archive   # Move to archive when done
```

## When to Update vs. Start Fresh

OPSX lets you update artifacts anytime. But when does "update as you learn" become "this is different work"?

### What a Proposal Captures

A proposal defines three things:
1. **Intent** â€” What problem are you solving?
2. **Scope** â€” What's in/out of bounds?
3. **Approach** â€” How will you solve it?

The question is: which changed, and by how much?

### Update the Existing Change When:

**Same intent, refined execution**
- You discover edge cases you didn't consider
- The approach needs tweaking but the goal is unchanged
- Implementation reveals the design was slightly off

**Scope narrows**
- You realize full scope is too big, want to ship MVP first
- "Add dark mode" â†’ "Add dark mode toggle (system preference in v2)"

**Learning-driven corrections**
- Codebase isn't structured how you thought
- A dependency doesn't work as expected
- "Use CSS variables" â†’ "Use Tailwind's dark: prefix instead"

### Start a New Change When:

**Intent fundamentally changed**
- The problem itself is different now
- "Add dark mode" â†’ "Add comprehensive theme system with custom colors, fonts, spacing"

**Scope exploded**
- Change grew so much it's essentially different work
- Original proposal would be unrecognizable after updates
- "Fix login bug" â†’ "Rewrite auth system"

**Original is completable**
- The original change can be marked "done"
- New work stands alone, not a refinement
- Complete "Add dark mode MVP" â†’ Archive â†’ New change "Enhance dark mode"

### The Heuristics

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     Is this the same work?          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
                    â–¼                  â–¼                  â–¼
             Same intent?      >50% overlap?      Can original
             Same problem?     Same scope?        be "done" without
                    â”‚                  â”‚          these changes?
                    â”‚                  â”‚                  â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚  â”‚             â”‚   â”‚               â”‚
         YES               NO YES           NO  NO              YES
          â”‚                 â”‚  â”‚             â”‚   â”‚               â”‚
          â–¼                 â–¼  â–¼             â–¼   â–¼               â–¼
       UPDATE            NEW  UPDATE       NEW  UPDATE          NEW
```

| Test | Update | New Change |
|------|--------|------------|
| **Identity** | "Same thing, refined" | "Different work" |
| **Scope overlap** | >50% overlaps | <50% overlaps |
| **Completion** | Can't be "done" without changes | Can finish original, new work stands alone |
| **Story** | Update chain tells coherent story | Patches would confuse more than clarify |

### The Principle

> **Update preserves context. New change provides clarity.**
>
> Choose update when the history of your thinking is valuable.
> Choose new when starting fresh would be clearer than patching.

Think of it like git branches:
- Keep committing while working on the same feature
- Start a new branch when it's genuinely new work
- Sometimes merge a partial feature and start fresh for phase 2

## What's Different?

| | Standard (`/openspec:proposal`) | Experimental (`/opsx:*`) |
|---|---|---|
| **Structure** | One big proposal document | Discrete artifacts with dependencies |
| **Workflow** | Linear phases: plan â†’ implement â†’ archive | Fluid actions â€” do anything anytime |
| **Iteration** | Awkward to go back | Update artifacts as you learn |
| **Customization** | Fixed structure | Schema-driven (define your own artifacts) |

**The key insight:** work isn't linear. OPSX stops pretending it is.

## Architecture Deep Dive

This section explains how OPSX works under the hood and how it compares to the standard workflow.

### Philosophy: Phases vs Actions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STANDARD WORKFLOW                                    â”‚
â”‚                    (Phase-Locked, All-or-Nothing)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚   PLANNING   â”‚ â”€â”€â”€â–º â”‚ IMPLEMENTING â”‚ â”€â”€â”€â–º â”‚   ARCHIVING  â”‚             â”‚
â”‚   â”‚    PHASE     â”‚      â”‚    PHASE     â”‚      â”‚    PHASE     â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                     â”‚                     â”‚                       â”‚
â”‚         â–¼                     â–¼                     â–¼                       â”‚
â”‚   /openspec:proposal   /openspec:apply      /openspec:archive              â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Creates ALL artifacts at once                                          â”‚
â”‚   â€¢ Can't go back to update specs during implementation                    â”‚
â”‚   â€¢ Phase gates enforce linear progression                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            OPSX WORKFLOW                                     â”‚
â”‚                      (Fluid Actions, Iterative)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚              â”‚           ACTIONS (not phases)             â”‚                 â”‚
â”‚              â”‚                                            â”‚                 â”‚
â”‚              â”‚   new â—„â”€â”€â–º continue â—„â”€â”€â–º apply â—„â”€â”€â–º sync   â”‚                 â”‚
â”‚              â”‚    â”‚          â”‚           â”‚          â”‚     â”‚                 â”‚
â”‚              â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                 â”‚
â”‚              â”‚              any order                     â”‚                 â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Create artifacts one at a time OR fast-forward                         â”‚
â”‚   â€¢ Update specs/design/tasks during implementation                        â”‚
â”‚   â€¢ Dependencies enable progress, phases don't exist                       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

**Standard workflow** uses hardcoded templates in TypeScript:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STANDARD WORKFLOW COMPONENTS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Hardcoded Templates (TypeScript strings)                                  â”‚
â”‚                    â”‚                                                        â”‚
â”‚                    â–¼                                                        â”‚
â”‚   Configurators (18+ classes, one per editor)                               â”‚
â”‚                    â”‚                                                        â”‚
â”‚                    â–¼                                                        â”‚
â”‚   Generated Command Files (.claude/commands/openspec/*.md)                  â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Fixed structure, no artifact awareness                                  â”‚
â”‚   â€¢ Change requires code modification + rebuild                             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**OPSX** uses external schemas and a dependency graph engine:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OPSX COMPONENTS                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Schema Definitions (YAML)                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  name: spec-driven                                                  â”‚   â”‚
â”‚   â”‚  artifacts:                                                         â”‚   â”‚
â”‚   â”‚    - id: proposal                                                   â”‚   â”‚
â”‚   â”‚      generates: proposal.md                                         â”‚   â”‚
â”‚   â”‚      requires: []              â—„â”€â”€ Dependencies                     â”‚   â”‚
â”‚   â”‚    - id: specs                                                      â”‚   â”‚
â”‚   â”‚      generates: specs/**/*.md  â—„â”€â”€ Glob patterns                    â”‚   â”‚
â”‚   â”‚      requires: [proposal]      â—„â”€â”€ Enables after proposal           â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    â”‚                                                        â”‚
â”‚                    â–¼                                                        â”‚
â”‚   Artifact Graph Engine                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  â€¢ Topological sort (dependency ordering)                           â”‚   â”‚
â”‚   â”‚  â€¢ State detection (filesystem existence)                           â”‚   â”‚
â”‚   â”‚  â€¢ Rich instruction generation (templates + context)                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    â”‚                                                        â”‚
â”‚                    â–¼                                                        â”‚
â”‚   Skill Files (.claude/skills/openspec-*/SKILL.md)                          â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Cross-editor compatible (Claude Code, Cursor, Windsurf)                 â”‚
â”‚   â€¢ Skills query CLI for structured data                                    â”‚
â”‚   â€¢ Fully customizable via schema files                                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dependency Graph Model

Artifacts form a directed acyclic graph (DAG). Dependencies are **enablers**, not gates:

```
                              proposal
                             (root node)
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                           â”‚
                    â–¼                           â–¼
                 specs                       design
              (requires:                  (requires:
               proposal)                   proposal)
                    â”‚                           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                               tasks
                           (requires:
                           specs, design)
                                  â”‚
                                  â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ APPLY PHASE  â”‚
                          â”‚ (requires:   â”‚
                          â”‚  tasks)      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**State transitions:**

```
   BLOCKED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º READY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DONE
      â”‚                        â”‚                       â”‚
   Missing                  All deps               File exists
   dependencies             are DONE               on filesystem
```

### Information Flow

**Standard workflow** â€” agent receives static instructions:

```
  User: "/openspec:proposal"
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Static instructions:                   â”‚
  â”‚  â€¢ Create proposal.md                   â”‚
  â”‚  â€¢ Create tasks.md                      â”‚
  â”‚  â€¢ Create design.md                     â”‚
  â”‚  â€¢ Create specs/*.md                    â”‚
  â”‚                                         â”‚
  â”‚  No awareness of what exists or         â”‚
  â”‚  dependencies between artifacts         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  Agent creates ALL artifacts in one go
```

**OPSX** â€” agent queries for rich context:

```
  User: "/opsx:continue"
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Step 1: Query current state                                             â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚  $ openspec status --change "add-auth" --json                      â”‚  â”‚
  â”‚  â”‚                                                                    â”‚  â”‚
  â”‚  â”‚  {                                                                 â”‚  â”‚
  â”‚  â”‚    "artifacts": [                                                  â”‚  â”‚
  â”‚  â”‚      {"id": "proposal", "status": "done"},                         â”‚  â”‚
  â”‚  â”‚      {"id": "specs", "status": "ready"},      â—„â”€â”€ First ready      â”‚  â”‚
  â”‚  â”‚      {"id": "design", "status": "ready"},                          â”‚  â”‚
  â”‚  â”‚      {"id": "tasks", "status": "blocked", "missingDeps": ["specs"]}â”‚  â”‚
  â”‚  â”‚    ]                                                               â”‚  â”‚
  â”‚  â”‚  }                                                                 â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                                                                          â”‚
  â”‚  Step 2: Get rich instructions for ready artifact                        â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚  $ openspec instructions specs --change "add-auth" --json          â”‚  â”‚
  â”‚  â”‚                                                                    â”‚  â”‚
  â”‚  â”‚  {                                                                 â”‚  â”‚
  â”‚  â”‚    "template": "# Specification\n\n## ADDED Requirements...",      â”‚  â”‚
  â”‚  â”‚    "dependencies": [{"id": "proposal", "path": "...", "done": true}â”‚  â”‚
  â”‚  â”‚    "unlocks": ["tasks"]                                            â”‚  â”‚
  â”‚  â”‚  }                                                                 â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                                                                          â”‚
  â”‚  Step 3: Read dependencies â†’ Create ONE artifact â†’ Show what's unlocked  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Iteration Model

**Standard workflow** â€” awkward to iterate:

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚/proposalâ”‚ â”€â”€â–º â”‚ /apply  â”‚ â”€â”€â–º â”‚/archive â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚
       â”‚               â”œâ”€â”€ "Wait, the design is wrong"
       â”‚               â”‚
       â”‚               â”œâ”€â”€ Options:
       â”‚               â”‚   â€¢ Edit files manually (breaks context)
       â”‚               â”‚   â€¢ Abandon and start over
       â”‚               â”‚   â€¢ Push through and fix later
       â”‚               â”‚
       â”‚               â””â”€â”€ No official "go back" mechanism
       â”‚
       â””â”€â”€ Creates ALL artifacts at once
```

**OPSX** â€” natural iteration:

```
  /opsx:new â”€â”€â”€â–º /opsx:continue â”€â”€â”€â–º /opsx:apply â”€â”€â”€â–º /opsx:archive
      â”‚                â”‚                  â”‚
      â”‚                â”‚                  â”œâ”€â”€ "The design is wrong"
      â”‚                â”‚                  â”‚
      â”‚                â”‚                  â–¼
      â”‚                â”‚            Just edit design.md
      â”‚                â”‚            and continue!
      â”‚                â”‚                  â”‚
      â”‚                â”‚                  â–¼
      â”‚                â”‚         /opsx:apply picks up
      â”‚                â”‚         where you left off
      â”‚                â”‚
      â”‚                â””â”€â”€ Creates ONE artifact, shows what's unlocked
      â”‚
      â””â”€â”€ Scaffolds change, waits for direction
```

### Custom Schemas

Create custom workflows using the schema management commands:

```bash
# Create a new schema from scratch (interactive)
openspec schema init my-workflow

# Or fork an existing schema as a starting point
openspec schema fork spec-driven my-workflow

# Validate your schema structure
openspec schema validate my-workflow

# See where a schema resolves from (useful for debugging)
openspec schema which my-workflow
```

Schemas are stored in `openspec/schemas/` (project-local, version controlled) or `~/.local/share/openspec/schemas/` (user global).

**Schema structure:**
```
openspec/schemas/research-first/
â”œâ”€â”€ schema.yaml
â””â”€â”€ templates/
    â”œâ”€â”€ research.md
    â”œâ”€â”€ proposal.md
    â””â”€â”€ tasks.md
```

**Example schema.yaml:**
```yaml
name: research-first
artifacts:
  - id: research        # Added before proposal
    generates: research.md
    requires: []

  - id: proposal
    generates: proposal.md
    requires: [research]  # Now depends on research

  - id: tasks
    generates: tasks.md
    requires: [proposal]
```

**Dependency Graph:**
```
   research â”€â”€â–º proposal â”€â”€â–º tasks
```

### Summary

| Aspect | Standard | OPSX |
|--------|----------|------|
| **Templates** | Hardcoded TypeScript | External YAML + Markdown |
| **Dependencies** | None (all at once) | DAG with topological sort |
| **State** | Phase-based mental model | Filesystem existence |
| **Customization** | Edit source, rebuild | Create schema.yaml |
| **Iteration** | Phase-locked | Fluid, edit anything |
| **Editor Support** | 18+ configurator classes | Single skills directory |

## Schemas

Schemas define what artifacts exist and their dependencies. Currently available:

- **spec-driven** (default): proposal â†’ specs â†’ design â†’ tasks
- **tdd**: tests â†’ implementation â†’ docs

```bash
# List available schemas
openspec schemas

# See all schemas with their resolution sources
openspec schema which --all

# Create a new schema interactively
openspec schema init my-workflow

# Fork an existing schema for customization
openspec schema fork spec-driven my-workflow

# Validate schema structure before use
openspec schema validate my-workflow
```

## Tips

- Use `/opsx:explore` to think through an idea before committing to a change
- `/opsx:ff` when you know what you want, `/opsx:continue` when exploring
- During `/opsx:apply`, if something's wrong â€” fix the artifact, then continue
- Tasks track progress via checkboxes in `tasks.md`
- Check status anytime: `openspec status --change "name"`

## Feedback

This is rough. That's intentional â€” we're learning what works.

Found a bug? Have ideas? Join us on [Discord](https://discord.gg/YctCnvvshC) or open an issue on [GitHub](https://github.com/Fission-AI/openspec/issues).



================================================
FILE: docs/project-config-demo.md
================================================
# Project Config Demo Guide

A quick-reference guide for demonstrating the `openspec/config.yaml` feature.

## Summary: What Project Config Does

The feature adds `openspec/config.yaml` as a lightweight customization layer that lets teams:

- **Set a default schema** - New changes automatically use this schema instead of having to specify `--schema` every time
- **Inject project context** - Shared context (tech stack, conventions) shown to AI when creating any artifact
- **Add per-artifact rules** - Custom rules that only apply to specific artifacts (e.g., proposal, specs)

## Demo Walkthrough

### Demo 1: Interactive Setup (Recommended Entry Point)

The easiest way to demo is through the experimental setup command:

```bash
openspec artifact-experimental-setup
```

After creating skills/commands, it will prompt:

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ Project Configuration (Optional)

Configure project defaults for OpenSpec workflows.

? Create openspec/config.yaml? (Y/n)
```

Walk through:

1. **Select schema** - Shows available schemas with their artifact flows
2. **Add context** - Opens editor for multi-line project context (tech stack, conventions)
3. **Add rules** - Checkbox to select artifacts, then line-by-line rule entry

This creates `openspec/config.yaml` with the user's choices.

### Demo 2: Manual Config Creation

Show that users can create the config directly:

```bash
cat > openspec/config.yaml << 'EOF'
schema: spec-driven

context: |
  Tech stack: TypeScript, React, Node.js, PostgreSQL
  API style: RESTful, documented in docs/api.md
  Testing: Jest + React Testing Library
  We value backwards compatibility for all public APIs

rules:
  proposal:
    - Include rollback plan
    - Identify affected teams and notify in #platform-changes
  specs:
    - Use Given/When/Then format
    - Reference existing patterns before inventing new ones
EOF
```

### Demo 3: Effect on New Changes

Show that creating a new change now uses the default schema:

```bash
# Before config: had to specify schema
openspec new change my-feature --schema spec-driven

# After config: schema is automatic
openspec new change my-feature
# Automatically uses spec-driven from config
```

### Demo 4: Context and Rules Injection

The key demo moment - show how instructions are enriched:

```bash
# Get instructions for an artifact
openspec instructions proposal --change my-feature
```

Output shows the XML structure:

```xml
<context>
Tech stack: TypeScript, React, Node.js, PostgreSQL
API style: RESTful, documented in docs/api.md
...
</context>

<rules>
- Include rollback plan
- Identify affected teams and notify in #platform-changes
</rules>

<template>
[Schema's built-in proposal template]
</template>
```

Key points to highlight:

- **Context** appears in ALL artifacts (proposal, specs, design, tasks)
- **Rules** ONLY appear for the matching artifact (proposal rules only in proposal instructions)

### Demo 5: Precedence Override

Show the schema resolution order:

```bash
# Config sets schema: spec-driven

# 1. CLI flag wins
openspec new change feature-a --schema tdd  # Uses tdd

# 2. Change metadata wins over config
# (if .openspec.yaml in change directory specifies schema)

# 3. Config is used as default
openspec new change feature-b  # Uses spec-driven from config

# 4. Hardcoded default (no config)
# Would fall back to spec-driven anyway
```

### Demo 6: Validation and Error Handling

Show graceful error handling:

```bash
# Create config with typo
echo "schema: spec-drivne" > openspec/config.yaml

# Try to use it - shows fuzzy matching suggestions
openspec new change test
# Schema 'spec-drivne' not found
# Did you mean: spec-driven (built-in)
```

```bash
# Unknown artifact ID in rules - warns but doesn't halt
cat > openspec/config.yaml << 'EOF'
schema: spec-driven
rules:
  testplan:  # Schema doesn't have this
    - Some rule
EOF

openspec instructions proposal --change test
# âš ï¸ Unknown artifact ID in rules: "testplan". Valid IDs for schema "spec-driven": ...
# (continues working)
```

## Quick Demo Script

Here's a quick all-in-one demo:

```bash
# 1. Show there's no config initially
cat openspec/config.yaml 2>/dev/null || echo "No config exists"

# 2. Create a simple config
cat > openspec/config.yaml << 'EOF'
schema: spec-driven
context: |
  This is a demo project using React and TypeScript.
  We follow semantic versioning.
rules:
  proposal:
    - Include migration steps if breaking change
EOF

# 3. Show the config
cat openspec/config.yaml

# 4. Create a change (uses default schema from config)
openspec new change demo-feature

# 5. Show instructions with injected context/rules
openspec instructions proposal --change demo-feature | head -30

# 6. Show that specs don't have proposal rules
openspec instructions specs --change demo-feature | head -30
```

## What to Emphasize in Demo

- **Low friction** - Teams can customize without forking schemas
- **Shared context** - Everyone on the team gets the same project knowledge
- **Per-artifact rules** - Targeted guidance where it matters
- **Graceful failures** - Typos warn, don't break workflow
- **Team sharing** - Just commit `openspec/config.yaml` and everyone benefits

## Related Documentation

- [Experimental Workflow Guide](./experimental-workflow.md) - Full user guide with config section
- [Project Config Proposal](../openspec/changes/project-config/proposal.md) - Original design proposal
- [Project Config Design](../openspec/changes/project-config/design.md) - Technical implementation details



================================================
FILE: docs/schema-customization.md
================================================
# Schema Customization

This document describes how users can customize OpenSpec schemas and templates, the current manual process, and the gap that needs to be addressed.

---

## Overview

OpenSpec uses a 2-level schema resolution system following the XDG Base Directory Specification:

1. **User override**: `${XDG_DATA_HOME}/openspec/schemas/<name>/`
2. **Package built-in**: `<npm-package>/schemas/<name>/`

When a schema is requested (e.g., `spec-driven`), the resolver checks the user directory first. If found, that entire schema directory is used. Otherwise, it falls back to the package's built-in schema.

---

## Current Manual Process

To override the default `spec-driven` schema, a user must:

### 1. Determine the correct directory path

| Platform | Path |
|----------|------|
| macOS/Linux | `~/.local/share/openspec/schemas/` |
| Windows | `%LOCALAPPDATA%\openspec\schemas\` |
| All (if set) | `$XDG_DATA_HOME/openspec/schemas/` |

### 2. Create the directory structure

```bash
# macOS/Linux example
mkdir -p ~/.local/share/openspec/schemas/spec-driven/templates
```

### 3. Find and copy the default schema files

The user must locate the installed npm package to copy the defaults:

```bash
# Find the package location (varies by install method)
npm list -g openspec --parseable
# or
which openspec && readlink -f $(which openspec)

# Copy files from the package's schemas/ directory
cp <package-path>/schemas/spec-driven/schema.yaml ~/.local/share/openspec/schemas/spec-driven/
cp <package-path>/schemas/spec-driven/templates/*.md ~/.local/share/openspec/schemas/spec-driven/templates/
```

### 4. Modify the copied files

Edit `schema.yaml` to change the workflow structure:

```yaml
name: spec-driven
version: 1
description: My custom workflow
artifacts:
  - id: proposal
    generates: proposal.md
    description: Initial proposal
    template: proposal.md
    requires: []
  # Add, remove, or modify artifacts...
```

Edit templates in `templates/` to customize the content guidance.

### 5. Verify the override is active

Currently there's no command to verify which schema is being used. Users must trust that the file exists in the right location.

---

## Gap Analysis

The current process has several friction points:

| Issue | Impact |
|-------|--------|
| **Path discovery** | Users must know XDG conventions and platform-specific paths |
| **Package location** | Finding the npm package path varies by install method (global, local, pnpm, yarn, volta, etc.) |
| **No scaffolding** | Users must manually create directories and copy files |
| **No verification** | No way to confirm which schema is actually being resolved |
| **No diffing** | When upgrading openspec, users can't see what changed in built-in templates |
| **Full copy required** | Must copy entire schema even to change one template |

### User Stories Not Currently Supported

1. *"I want to add a `research` artifact before `proposal`"* â€” requires manual copy and edit
2. *"I want to customize just the proposal template"* â€” must copy entire schema
3. *"I want to see what the default schema looks like"* â€” must find package path
4. *"I want to revert to defaults"* â€” must delete files and hope paths are correct
5. *"I upgraded openspec, did the templates change?"* â€” no way to diff

---

## Proposed Solution: Schema Configurator

A CLI command (or set of commands) that handles path resolution and file operations for users.

### Option A: Single `openspec schema` command

```bash
# List available schemas (built-in and user overrides)
openspec schema list

# Show where a schema resolves from
openspec schema which spec-driven
# Output: /Users/me/.local/share/openspec/schemas/spec-driven/ (user override)
# Output: /usr/local/lib/node_modules/openspec/schemas/spec-driven/ (built-in)

# Copy a built-in schema to user directory for customization
openspec schema copy spec-driven
# Creates ~/.local/share/openspec/schemas/spec-driven/ with all files

# Show diff between user override and built-in
openspec schema diff spec-driven

# Remove user override (revert to built-in)
openspec schema reset spec-driven

# Validate a schema
openspec schema validate spec-driven
```

### Option B: Dedicated `openspec customize` command

```bash
# Interactive schema customization
openspec customize
# Prompts: Which schema? What do you want to change? etc.

# Copy and open for editing
openspec customize spec-driven
# Copies to user dir, prints path, optionally opens in $EDITOR
```

### Option C: Init-time schema selection

```bash
# During project init, offer schema customization
openspec init
# ? Select a workflow schema:
#   > spec-driven (default)
#     tdd
#     minimal
#     custom (copy and edit)
```

### Recommended Approach

**Option A** provides the most flexibility and follows Unix conventions (subcommands for discrete operations). Key commands in priority order:

1. `openspec schema list` â€” see what's available
2. `openspec schema which <name>` â€” debug resolution
3. `openspec schema copy <name>` â€” scaffold customization
4. `openspec schema diff <name>` â€” compare with built-in
5. `openspec schema reset <name>` â€” revert to defaults

---

## Implementation Considerations

### Path Resolution

The resolver already exists in `src/core/artifact-graph/resolver.ts`:

```typescript
export function getPackageSchemasDir(): string { ... }
export function getUserSchemasDir(): string { ... }
export function getSchemaDir(name: string): string | null { ... }
export function listSchemas(): string[] { ... }
```

New commands would leverage these existing functions.

### File Operations

- Copy should preserve file permissions
- Copy should not overwrite existing user files without `--force`
- Reset should prompt for confirmation

### Template-Only Overrides

A future enhancement could support overriding individual templates without copying the entire schema. This would require changes to the resolution logic:

```
Current: schema dir (user) OR schema dir (built-in)
Future:  schema.yaml from user OR built-in
         + each template from user OR built-in (independent fallback)
```

This adds complexity but enables the "I just want to change one template" use case.

---

## Related Documents

- [Schema Workflow Gaps](./schema-workflow-gaps.md) â€” End-to-end workflow analysis and phased implementation plan

## Related Files

| File | Purpose |
|------|---------|
| `src/core/artifact-graph/resolver.ts` | Schema resolution logic |
| `src/core/artifact-graph/instruction-loader.ts` | Template loading |
| `src/core/global-config.ts` | XDG path helpers |
| `schemas/spec-driven/` | Default schema and templates |



================================================
FILE: docs/schema-workflow-gaps.md
================================================
# Schema Workflow: End-to-End Analysis

This document analyzes the complete user journey for working with schemas in OpenSpec, identifies gaps, and proposes a phased solution.

---

## Current State

### What Exists

| Component | Status |
|-----------|--------|
| Schema resolution | 3-level: project â†’ user â†’ package (PR #522) |
| Built-in schemas | `spec-driven`, `tdd` |
| Artifact workflow commands | `status`, `next`, `instructions`, `templates` with `--schema` flag |
| Change creation | `openspec new change <name>` â€” no schema binding |
| Project-local schemas | âœ… Supported via `openspec/schemas/` (PR #522) |
| Schema management CLI | âœ… `schema which`, `validate`, `fork`, `init` (PR #525) |

### What's Missing

| Component | Status |
|-----------|--------|
| Schema bound to change | Not stored â€” must pass `--schema` every time |
| Project default schema | None â€” hardcoded to `spec-driven` |

---

## User Journey Analysis

### Scenario 1: Using a Non-Default Schema

**Goal:** User wants to use TDD workflow for a new feature.

**Today's experience:**
```bash
openspec new change add-auth
# Creates directory, no schema info stored

openspec status --change add-auth
# Shows spec-driven artifacts (WRONG - user wanted TDD)

# User realizes mistake...
openspec status --change add-auth --schema tdd
# Correct, but must remember --schema every time

# 6 months later...
openspec status --change add-auth
# Wrong again - nobody remembers this was TDD
```

**Problems:**
- Schema is a runtime argument, not persisted
- Easy to forget `--schema` and get wrong results
- No record of intended schema for future reference

---

### Scenario 2: Customizing a Schema

**Goal:** User wants to add a "research" artifact before "proposal".

**Today's experience:**
```bash
# Step 1: Figure out where to put overrides
# Must know XDG conventions:
#   macOS/Linux: ~/.local/share/openspec/schemas/
#   Windows: %LOCALAPPDATA%\openspec\schemas/

# Step 2: Create directory structure
mkdir -p ~/.local/share/openspec/schemas/my-workflow/templates

# Step 3: Find the npm package to copy defaults
npm list -g openspec --parseable
# Output varies by package manager:
#   npm: /usr/local/lib/node_modules/openspec
#   pnpm: ~/.local/share/pnpm/global/5/node_modules/openspec
#   volta: ~/.volta/tools/image/packages/openspec/...
#   yarn: ~/.config/yarn/global/node_modules/openspec

# Step 4: Copy files
cp -r <package-path>/schemas/spec-driven/* \
      ~/.local/share/openspec/schemas/my-workflow/

# Step 5: Edit schema.yaml and templates
# No way to verify override is active
# No way to diff against original
```

**Problems:**
- Must know XDG path conventions
- Finding npm package path varies by install method
- No tooling to scaffold or verify
- No diff capability when upgrading openspec

---

### Scenario 3: Team Sharing Custom Workflow

**Goal:** Team wants everyone to use the same custom schema.

**Today's options:**
1. Everyone manually sets up XDG override â€” error-prone, drift risk
2. Document setup in README â€” still manual, easy to miss
3. Publish separate npm package â€” overkill for most teams
4. Check schema into repo â€” **not supported** (no project-local resolution)

**Problems:**
- No project-local schema resolution
- Can't version control custom schemas with the codebase
- No single source of truth for team workflow

---

## Gap Summary

| Gap | Impact | Status |
|-----|--------|--------|
| Schema not bound to change | Wrong results, forgotten context | â³ Pending (Phase 1) |
| No project-local schemas | Can't share via repo | âœ… Fixed (PR #522) |
| No schema management CLI | Manual path hunting | âœ… Fixed (PR #525) |
| No project default schema | Must specify every time | â³ Pending (Phase 4) |
| No init-time schema selection | Missed setup opportunity | â³ Pending (Phase 4) |

---

## Proposed Architecture

### New File Structure

```
openspec/
â”œâ”€â”€ config.yaml                 # Project config (NEW)
â”œâ”€â”€ schemas/                    # Project-local schemas (NEW)
â”‚   â””â”€â”€ my-workflow/
â”‚       â”œâ”€â”€ schema.yaml
â”‚       â””â”€â”€ templates/
â”‚           â”œâ”€â”€ research.md
â”‚           â”œâ”€â”€ proposal.md
â”‚           â””â”€â”€ ...
â””â”€â”€ changes/
    â””â”€â”€ add-auth/
        â”œâ”€â”€ change.yaml         # Change metadata (NEW)
        â”œâ”€â”€ proposal.md
        â””â”€â”€ ...
```

### config.yaml (Project Config)

```yaml
# openspec/config.yaml
defaultSchema: spec-driven
```

Sets the project-wide default schema. Used when:
- Creating new changes without `--schema`
- Running commands on changes without `change.yaml`

### change.yaml (Change Metadata)

```yaml
# openspec/changes/add-auth/change.yaml
schema: tdd
created: 2025-01-15T10:30:00Z
description: Add user authentication system
```

Binds a specific schema to a change. Created automatically by `openspec new change`.

### Schema Resolution Order

```
1. ./openspec/schemas/<name>/                    # Project-local
2. ~/.local/share/openspec/schemas/<name>/       # User global (XDG)
3. <npm-package>/schemas/<name>/                 # Built-in
```

Project-local takes priority, enabling version-controlled custom schemas.

### Schema Selection Order (Per Command)

```
1. --schema CLI flag                    # Explicit override
2. change.yaml in change directory      # Change-specific binding
3. openspec/config.yaml defaultSchema   # Project default
4. "spec-driven"                        # Hardcoded fallback
```

---

## Ideal User Experience

### Creating a Change

```bash
# Uses project default (from config.yaml, or spec-driven)
openspec new change add-auth
# Creates openspec/changes/add-auth/change.yaml:
#   schema: spec-driven
#   created: 2025-01-15T10:30:00Z

# Explicit schema for this change
openspec new change add-auth --schema tdd
# Creates change.yaml with schema: tdd
```

### Working with Changes

```bash
# Auto-reads schema from change.yaml â€” no --schema needed
openspec status --change add-auth
# Output: "Change: add-auth (schema: tdd)"
# Shows which artifacts are ready/blocked/done

# Explicit override still works (with informational message)
openspec status --change add-auth --schema spec-driven
# "Note: change.yaml specifies 'tdd', using 'spec-driven' per --schema flag"
```

### Customizing Schemas

```bash
# See what's available
openspec schema list
# Built-in:
#   spec-driven    proposal â†’ specs â†’ design â†’ tasks
#   tdd            spec â†’ tests â†’ implementation â†’ docs
# Project: (none)
# User: (none)

# Copy to project for customization
openspec schema copy spec-driven my-workflow
# Created ./openspec/schemas/my-workflow/
# Edit schema.yaml and templates/ to customize

# Copy to global (user-level override)
openspec schema copy spec-driven --global
# Created ~/.local/share/openspec/schemas/spec-driven/

# See where a schema resolves from
openspec schema which spec-driven
# ./openspec/schemas/spec-driven/ (project)
# or: ~/.local/share/openspec/schemas/spec-driven/ (user)
# or: /usr/local/lib/node_modules/openspec/schemas/spec-driven/ (built-in)

# Compare override with built-in
openspec schema diff spec-driven
# Shows diff between user/project version and package built-in

# Remove override, revert to built-in
openspec schema reset spec-driven
# Removes ./openspec/schemas/spec-driven/ (or --global for user dir)
```

### Project Setup

```bash
openspec init
# ? Select default workflow schema:
#   > spec-driven (proposal â†’ specs â†’ design â†’ tasks)
#     tdd (spec â†’ tests â†’ implementation â†’ docs)
#     (custom schemas if detected)
#
# Writes to openspec/config.yaml:
#   defaultSchema: spec-driven
```

---

## Implementation Phases

### Phase 1: Change Metadata (change.yaml)

**Priority:** High
**Solves:** "Forgot --schema", lost context, wrong results

**Scope:**
- Create `change.yaml` when running `openspec new change`
- Store `schema`, `created` timestamp
- Modify workflow commands to read schema from `change.yaml`
- `--schema` flag overrides (with informational message)
- Backwards compatible: missing `change.yaml` â†’ use default

**change.yaml format:**
```yaml
schema: tdd
created: 2025-01-15T10:30:00Z
```

**Migration:**
- Existing changes without `change.yaml` continue to work
- Default to `spec-driven` (current behavior)
- Optional: `openspec migrate` to add `change.yaml` to existing changes

---

### Phase 2: Project-Local Schemas

**Status:** âœ… Complete (PR #522)
**Solves:** Team sharing, version control, no XDG knowledge needed

**Implemented:**
- `./openspec/schemas/` added to resolution order (first priority)
- `openspec schema fork <name> [new-name]` creates in project by default
- Teams can commit `openspec/schemas/` to repo

**Resolution order:**
```
1. ./openspec/schemas/<name>/           # Project-local
2. ~/.local/share/openspec/schemas/<name>/  # User global
3. <npm-package>/schemas/<name>/        # Built-in
```

---

### Phase 3: Schema Management CLI

**Status:** âœ… Complete (PR #525)
**Solves:** Path discovery, scaffolding, debugging

**Implemented Commands:**
```bash
openspec schema which [name]          # Show resolution path, --all for all schemas
openspec schema validate [name]       # Validate schema structure and templates
openspec schema fork <source> [name]  # Copy existing schema for customization
openspec schema init <name>           # Create new project-local schema (interactive)
```

**Not implemented (may add later):**
- `schema diff` â€” Compare override with built-in
- `schema reset` â€” Remove override, revert to built-in

---

### Phase 4: Project Config + Init Enhancement

**Priority:** Low
**Solves:** Project-wide defaults, streamlined setup

**Scope:**
- Add `openspec/config.yaml` with `defaultSchema` field
- `openspec init` prompts for schema selection
- Store selection in `config.yaml`
- Commands use as fallback when no `change.yaml` exists

**config.yaml format:**
```yaml
defaultSchema: spec-driven
```

---

## Backwards Compatibility

| Scenario | Behavior |
|----------|----------|
| Existing change without `change.yaml` | Uses `--schema` flag or project default or `spec-driven` |
| Existing project without `config.yaml` | Falls back to `spec-driven` |
| `--schema` flag provided | Overrides `change.yaml` (with info message) |
| No project-local schemas dir | Skipped in resolution, checks user/built-in |

All existing functionality continues to work. New features are additive.

---

## Related Documents

- [Schema Customization](./schema-customization.md) â€” Details on manual override process and CLI gaps
- [Artifact POC](./artifact_poc.md) â€” Core artifact graph architecture

## Related Code

| File | Purpose |
|------|---------|
| `src/core/artifact-graph/resolver.ts` | Schema resolution logic |
| `src/core/artifact-graph/instruction-loader.ts` | Template loading |
| `src/core/global-config.ts` | XDG path helpers |
| `src/commands/artifact-workflow.ts` | CLI commands |
| `src/utils/change-utils.ts` | Change creation utilities |



================================================
FILE: openspec/AGENTS.md
================================================
# OpenSpec Instructions

Instructions for AI coding assistants using OpenSpec for spec-driven development.

## TL;DR Quick Checklist

- Search existing work: `openspec spec list --long`, `openspec list` (use `rg` only for full-text search)
- Decide scope: new capability vs modify existing capability
- Pick a unique `change-id`: kebab-case, verb-led (`add-`, `update-`, `remove-`, `refactor-`)
- Scaffold: `proposal.md`, `tasks.md`, `design.md` (only if needed), and delta specs per affected capability
- Write deltas: use `## ADDED|MODIFIED|REMOVED|RENAMED Requirements`; include at least one `#### Scenario:` per requirement
- Validate: `openspec validate [change-id] --strict --no-interactive` and fix issues
- Request approval: Do not start implementation until proposal is approved

## Three-Stage Workflow

### Stage 1: Creating Changes
Create proposal when you need to:
- Add features or functionality
- Make breaking changes (API, schema)
- Change architecture or patterns
- Optimize performance (changes behavior)
- Update security patterns

Triggers (examples):
- "Help me create a change proposal"
- "Help me plan a change"
- "Help me create a proposal"
- "I want to create a spec proposal"
- "I want to create a spec"

Loose matching guidance:
- Contains one of: `proposal`, `change`, `spec`
- With one of: `create`, `plan`, `make`, `start`, `help`

Skip proposal for:
- Bug fixes (restore intended behavior)
- Typos, formatting, comments
- Dependency updates (non-breaking)
- Configuration changes
- Tests for existing behavior

**Workflow**
1. Review `openspec/project.md`, `openspec list`, and `openspec list --specs` to understand current context.
2. Choose a unique verb-led `change-id` and scaffold `proposal.md`, `tasks.md`, optional `design.md`, and spec deltas under `openspec/changes/<id>/`.
3. Draft spec deltas using `## ADDED|MODIFIED|REMOVED Requirements` with at least one `#### Scenario:` per requirement.
4. Run `openspec validate <id> --strict --no-interactive` and resolve any issues before sharing the proposal.

### Stage 2: Implementing Changes
Track these steps as TODOs and complete them one by one.
1. **Read proposal.md** - Understand what's being built
2. **Read design.md** (if exists) - Review technical decisions
3. **Read tasks.md** - Get implementation checklist
4. **Implement tasks sequentially** - Complete in order
5. **Confirm completion** - Ensure every item in `tasks.md` is finished before updating statuses
6. **Update checklist** - After all work is done, set every task to `- [x]` so the list reflects reality
7. **Approval gate** - Do not start implementation until the proposal is reviewed and approved

### Stage 3: Archiving Changes
After deployment, create separate PR to:
- Move `changes/[name]/` â†’ `changes/archive/YYYY-MM-DD-[name]/`
- Update `specs/` if capabilities changed
- Use `openspec archive <change-id> --skip-specs --yes` for tooling-only changes (always pass the change ID explicitly)
- Run `openspec validate --strict --no-interactive` to confirm the archived change passes checks

## Before Any Task

**Context Checklist:**
- [ ] Read relevant specs in `specs/[capability]/spec.md`
- [ ] Check pending changes in `changes/` for conflicts
- [ ] Read `openspec/project.md` for conventions
- [ ] Run `openspec list` to see active changes
- [ ] Run `openspec list --specs` to see existing capabilities

**Before Creating Specs:**
- Always check if capability already exists
- Prefer modifying existing specs over creating duplicates
- Use `openspec show [spec]` to review current state
- If request is ambiguous, ask 1â€“2 clarifying questions before scaffolding

### Search Guidance
- Enumerate specs: `openspec spec list --long` (or `--json` for scripts)
- Enumerate changes: `openspec list` (or `openspec change list --json` - deprecated but available)
- Show details:
  - Spec: `openspec show <spec-id> --type spec` (use `--json` for filters)
  - Change: `openspec show <change-id> --json --deltas-only`
- Full-text search (use ripgrep): `rg -n "Requirement:|Scenario:" openspec/specs`

## Quick Start

### CLI Commands

```bash
# Essential commands
openspec list                  # List active changes
openspec list --specs          # List specifications
openspec show [item]           # Display change or spec
openspec validate [item]       # Validate changes or specs
openspec archive <change-id> [--yes|-y]   # Archive after deployment (add --yes for non-interactive runs)

# Project management
openspec init [path]           # Initialize OpenSpec
openspec update [path]         # Update instruction files

# Interactive mode
openspec show                  # Prompts for selection
openspec validate              # Bulk validation mode

# Debugging
openspec show [change] --json --deltas-only
openspec validate [change] --strict --no-interactive
```

### Command Flags

- `--json` - Machine-readable output
- `--type change|spec` - Disambiguate items
- `--strict` - Comprehensive validation
- `--no-interactive` - Disable prompts
- `--skip-specs` - Archive without spec updates
- `--yes`/`-y` - Skip confirmation prompts (non-interactive archive)

## Directory Structure

```
openspec/
â”œâ”€â”€ project.md              # Project conventions
â”œâ”€â”€ specs/                  # Current truth - what IS built
â”‚   â””â”€â”€ [capability]/       # Single focused capability
â”‚       â”œâ”€â”€ spec.md         # Requirements and scenarios
â”‚       â””â”€â”€ design.md       # Technical patterns
â”œâ”€â”€ changes/                # Proposals - what SHOULD change
â”‚   â”œâ”€â”€ [change-name]/
â”‚   â”‚   â”œâ”€â”€ proposal.md     # Why, what, impact
â”‚   â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
â”‚   â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional; see criteria)
â”‚   â”‚   â””â”€â”€ specs/          # Delta changes
â”‚   â”‚       â””â”€â”€ [capability]/
â”‚   â”‚           â””â”€â”€ spec.md # ADDED/MODIFIED/REMOVED
â”‚   â””â”€â”€ archive/            # Completed changes
```

## Creating Change Proposals

### Decision Tree

```
New request?
â”œâ”€ Bug fix restoring spec behavior? â†’ Fix directly
â”œâ”€ Typo/format/comment? â†’ Fix directly
â”œâ”€ New feature/capability? â†’ Create proposal
â”œâ”€ Breaking change? â†’ Create proposal
â”œâ”€ Architecture change? â†’ Create proposal
â””â”€ Unclear? â†’ Create proposal (safer)
```

### Proposal Structure

1. **Create directory:** `changes/[change-id]/` (kebab-case, verb-led, unique)

2. **Write proposal.md:**
```markdown
# Change: [Brief description of change]

## Why
[1-2 sentences on problem/opportunity]

## What Changes
- [Bullet list of changes]
- [Mark breaking changes with **BREAKING**]

## Impact
- Affected specs: [list capabilities]
- Affected code: [key files/systems]
```

3. **Create spec deltas:** `specs/[capability]/spec.md`
```markdown
## ADDED Requirements
### Requirement: New Feature
The system SHALL provide...

#### Scenario: Success case
- **WHEN** user performs action
- **THEN** expected result

## MODIFIED Requirements
### Requirement: Existing Feature
[Complete modified requirement]

## REMOVED Requirements
### Requirement: Old Feature
**Reason**: [Why removing]
**Migration**: [How to handle]
```
If multiple capabilities are affected, create multiple delta files under `changes/[change-id]/specs/<capability>/spec.md`â€”one per capability.

4. **Create tasks.md:**
```markdown
## 1. Implementation
- [ ] 1.1 Create database schema
- [ ] 1.2 Implement API endpoint
- [ ] 1.3 Add frontend component
- [ ] 1.4 Write tests
```

5. **Create design.md when needed:**
Create `design.md` if any of the following apply; otherwise omit it:
- Cross-cutting change (multiple services/modules) or a new architectural pattern
- New external dependency or significant data model changes
- Security, performance, or migration complexity
- Ambiguity that benefits from technical decisions before coding

Minimal `design.md` skeleton:
```markdown
## Context
[Background, constraints, stakeholders]

## Goals / Non-Goals
- Goals: [...]
- Non-Goals: [...]

## Decisions
- Decision: [What and why]
- Alternatives considered: [Options + rationale]

## Risks / Trade-offs
- [Risk] â†’ Mitigation

## Migration Plan
[Steps, rollback]

## Open Questions
- [...]
```

## Spec File Format

### Critical: Scenario Formatting

**CORRECT** (use #### headers):
```markdown
#### Scenario: User login success
- **WHEN** valid credentials provided
- **THEN** return JWT token
```

**WRONG** (don't use bullets or bold):
```markdown
- **Scenario: User login**  âŒ
**Scenario**: User login     âŒ
### Scenario: User login      âŒ
```

Every requirement MUST have at least one scenario.

### Requirement Wording
- Use SHALL/MUST for normative requirements (avoid should/may unless intentionally non-normative)

### Delta Operations

- `## ADDED Requirements` - New capabilities
- `## MODIFIED Requirements` - Changed behavior
- `## REMOVED Requirements` - Deprecated features
- `## RENAMED Requirements` - Name changes

Headers matched with `trim(header)` - whitespace ignored.

#### When to use ADDED vs MODIFIED
- ADDED: Introduces a new capability or sub-capability that can stand alone as a requirement. Prefer ADDED when the change is orthogonal (e.g., adding "Slash Command Configuration") rather than altering the semantics of an existing requirement.
- MODIFIED: Changes the behavior, scope, or acceptance criteria of an existing requirement. Always paste the full, updated requirement content (header + all scenarios). The archiver will replace the entire requirement with what you provide here; partial deltas will drop previous details.
- RENAMED: Use when only the name changes. If you also change behavior, use RENAMED (name) plus MODIFIED (content) referencing the new name.

Common pitfall: Using MODIFIED to add a new concern without including the previous text. This causes loss of detail at archive time. If you arenâ€™t explicitly changing the existing requirement, add a new requirement under ADDED instead.

Authoring a MODIFIED requirement correctly:
1) Locate the existing requirement in `openspec/specs/<capability>/spec.md`.
2) Copy the entire requirement block (from `### Requirement: ...` through its scenarios).
3) Paste it under `## MODIFIED Requirements` and edit to reflect the new behavior.
4) Ensure the header text matches exactly (whitespace-insensitive) and keep at least one `#### Scenario:`.

Example for RENAMED:
```markdown
## RENAMED Requirements
- FROM: `### Requirement: Login`
- TO: `### Requirement: User Authentication`
```

## Troubleshooting

### Common Errors

**"Change must have at least one delta"**
- Check `changes/[name]/specs/` exists with .md files
- Verify files have operation prefixes (## ADDED Requirements)

**"Requirement must have at least one scenario"**
- Check scenarios use `#### Scenario:` format (4 hashtags)
- Don't use bullet points or bold for scenario headers

**Silent scenario parsing failures**
- Exact format required: `#### Scenario: Name`
- Debug with: `openspec show [change] --json --deltas-only`

### Validation Tips

```bash
# Always use strict mode for comprehensive checks
openspec validate [change] --strict --no-interactive

# Debug delta parsing
openspec show [change] --json | jq '.deltas'

# Check specific requirement
openspec show [spec] --json -r 1
```

## Happy Path Script

```bash
# 1) Explore current state
openspec spec list --long
openspec list
# Optional full-text search:
# rg -n "Requirement:|Scenario:" openspec/specs
# rg -n "^#|Requirement:" openspec/changes

# 2) Choose change id and scaffold
CHANGE=add-two-factor-auth
mkdir -p openspec/changes/$CHANGE/{specs/auth}
printf "## Why\n...\n\n## What Changes\n- ...\n\n## Impact\n- ...\n" > openspec/changes/$CHANGE/proposal.md
printf "## 1. Implementation\n- [ ] 1.1 ...\n" > openspec/changes/$CHANGE/tasks.md

# 3) Add deltas (example)
cat > openspec/changes/$CHANGE/specs/auth/spec.md << 'EOF'
## ADDED Requirements
### Requirement: Two-Factor Authentication
Users MUST provide a second factor during login.

#### Scenario: OTP required
- **WHEN** valid credentials are provided
- **THEN** an OTP challenge is required
EOF

# 4) Validate
openspec validate $CHANGE --strict --no-interactive
```

## Multi-Capability Example

```
openspec/changes/add-2fa-notify/
â”œâ”€â”€ proposal.md
â”œâ”€â”€ tasks.md
â””â”€â”€ specs/
    â”œâ”€â”€ auth/
    â”‚   â””â”€â”€ spec.md   # ADDED: Two-Factor Authentication
    â””â”€â”€ notifications/
        â””â”€â”€ spec.md   # ADDED: OTP email notification
```

auth/spec.md
```markdown
## ADDED Requirements
### Requirement: Two-Factor Authentication
...
```

notifications/spec.md
```markdown
## ADDED Requirements
### Requirement: OTP Email Notification
...
```

## Best Practices

### Simplicity First
- Default to <100 lines of new code
- Single-file implementations until proven insufficient
- Avoid frameworks without clear justification
- Choose boring, proven patterns

### Complexity Triggers
Only add complexity with:
- Performance data showing current solution too slow
- Concrete scale requirements (>1000 users, >100MB data)
- Multiple proven use cases requiring abstraction

### Clear References
- Use `file.ts:42` format for code locations
- Reference specs as `specs/auth/spec.md`
- Link related changes and PRs

### Capability Naming
- Use verb-noun: `user-auth`, `payment-capture`
- Single purpose per capability
- 10-minute understandability rule
- Split if description needs "AND"

### Change ID Naming
- Use kebab-case, short and descriptive: `add-two-factor-auth`
- Prefer verb-led prefixes: `add-`, `update-`, `remove-`, `refactor-`
- Ensure uniqueness; if taken, append `-2`, `-3`, etc.

## Tool Selection Guide

| Task | Tool | Why |
|------|------|-----|
| Find files by pattern | Glob | Fast pattern matching |
| Search code content | Grep | Optimized regex search |
| Read specific files | Read | Direct file access |
| Explore unknown scope | Task | Multi-step investigation |

## Error Recovery

### Change Conflicts
1. Run `openspec list` to see active changes
2. Check for overlapping specs
3. Coordinate with change owners
4. Consider combining proposals

### Validation Failures
1. Run with `--strict` flag
2. Check JSON output for details
3. Verify spec file format
4. Ensure scenarios properly formatted

### Missing Context
1. Read project.md first
2. Check related specs
3. Review recent archives
4. Ask for clarification

## Quick Reference

### Stage Indicators
- `changes/` - Proposed, not yet built
- `specs/` - Built and deployed
- `archive/` - Completed changes

### File Purposes
- `proposal.md` - Why and what
- `tasks.md` - Implementation steps
- `design.md` - Technical decisions
- `spec.md` - Requirements and behavior

### CLI Essentials
```bash
openspec list              # What's in progress?
openspec show [item]       # View details
openspec validate --strict --no-interactive  # Is it correct?
openspec archive <change-id> [--yes|-y]  # Mark complete (add --yes for automation)
```

Remember: Specs are truth. Changes are proposals. Keep them in sync.



================================================
FILE: openspec/config.yaml
================================================
schema: spec-driven

context: |
  Tech stack: TypeScript, Node.js (â‰¥20.19.0), ESM modules
  Package manager: pnpm
  CLI framework: Commander.js

  Cross-platform requirements:
  - This tool runs on macOS, Linux, AND Windows
  - Always use path.join() or path.resolve() for file paths - never hardcode slashes
  - Never assume forward-slash path separators
  - Tests must use path.join() for expected path values, not hardcoded strings
  - Consider case sensitivity differences in file systems

rules:
  specs:
    - Include scenarios for Windows path handling when dealing with file paths
    - Requirements involving paths must specify cross-platform behavior
  tasks:
    - Add Windows CI verification as a task when changes involve file paths
    - Include cross-platform testing considerations
  design:
    - Document any platform-specific behavior or limitations
    - Prefer Node.js path module over string manipulation for paths



================================================
FILE: openspec/project.md
================================================
# OpenSpec Project Overview

A minimal CLI tool that helps developers set up OpenSpec file structures and keep AI instructions updated. The AI tools themselves handle all the change management complexity by working directly with markdown files.

## Technology Stack
- Language: TypeScript
- Runtime: Node.js (â‰¥20.19.0, ESM modules)
- Package Manager: pnpm
- CLI Framework: Commander.js
- User Interaction: @inquirer/prompts
- Distribution: npm package

## Project Structure
```
src/
â”œâ”€â”€ cli/        # CLI command implementations
â”œâ”€â”€ core/       # Core OpenSpec logic (templates, structure)
â””â”€â”€ utils/      # Shared utilities (file operations, rollback)

dist/           # Compiled output (gitignored)
```

## Conventions
- TypeScript strict mode enabled
- Async/await for all asynchronous operations
- Minimal dependencies principle
- Clear separation of CLI, core logic, and utilities
- AI-friendly code with descriptive names

## Error Handling
- Let errors bubble up to CLI level for consistent user messaging
- Use native Error types with descriptive messages
- Exit with appropriate codes: 0 (success), 1 (general error), 2 (misuse)
- No try-catch in utility functions, handle at command level

## Logging
- Use console methods directly (no logging library)
- console.log() for normal output
- console.error() for errors (outputs to stderr)
- No verbose/debug modes initially (keep it simple)

## Testing Strategy
- Manual testing via `pnpm link` during development
- Smoke tests for critical paths only (init, help commands)
- No unit tests initially - add when complexity grows
- Test commands: `pnpm test:smoke` (when added)

## Development Workflow
- Use pnpm for all package management
- Run `pnpm run build` to compile TypeScript
- Run `pnpm run dev` for development mode
- Test locally with `pnpm link`
- Follow OpenSpec's own change-driven development process


================================================
FILE: openspec/changes/IMPLEMENTATION_ORDER.md
================================================
# Implementation Order and Dependencies

## Required Implementation Sequence

The following changes must be implemented in this specific order due to dependencies:

### Phase 1: Foundation
**1. add-zod-validation** (No dependencies)
- Creates all core schemas (RequirementSchema, ScenarioSchema, SpecSchema, ChangeSchema, DeltaSchema)
- Implements markdown parser utilities
- Implements validation infrastructure and rules
- Establishes validation patterns used by all commands
- Must be completed first

### Phase 2: Change Commands
**2. add-change-commands** (Depends on: add-zod-validation)
- Imports ChangeSchema and DeltaSchema from zod validation
- Reuses markdown parsing utilities
- Implements change command with built-in validation
- Uses validation infrastructure for change validate subcommand
- Cannot start until schemas and validation exist

### Phase 3: Spec Commands
**3. add-spec-commands** (Depends on: add-zod-validation, add-change-commands)
- Imports RequirementSchema, ScenarioSchema, SpecSchema from zod validation
- Reuses markdown parsing utilities
- Implements spec command with built-in validation
- Uses validation infrastructure for spec validate subcommand
- Builds on patterns established by change commands

## Dependency Graph
```
add-zod-validation
    â†“
add-change-commands
    â†“
add-spec-commands
```

## Key Dependencies

### Shared Code Dependencies
1. **Schemas**: All schemas created in add-zod-validation, used by both command implementations
2. **Validation**: Infrastructure created in add-zod-validation, integrated into both commands
3. **Parsers**: Markdown parsing utilities created in add-zod-validation, used by both commands

### File Dependencies
- `src/core/schemas/*.schema.ts` (created by add-zod-validation) â†’ imported by both commands
- `src/core/validation/validator.ts` (created by add-zod-validation) â†’ used by both commands
- `src/core/parsers/markdown-parser.ts` (created by add-zod-validation) â†’ used by both commands

## Implementation Notes

### For Developers
1. Complete each phase fully before moving to the next
2. Run tests after each phase to ensure stability
3. The legacy `list` command remains functional throughout

### For CI/CD
1. Each change can be validated independently
2. Integration tests should run after each phase
3. Full system tests required after Phase 3

### Parallel Work Opportunities
Within each phase, the following can be done in parallel:
- **Phase 1**: Schema design, validation rules, and parser implementation
- **Phase 2**: Change command features and legacy compatibility work
- **Phase 3**: Spec command features and final integration


================================================
FILE: openspec/changes/add-feedback-command/proposal.md
================================================
## Why

Users and agents need a simple way to submit feedback about OpenSpec directly from the CLI. Currently there's no mechanism to collect user feedback, feature requests, or bug reports in a way that enables follow-up conversation. Using GitHub Issues allows us to track feedback, prevent spam via GitHub auth, and enables outreach to users.

## What Changes

- Add `openspec feedback <message>` CLI command
- Leverage `gh` CLI for GitHub authentication and issue creation
- Add `/feedback` skill for agent-assisted feedback with context enrichment
- Ensure cross-platform compatibility (macOS, Linux, Windows)

## Impact

- Affected specs: New `cli-feedback` capability
- Affected code:
  - `src/cli/index.ts` - Register feedback command
  - `src/commands/feedback.ts` - Command implementation using `gh` CLI
  - `src/core/templates/skill-templates.ts` - Feedback skill template
  - `src/core/completions/command-registry.ts` - Shell completions
- External dependency: Requires `gh` CLI installed and authenticated



================================================
FILE: openspec/changes/add-feedback-command/tasks.md
================================================
## 1. Feedback Command

- [x] 1.1 Create `src/commands/feedback.ts` with command implementation
- [x] 1.2 Check `gh` CLI availability using platform-appropriate command (`which` on Unix/macOS, `where` on Windows)
- [x] 1.3 Check GitHub auth status with `gh auth status`
- [x] 1.4 Execute `gh issue create` with formatted title and body using `execFileSync` to prevent shell injection
- [x] 1.5 Display issue URL returned by `gh` CLI
- [x] 1.6 Register `feedback <message>` command in `src/cli/index.ts`
- [x] 1.7 Ensure cross-platform compatibility (macOS, Linux, Windows)

## 2. Shell Completions

- [x] 2.1 Add `feedback` command to command registry
- [x] 2.2 Regenerate completion scripts for all shells

## 3. Feedback Skill

- [x] 3.1 Create feedback skill template in `skill-templates.ts`
- [x] 3.2 Document context gathering workflow
- [x] 3.3 Document anonymization rules
- [x] 3.4 Document user confirmation flow

## 4. Testing

- [x] 4.1 Add unit tests for feedback command (mock `gh` subprocess calls)
- [x] 4.2 Add integration test for full feedback flow with mocked `gh` CLI
- [x] 4.3 Test error handling for missing `gh` CLI
- [x] 4.4 Test error handling for unauthenticated `gh` session
- [x] 4.5 Test cross-platform `gh` CLI detection (verify `which` on Unix, `where` on Windows)
- [x] 4.6 Test platform metadata includes correct value for Windows (win32)



================================================
FILE: openspec/changes/add-feedback-command/specs/cli-feedback/spec.md
================================================
## ADDED Requirements

### Requirement: Feedback command

The system SHALL provide an `openspec feedback` command that creates a GitHub Issue in the openspec repository using the `gh` CLI. The system SHALL use `execFileSync` with argument arrays to prevent shell injection vulnerabilities.

#### Scenario: Simple feedback submission

- **WHEN** user executes `openspec feedback "Great tool!"`
- **THEN** the system executes `gh issue create` with title "Feedback: Great tool!"
- **AND** the issue is created in the openspec repository
- **AND** the issue has the `feedback` label
- **AND** the system displays the created issue URL

#### Scenario: Safe command execution

- **WHEN** submitting feedback via `gh` CLI
- **THEN** the system uses `execFileSync` with separate arguments array
- **AND** user input is NOT passed through a shell
- **AND** shell metacharacters (quotes, backticks, $(), etc.) are treated as literal text

#### Scenario: Feedback with body

- **WHEN** user executes `openspec feedback "Title here" --body "Detailed description..."`
- **THEN** the system creates a GitHub Issue with the specified title
- **AND** the issue body contains the detailed description
- **AND** the issue body includes metadata (OpenSpec version, platform, timestamp)

### Requirement: GitHub CLI dependency

The system SHALL use `gh` CLI for automatic feedback submission when available, and provide a manual submission fallback when `gh` is not installed or not authenticated. The system SHALL use platform-appropriate commands to detect `gh` CLI availability.

#### Scenario: Missing gh CLI with fallback

- **WHEN** user runs `openspec feedback "message"`
- **AND** `gh` CLI is not installed (not found in PATH)
- **THEN** the system displays warning: "GitHub CLI not found. Manual submission required."
- **AND** outputs structured feedback content with delimiters:
  - "--- FORMATTED FEEDBACK ---"
  - Title line
  - Labels line
  - Body content with metadata
  - "--- END FEEDBACK ---"
- **AND** displays pre-filled GitHub issue URL for manual submission
- **AND** exits with zero code (successful fallback)

#### Scenario: Cross-platform gh CLI detection on Unix

- **WHEN** system is running on macOS or Linux (platform is 'darwin' or 'linux')
- **AND** checking if `gh` CLI is installed
- **THEN** the system executes `which gh` command

#### Scenario: Cross-platform gh CLI detection on Windows

- **WHEN** system is running on Windows (platform is 'win32')
- **AND** checking if `gh` CLI is installed
- **THEN** the system executes `where gh` command

#### Scenario: Unauthenticated gh CLI with fallback

- **WHEN** user runs `openspec feedback "message"`
- **AND** `gh` CLI is installed but not authenticated
- **THEN** the system displays warning: "GitHub authentication required. Manual submission required."
- **AND** outputs structured feedback content (same format as missing gh CLI scenario)
- **AND** displays pre-filled GitHub issue URL for manual submission
- **AND** displays authentication instructions: "To auto-submit in the future: gh auth login"
- **AND** exits with zero code (successful fallback)

#### Scenario: Authenticated gh CLI

- **WHEN** user runs `openspec feedback "message"`
- **AND** `gh auth status` returns success (authenticated)
- **THEN** the system proceeds with feedback submission

### Requirement: Issue metadata

The system SHALL include relevant metadata in the GitHub Issue body.

#### Scenario: Standard metadata

- **WHEN** creating a GitHub Issue for feedback
- **THEN** the issue body includes:
  - OpenSpec CLI version
  - Platform (darwin, linux, win32)
  - Submission timestamp
  - Separator line: "---\nSubmitted via OpenSpec CLI"

#### Scenario: Windows platform metadata

- **WHEN** creating a GitHub Issue for feedback on Windows
- **THEN** the issue body includes "Platform: win32"
- **AND** all platform detection uses Node.js `os.platform()` API

#### Scenario: No sensitive metadata

- **WHEN** creating a GitHub Issue for feedback
- **THEN** the issue body does NOT include:
  - File paths from user's system
  - Project names or directory names
  - Environment variables
  - IP addresses

### Requirement: Feedback always works

The system SHALL allow feedback submission regardless of telemetry settings.

#### Scenario: Feedback with telemetry disabled

- **WHEN** user has disabled telemetry via `OPENSPEC_TELEMETRY=0`
- **AND** user runs `openspec feedback "message"`
- **THEN** the feedback is still submitted via `gh` CLI
- **AND** telemetry events are not sent

#### Scenario: Feedback in CI environment

- **WHEN** `CI=true` is set in the environment
- **AND** user runs `openspec feedback "message"`
- **THEN** the feedback submission proceeds normally (if `gh` is available and authenticated)

### Requirement: Error handling

The system SHALL handle feedback submission errors gracefully.

#### Scenario: gh CLI execution failure

- **WHEN** `gh issue create` command fails
- **THEN** the system displays the error output from `gh` CLI
- **AND** exits with the same exit code as `gh`

#### Scenario: Network failure

- **WHEN** `gh` CLI reports network connectivity issues
- **THEN** the system displays the error message from `gh`
- **AND** suggests checking network connectivity
- **AND** exits with non-zero code

### Requirement: Feedback skill for agents

The system SHALL provide a `/feedback` skill that guides agents through collecting and submitting user feedback.

#### Scenario: Agent-initiated feedback

- **WHEN** user invokes `/feedback` in an agent conversation
- **THEN** the agent gathers context from the conversation
- **AND** drafts a feedback issue with enriched content
- **AND** anonymizes sensitive information
- **AND** presents the draft to the user for approval
- **AND** submits via `openspec feedback` command on user confirmation

#### Scenario: Context enrichment

- **WHEN** agent drafts feedback
- **THEN** the agent includes relevant context such as:
  - What task was being performed
  - What worked well or poorly
  - Specific friction points or praise

#### Scenario: Anonymization

- **WHEN** agent drafts feedback
- **THEN** the agent removes or replaces:
  - File paths with `<path>` or generic descriptions
  - API keys, tokens, secrets with `<redacted>`
  - Company/organization names with `<company>`
  - Personal names with `<user>`
  - Specific URLs with `<url>` unless public/relevant

#### Scenario: User confirmation required

- **WHEN** agent has drafted feedback
- **THEN** the agent MUST show the complete draft to the user
- **AND** ask for explicit approval before submitting
- **AND** allow the user to request modifications
- **AND** only submit after user confirms

### Requirement: Shell completions

The system SHALL provide shell completions for the feedback command.

#### Scenario: Command completion

- **WHEN** user types `openspec fee<TAB>`
- **THEN** the shell completes to `openspec feedback`

#### Scenario: Flag completion

- **WHEN** user types `openspec feedback "msg" --<TAB>`
- **THEN** the shell suggests available flags (`--body`)



================================================
FILE: openspec/changes/add-verify-skill/design.md
================================================
# Design: Add /opsx:verify Skill

## Architecture Decision: Dynamic Generation via Setup Command

### Context

All existing opsx experimental skills (explore, new, continue, apply, ff, sync, archive) are dynamically generated when users run `openspec artifact-experimental-setup`. They are not manually created files checked into the repository.

### Decision

**Integrate verify into the existing artifact-experimental-setup system rather than creating static skill files.**

### Rationale

1. **Consistency**: All 7 existing opsx skills follow this pattern. Adding verify as the 8th skill should follow the same architecture.

2. **Maintainability**: Template functions in `skill-templates.ts` are the single source of truth. Changes to skill definitions automatically propagate to all users when they re-run setup.

3. **Distribution**: Users get the verify skill automatically when running `openspec artifact-experimental-setup`, just like all other opsx skills. No special installation steps needed.

4. **Versioning**: Skills are generated from the installed npm package version, ensuring consistency between CLI version and skill behavior.

### Implementation Approach

#### 1. Template Functions

Add two template functions to `src/core/templates/skill-templates.ts`:

```typescript
export function getVerifyChangeSkillTemplate(): SkillTemplate
export function getOpsxVerifyCommandTemplate(): CommandTemplate
```

These return the skill definition (for Agent Skills) and slash command definition (for explicit invocation).

#### 2. Setup Integration

Update `artifactExperimentalSetupCommand()` in `src/commands/artifact-workflow.ts`:

- Import both template functions
- Add verify to the `skills` array (position 8)
- Add verify to the `commands` array (position 8)
- Update help text to list `/opsx:verify`

#### 3. Generated Artifacts

When users run `openspec artifact-experimental-setup`, the command creates:

- `.claude/skills/openspec-verify-change/SKILL.md` - Agent Skills format
- `.claude/commands/opsx/verify.md` - Slash command format

Both are generated from the template functions, with YAML frontmatter automatically added.

### Alternatives Considered

**Alternative 1: Static skill files in repository**

Create `.claude/skills/openspec-verify-change/SKILL.md` as a static file in the OpenSpec repository.

**Rejected because:**
- Inconsistent with all other opsx skills
- Requires users to manually copy/update files
- Versioning becomes complicated (repo version vs installed package version)
- Breaks the established pattern

**Alternative 2: Separate verify setup command**

Add `openspec setup-verify` as a separate command.

**Rejected because:**
- Fragments the setup experience
- Users would need to run multiple commands
- Doesn't scale if we add more skills in the future
- Goes against the "setup once, get everything" philosophy

### Trade-offs

**Advantages:**
- Consistent with existing architecture
- Zero additional setup burden for users
- Easy to update and maintain
- Automatic version compatibility

**Disadvantages:**
- Slightly more complex initial implementation (template functions + integration)
- Requires understanding the setup system (but that's already documented)

### Verification

The implementation correctly follows this design if:

1. Both template functions exist in `skill-templates.ts`
2. Verify appears in both skills and commands arrays in `artifact-workflow.ts`
3. Help text mentions `/opsx:verify`
4. Running `openspec artifact-experimental-setup` generates both skill and command files
5. Build succeeds with no TypeScript errors



================================================
FILE: openspec/changes/add-verify-skill/proposal.md
================================================
# Change: Add /opsx:verify Skill

## Why

Users need a way to validate that their implementation actually matches what was requested before archiving a change. Currently, there's no systematic way to check:
- Whether all tasks are truly complete
- Whether the implementation covers all spec requirements and scenarios
- Whether the implementation follows the design decisions
- Whether the code is coherent and makes sense

A user requested: "Can we get a :verify that will ensure that the implementation matches what was requested?"

## What Changes

- Add `getVerifyChangeSkillTemplate()` function to `skill-templates.ts`
- Add `getOpsxVerifyCommandTemplate()` function to `skill-templates.ts`
- Integrate verify skill into `artifactExperimentalSetupCommand` in `artifact-workflow.ts`
- Add verify to the skills and commands arrays in the setup command
- Update help text to include `/opsx:verify` in the list of available commands
- Create `opsx-verify-skill` capability spec

## Verification Dimensions

The skill verifies across three dimensions:

1. **Completeness** - Are all tasks done? Are all specs addressed?
2. **Correctness** - Does the implementation match specs? Are scenarios covered?
3. **Coherence** - Does the implementation make sense? Does it follow design.md?

## Output Format

Produces a prioritized report with:
- Summary scorecard (tasks, specs, design adherence)
- Critical issues first (must fix before archive)
- Warnings second (should fix)
- Suggestions third (nice to have)
- Actionable fix recommendations for each issue

## Impact

- Affected specs: New `opsx-verify-skill` spec
- Affected code:
  - `src/core/templates/skill-templates.ts` - Added 2 new template functions
  - `src/commands/artifact-workflow.ts` - Integrated verify into experimental setup
- Generated artifacts: When users run `openspec artifact-experimental-setup`:
  - Creates `.claude/skills/openspec-verify-change/SKILL.md`
  - Creates `.claude/commands/opsx/verify.md`
- Related skills: Works alongside `/opsx:apply` and before `/opsx:archive`



================================================
FILE: openspec/changes/add-verify-skill/tasks.md
================================================
# Tasks: Add /opsx:verify Skill

## 1. Skill Template Functions
- [x] 1.1 Add `getVerifyChangeSkillTemplate()` to skill-templates.ts
- [x] 1.2 Add `getOpsxVerifyCommandTemplate()` to skill-templates.ts

## 2. Integration with artifact-experimental-setup
- [x] 2.1 Import verify template functions in artifact-workflow.ts
- [x] 2.2 Add verify to skills array in artifactExperimentalSetupCommand
- [x] 2.3 Add verify to commands array in artifactExperimentalSetupCommand
- [x] 2.4 Add verify to help text output

## 3. Verification (Build & Test)
- [x] 3.1 Verify TypeScript compilation succeeds
- [x] 3.2 Verify all 8 skills are now included (was 7, now 8)



================================================
FILE: openspec/changes/add-verify-skill/specs/opsx-verify-skill/spec.md
================================================
# opsx-verify-skill Specification

## Purpose
Defines the agent skill for verifying that implementation matches change artifacts (specs, tasks, design).

## ADDED Requirements

### Requirement: Verify Skill Invocation
The system SHALL provide an `/opsx:verify` skill that validates implementation against change artifacts.

#### Scenario: Verify with change name provided
- **WHEN** agent executes `/opsx:verify <change-name>`
- **THEN** the agent verifies implementation for that specific change
- **AND** produces a verification report

#### Scenario: Verify without change name
- **WHEN** agent executes `/opsx:verify` without a change name
- **THEN** the agent prompts user to select from available changes
- **AND** shows only changes that have implementation tasks

#### Scenario: Change has no tasks
- **WHEN** selected change has no tasks.md or tasks are empty
- **THEN** the agent reports "No tasks to verify"
- **AND** suggests running `/opsx:continue` to create tasks

### Requirement: Completeness Verification
The agent SHALL verify that all required work has been completed.

#### Scenario: Task completion check
- **WHEN** verifying completeness
- **THEN** the agent reads tasks.md
- **AND** counts tasks marked `- [x]` (complete) vs `- [ ]` (incomplete)
- **AND** reports completion status with specific incomplete tasks listed

#### Scenario: Spec coverage check
- **WHEN** verifying completeness
- **AND** delta specs exist in `openspec/changes/<name>/specs/`
- **THEN** the agent extracts all requirements from delta specs
- **AND** searches codebase for implementation of each requirement
- **AND** reports which requirements appear to have implementation vs which are missing

#### Scenario: All tasks complete
- **WHEN** all tasks are marked complete
- **THEN** report "Tasks: N/N complete"
- **AND** mark completeness dimension as passed

#### Scenario: Incomplete tasks found
- **WHEN** some tasks are incomplete
- **THEN** report "Tasks: X/N complete"
- **AND** list each incomplete task
- **AND** mark as CRITICAL issue
- **AND** suggest: "Complete remaining tasks or mark as done if already implemented"

### Requirement: Correctness Verification
The agent SHALL verify that implementation matches the specifications.

#### Scenario: Requirement implementation mapping
- **WHEN** verifying correctness
- **THEN** for each requirement in delta specs:
  - Search codebase for implementation
  - Identify relevant files and line numbers
  - Assess whether implementation satisfies the requirement

#### Scenario: Scenario coverage check
- **WHEN** verifying correctness
- **THEN** for each scenario in delta specs:
  - Check if the scenario's conditions are handled in code
  - Check if tests exist that cover the scenario
  - Report coverage status

#### Scenario: Implementation matches spec
- **WHEN** implementation appears to satisfy a requirement
- **THEN** report which files/lines implement it
- **AND** mark requirement as covered

#### Scenario: Implementation diverges from spec
- **WHEN** implementation exists but doesn't match spec intent
- **THEN** report the divergence as WARNING
- **AND** explain what differs
- **AND** suggest: either update implementation or update spec to match reality

#### Scenario: Missing implementation
- **WHEN** no implementation found for a requirement
- **THEN** report as CRITICAL issue
- **AND** suggest: "Implement requirement X" with guidance on what's needed

### Requirement: Coherence Verification
The agent SHALL verify that implementation is sensible and follows design decisions.

#### Scenario: Design.md adherence check
- **WHEN** verifying coherence
- **AND** design.md exists for the change
- **THEN** extract key decisions from design.md
- **AND** verify implementation follows those decisions
- **AND** report any deviations

#### Scenario: No design.md
- **WHEN** verifying coherence
- **AND** no design.md exists
- **THEN** skip design adherence check
- **AND** note "No design.md to verify against"

#### Scenario: Design decision followed
- **WHEN** implementation follows a design decision
- **THEN** report as confirmed
- **AND** cite evidence from code

#### Scenario: Design decision violated
- **WHEN** implementation contradicts a design decision
- **THEN** report as WARNING
- **AND** explain the contradiction
- **AND** suggest: either update implementation or update design.md

#### Scenario: Code pattern consistency
- **WHEN** verifying coherence
- **THEN** check if new code follows existing project patterns
- **AND** flag any significant deviations as suggestions

### Requirement: Verification Report Format
The agent SHALL produce a structured, prioritized report.

#### Scenario: Report summary
- **WHEN** verification completes
- **THEN** display summary scorecard:
  ```
  ## Verification Report: <change-name>

  ### Summary
  | Dimension    | Status   |
  |--------------|----------|
  | Completeness | X/Y      |
  | Correctness  | X/Y      |
  | Coherence    | Followed |
  ```

#### Scenario: Issue prioritization
- **WHEN** issues are found
- **THEN** group and display in priority order:
  1. CRITICAL - Must fix before archive (missing implementation, incomplete tasks)
  2. WARNING - Should fix (divergence from spec/design, missing tests)
  3. SUGGESTION - Nice to fix (pattern inconsistencies, minor improvements)

#### Scenario: Actionable recommendations
- **WHEN** reporting an issue
- **THEN** include specific, actionable fix recommendation
- **AND** reference relevant files and line numbers where applicable
- **AND** avoid vague suggestions like "consider reviewing"

#### Scenario: All checks pass
- **WHEN** no issues found across all dimensions
- **THEN** display:
  ```
  All checks passed. Ready for archive.
  ```

#### Scenario: Critical issues found
- **WHEN** CRITICAL issues exist
- **THEN** display:
  ```
  X critical issue(s) found. Fix before archiving.
  ```
- **AND** do NOT suggest running archive

#### Scenario: Only warnings/suggestions
- **WHEN** no CRITICAL issues but warnings exist
- **THEN** display:
  ```
  No critical issues. Y warning(s) to consider.
  Ready for archive (with noted improvements).
  ```

### Requirement: Flexible Artifact Handling
The agent SHALL gracefully handle changes with varying artifact completeness.

#### Scenario: Minimal change (tasks only)
- **WHEN** change has only tasks.md
- **THEN** verify task completion only
- **AND** skip spec and design checks
- **AND** note which checks were skipped

#### Scenario: Change with specs but no design
- **WHEN** change has tasks.md and delta specs but no design.md
- **THEN** verify completeness and correctness
- **AND** skip design adherence
- **AND** still check code coherence against project patterns

#### Scenario: Full change (all artifacts)
- **WHEN** change has proposal, design, specs, and tasks
- **THEN** perform all verification checks
- **AND** cross-reference artifacts for consistency



================================================
FILE: openspec/changes/archive/2025-01-11-add-update-command/design.md
================================================
# Technical Design

## Architecture Decisions

### Simplicity First
- No version tracking - always update when commanded
- Full replacement for OpenSpec-managed files only (e.g., `openspec/README.md`)
- Marker-based updates for user-owned files (e.g., `CLAUDE.md`)
- Templates bundled with package - no network required
- Minimal error handling - only check prerequisites

### Template Strategy
- Use existing template utilities
  - `readmeTemplate` from `src/core/templates/readme-template.ts` for `openspec/README.md`
  - `TemplateManager.getClaudeTemplate()` for `CLAUDE.md`
- Directory name is fixed to `openspec` (from `OPENSPEC_DIR_NAME`)

### File Operations
- Use async utilities for consistency
  - `FileSystemUtils.writeFile` for `openspec/README.md`
  - `FileSystemUtils.updateFileWithMarkers` for `CLAUDE.md`
- No atomic operations needed - users have git
- Check directory existence before proceeding

## Implementation

### Update Command (`src/core/update.ts`)
```typescript
export class UpdateCommand {
  async execute(projectPath: string): Promise<void> {
    const openspecDirName = OPENSPEC_DIR_NAME;
    const openspecPath = path.join(projectPath, openspecDirName);

    // 1. Check openspec directory exists
    if (!await FileSystemUtils.directoryExists(openspecPath)) {
      throw new Error(`No OpenSpec directory found. Run 'openspec init' first.`);
    }

    // 2. Update README.md (full replacement)
    const readmePath = path.join(openspecPath, 'README.md');
    await FileSystemUtils.writeFile(readmePath, readmeTemplate);

    // 3. Update CLAUDE.md (marker-based)
    const claudePath = path.join(projectPath, 'CLAUDE.md');
    const claudeContent = TemplateManager.getClaudeTemplate();
    await FileSystemUtils.updateFileWithMarkers(
      claudePath,
      claudeContent,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );

    // 4. Success message (ASCII-safe, checkmark optional by terminal)
    console.log('Updated OpenSpec instructions');
  }
}
```

## Why This Approach

### Benefits
- **Dead simple**: ~40 lines of code total
- **Fast**: No version checks, minimal parsing
- **Predictable**: Same result every time; idempotent
- **Maintainable**: Reuses existing utilities

### Trade-offs Accepted
- No version tracking (unnecessary complexity)
- Full overwrite only for OpenSpec-managed files
- Marker-managed updates for user-owned files

## Error Handling

Only handle critical errors:
- Missing `openspec` directory â†’ throw error handled by CLI to present a friendly message
- File write failures â†’ let errors bubble up to CLI

## Testing Strategy

Manual smoke tests are sufficient initially:
1. Run `openspec init` in a test project
2. Modify both files (including custom content around markers in `CLAUDE.md`)
3. Run `openspec update`
4. Verify `openspec/README.md` fully replaced; `CLAUDE.md` OpenSpec block updated without altering user content outside markers
5. Run the command twice to verify idempotency and no duplicate markers
6. Test with missing `openspec` directory (expect failure)


================================================
FILE: openspec/changes/archive/2025-01-11-add-update-command/proposal.md
================================================
# Add Update Command

## Why

Users need a way to update their local OpenSpec instructions (README.md and CLAUDE.md) when the OpenSpec package releases new versions with improved AI agent instructions or structural conventions.

## What Changes

- Add new `openspec update` CLI command that updates OpenSpec instructions
- Replace `openspec/README.md` with the latest template
  - Safe because this file is fully OpenSpec-managed
- Update only the OpenSpec-managed block in `CLAUDE.md` using markers
  - Preserve all user content outside markers
  - If `CLAUDE.md` is missing, create it with the managed block
- Display success message after update (ASCII-safe): "Updated OpenSpec instructions"
  - A leading checkmark MAY be shown when the terminal supports it
  - Operation is idempotent (re-running yields identical results)

## Impact

- Affected specs: `cli-update` (new capability)
- Affected code:
  - `src/core/update.ts` (new command class, mirrors `InitCommand` placement)
  - `src/cli/index.ts` (register new command)
  - Uses existing templates via `TemplateManager` and `readmeTemplate`

## Out of Scope

- No `.openspec/config.json` is introduced by this change. The default directory name `openspec` is used.


================================================
FILE: openspec/changes/archive/2025-01-11-add-update-command/tasks.md
================================================
# Implementation Tasks

## 1. Update Command Implementation
- [x] 1.1 Create `src/core/update.ts` with `UpdateCommand` class
- [x] 1.2 Check if `openspec` directory exists (use `FileSystemUtils.directoryExists`)
- [x] 1.3 Write `readmeTemplate` to `openspec/README.md` using `FileSystemUtils.writeFile`
- [x] 1.4 Update `CLAUDE.md` using markers via `FileSystemUtils.updateFileWithMarkers` and `TemplateManager.getClaudeTemplate()`
- [x] 1.5 Display ASCII-safe success message: `Updated OpenSpec instructions`

## 2. CLI Integration
- [x] 2.1 Register `update` command in `src/cli/index.ts`
- [x] 2.2 Add command description: `Update OpenSpec instruction files`
- [x] 2.3 Handle errors with `ora().fail(...)` and exit code 1 (missing `openspec` directory, file write errors)

## 3. Testing
- [x] 3.1 Verify `openspec/README.md` is fully replaced with latest template
- [x] 3.2 Verify `CLAUDE.md` OpenSpec block updates without altering user content outside markers
- [x] 3.3 Verify idempotency (running twice yields identical files, no duplicate markers)
- [x] 3.4 Verify error when `openspec` directory is missing with friendly message
- [x] 3.5 Verify success message displays properly in ASCII-only terminals


================================================
FILE: openspec/changes/archive/2025-01-11-add-update-command/specs/cli-update/spec.md
================================================
# Update Command Specification

## Purpose

As a developer using OpenSpec, I want to update the OpenSpec instructions in my project when new versions are released, so that I can benefit from improvements to AI agent instructions.

## Core Requirements

### Update Behavior

The update command SHALL update OpenSpec instruction files to the latest templates.

WHEN a user runs `openspec update` THEN the command SHALL:
- Check if the `openspec` directory exists
- Replace `openspec/README.md` with the latest template (complete replacement)
- Update the OpenSpec-managed block in `CLAUDE.md` using markers
  - Preserve user content outside markers
  - Create `CLAUDE.md` if missing
- Display ASCII-safe success message: "Updated OpenSpec instructions"

### Prerequisites

The command SHALL require:
- An existing `openspec` directory (created by `openspec init`)

IF the `openspec` directory does not exist THEN:
- Display error: "No OpenSpec directory found. Run 'openspec init' first."
- Exit with code 1

### File Handling

The update command SHALL:
- Completely replace `openspec/README.md` with the latest template
- Update only the OpenSpec-managed block in `CLAUDE.md` using markers
- Use the default directory name `openspec`
- Be idempotent (repeated runs have no additional effect)

## Edge Cases

### File Permissions
IF file write fails THEN let the error bubble up naturally with file path.

### Missing CLAUDE.md
IF CLAUDE.md doesn't exist THEN create it with the template content.

### Custom Directory Name
Not supported in this change. The default directory name `openspec` SHALL be used.

## Success Criteria

Users SHALL be able to:
- Update OpenSpec instructions with a single command
- Get the latest AI agent instructions
- See clear confirmation of the update

The update process SHALL be:
- Simple and fast (no version checking)
- Predictable (same result every time)
- Self-contained (no network required)


================================================
FILE: openspec/changes/archive/2025-01-13-add-list-command/proposal.md
================================================
# Add List Command to OpenSpec CLI

## Why

Developers need visibility into available changes and their status to understand the project's evolution and pending work.

## What Changes

- Add `openspec list` command that displays all changes in the changes/ directory
- Show each change name with task completion count (e.g., "add-auth: 3/5 tasks")
- Display completion status indicator (âœ“ for fully complete, progress for partial)
- Skip the archive/ subdirectory to focus on active changes
- Simple table output for easy scanning

## Impact

- Affected specs: New capability `cli-list` will be added
- Affected code:
  - `src/cli/index.ts` - Add list command
  - `src/core/list.ts` - New file with directory scanning and task parsing (~60 lines)


================================================
FILE: openspec/changes/archive/2025-01-13-add-list-command/tasks.md
================================================
# Implementation Tasks

## 1. Core Implementation
- [x] 1.1 Create `src/core/list.ts` with list logic
  - [x] 1.1.1 Implement directory scanning (exclude archive/)
  - [x] 1.1.2 Implement task counting from tasks.md files
  - [x] 1.1.3 Format output as simple table
- [x] 1.2 Add list command to CLI in `src/cli/index.ts`
  - [x] 1.2.1 Register `openspec list` command
  - [x] 1.2.2 Connect to list.ts implementation

## 2. Error Handling
- [x] 2.1 Handle missing openspec/changes/ directory
- [x] 2.2 Handle changes without tasks.md files
- [x] 2.3 Handle empty changes directory

## 3. Testing
- [x] 3.1 Add tests for list functionality
  - [x] 3.1.1 Test with multiple changes
  - [x] 3.1.2 Test with completed changes
  - [x] 3.1.3 Test with no changes
  - [x] 3.1.4 Test error conditions

## 4. Documentation
- [x] 4.1 Update CLI help text with list command
- [x] 4.2 Add list command to README if applicable


================================================
FILE: openspec/changes/archive/2025-01-13-add-list-command/specs/cli-list/spec.md
================================================
# List Command Specification

## Purpose

The `openspec list` command SHALL provide developers with a quick overview of all active changes in the project, showing their names and task completion status.

## Behavior

### Command Execution

WHEN `openspec list` is executed
THEN scan the `openspec/changes/` directory for change directories
AND exclude the `archive/` subdirectory from results
AND parse each change's `tasks.md` file to count task completion

### Task Counting

WHEN parsing a `tasks.md` file
THEN count tasks matching these patterns:
- Completed: Lines containing `- [x]`
- Incomplete: Lines containing `- [ ]`
AND calculate total tasks as the sum of completed and incomplete

### Output Format

WHEN displaying the list
THEN show a table with columns:
- Change name (directory name)
- Task progress (e.g., "3/5 tasks" or "âœ“ Complete")
- Status indicator:
  - `âœ“` for fully completed changes (all tasks done)
  - Progress fraction for partial completion

Example output:
```
Changes:
  add-auth-feature     3/5 tasks
  update-api-docs      âœ“ Complete
  fix-validation       0/2 tasks
  add-list-command     1/4 tasks
```

### Empty State

WHEN no active changes exist (only archive/ or empty changes/)
THEN display: "No active changes found."

### Error Handling

IF a change directory has no `tasks.md` file
THEN display the change with "No tasks" status

IF `openspec/changes/` directory doesn't exist
THEN display error: "No OpenSpec changes directory found. Run 'openspec init' first."
AND exit with code 1

### Sorting

Changes SHALL be displayed in alphabetical order by change name for consistency.

## Why

Developers need a quick way to:
- See what changes are in progress
- Identify which changes are ready to archive
- Understand the overall project evolution status
- Get a bird's-eye view without opening multiple files

This command provides that visibility with minimal effort, following OpenSpec's philosophy of simplicity and clarity.


================================================
FILE: openspec/changes/archive/2025-08-05-initialize-typescript-project/design.md
================================================
# Technical Design

## Technology Choices

### TypeScript Configuration
- **Strict mode**: Enable all strict type checking for better AI understanding
- **Target**: ES2022 for modern JavaScript features
- **Module**: ES2022 for modern ESM support
- **Module Resolution**: Node for proper package resolution
- **Output**: dist/ directory for compiled JavaScript
- **Source Maps**: Enable for debugging TypeScript directly
- **Declaration Files**: Generate .d.ts files for type definitions
- **ES Module Interop**: true for better CommonJS compatibility
- **Skip Lib Check**: false to ensure all types are validated

### Package Structure
```
openspec
â”œâ”€â”€ bin/            # CLI entry point
â”œâ”€â”€ dist/           # Compiled JavaScript
â”œâ”€â”€ src/            # TypeScript source
â”‚   â”œâ”€â”€ cli/        # Command implementations
â”‚   â”œâ”€â”€ core/       # Core OpenSpec logic
â”‚   â””â”€â”€ utils/      # Shared utilities
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ build.js        # Build script
```

### Dependency Strategy
- **Minimal dependencies**: Only essential packages
- **commander**: Industry-standard CLI framework
- **@inquirer/prompts**: Modern prompting library
- **No heavy frameworks**: Direct, readable implementation

### Build Approach
- Native TypeScript compilation via tsc
- Simple build.js script for packaging
- No complex build toolchain needed
- ESM output with proper .js extensions in imports

### Development Workflow
1. `pnpm install` - Install dependencies
2. `pnpm run build` - Compile TypeScript
3. `pnpm run dev` - Development mode
4. `pnpm link` - Test CLI locally

### Node.js Requirements
- **Minimum version**: Node.js 20.19.0
- **Recommended**: Node.js 22 LTS
- **Rationale**: Full ESM support without flags, modern JavaScript features

### ESM Configuration
- **Package type**: `"type": "module"` in package.json
- **File extensions**: Use .js extensions in TypeScript imports (compiles correctly)
- **Top-level await**: Available for cleaner async initialization
- **Future-proof**: Aligns with JavaScript standards

### TypeScript Best Practices
- **All code in TypeScript**: No .js files in src/, only .ts
- **Explicit types**: Prefer explicit typing over inference where it adds clarity
- **Interfaces over types**: Use interfaces for object shapes, types for unions/aliases
- **No any**: Strict mode prevents implicit any, use unknown when needed
- **Async/await**: Modern async patterns throughout


================================================
FILE: openspec/changes/archive/2025-08-05-initialize-typescript-project/proposal.md
================================================
# Initialize TypeScript Project

## Why
The OpenSpec project needs a proper TypeScript foundation to build the minimal CLI that helps developers set up OpenSpec file structures and keep AI instructions updated.

## What Changes
- Create TypeScript project configuration with ESM modules (package.json, tsconfig.json)
- Set up the base directory structure for the CLI implementation
- Configure build scripts and development tooling
- Add essential dependencies for CLI development
- Create .gitignore for Node.js/TypeScript projects
- Set minimum Node.js version to 20.19.0 for native ESM support

## Impact
- Affected specs: None (initial project setup)
- Affected code: None (greenfield project)
- New directories: src/, dist/, node_modules/
- New files: package.json, tsconfig.json, .gitignore, build.js


================================================
FILE: openspec/changes/archive/2025-08-05-initialize-typescript-project/tasks.md
================================================
# Tasks

## 1. Project Configuration
- [x] 1.1 Create package.json with project metadata, scripts, and ESM configuration
- [x] 1.2 Configure TypeScript with tsconfig.json for ESM output
- [x] 1.3 Add .gitignore for Node.js/TypeScript projects
- [x] 1.4 Set Node.js engine requirement to >=20.19.0

## 2. Directory Structure
- [x] 2.1 Create src/ directory for source code
- [x] 2.2 Create src/cli/ for CLI commands
- [x] 2.3 Create src/core/ for core OpenSpec logic
- [x] 2.4 Create src/utils/ for shared utilities

## 3. Build Configuration
- [x] 3.1 Create build.js for native TypeScript compilation
- [x] 3.2 Configure development scripts (build, dev)
- [x] 3.3 Set up package entry points with ESM exports
- [x] 3.4 Configure proper file extensions handling for ESM

## 4. Initial Dependencies
- [x] 4.1 Add TypeScript as dev dependency
- [x] 4.2 Add commander for CLI framework
- [x] 4.3 Add @inquirer/prompts for user interaction
- [x] 4.4 Add necessary type definitions


================================================
FILE: openspec/changes/archive/2025-08-06-add-init-command/design.md
================================================
# Technical Design for Init Command

## Architecture Overview

The init command follows a modular architecture with clear separation of concerns:

```
CLI Layer (src/cli/index.ts)
    â†“
Core Logic (src/core/init.ts)
    â†“
Templates (src/core/templates/)
    â†“
File System Utils (src/utils/file-system.ts)
```

## Key Design Decisions

### 1. Template Management

**Decision**: Store templates as TypeScript modules rather than separate files
**Rationale**: 
- Ensures templates are bundled with the compiled code
- Allows for dynamic content insertion
- Type-safe template handling
- No need for complex file path resolution

### 2. Interactive vs Non-Interactive Mode

**Decision**: Support both interactive (default) and non-interactive modes
**Rationale**:
- Interactive mode for developer experience
- Non-interactive for CI/CD and automation
- Flags: `--yes` to accept defaults, `--no-input` for full automation

### 3. Directory Structure Creation

**Decision**: Create all directories upfront, then populate files
**Rationale**:
- Fail fast if permissions issues
- Clear transaction boundary
- Easier to clean up on failure

### 4. Error Handling Strategy

**Decision**: Implement rollback on failure
**Rationale**:
- Prevent partial installations
- Clear error states
- Better user experience

## Implementation Details

### File System Operations

```typescript
// Atomic directory creation with rollback
interface InitTransaction {
  createdPaths: string[];
  rollback(): Promise<void>;
  commit(): Promise<void>;
}
```

### Template System

```typescript
interface Template {
  path: string;
  content: string | ((context: ProjectContext) => string);
}

interface ProjectContext {
  projectName: string;
  description: string;
  techStack: string[];
  conventions: string;
}
```

### CLI Command Structure

```bash
openspec init [path]           # Initialize in specified path (default: current directory)
  --yes                       # Accept all defaults
  --no-input                  # Skip all prompts
  --force                     # Overwrite existing OpenSpec directory
  --dry-run                   # Show what would be created
```

## Security Considerations

1. **Path Traversal**: Sanitize all user-provided paths
2. **File Permissions**: Check write permissions before starting
3. **Existing Files**: Never overwrite without explicit --force flag
4. **Template Injection**: Sanitize user inputs in templates

## Future Extensibility

The design supports future enhancements:
- Custom template sources
- Project type presets (API, web app, library)
- Migration from other documentation systems
- Integration with version control systems


================================================
FILE: openspec/changes/archive/2025-08-06-add-init-command/proposal.md
================================================
# Add Init Command for OpenSpec

## Why

Projects need a simple way to adopt OpenSpec conventions. Currently, users must manually create the directory structure and understand all the conventions, which creates friction for adoption. An init command would enable instant OpenSpec setup with proper structure and guidance.

## What Changes

- Add `openspec init` CLI command that creates the complete OpenSpec directory structure
- Generate template files (README.md with AI instructions, project.md template)
- Interactive prompt to select which AI tools to configure (Claude Code initially, others marked as "coming soon")
- Support for multiple AI coding assistants with extensible plugin architecture
- Smart file updates using content markers to preserve existing configurations
- Custom directory naming with `--dir` flag
- Validation to prevent overwriting existing OpenSpec structures
- Clear error messages with helpful guidance (e.g., suggesting 'openspec update' for existing structures)
- Display actionable next steps after successful initialization

### Breaking Changes
- None - this is a new feature

## Impact

- Affected specs: None (new feature)
- Affected code: 
  - src/cli/index.ts (add init command)
  - src/core/init.ts (new - initialization logic)
  - src/core/templates/ (new - template files)
  - src/core/configurators/ (new - AI tool plugins)
  - src/utils/file-system.ts (new - file operations)


================================================
FILE: openspec/changes/archive/2025-08-06-add-init-command/tasks.md
================================================
# Implementation Tasks for Init Command

## 1. Core Infrastructure
- [x] 1.1 Create src/utils/file-system.ts with directory/file creation utilities
- [x] 1.2 Create src/core/templates/index.ts for template management
- [x] 1.3 Create src/core/init.ts with main initialization logic
- [x] 1.4 Create src/core/config.ts for configuration management

## 2. Template Files
- [x] 2.1 Create src/core/templates/readme-template.ts with OpenSpec README content
- [x] 2.2 Create src/core/templates/project-template.ts with customizable project.md
- [x] 2.3 Create src/core/templates/claude-template.ts for CLAUDE.md content with markers

## 3. AI Tool Configurators
- [x] 3.1 Create src/core/configurators/base.ts with ToolConfigurator interface
- [x] 3.2 Create src/core/configurators/claude.ts for Claude Code configuration
- [x] 3.3 Create src/core/configurators/registry.ts for tool registration
- [x] 3.4 Implement marker-based file updates for existing configurations

## 4. Init Command Implementation
- [x] 4.1 Add init command to src/cli/index.ts using Commander
- [x] 4.2 Implement AI tool selection with multi-select prompt (Claude Code available, others "coming soon") - requires at least one selection
- [x] 4.3 Add validation for existing OpenSpec directories with helpful error message
- [x] 4.4 Implement directory structure creation
- [x] 4.5 Implement file generation with templates and markers

## 5. User Experience
- [x] 5.1 Add colorful console output for better UX
- [x] 5.2 Implement progress indicators (Step 1/3, 2/3, 3/3)
- [x] 5.3 Add success message with actionable next steps (edit project.md, create first change)
- [x] 5.4 Add error handling with helpful messages

## 6. Testing and Documentation
- [x] 6.1 Add unit tests for file system utilities
- [x] 6.2 Add unit tests for marker-based file updates
- [x] 6.3 Add integration tests for init command
- [x] 6.4 Update package.json with proper bin configuration
- [x] 6.5 Test the built CLI command end-to-end


================================================
FILE: openspec/changes/archive/2025-08-06-add-init-command/specs/cli-init/spec.md
================================================
# CLI Init Specification

## Purpose

The `openspec init` command SHALL create a complete OpenSpec directory structure in any project, enabling immediate adoption of OpenSpec conventions with support for multiple AI coding assistants.

## Behavior

### Progress Indicators

WHEN executing initialization steps
THEN validate environment silently in background (no output unless error)
AND display progress with ora spinners:
- Show spinner: "â ‹ Creating OpenSpec structure..."
- Then success: "âœ” OpenSpec structure created"
- Show spinner: "â ‹ Configuring AI tools..."
- Then success: "âœ” AI tools configured"

### Directory Creation

WHEN `openspec init` is executed
THEN create the following directory structure:
```
openspec/
â”œâ”€â”€ project.md
â”œâ”€â”€ README.md
â”œâ”€â”€ specs/
â””â”€â”€ changes/
    â””â”€â”€ archive/
```

### File Generation

The command SHALL generate:
- `README.md` containing complete OpenSpec instructions for AI assistants
- `project.md` with project context template

### AI Tool Configuration

WHEN run interactively
THEN prompt user to select AI tools to configure:
- Claude Code (updates/creates CLAUDE.md with OpenSpec markers)
- Cursor (future)
- Aider (future)

### AI Tool Configuration Details

WHEN Claude Code is selected
THEN create or update `CLAUDE.md` in the project root directory (not inside openspec/)

WHEN CLAUDE.md does not exist
THEN create new file with OpenSpec content wrapped in markers:
```markdown
<!-- OPENSPEC:START -->
# OpenSpec Project

This document provides instructions for AI coding assistants on how to use OpenSpec conventions for spec-driven development. Follow these rules precisely when working on OpenSpec-enabled projects.

This project uses OpenSpec for spec-driven development. Specifications are the source of truth.

See @openspec/README.md for detailed conventions and guidelines.
<!-- OPENSPEC:END -->
```

WHEN CLAUDE.md already exists
THEN preserve all existing content
AND insert OpenSpec content at the beginning of the file using markers
AND ensure markers don't duplicate if they already exist

The marker system SHALL:
- Use `<!-- OPENSPEC:START -->` to mark the beginning of managed content
- Use `<!-- OPENSPEC:END -->` to mark the end of managed content
- Allow OpenSpec to update its content without affecting user customizations
- Preserve all content outside the markers intact

WHY use markers:
- Users may have existing CLAUDE.md instructions they want to keep
- OpenSpec can update its instructions in future versions
- Clear boundary between OpenSpec-managed and user-managed content

### Interactive Mode

WHEN run
THEN prompt user with: "Which AI tool do you use?"
AND show single-select menu with available tools:
- Claude Code
AND show disabled options as "coming soon" (not selectable):
- Cursor (coming soon)
- Aider (coming soon)  
- Continue (coming soon)

User navigation:
- Use arrow keys to move between options
- Press Enter to select the highlighted option

### Safety Checks

WHEN `openspec/` directory already exists
THEN display error with ora fail indicator:
"âœ– Error: OpenSpec seems to already be initialized. Use 'openspec update' to update the structure."

WHEN checking initialization feasibility
THEN verify write permissions in the target directory silently
AND only display error if permissions are insufficient

### Success Output

WHEN initialization completes successfully
THEN display actionable prompts for AI-driven workflow:
```
âœ” OpenSpec initialized successfully!

Next steps - Copy these prompts to Claude:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Populate your project context:
   "Please read openspec/project.md and help me fill it out
    with details about my project, tech stack, and conventions"

2. Create your first change proposal:
   "I want to add [YOUR FEATURE HERE]. Please create an
    OpenSpec change proposal for this feature"

3. Learn the OpenSpec workflow:
   "Please explain the OpenSpec workflow from openspec/README.md
    and how I should work with you on this project"
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

The prompts SHALL:
- Be copy-pasteable for immediate use with AI tools
- Guide users through the AI-driven workflow
- Replace placeholder text ([YOUR FEATURE HERE]) with actual features

### Exit Codes

- 0: Success
- 1: General error (including when OpenSpec directory already exists)
- 2: Insufficient permissions (reserved for future use)
- 3: User cancelled operation (reserved for future use)

## Why

Manual creation of OpenSpec structure is error-prone and creates adoption friction. A standardized init command ensures:
- Consistent structure across all projects
- Proper AI instruction files are always included
- Quick onboarding for new projects
- Clear conventions from the start


================================================
FILE: openspec/changes/archive/2025-08-06-adopt-future-state-storage/proposal.md
================================================
# Adopt Future State Storage for OpenSpec Changes

## Why

The current approach of storing spec changes as diff files (`.spec.md.diff`) creates friction for both humans and AI. Diff syntax with `+` and `-` prefixes makes specs hard to read, AI tools struggle with the format when understanding future state, and GitHub can't show nice comparisons between current and proposed specs in different folders.

## What Changes

- Change from storing diffs (`patches/[capability]/spec.md.diff`) to storing complete future state (`specs/[capability]/spec.md`)
- Update all documentation to reflect new storage format
- Migrate existing `add-init-command` change to new format
- Add new `openspec-conventions` capability to document these conventions



## Impact

- Affected specs: New `openspec-conventions` capability
- Affected code: 
  - openspec/README.md (lines 85-108)
  - docs/PRD.md (lines 376-382, 778-783)
  - docs/openspec-walkthrough.md (lines 58-62, 112-126)
  - openspec/changes/add-init-command/ (migration needed)




================================================
FILE: openspec/changes/archive/2025-08-06-adopt-future-state-storage/tasks.md
================================================
# Implementation Tasks

## 1. Update Core Documentation
- [x] 1.1 Update openspec/README.md section on "Creating a Change Proposal"
  - [x] Replace `patches/` with `specs/` in directory structure
  - [x] Update step 3 to show storing complete future state
  - [x] Remove diff syntax instructions (+/- prefixes)

## 2. Migrate Existing Change
- [x] 2.1 Convert add-init-command change to new format
  - [x] Create `specs/cli-init/spec.md` with clean content (no diff markers)
  - [x] Delete old `patches/` directory
- [x] 2.2 Test that the migrated change is clear and reviewable

## 3. Update Documentation Examples
- [x] 3.1 Update docs/PRD.md
  - [x] Fix directory structure examples (lines 376-382)
  - [x] Update archive examples (lines 778-783)
  - [x] Ensure consistency throughout
- [x] 3.2 Update docs/openspec-walkthrough.md
  - [x] Replace diff examples with future state examples
  - [x] Ensure the walkthrough reflects new approach

## 4. Create New Spec
- [x] 4.1 Finalize openspec-conventions spec in main specs/ directory
  - [x] Document the future state storage approach
  - [x] Include examples of good proposals
  - [x] Make it the source of truth for conventions

## 5. Validation
- [x] 5.1 Verify all documentation is consistent
- [x] 5.2 Test creating a new change with the new approach
- [x] 5.3 Ensure GitHub PR view shows diffs clearly

## 6. Deployment
- [x] 6.1 Get approval for this change
- [x] 6.2 Implement all tasks above
- [x] 6.3 After deployment, archive this change with completion date


================================================
FILE: openspec/changes/archive/2025-08-06-adopt-future-state-storage/specs/openspec-conventions/spec.md
================================================
# OpenSpec Conventions Specification

## Purpose

OpenSpec conventions SHALL define how system capabilities are documented, how changes are proposed and tracked, and how specifications evolve over time. This meta-specification serves as the source of truth for OpenSpec's own conventions.

## Core Principles

The system SHALL follow these principles:
- Specs reflect what IS currently built and deployed
- Changes contain proposals for what SHOULD be changed
- AI drives the documentation process
- Specs are living documentation kept in sync with deployed code

## Directory Structure

WHEN an OpenSpec project is initialized
THEN it SHALL have this structure:
```
openspec/
â”œâ”€â”€ project.md              # Project-specific context
â”œâ”€â”€ README.md               # AI assistant instructions
â”œâ”€â”€ specs/                  # Current deployed capabilities
â”‚   â””â”€â”€ [capability]/       # Single, focused capability
â”‚       â”œâ”€â”€ spec.md         # WHAT and WHY
â”‚       â””â”€â”€ design.md       # HOW (optional, for established patterns)
â””â”€â”€ changes/                # Proposed changes
    â”œâ”€â”€ [change-name]/      # Descriptive change identifier
    â”‚   â”œâ”€â”€ proposal.md     # Why, what, and impact
    â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
    â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional)
    â”‚   â””â”€â”€ specs/          # Complete future state
    â”‚       â””â”€â”€ [capability]/
    â”‚           â””â”€â”€ spec.md # Clean markdown (no diff syntax)
    â””â”€â”€ archive/            # Completed changes
        â””â”€â”€ YYYY-MM-DD-[name]/
```

## Change Storage Convention

### Future State Storage

WHEN creating a change proposal
THEN store the complete future state of affected specs
AND use clean markdown without diff syntax

The `changes/[name]/specs/` directory SHALL contain:
- Complete spec files as they will exist after the change
- Clean markdown without `+` or `-` prefixes
- All formatting and structure of the final intended state

### Proposal Format

WHEN documenting what changes
THEN the proposal SHALL explicitly describe each change:

```markdown
**[Section or Behavior Name]**
- From: [current state/requirement]
- To: [future state/requirement]
- Reason: [why this change is needed]
- Impact: [breaking/non-breaking, who's affected]
```

This explicit format compensates for not having inline diffs and ensures reviewers understand exactly what will change.

## Change Lifecycle

The change process SHALL follow these states:

1. **Propose**: AI creates change with future state specs and explicit proposal
2. **Review**: Humans review proposal and future state
3. **Approve**: Change is approved for implementation
4. **Implement**: Follow tasks.md checklist (can span multiple PRs)
5. **Deploy**: Changes are deployed to production
6. **Update**: Specs in `specs/` are updated to match deployed reality
7. **Archive**: Change is moved to `archive/YYYY-MM-DD-[name]/`

## Viewing Changes

WHEN reviewing proposed changes
THEN reviewers can compare using:
- GitHub PR diff view when changes are committed
- Command line: `diff -u specs/[capability]/spec.md changes/[name]/specs/[capability]/spec.md`
- Any visual diff tool comparing current vs future state

The system relies on tools to generate diffs rather than storing them.

## Capability Naming

Capabilities SHALL use:
- Verb-noun patterns (e.g., `user-auth`, `payment-capture`)
- Hyphenated lowercase names
- Singular focus (one responsibility per capability)
- No nesting (flat structure under `specs/`)

## When Changes Require Proposals

A proposal SHALL be created for:
- New features or capabilities
- Breaking changes to existing behavior
- Architecture or pattern changes
- Performance optimizations that change behavior
- Security updates affecting access patterns

A proposal is NOT required for:
- Bug fixes restoring intended behavior
- Typos or formatting fixes
- Non-breaking dependency updates
- Adding tests for existing behavior
- Documentation clarifications

## Why This Approach

Clean future state storage provides:
- **Readability**: No diff syntax pollution
- **AI-compatibility**: Standard markdown that AI tools understand
- **Simplicity**: No special parsing or processing needed
- **Tool-agnostic**: Any diff tool can show changes
- **Clear intent**: Explicit proposals document reasoning


================================================
FILE: openspec/changes/archive/2025-08-11-add-complexity-guidelines/proposal.md
================================================
# Add Complexity Management Guidelines

## Why
OpenSpec currently lacks guidance on managing complexity, leading to over-engineered solutions when simple ones suffice.

## What Changes
- Add "Start Simple" section to openspec/README.md with default minimalism rules
- Add complexity triggers to help identify when complexity is justified
- Enhance AI assistant instructions in CLAUDE.md to bias toward simplicity

## Impact
- Affected specs: None (documentation only)
- Affected code: openspec/README.md, CLAUDE.md


================================================
FILE: openspec/changes/archive/2025-08-11-add-complexity-guidelines/tasks.md
================================================
# Implementation Tasks

## 1. Update OpenSpec README
- [x] 1.1 Add "Start Simple" section after Core Principle
- [x] 1.2 Add complexity triggers to "When to Create Change Proposals" section
- [x] 1.3 Update AI workflow guidance to emphasize minimal implementations

## 2. Update CLAUDE.md
- [x] 2.1 Add complexity management rules to project instructions


================================================
FILE: openspec/changes/archive/2025-08-11-add-complexity-guidelines/specs/openspec-docs/README.md
================================================
# OpenSpec Instructions

This document provides instructions for AI coding assistants on how to use OpenSpec conventions for spec-driven development. Follow these rules precisely when working on OpenSpec-enabled projects.

## Core Principle

OpenSpec is an AI-native system for change-driven development where:
- **Specs** (`specs/`) reflect what IS currently built and deployed
- **Changes** (`changes/`) contain proposals for what SHOULD be changed
- **AI drives the process** - You generate proposals, humans review and approve
- **Specs are living documentation** - Always kept in sync with deployed code

## Start Simple

**Default to minimal implementations:**
- New features should be <100 lines of code initially
- Use the simplest solution that works
- Avoid premature optimization (no caching, parallelization, or complex patterns without proven need)
- Choose boring technology over cutting-edge solutions

**Complexity triggers** - Only add complexity when you have:
- **Performance data** showing current solution is too slow
- **Scale requirements** with specific numbers (>1000 users, >100MB data)
- **Multiple use cases** requiring the same abstraction
- **Regulatory compliance** mandating specific patterns
- **Security threats** that simple solutions cannot address

When triggered, document the specific justification in your change proposal.

## Directory Structure

```
openspec/
â”œâ”€â”€ project.md              # Project-specific context (tech stack, conventions)
â”œâ”€â”€ README.md               # This file - OpenSpec instructions
â”œâ”€â”€ specs/                  # Current truth - what IS built
â”‚   â”œâ”€â”€ [capability]/       # Single, focused capability
â”‚   â”‚   â”œâ”€â”€ spec.md         # WHAT the capability does and WHY
â”‚   â”‚   â””â”€â”€ design.md       # HOW it's built (established patterns)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ changes/                # Proposed changes - what we're CHANGING
â”‚   â”œâ”€â”€ [change-name]/
â”‚   â”‚   â”œâ”€â”€ proposal.md     # Why, what, impact (consolidated)
â”‚   â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
â”‚   â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional, for complex changes)
â”‚   â”‚   â””â”€â”€ specs/          # Future state of affected specs
â”‚   â”‚       â””â”€â”€ [capability]/
â”‚   â”‚           â””â”€â”€ spec.md # Clean markdown (no diff syntax)
â”‚   â””â”€â”€ archive/            # Completed changes (dated)
```

### Capability Organization

**Use capabilities, not features** - Each directory under `specs/` represents a single, focused responsibility:
- **Verb-noun naming**: `user-auth`, `payment-capture`, `order-checkout`
- **10-minute rule**: Each capability should be understandable in <10 minutes
- **Single purpose**: If it needs "AND" to describe it, split it

Examples:
```
âœ… GOOD: user-auth, user-sessions, payment-capture, payment-refunds
âŒ BAD: users, payments, core, misc
```

## Key Behavioral Rules

### 1. Always Start by Reading

Before any task:
1. **Read relevant specs** in `specs/[capability]/spec.md` to understand current state
2. **Check pending changes** in `changes/` directory for potential conflicts
3. **Read project.md** for project-specific conventions

### 2. When to Create Change Proposals

**ALWAYS create a change proposal for:**
- New features or functionality
- Breaking changes (API changes, schema updates)
- Architecture changes or new patterns
- Performance optimizations that change behavior
- Security updates affecting auth/access patterns
- Any change requiring multiple steps or affecting multiple systems

**SKIP proposals for:**
- Bug fixes that restore intended behavior
- Typos, formatting, or comment updates
- Dependency updates (unless breaking)
- Configuration or environment variable changes
- Adding tests for existing behavior
- Documentation fixes

**Complexity assessment:**
- If your solution requires >100 lines of new code, justify the complexity
- If adding dependencies, frameworks, or architectural patterns, document why simpler alternatives won't work
- Default to single-file implementations until proven insufficient

### 3. Creating a Change Proposal

When a user requests a significant change:

```bash
# 1. Create the change directory
openspec/changes/[descriptive-name]/

# 2. Generate proposal.md with all context
## Why
[1-2 sentences on the problem/opportunity]

## What Changes  
[Bullet list of changes, including breaking changes]

## Impact
- Affected specs: [list capabilities that will change]
- Affected code: [list key files/systems]

# 3. Create future state specs for ALL affected capabilities
# - Store complete spec files as they will exist after the change
# - Use clean markdown without diff syntax (+/- prefixes)
# - Include all formatting and structure of the final intended state
specs/
â””â”€â”€ [capability]/
    â””â”€â”€ spec.md

# 4. Create tasks.md with implementation steps
## 1. [Task Group]
- [ ] 1.1 [Specific task]
- [ ] 1.2 [Specific task]

# 5. For complex changes, add design.md
[Technical decisions and trade-offs]
```

### 4. The Change Lifecycle

1. **Propose** â†’ Create change directory with all documentation
2. **Review** â†’ User reviews and approves the proposal
3. **Implement** â†’ Follow the approved tasks.md (can be multiple PRs)
4. **Deploy** â†’ User confirms deployment
5. **Update Specs** â†’ Sync specs/ with new reality (IF the change affects system capabilities)
6. **Archive** â†’ Move to `changes/archive/YYYY-MM-DD-[name]/`

### 5. Implementing Changes

When implementing an approved change:
1. Follow the tasks.md checklist exactly
2. **Mark completed tasks** in tasks.md as you finish them (e.g., `- [x] 1.1 Task completed`)
3. Ensure code matches the proposed behavior
4. Update any affected tests
5. **Keep change in `changes/` directory** - do NOT archive in implementation PR

**Multiple Implementation PRs:**
- Changes can be implemented across multiple PRs
- Each PR should update tasks.md to mark what was completed
- Different developers can work on different task groups
- Example: PR #1 completes tasks 1.1-1.3, PR #2 completes tasks 2.1-2.4

### 6. Updating Specs and Archiving After Deployment

**Create a separate PR after deployment** that:
1. Moves change to `changes/archive/YYYY-MM-DD-[name]/`
2. Updates relevant files in `specs/` to reflect new reality (if needed)
3. If design.md exists, incorporates proven patterns into `specs/[capability]/design.md`

This ensures changes are only archived when truly complete and deployed.

### 7. Types of Changes That Don't Require Specs

Some changes only affect development infrastructure and don't need specs:
- Initial project setup (package.json, tsconfig.json, etc.)
- Development tooling changes (linters, formatters, build tools)
- CI/CD configuration
- Development dependencies

For these changes:
1. Implement â†’ Deploy â†’ Mark tasks complete â†’ Archive
2. Skip the "Update Specs" step entirely

### What Deserves a Spec?

Ask yourself:
- Is this a system capability that users or other systems interact with?
- Does it have ongoing behavior that needs documentation?
- Would a new developer need to understand this to work with the system?

If NO to all â†’ No spec needed (likely just tooling/infrastructure)

## Understanding Specs vs Code

### Specs Document WHAT and WHY
```markdown
# Authentication Spec

Users SHALL authenticate with email and password.

WHEN credentials are valid THEN issue JWT token.
WHEN credentials are invalid THEN return generic error.

WHY: Prevent user enumeration attacks.
```

### Code Documents HOW
```javascript
// Implementation details
const user = await db.users.findOne({ email });
const valid = await bcrypt.compare(password, user.hashedPassword);
```

**Key Distinction**: Specs capture intent, constraints, and decisions that aren't obvious from code.

## Common Scenarios

### New Feature Request
```
User: "Add password reset functionality"

You should:
1. Read specs/user-auth/spec.md
2. Check changes/ for pending auth changes
3. Create changes/add-password-reset/ with proposal
4. Wait for approval before implementing
```

### Bug Fix
```
User: "Getting null pointer error when bio is empty"

You should:
1. Check if spec says bios are optional
2. If yes â†’ Fix directly (it's a bug)
3. If no â†’ Create change proposal (it's a behavior change)
```

### Infrastructure Setup
```
User: "Initialize TypeScript project"

You should:
1. Create change proposal for TypeScript setup
2. Implement configuration files (PR #1)
3. Mark tasks complete in tasks.md
4. After deployment, create separate PR to archive
   (no specs update needed - this is tooling, not a capability)
```

## Summary Workflow

1. **Receive request** â†’ Determine if it needs a change proposal
2. **Read current state** â†’ Check specs and pending changes
3. **Create proposal** â†’ Generate complete change documentation
4. **Get approval** â†’ User reviews the proposal
5. **Implement** â†’ Follow approved tasks, mark completed items in tasks.md
6. **Deploy** â†’ User deploys the implementation
7. **Archive PR** â†’ Create separate PR to:
   - Move change to archive
   - Update specs if needed
   - Mark change as complete

## PR Workflow Examples

### Single Developer, Simple Change
```
PR #1: Implementation
- Implement all tasks
- Update tasks.md marking items complete
- Get merged and deployed

PR #2: Archive (after deployment)
- Move changes/feature-x/ â†’ changes/archive/2025-01-15-feature-x/
- Update specs if needed
```

### Multiple Developers, Complex Change
```
PR #1: Alice implements auth components
- Complete tasks 1.1, 1.2, 1.3
- Update tasks.md marking these complete

PR #2: Bob implements UI components  
- Complete tasks 2.1, 2.2
- Update tasks.md marking these complete

PR #3: Alice fixes integration issues
- Complete remaining task 1.4
- Update tasks.md

[Deploy all changes]

PR #4: Archive
- Move to archive with deployment date
- Update specs to reflect new auth flow
```

### Key Rules
- **Never archive in implementation PRs** - changes aren't done until deployed
- **Always update tasks.md** - shows accurate progress
- **One archive PR per change** - clear completion boundary
- **Archive PR includes spec updates** - keeps specs current

## Capability Organization Best Practices

### Naming Capabilities
- Use **verb-noun** patterns: `user-auth`, `payment-capture`, `order-checkout`
- Be specific: `payment-capture` not just `payments`
- Keep flat: Avoid nesting capabilities within capabilities
- Singular focus: If you need "AND" to describe it, split it

### When to Split Capabilities
Split when you have:
- Multiple unrelated API endpoints
- Different user personas or actors
- Separate deployment considerations
- Independent evolution paths

#### Capability Boundary Guidelines
- Would you import these separately? â†’ Separate capabilities
- Different deployment cadence? â†’ Separate capabilities
- Different teams own them? â†’ Separate capabilities
- Shared data models are OK, shared business logic means combine

Examples:
- user-auth (login/logout) vs user-sessions (token management) â†’ SEPARATE
- payment-capture vs payment-refunds â†’ SEPARATE (different workflows)
- user-profile vs user-settings â†’ COMBINE (same data model, same owner)

### Cross-Cutting Concerns
For system-wide policies (rate limiting, error handling, security), document them in:
- `project.md` for project-wide conventions
- Within relevant capability specs where they apply
- Or create a dedicated capability if complex enough (e.g., `api-rate-limiting/`)

### Examples of Well-Organized Capabilities
```
specs/
â”œâ”€â”€ user-auth/              # Login, logout, password reset
â”œâ”€â”€ user-sessions/          # Token management, refresh
â”œâ”€â”€ user-profile/           # Profile CRUD operations
â”œâ”€â”€ payment-capture/        # Processing payments
â”œâ”€â”€ payment-refunds/        # Handling refunds
â””â”€â”€ order-checkout/         # Checkout workflow
```

For detailed guidance, see the [Capability Organization Guide](../docs/capability-organization.md).

## Common Scenarios and Clarifications

### Decision Ambiguity: Bug vs Behavior Change

When specs are missing or ambiguous:
- If NO spec exists â†’ Treat current code behavior as implicit spec, require proposal
- If spec is VAGUE â†’ Require proposal to clarify spec alongside fix
- If code and spec DISAGREE â†’ Spec is truth, code is buggy (fix without proposal)
- If unsure â†’ Default to creating a proposal (safer option)

Example:
```
User: "The API returns 404 for missing users but should return 400"
AI: Is this a bug (spec says 400) or behavior change (spec says 404)?
```

### When You Don't Know the Scope
It's OK to explore first! Tell the user you need to investigate, then create an informed proposal.

### Exploration Phase (When Needed)

BEFORE creating proposal, you may need exploration when:
- User request is vague or high-level
- Multiple implementation approaches exist
- Scope is unclear without seeing code

Exploration checklist:
1. Tell user you need to explore first
2. Use Grep/Read to understand current state
3. Create initial proposal based on findings
4. Refine with user feedback

Example:
```
User: "Add caching to improve performance"
AI: "Let me explore the codebase to understand the current architecture and identify caching opportunities."
[After exploration]
AI: "Based on my analysis, I've identified three areas where caching would help. Here's my proposal..."
```

### When No Specs Exist
Treat current code as implicit spec. Your proposal should document current state AND proposed changes.

### When in Doubt
Default to creating a proposal. It's easier to skip an unnecessary proposal than fix an undocumented change.

### AI Workflow Adaptations

Task tracking with OpenSpec:
- Track exploration tasks separately from implementation
- Document proposal creation steps as you go
- Keep implementation tasks separate until proposal approved

Parallel operations encouraged:
- Read multiple specs simultaneously
- Check multiple pending changes at once
- Batch related searches for efficiency

Progress communication:
- "Exploring codebase to understand scope..."
- "Creating proposal based on findings..."
- "Implementing approved changes..."

### For AI Assistants
- **Bias toward simplicity** - Propose the minimal solution that works
- Use your exploration tools liberally before proposing
- Batch operations for efficiency
- Communicate your progress
- It's OK to revise proposals based on discoveries
- **Question complexity** - If your solution feels complex, simplify first

## Edge Case Handling

### Multi-Capability Changes
Create ONE proposal that:
- Lists all affected capabilities
- Shows changes per capability
- Has unified task list
- Gets approved as a whole

### Outdated Specs
If specs clearly outdated:
1. Create proposal to update specs to match reality
2. Implement new feature in separate proposal
3. OR combine both in one proposal with clear sections

### Emergency Hotfixes
For critical production issues:
1. Announce: "This is an emergency fix"
2. Implement fix immediately
3. Create retroactive proposal
4. Update specs after deployment
5. Tag with [EMERGENCY] in archive

### Pure Refactoring
No proposal needed for:
- Code formatting/style
- Internal refactoring (same API)
- Performance optimization (same behavior)
- Adding types to untyped code

Proposal REQUIRED for:
- API changes (even if compatible)
- Database schema changes
- Architecture changes
- New dependencies

### Observability Additions
No proposal needed for:
- Adding log statements
- New metrics/traces
- Debugging additions
- Error tracking

Proposal REQUIRED if:
- Changes log format/structure
- Adds new monitoring service
- Changes what's logged (privacy)

## Remember

- You are the process driver - automate documentation burden
- Specs must always reflect deployed reality
- Changes are proposed, not imposed
- Impact analysis prevents surprises
- **Simplicity is the power** - just markdown files, minimal solutions
- Start simple, add complexity only when justified

By following these conventions, you enable true spec-driven development where documentation stays current, changes are traceable, and evolution is intentional.


================================================
FILE: openspec/changes/archive/2025-08-13-add-archive-command/proposal.md
================================================
## Why
Need a command to archive completed changes to the archive folder with proper date prefixing, following OpenSpec conventions. Currently changes must be manually moved and renamed.

## What Changes
- Add new `archive` command to CLI that moves changes to `changes/archive/YYYY-MM-DD-[change-name]/`
- Check for incomplete tasks before archiving and warn user
- Allow interactive selection of change to archive
- Prevent archiving if target directory already exists
- Update main specs from the change's future state specs (copy from `changes/[name]/specs/` to `openspec/specs/`)
- Show confirmation prompt before updating specs, displaying which specs will be created/updated
- Support `--yes` flag to skip confirmations for automation

## Impact
- Affected specs: cli-archive (new)
- Affected code: src/cli/index.ts, src/core/archive.ts (new)


================================================
FILE: openspec/changes/archive/2025-08-13-add-archive-command/tasks.md
================================================
# Implementation Tasks

## 1. Core Implementation
- [ ] 1.1 Create `src/core/archive.ts` with ArchiveCommand class
  - [ ] 1.1.1 Implement change selection (interactive if not provided)
  - [ ] 1.1.2 Implement incomplete task checking from tasks.md
  - [ ] 1.1.3 Implement confirmation prompt for incomplete tasks
  - [ ] 1.1.4 Implement spec update functionality
    - [ ] 1.1.4.1 Detect specs in change directory
    - [ ] 1.1.4.2 Compare with existing main specs
    - [ ] 1.1.4.3 Display summary of new vs updated specs
    - [ ] 1.1.4.4 Show confirmation prompt for spec updates
    - [ ] 1.1.4.5 Copy specs to main spec directory
  - [ ] 1.1.5 Implement archive move with date prefixing
  - [ ] 1.1.6 Support --yes flag to skip confirmations

## 2. CLI Integration
- [ ] 2.1 Add archive command to `src/cli/index.ts`
  - [ ] 2.1.1 Import ArchiveCommand
  - [ ] 2.1.2 Register command with commander
  - [ ] 2.1.3 Add --yes/-y flag option
  - [ ] 2.1.4 Add proper error handling

## 3. Error Handling
- [ ] 3.1 Handle missing openspec/changes/ directory
- [ ] 3.2 Handle change not found
- [ ] 3.3 Handle archive target already exists
- [ ] 3.4 Handle user cancellation

## 4. Testing
- [ ] 4.1 Test with fully completed change
- [ ] 4.2 Test with incomplete tasks (warning shown)
- [ ] 4.3 Test interactive selection mode
- [ ] 4.4 Test duplicate archive prevention
- [ ] 4.5 Test spec update functionality
  - [ ] 4.5.1 Test creating new specs
  - [ ] 4.5.2 Test updating existing specs
  - [ ] 4.5.3 Test confirmation prompt display
  - [ ] 4.5.4 Test declining confirmation (no changes made)
  - [ ] 4.5.5 Test --yes flag skips confirmation

## 5. Build and Validation
- [ ] 5.1 Ensure TypeScript compilation succeeds
- [ ] 5.2 Test command execution


================================================
FILE: openspec/changes/archive/2025-08-13-add-archive-command/specs/cli-archive/spec.md
================================================
# CLI Archive Command Specification

## Purpose
The archive command moves completed changes from the active changes directory to the archive folder with date-based naming, following OpenSpec conventions.

## Command Syntax
```bash
openspec archive [change-name] [--yes|-y]
```

Options:
- `--yes`, `-y`: Skip confirmation prompts (for automation)

## Behavior

### Change Selection
WHEN no change-name is provided
THEN display interactive list of available changes (excluding archive/)
AND allow user to select one

WHEN change-name is provided
THEN use that change directly
AND validate it exists

### Task Completion Check
The command SHALL scan the change's tasks.md file for incomplete tasks (marked with `- [ ]`)

WHEN incomplete tasks are found
THEN display all incomplete tasks to the user
AND prompt for confirmation to continue
AND default to "No" for safety

WHEN all tasks are complete OR no tasks.md exists
THEN proceed with archiving without prompting

### Archive Process
The archive operation SHALL:
1. Create archive/ directory if it doesn't exist
2. Generate target name as `YYYY-MM-DD-[change-name]` using current date
3. Check if target directory already exists
4. Update main specs from the change's future state specs (see Spec Update Process below)
5. Move the entire change directory to the archive location

WHEN target archive already exists
THEN fail with error message
AND do not overwrite existing archive

WHEN move succeeds
THEN display success message with archived name and list of updated specs

### Spec Update Process
Before moving the change to archive, the command SHALL update main specs to reflect the deployed reality:

WHEN the change contains specs in `changes/[name]/specs/`
THEN:
1. Analyze which specs will be affected by comparing with existing specs
2. Display a summary of spec updates to the user (see Confirmation Behavior below)
3. Prompt for confirmation unless `--yes` flag is provided
4. If confirmed, for each capability spec in the change directory:
   - Copy the spec from `changes/[name]/specs/[capability]/spec.md` to `openspec/specs/[capability]/spec.md`
   - Create the target directory structure if it doesn't exist
   - Overwrite existing spec files (specs represent current reality, change specs are the new reality)
   - Track which specs were updated for the success message

WHEN no specs exist in the change
THEN skip the spec update step
AND proceed with archiving

### Confirmation Behavior
The spec update confirmation SHALL:
- Display a clear summary showing:
  - Which specs will be created (new capabilities)
  - Which specs will be updated (existing capabilities)
  - The source path for each spec
- Format the confirmation prompt as:
  ```
  The following specs will be updated:
  
  NEW specs to be created:
    - cli-archive (from changes/add-archive-command/specs/cli-archive/spec.md)
  
  EXISTING specs to be updated:
    - cli-init (from changes/update-init-command/specs/cli-init/spec.md)
  
  Update 2 specs and archive 'add-archive-command'? [y/N]:
  ```
- Default to "No" for safety (require explicit "y" or "yes")
- Skip confirmation when `--yes` or `-y` flag is provided

WHEN user declines the confirmation
THEN abort the entire archive operation
AND display message: "Archive cancelled. No changes were made."
AND exit with non-zero status code

## Error Handling

SHALL handle the following error conditions:
- Missing openspec/changes/ directory
- Change not found
- Archive target already exists
- File system permissions issues

## Why These Decisions

**Interactive selection**: Reduces typing and helps users see available changes
**Task checking**: Prevents accidental archiving of incomplete work
**Date prefixing**: Maintains chronological order and prevents naming conflicts
**No overwrite**: Preserves historical archives and prevents data loss
**Spec updates before archiving**: Specs in the main directory represent current reality; when a change is deployed and archived, its future state specs become the new reality and must replace the main specs
**Confirmation for spec updates**: Provides visibility into what will change, prevents accidental overwrites, and ensures users understand the impact before specs are modified
**--yes flag for automation**: Allows CI/CD pipelines to archive without interactive prompts while maintaining safety by default for manual use


================================================
FILE: openspec/changes/archive/2025-08-13-add-diff-command/proposal.md
================================================
# Add Diff Command to OpenSpec CLI

## Why

Developers need to easily view differences between proposed spec changes and current specs without manually comparing files.

## What Changes

- Add `openspec diff [change-name]` command that shows differences between change specs and current specs
- Compare files in `changes/[change-name]/specs/` with corresponding files in `specs/`
- Display unified diff output showing added/removed/modified lines
- Support colored output for better readability

## Impact

- Affected specs: New capability `cli-diff` will be added
- Affected code:
  - `src/cli/index.ts` - Add diff command
  - `src/core/diff.ts` - New file with diff logic (~80 lines)


================================================
FILE: openspec/changes/archive/2025-08-13-add-diff-command/tasks.md
================================================
# Implementation Tasks

## 1. Core Implementation
- [x] 1.1 Create `src/core/diff.ts` with diff logic
- [x] 1.2 Implement change directory scanning
- [x] 1.3 Implement file comparison using unified diff format
- [x] 1.4 Add color support for terminal output

## 2. CLI Integration
- [x] 2.1 Add diff command to `src/cli/index.ts`
- [x] 2.2 Implement interactive change selection when no argument provided
- [x] 2.3 Add error handling for missing changes

## 3. Enhancements
- [x] 3.1 Replace with jest-diff for professional diff output
- [x] 3.2 Improve file headers with status and statistics
- [x] 3.3 Add summary view with file counts and line changes

## 4. Testing
- [ ] 4.1 Test diff generation for modified files
- [ ] 4.2 Test handling of new files
- [ ] 4.3 Test handling of deleted files
- [ ] 4.4 Test interactive mode


================================================
FILE: openspec/changes/archive/2025-08-13-add-diff-command/specs/cli-diff/spec.md
================================================
# CLI Diff Command Specification

## Purpose

The `openspec diff` command provides developers with a visual comparison between proposed spec changes and the current deployed specs.

## Command Syntax

```bash
openspec diff [change-name]
```

## Behavior

### Without Arguments

WHEN running `openspec diff` without arguments
THEN list all available changes in the `changes/` directory (excluding archive)
AND prompt user to select a change

### With Change Name

WHEN running `openspec diff <change-name>`
THEN compare all spec files in `changes/<change-name>/specs/` with corresponding files in `specs/`

### Diff Output

FOR each spec file in the change:
- IF file exists in both locations THEN show unified diff
- IF file only exists in change THEN show as new file (all lines with +)
- IF file only exists in current specs THEN show as deleted (all lines with -)

### Display Format

The diff SHALL use standard unified diff format:
- Lines prefixed with `-` for removed content
- Lines prefixed with `+` for added content
- Lines without prefix for unchanged context
- File headers showing the paths being compared

### Color Support

WHEN terminal supports colors:
- Removed lines displayed in red
- Added lines displayed in green
- File headers displayed in bold
- Context lines in default color

### Error Handling

WHEN specified change doesn't exist THEN display error "Change '<name>' not found"
WHEN no specs directory in change THEN display "No spec changes found for '<name>'"
WHEN changes directory doesn't exist THEN display "No OpenSpec changes directory found"

## Examples

```bash
# View diff for specific change
$ openspec diff add-auth-feature

--- specs/user-auth/spec.md
+++ changes/add-auth-feature/specs/user-auth/spec.md
@@ -10,6 +10,8 @@
 Users SHALL authenticate with email and password.
 
+Users MAY authenticate with OAuth providers.
+
 WHEN credentials are valid THEN issue JWT token.

# List all changes and select
$ openspec diff
Available changes:
  1. add-auth-feature
  2. update-payment-flow
  3. add-status-command
Select a change (1-3): 
```


================================================
FILE: openspec/changes/archive/2025-08-19-add-change-commands/design.md
================================================
# Design: Change Commands

## Architecture Decisions

### Command Structure
Similar to spec commands, we use subcommands (`change show`, `change list`, `change validate`) for:
- Consistency with spec command pattern
- Clear separation of concerns
- Future extensibility for change management features

### JSON Schema for Changes
```typescript
{
  version: string,           // Schema version
  format: "change",         // Identifies as change document
  sourcePath: string,       // Original markdown file path
  id: string,              // Change identifier
  title: string,           // Change title
  why: string,            // Motivation section
  whatChanges: Array<{
    type: "ADDED" | "MODIFIED" | "REMOVED" | "RENAMED",
    deltas: Array<{
      specId: string,
      description: string,
      requirements?: Array<Requirement>  // Only for ADDED/MODIFIED
    }>
  }>
}
```

**Rationale:**
- Group deltas by operation type for clearer organization
- Optional requirements field (only relevant for ADDED/MODIFIED)
- Reuse RequirementSchema from spec commands for consistency

### Delta Operations
**Four operation types:**
1. **ADDED**: New requirements added to specs
2. **MODIFIED**: Changes to existing requirements
3. **REMOVED**: Requirements being deleted
4. **RENAMED**: Spec identifier changes

**Design choice:** Explicit operation types rather than diff-based approach for:
- Human readability in markdown
- Clear intent communication
- Easier validation and tooling

### Dependency on Spec Commands
- **Shared schemas**: RequirementSchema and ScenarioSchema reused
- **Implementation order**: spec commands must be implemented first
- **Common parser utilities**: Share markdown parsing logic

### Legacy Compatibility
- Keep existing `list` command functional with deprecation warning
- Migration path: `list` â†’ `change list` with same functionality
- Gradual transition to avoid breaking existing workflows


================================================
FILE: openspec/changes/archive/2025-08-19-add-change-commands/proposal.md
================================================
# Change: Add Change Commands with JSON Output

## Why

OpenSpec change proposals currently can only be viewed as markdown files, creating the same programmatic access limitations as specs. Additionally, the current `openspec list` command only lists changes, which is inconsistent with the new resource-based command structure.

## What Changes

- **cli-change:** Add new command for managing change proposals with show, list, and validate subcommands
- **cli-list:** Add deprecation notice for legacy list command to guide users to the new change list command

## Impact

- **Affected specs**: cli-list (modify to add deprecation notice)
- **Affected code**:
  - src/cli/index.ts (register new command)
  - src/core/list.ts (add deprecation notice)


================================================
FILE: openspec/changes/archive/2025-08-19-add-change-commands/tasks.md
================================================
# Implementation Tasks (Phase 2: Builds on add-zod-validation)

## 1. Command Implementation
- [x] 1.1 Create src/commands/change.ts
- [x] 1.2 Import ChangeSchema and DeltaSchema from src/core/schemas/change.schema.ts
- [x] 1.3 Import markdown parser from src/core/parsers/markdown-parser.ts
- [x] 1.4 Import ChangeValidator from src/core/validation/validator.ts
- [x] 1.5 Import JSON converter from src/core/converters/json-converter.ts
- [x] 1.6 Implement show subcommand with JSON output using existing converter
- [x] 1.7 Implement list subcommand
- [x] 1.8 Implement validate subcommand using existing ChangeValidator
- [x] 1.9 Add --requirements-only filtering option
- [x] 1.10 Add --strict mode support (leveraging existing validation infrastructure)
- [x] 1.11 Add --json flag for validation reports

## 2. Change-Specific Parser Extensions
- [x] 2.1 Create src/core/parsers/change-parser.ts (extends base markdown parser)
- [x] 2.2 Parse proposal structure (Why, What Changes sections)
- [x] 2.3 Extract ADDED/MODIFIED/REMOVED/RENAMED sections
- [x] 2.4 Parse delta operations within each section
- [x] 2.5 Add tests for change parser

## 3. Legacy Compatibility
- [x] 3.1 Update src/core/list.ts to add deprecation notice
- [x] 3.2 Ensure existing list command continues to work
- [x] 3.3 Add console warning for deprecated command usage

## 4. Integration
- [x] 4.1 Register change command in src/cli/index.ts
- [ ] 4.2 Add integration tests for all subcommands
- [x] 4.3 Test JSON output for changes
- [x] 4.4 Test legacy compatibility
- [x] 4.5 Test validation with strict mode
- [x] 4.6 Update CLI help documentation (add 'change' command to main help, document subcommands: show, list, validate)


================================================
FILE: openspec/changes/archive/2025-08-19-add-change-commands/specs/cli-change/spec.md
================================================
## ADDED Requirements

### Requirement: Change Command

The system SHALL provide a `change` command with subcommands for displaying, listing, and validating change proposals.

#### Scenario: Show change as JSON

- **WHEN** executing `openspec change show update-error --json`
- **THEN** parse the markdown change file
- **AND** extract change structure and deltas
- **AND** output valid JSON to stdout

#### Scenario: List all changes

- **WHEN** executing `openspec change list`
- **THEN** scan the openspec/changes directory
- **AND** return list of all pending changes
- **AND** support JSON output with `--json` flag

#### Scenario: Show only requirement changes

- **WHEN** executing `openspec change show update-error --requirements-only`
- **THEN** display only the requirement changes (ADDED/MODIFIED/REMOVED/RENAMED)
- **AND** exclude why and what changes sections

#### Scenario: Validate change structure

- **WHEN** executing `openspec change validate update-error`
- **THEN** parse the change file
- **AND** validate against Zod schema
- **AND** ensure deltas are well-formed

### Requirement: Legacy Compatibility

The system SHALL maintain backward compatibility with the existing `list` command while showing deprecation notices.

#### Scenario: Legacy list command

- **WHEN** executing `openspec list`
- **THEN** display current list of changes (existing behavior)
- **AND** show deprecation notice: "Note: 'openspec list' is deprecated. Use 'openspec change list' instead."

#### Scenario: Legacy list with --all flag

- **WHEN** executing `openspec list --all`
- **THEN** display all changes (existing behavior)
- **AND** show same deprecation notice


================================================
FILE: openspec/changes/archive/2025-08-19-add-change-commands/specs/cli-list/spec.md
================================================
## MODIFIED Requirements

### Requirement: Command Execution

The current `list` command behavior SHALL be preserved but marked as deprecated.

#### Scenario: Deprecation notice

- **WHEN** using the legacy `list` command
- **THEN** continue to work as before
- **AND** display deprecation notice
- **AND** suggest using `openspec change list` instead


================================================
FILE: openspec/changes/archive/2025-08-19-add-interactive-show-command/proposal.md
================================================
## Why

Users frequently need to view changes and specs but must know in advance whether they're looking at a change or spec. The current subcommand structure (`change show`, `spec show`) creates friction when:
- Users want to quickly view an item without remembering its type
- Exploring the codebase requires switching between different show commands
- Show commands without arguments return errors instead of helpful guidance

## What Changes

- Add new top-level `show` command for displaying changes or specs with intelligent selection
- Support direct item display: `openspec show <item>` with automatic type detection
- Interactive selection when no arguments provided
- Enhance existing `change show` and `spec show` to support interactive selection (backwards compatibility)
- Maintain all existing format options (--json, --deltas-only, --requirements, etc.)

## Impact

- New specs to create: cli-show
- Specs to enhance: cli-change, cli-spec (for backwards compatibility)
- Affected code: src/cli/index.ts, src/commands/show.ts (new), src/commands/spec.ts, src/commands/change.ts


================================================
FILE: openspec/changes/archive/2025-08-19-add-interactive-show-command/tasks.md
================================================
# Implementation Tasks â€” Add Interactive Show Command

## Goals
- Add a top-level `show` command with intelligent selection and type detection.
- Add interactive selection to `change show` and `spec show` when no ID is provided.
- Preserve raw-first output behavior and existing JSON formats/filters.
- Respect `--no-interactive` and `OPEN_SPEC_INTERACTIVE=0` consistently.

---

## 1) CLI wiring
- [x] In `src/cli/index.ts` add a top-level command: `program.command('show [item-name]')`
  - Options:
    - `--json`
    - `--type <type>` where `<type>` is `change|spec`
    - `--no-interactive`
    - Allow passing-through type-specific flags using `.allowUnknownOption(true)` so the top-level can forward flags to the underlying type handler.
  - Action: instantiate `new ShowCommand().execute(itemName, options)`.
- [x] Update `change show` subcommand to accept `--no-interactive` and pass it to `ChangeCommand.show(...)`.
- [x] Change `spec show` subcommand to accept optional ID (`show [spec-id]`), add `--no-interactive`, and pass to spec show implementation.

Acceptance:
- `openspec show` exists and prints a helpful hint in non-interactive contexts when no args.
- Unknown flags for other types do not crash parsing; they are warned/ignored appropriately.

---

## 2) New module: `src/commands/show.ts`
- [x] Create `ShowCommand` with:
  - `execute(itemName?: string, options?: { json?: boolean; type?: string; noInteractive?: boolean; [k: string]: any })`
  - Interactive path when `!itemName` and interactive is enabled:
    - Prompt: "What would you like to show?" â†’ `change` or `spec`.
    - Load available IDs for the chosen type and prompt selection.
    - Delegate to type-specific show implementation.
  - Non-interactive path when `!itemName`:
    - Print hint with examples:
      - `openspec show <item>`
      - `openspec change show`
      - `openspec spec show`
    - Exit with code 1.
  - Direct item path when `itemName` is provided:
    - Type override via `--type` takes precedence.
    - Otherwise detect using `getActiveChangeIds()` and `getSpecIds()`.
    - If ambiguous and no override: print error + suggestion to pass `--type` or use subcommands; exit code 1.
    - If unknown: print not-found with nearest-match suggestions; exit code 1.
    - On success: delegate to type-specific show.
- [x] Flag scoping and pass-through:
  - Common: `--json` â†’ forwarded to both types.
  - Change-only: `--deltas-only`, `--requirements-only` (deprecated alias).
  - Spec-only: `--requirements`, `--no-scenarios`, `-r/--requirement`.
  - Warn and ignore irrelevant flags for the resolved type.

Acceptance:
- `openspec show <change-id> --json --deltas-only` matches `openspec change show <id> --json --deltas-only` output.
- `openspec show <spec-id> --json --requirements` matches `openspec spec show <id> --json --requirements` output.
- Ambiguity and not-found behaviors match the `cli-show` spec.

---

## 3) Refactor spec show into reusable API
- [x] In `src/commands/spec.ts`, extract show logic into an exported `SpecCommand` with `show(specId?: string, options?: { json?: boolean; requirements?: boolean; scenarios?: boolean; requirement?: string; noInteractive?: boolean })`.
  - Reuse current helpers (`parseSpecFromFile`, `filterSpec`, raw-first printing).
  - Keep `registerSpecCommand` but delegate to `new SpecCommand().show(...)`.
- [x] Update CLI spec show subcommand to optional arg and interactive behavior (see section 4).

Acceptance:
- Existing `spec show` tests continue to pass.
- New `SpecCommand.show` can be called from `ShowCommand`.

---

## 4) Backwards-compatible interactive in subcommands
- [x] `src/commands/change.ts` â†’ extend `show(changeName?: string, options?: { json?: boolean; requirementsOnly?: boolean; deltasOnly?: boolean; noInteractive?: boolean })`:
  - When `!changeName` and interactive enabled: prompt from `getActiveChangeIds()` and show the selected change.
  - Non-interactive fallback: keep current behavior (print available IDs + `openspec change list` hint, set `process.exitCode = 1`).
- [x] `src/commands/spec.ts` â†’ `SpecCommand.show` as above:
  - When `!specId` and interactive enabled: prompt from `getSpecIds()` and show the selected spec.
  - Non-interactive fallback: print the same error as existing behavior for missing `<spec-id>` and set non-zero exit code.

Acceptance:
- `openspec change show` in non-interactive prints list hint and exits non-zero.
- `openspec spec show` in non-interactive prints missing-arg error and exits non-zero.

---

## 5) Shared utilities
- [x] Extract `nearestMatches` and `levenshtein` from `src/commands/validate.ts` into `src/utils/match.ts` (exported helpers).
- [x] Update `ValidateCommand` and new `ShowCommand` to import from `utils/match`.

Acceptance:
- Build succeeds with shared helpers and no duplication.

---

## 6) Hints, warnings, and messages
- [x] Top-level `show` hint (non-interactive no-arg):
  - Lines include: `openspec show <item>`, `openspec change show`, `openspec spec show`, and "Or run in an interactive terminal.".
- [x] Ambiguity message suggests `--type change|spec` and the subcommands.
- [x] Not-found suggests nearest matches (up to 5).
- [x] Irrelevant flag warnings for the resolved type (printed to stderr, no crash).

Acceptance:
- Messages match the `cli-show` spec wording intent and style used elsewhere.

---

## 7) Tests
Add tests mirroring existing patterns (non-TTY simulation via `OPEN_SPEC_INTERACTIVE=0`).

- [x] `test/commands/show.test.ts`
  - Non-interactive, no arg â†’ prints hint and exits non-zero.
  - Direct item detection for change and for spec.
  - Ambiguity case when both exist â†’ error and suggestion for `--type`.
  - Not-found case â†’ nearest-match suggestions.
  - Pass-through flags: change `--json --deltas-only`, spec `--json --requirements`.
- [x] `test/commands/change.interactive-show.test.ts` (non-interactive fallback)
  - Ensure `openspec change show` without args prints available IDs + list hint and non-zero exit.
- [x] `test/commands/spec.interactive-show.test.ts` (non-interactive fallback)
  - Ensure `openspec spec show` without args prints missing-arg error and non-zero exit.

Acceptance:
- All new tests pass after build; no regressions in existing tests.

---

## 8) Documentation (optional but recommended)
- [x] Update `openspec/README.md` usage examples to include the new `show` command with type detection and flags.

---

## 9) Non-functional checks
- [x] Run `pnpm build` and all tests (`pnpm test`).
- [x] Ensure no linter/type errors and messages are consistent with existing style.

---

## Notes on consistency
- Follow raw-first behavior for text output: passthrough file content with no formatting, mirroring current `change show` and `spec show`.
- Reuse `isInteractive` and `item-discovery` helpers for consistent prompting behavior.
- Keep JSON output shapes identical to current `ChangeCommand.show` and `spec show` outputs.





================================================
FILE: openspec/changes/archive/2025-08-19-add-interactive-show-command/specs/cli-change/spec.md
================================================
# CLI Change Command Spec

## ADDED Requirements

### Requirement: Interactive show selection

The change show command SHALL support interactive selection when no change name is provided.

#### Scenario: Interactive change selection for show

- **WHEN** executing `openspec change show` without arguments
- **THEN** display an interactive list of available changes
- **AND** allow the user to select a change to show
- **AND** display the selected change content
- **AND** maintain all existing show options (--json, --deltas-only)

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec change show` without a change name
- **THEN** do not prompt interactively
- **AND** print the existing hint including available change IDs
- **AND** set `process.exitCode = 1`


================================================
FILE: openspec/changes/archive/2025-08-19-add-interactive-show-command/specs/cli-show/spec.md
================================================
# CLI Show Command Spec

## ADDED Requirements

### Requirement: Top-level show command

The CLI SHALL provide a top-level `show` command for displaying changes and specs with intelligent selection.

#### Scenario: Interactive show selection

- **WHEN** executing `openspec show` without arguments
- **THEN** prompt user to select type (change or spec)
- **AND** display list of available items for selected type
- **AND** show the selected item's content

#### Scenario: Non-interactive environments do not prompt

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec show` without arguments
- **THEN** do not prompt
- **AND** print a helpful hint with examples for `openspec show <item>` or `openspec change/spec show`
- **AND** exit with code 1

#### Scenario: Direct item display

- **WHEN** executing `openspec show <item-name>`
- **THEN** automatically detect if item is a change or spec
- **AND** display the item's content
- **AND** use appropriate formatting based on item type

#### Scenario: Type detection and ambiguity handling

- **WHEN** executing `openspec show <item-name>`
- **THEN** if `<item-name>` uniquely matches a change or a spec, show that item
- **AND** if it matches both, print an ambiguity error and suggest `--type change|spec` or using `openspec change show`/`openspec spec show`
- **AND** if it matches neither, print not-found with nearest-match suggestions

#### Scenario: Explicit type override

- **WHEN** executing `openspec show --type change <item>`
- **THEN** treat `<item>` as a change ID and show it (skipping auto-detection)

- **WHEN** executing `openspec show --type spec <item>`
- **THEN** treat `<item>` as a spec ID and show it (skipping auto-detection)

### Requirement: Output format options

The show command SHALL support various output formats consistent with existing commands.

#### Scenario: JSON output

- **WHEN** executing `openspec show <item> --json`
- **THEN** output the item in JSON format
- **AND** include parsed metadata and structure
- **AND** maintain format consistency with existing change/spec show commands

#### Scenario: Flag scoping and delegation

- **WHEN** showing a change or a spec via the top-level command
- **THEN** accept common flags such as `--json`
- **AND** pass through type-specific flags to the corresponding implementation
  - Change-only flags: `--deltas-only` (alias `--requirements-only` deprecated)
  - Spec-only flags: `--requirements`, `--no-scenarios`, `-r/--requirement`
- **AND** ignore irrelevant flags for the detected type with a warning

### Requirement: Interactivity controls

- The CLI SHALL respect `--no-interactive` to disable prompts.
- The CLI SHALL respect `OPEN_SPEC_INTERACTIVE=0` to disable prompts globally.
- Interactive prompts SHALL only be shown when stdin is a TTY and interactivity is not disabled.

#### Scenario: Change-specific options

- **WHEN** showing a change with `openspec show <change-name> --deltas-only`
- **THEN** display only the deltas in JSON format
- **AND** maintain compatibility with existing change show options

#### Scenario: Spec-specific options  

- **WHEN** showing a spec with `openspec show <spec-id> --requirements`
- **THEN** display only requirements in JSON format
- **AND** support other spec options (--no-scenarios, -r)
- **AND** maintain compatibility with existing spec show options


================================================
FILE: openspec/changes/archive/2025-08-19-add-interactive-show-command/specs/cli-spec/spec.md
================================================
# CLI Spec Command Spec

## ADDED Requirements

### Requirement: Interactive spec show

The spec show command SHALL support interactive selection when no spec-id is provided.

#### Scenario: Interactive spec selection for show

- **WHEN** executing `openspec spec show` without arguments
- **THEN** display an interactive list of available specs
- **AND** allow the user to select a spec to show
- **AND** display the selected spec content
- **AND** maintain all existing show options (--json, --requirements, --no-scenarios, -r)

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec spec show` without a spec-id
- **THEN** do not prompt interactively
- **AND** print the existing error message for missing spec-id
- **AND** set non-zero exit code


================================================
FILE: openspec/changes/archive/2025-08-19-add-skip-specs-archive-option/proposal.md
================================================
## Why
The archive command currently forces users to either accept spec updates or cancel the entire archive operation. Users need flexibility to archive changes without updating specs, either through explicit flags or by declining the confirmation prompt. This is especially important for changes that don't modify specs (like tooling, documentation, or infrastructure updates).

## What Changes
- Add new `--skip-specs` flag to the archive command that bypasses all spec update operations
- Fix confirmation behavior: when users decline spec updates interactively, proceed with archiving instead of cancelling the entire operation
- When `--skip-specs` flag is used, skip both the spec discovery and update confirmation steps entirely
- Display clear message when specs are skipped (either via flag or user choice)
- Flag can be combined with existing `--yes` flag for fully automated archiving without spec updates

## Impact
- Affected specs: cli-archive
- Affected code: src/core/archive.ts, src/cli/index.ts


================================================
FILE: openspec/changes/archive/2025-08-19-add-skip-specs-archive-option/tasks.md
================================================
## 1. Update Archive Command Implementation
- [x] 1.1 Add `skipSpecs` option to the archive command options interface
- [x] 1.2 Modify the execute method to skip spec operations when flag is set
- [x] 1.3 Fix confirmation behavior: when user declines spec updates, proceed with archiving instead of cancelling
- [x] 1.4 Update console output to indicate when specs are being skipped (via flag or user choice)
- [x] 1.5 Ensure archive continues after declining spec updates

## 2. Update CLI Interface
- [x] 2.1 Add `--skip-specs` flag to the archive command definition
- [x] 2.2 Pass the flag value to the archive command execute method

## 3. Update Tests
- [x] 3.1 Add test case for archiving with --skip-specs flag
- [x] 3.2 Add test case for declining spec updates but continuing with archive
- [x] 3.3 Verify that spec updates are skipped when flag is used
- [x] 3.4 Verify that archive proceeds when user declines spec updates
- [x] 3.5 Ensure existing behavior remains unchanged when flag is not used

## 4. Update Documentation
- [x] 4.1 Update the cli-archive spec to document the new --skip-specs flag
- [x] 4.2 Document the new behavior when declining spec updates interactively

## Implementation Notes

### Key Design Decisions

1. **Non-blocking Confirmation Behavior**: When users decline spec updates interactively, the archive operation continues rather than cancelling entirely. This was a critical UX improvement because:
   - Users may want to review specs separately before updating them
   - Archiving work shouldn't be blocked by spec review decisions
   - Maintains flexibility in the deployment workflow

2. **Flag Naming Convention**: Chose `--skip-specs` for clarity and consistency:
   - Clearly indicates the action (skipping) and target (specs)
   - Follows kebab-case convention for CLI flags
   - Converts naturally to `skipSpecs` camelCase in code

3. **Console Messaging Strategy**: Added explicit messages for all spec-skipping scenarios:
   - When flag is used: "Skipping spec updates (--skip-specs flag provided)."
   - When user declines: "Skipping spec updates. Proceeding with archive."
   - Ensures users always understand what's happening with their specs

4. **Test Coverage Approach**: Created separate test cases for:
   - Flag-based skipping (explicit user choice via CLI)
   - Interactive declining (runtime user decision)
   - Both verify the same outcome but test different code paths

### Use Cases Addressed

- **Infrastructure Changes**: Changes to build tools, CI/CD, dependencies
- **Documentation Updates**: README updates, comment improvements
- **Tooling Modifications**: Developer tools, scripts, configuration files
- **Refactoring**: Code improvements that don't change functionality/specs

### Future Considerations

- Could potentially auto-detect when changes don't include specs and suggest using the flag
- May want to track which archives skipped spec updates for audit purposes


================================================
FILE: openspec/changes/archive/2025-08-19-add-skip-specs-archive-option/specs/cli-archive/spec.md
================================================
# CLI Archive Command Specification

## Purpose
The archive command moves completed changes from the active changes directory to the archive folder with date-based naming, following OpenSpec conventions.

## Command Syntax
```bash
openspec archive [change-name] [--yes|-y] [--skip-specs]
```

Options:
- `--yes`, `-y`: Skip confirmation prompts (for automation)
- `--skip-specs`: Skip spec update operations entirely (for changes without spec modifications)

## Behavior

### Requirement: Change Selection

The command SHALL support both interactive and direct change selection methods.

#### Scenario: Interactive selection

- **WHEN** no change-name is provided
- **THEN** display interactive list of available changes (excluding archive/)
- **AND** allow user to select one

#### Scenario: Direct selection

- **WHEN** change-name is provided
- **THEN** use that change directly
- **AND** validate it exists

### Requirement: Task Completion Check

The command SHALL verify task completion status before archiving to prevent premature archival.

#### Scenario: Incomplete tasks found

- **WHEN** incomplete tasks are found (marked with `- [ ]`)
- **THEN** display all incomplete tasks to the user
- **AND** prompt for confirmation to continue
- **AND** default to "No" for safety

#### Scenario: All tasks complete

- **WHEN** all tasks are complete OR no tasks.md exists
- **THEN** proceed with archiving without prompting

### Requirement: Archive Process

The archive operation SHALL follow a structured process to safely move changes to the archive.

#### Scenario: Performing archive

- **WHEN** archiving a change
- **THEN** execute these steps:
  1. Create archive/ directory if it doesn't exist
  2. Generate target name as `YYYY-MM-DD-[change-name]` using current date
  3. Check if target directory already exists
  4. Update main specs from the change's future state specs unless `--skip-specs` is provided (see Spec Update Process below)
  5. Move the entire change directory to the archive location

#### Scenario: Archive already exists

- **WHEN** target archive already exists
- **THEN** fail with error message
- **AND** do not overwrite existing archive

#### Scenario: Successful archive

- **WHEN** move succeeds
- **THEN** display success message with archived name and list of updated specs (if any)

### Requirement: Spec Update Process

Before moving the change to archive, the command SHALL update main specs to reflect the deployed reality unless the `--skip-specs` flag is provided.

#### Scenario: Skipping spec updates

- **WHEN** the `--skip-specs` flag is provided
- **THEN** skip all spec discovery and update operations
- **AND** proceed directly to moving the change to archive
- **AND** display message indicating specs were skipped

#### Scenario: Updating specs from change

- **WHEN** the change contains specs in `changes/[name]/specs/` AND `--skip-specs` is NOT provided
- **THEN** execute these steps:
  1. Analyze which specs will be affected by comparing with existing specs
  2. Display a summary of spec updates to the user (see Confirmation Behavior below)
  3. Prompt for confirmation unless `--yes` flag is provided
  4. If confirmed, for each capability spec in the change directory:
     - Copy the spec from `changes/[name]/specs/[capability]/spec.md` to `openspec/specs/[capability]/spec.md`
     - Create the target directory structure if it doesn't exist
     - Overwrite existing spec files (specs represent current reality, change specs are the new reality)
     - Track which specs were updated for the success message

#### Scenario: No specs in change

- **WHEN** no specs exist in the change AND `--skip-specs` is NOT provided
- **THEN** skip the spec update step
- **AND** proceed with archiving

### Requirement: Confirmation Behavior

The spec update confirmation SHALL provide clear visibility into changes before they are applied.

#### Scenario: Displaying confirmation

- **WHEN** prompting for confirmation AND `--skip-specs` is NOT provided
- **THEN** display a clear summary showing:
  - Which specs will be created (new capabilities)
  - Which specs will be updated (existing capabilities)
  - The source path for each spec
- **AND** format the confirmation prompt as:
  ```
  The following specs will be updated:
  
  NEW specs to be created:
    - cli-archive (from changes/add-archive-command/specs/cli-archive/spec.md)
  
  EXISTING specs to be updated:
    - cli-init (from changes/update-init-command/specs/cli-init/spec.md)
  
  Update 2 specs and archive 'add-archive-command'? [y/N]:
  ```
#### Scenario: Handling confirmation response

- **WHEN** waiting for user confirmation
- **THEN** default to "No" for safety (require explicit "y" or "yes")
- **AND** skip confirmation when `--yes` or `-y` flag is provided
- **AND** skip entire spec confirmation when `--skip-specs` flag is provided

#### Scenario: User declines spec update confirmation

- **WHEN** user declines the spec update confirmation
- **THEN** skip the spec update operations
- **AND** display message: "Skipping spec updates. Proceeding with archive."
- **AND** continue with the archive operation
- **AND** display success message indicating specs were not updated

## Error Handling

### Requirement: Error Conditions

The command SHALL handle various error conditions gracefully.

#### Scenario: Handling errors

- **WHEN** errors occur
- **THEN** handle the following conditions:
  - Missing openspec/changes/ directory
  - Change not found
  - Archive target already exists
  - File system permissions issues

## Why These Decisions

**Interactive selection**: Reduces typing and helps users see available changes
**Task checking**: Prevents accidental archiving of incomplete work
**Date prefixing**: Maintains chronological order and prevents naming conflicts
**No overwrite**: Preserves historical archives and prevents data loss
**Spec updates before archiving**: Specs in the main directory represent current reality; when a change is deployed and archived, its future state specs become the new reality and must replace the main specs
**Confirmation for spec updates**: Provides visibility into what will change, prevents accidental overwrites, and ensures users understand the impact before specs are modified
**Non-blocking confirmation**: Declining spec updates doesn't cancel archiving - users can review specs and choose to update them separately if needed
**--yes flag for automation**: Allows CI/CD pipelines to archive without interactive prompts while maintaining safety by default for manual use
**--skip-specs flag**: Enables archiving of changes that don't modify specs (like infrastructure, tooling, or documentation changes) without unnecessary spec update prompts or operations

## ADDED Requirements

### Requirement: Skip Specs Option

The archive command SHALL support a `--skip-specs` flag that skips all spec update operations and proceeds directly to archiving.

#### Scenario: Skipping spec updates with flag

- **WHEN** executing `openspec archive <change> --skip-specs`
- **THEN** skip spec discovery and update confirmation
- **AND** proceed directly to moving the change to archive
- **AND** display a message indicating specs were skipped

### Requirement: Non-blocking confirmation

The archive operation SHALL proceed when the user declines spec updates instead of cancelling the entire operation.

#### Scenario: User declines spec update confirmation

- **WHEN** the user declines spec update confirmation
- **THEN** skip spec updates
- **AND** continue with the archive operation
- **AND** display a success message indicating specs were not updated


================================================
FILE: openspec/changes/archive/2025-08-19-add-spec-commands/design.md
================================================
# Design: Spec Commands

## Architecture Decisions

### Command Hierarchy
We chose a subcommand pattern (`spec show`, `spec list`, `spec validate`) to:
- Group related functionality under a common namespace
- Enable future extensibility without polluting the top-level CLI
- Maintain consistency with the planned `change` command structure

### JSON Schema Structure
The spec JSON schema follows this structure:
```typescript
{
  version: string,        // Schema version for compatibility
  format: "spec",        // Identifies this as a spec document
  sourcePath: string,    // Original markdown file path
  id: string,           // Spec identifier from filename
  title: string,        // Human-readable title
  overview?: string,    // Optional overview section
  requirements: Array<{
    id: string,
    text: string,
    scenarios: Array<{
      id: string,
      text: string
    }>
  }>
}
```

**Rationale:**
- Flat structure for requirements array (vs nested objects) for easier iteration
- Scenarios nested within requirements to maintain relationship
- Metadata fields (version, format, sourcePath) for tooling integration

### Parser Architecture
- **Markdown-first approach**: Parse markdown headings rather than custom syntax
- **Streaming parser**: Process line-by-line to handle large files efficiently
- **Strict heading hierarchy**: Enforce ##/###/#### structure for consistency

### Validation Strategy
- **Parse-time validation**: Catch structural issues during parsing
- **Schema validation**: Use Zod for runtime type checking of parsed data
- **Separate validation command**: Allow validation without full parsing/conversion


================================================
FILE: openspec/changes/archive/2025-08-19-add-spec-commands/proposal.md
================================================
# Change: Add Spec Commands with JSON Output

## Why

Currently, OpenSpec specs can only be viewed as markdown files. This makes programmatic access difficult and prevents integration with CI/CD pipelines, external tools, and automated processing.

## What Changes

- Add new `openspec spec` command with three subcommands: `show`, `list`, and `validate`
- Implement JSON output capability for specs using heading-based parsing
- Add Zod schemas for spec structure validation
- Enable content filtering options (requirements only, no scenarios, specific requirement)

## Impact

- **Affected specs**: None (new capability)
- **Affected code**: 
  - src/cli/index.ts (register new command)
  - package.json (add zod dependency)



================================================
FILE: openspec/changes/archive/2025-08-19-add-spec-commands/tasks.md
================================================
# Implementation Tasks (Phase 3: Builds on add-zod-validation and add-change-commands)

## 1. Command Implementation
- [x] 1.1 Create src/commands/spec.ts
- [x] 1.2 Import RequirementSchema, ScenarioSchema, SpecSchema from src/core/schemas/
- [x] 1.3 Import markdown parser from src/core/parsers/markdown-parser.ts
- [x] 1.4 Import SpecValidator from src/core/validation/validator.ts
- [x] 1.5 Import JSON converter from src/core/converters/json-converter.ts
- [x] 1.6 Implement show subcommand with JSON output using existing converter
- [x] 1.7 Implement list subcommand
- [x] 1.8 Implement validate subcommand using existing SpecValidator
- [x] 1.9 Add filtering options (--requirements, --no-scenarios, -r)
- [x] 1.10 Add --strict mode support (leveraging existing validation infrastructure)
- [x] 1.11 Add --json flag for validation reports

## 2. Integration
- [x] 2.1 Register spec command in src/cli/index.ts
- [x] 2.2 Add integration tests for all subcommands
- [x] 2.3 Test JSON output validation
- [x] 2.4 Test filtering options
- [x] 2.5 Test validation with strict mode
- [x] 2.6 Update CLI help documentation (add 'spec' command to main help, document subcommands: show, list, validate)


================================================
FILE: openspec/changes/archive/2025-08-19-add-spec-commands/specs/cli-spec/spec.md
================================================
## ADDED Requirements

### Requirement: Spec Command

The system SHALL provide a `spec` command with subcommands for displaying, listing, and validating specifications.

#### Scenario: Show spec as JSON

- **WHEN** executing `openspec spec show init --json`
- **THEN** parse the markdown spec file
- **AND** extract headings and content hierarchically
- **AND** output valid JSON to stdout

#### Scenario: List all specs

- **WHEN** executing `openspec spec list`
- **THEN** scan the openspec/specs directory
- **AND** return list of all available capabilities
- **AND** support JSON output with `--json` flag

#### Scenario: Filter spec content

- **WHEN** executing `openspec spec show init --requirements`
- **THEN** display only requirement names and SHALL statements
- **AND** exclude scenario content

#### Scenario: Validate spec structure

- **WHEN** executing `openspec spec validate init`
- **THEN** parse the spec file
- **AND** validate against Zod schema
- **AND** report any structural issues

### Requirement: JSON Schema Definition

The system SHALL define Zod schemas that accurately represent the spec structure for runtime validation.

#### Scenario: Schema validation

- **WHEN** parsing a spec into JSON
- **THEN** validate the structure using Zod schemas
- **AND** ensure all required fields are present
- **AND** provide clear error messages for validation failures


================================================
FILE: openspec/changes/archive/2025-08-19-add-zod-validation/design.md
================================================
# Design: Zod Validation Framework

## Architecture Decisions

### Validation Levels
Three-tier validation system:
1. **ERROR**: Structural issues that prevent parsing (must fix)
2. **WARNING**: Quality issues that should be addressed (recommended fix)
3. **INFO**: Suggestions for improvement (optional)

**Rationale:** 
- Gradual enforcement allows teams to adopt validation incrementally
- CI/CD can fail on errors but allow warnings initially
- Info level provides guidance without blocking

### Validation Rules Hierarchy

#### Spec Validation Rules
```
ERROR level:
- Missing ## Overview or ## Requirements sections
- Invalid heading hierarchy
- Malformed requirement/scenario structure

WARNING level:
- Requirements without scenarios
- Requirements missing SHALL keyword
- Empty overview section

INFO level:
- Very long requirement text (>500 chars)
- Scenarios without Given/When/Then structure
```

#### Change Validation Rules
```
ERROR level:
- Missing ## Why or ## What Changes sections
- Invalid delta operation types
- Malformed delta structure

WARNING level:
- Why section too brief (<50 chars)
- Deltas without clear descriptions
- Missing requirements in ADDED/MODIFIED

INFO level:
- Very long why section (>1000 chars)
- Too many deltas in single change (>10)
```

### Strict Mode
- **Default**: Show all levels, fail on ERROR only
- **--strict flag**: Fail on both ERROR and WARNING
- **Use case**: Gradual quality improvement in CI/CD pipelines

### Archive Command Safety
**Problem:** Invalid specs could be archived, polluting the archive.

**Solution:** 
1. Pre-archive validation (default behavior)
2. --no-validate flag with safeguards:
   - Interactive confirmation prompt
   - Prominent warning message
   - Console logging with timestamp
   - Not recommended for CI/CD usage

**Rationale:**
- Protect archive integrity by default
- Allow emergency overrides with accountability
- Clear audit trail for validation bypasses

### Validation Report Format
```json
{
  "valid": boolean,
  "issues": [
    {
      "level": "ERROR" | "WARNING" | "INFO",
      "path": "requirements[0].scenarios",
      "message": "Requirement must have at least one scenario",
      "line": 15,
      "column": 0
    }
  ],
  "summary": {
    "errors": 2,
    "warnings": 5,
    "info": 3
  }
}
```

**Benefits:**
- Machine-readable for tooling integration
- Human-friendly messages
- Line/column info for IDE integration
- Summary for quick assessment

### Implementation Strategy
1. **Zod schemas with refinements**: Built-in validation in type definitions
2. **Custom validators**: Additional business logic validation
3. **Composable rules**: Mix and match for different contexts
4. **Extensible framework**: Easy to add new rules without refactoring


================================================
FILE: openspec/changes/archive/2025-08-19-add-zod-validation/proposal.md
================================================
# Change: Add Zod Runtime Validation

## Why

While the spec and change commands can output JSON, they currently don't perform strict runtime validation beyond basic structure checking. This can lead to invalid specs or changes being processed, silent failures when required fields are missing, and poor error messages.

## What Changes

- Enhance existing `spec validate` and `change validate` commands with strict Zod validation
- Add validation to the archive command to ensure changes are valid before applying
- Add validation to the diff command to ensure changes are well-formed
- Provide detailed validation reports in JSON format
- Add `--strict` mode that fails on warnings

## Impact

- **Affected specs**: cli-spec, cli-change, cli-archive, cli-diff
- **Affected code**:
  - src/commands/spec.ts (enhance validate subcommand)
  - src/commands/change.ts (enhance validate subcommand)
  - src/core/archive.ts (add pre-archive validation)
  - src/core/diff.ts (add validation check)


================================================
FILE: openspec/changes/archive/2025-08-19-add-zod-validation/tasks.md
================================================
# Implementation Tasks (Foundation Phase)

## 1. Core Schemas
- [x] 1.1 Add zod dependency to package.json
- [x] 1.2 Create src/core/schemas/base.schema.ts with ScenarioSchema and RequirementSchema
- [x] 1.3 Create src/core/schemas/spec.schema.ts with SpecSchema
- [x] 1.4 Create src/core/schemas/change.schema.ts with DeltaSchema and ChangeSchema
- [x] 1.5 Create src/core/schemas/index.ts to export all schemas

## 2. Parser Implementation
- [x] 2.1 Create src/core/parsers/markdown-parser.ts
- [x] 2.2 Implement heading extraction (##, ###, ####)
- [x] 2.3 Implement content capture between headings
- [x] 2.4 Add tests for parser edge cases

## 3. Validation Infrastructure
- [x] 3.1 Create src/core/validation/types.ts with ValidationLevel, ValidationIssue, ValidationReport types
- [x] 3.2 Create src/core/validation/constants.ts with validation rules and thresholds
- [x] 3.3 Create src/core/validation/validator.ts with SpecValidator and ChangeValidator classes

## 4. Enhanced Validation Rules
- [x] 4.1 Add RequirementValidation refinements (must have scenarios, must contain SHALL)
- [x] 4.2 Add SpecValidation refinements (must have requirements)
- [x] 4.3 Add ChangeValidation refinements (must have deltas, why section length)
- [x] 4.4 Implement custom error messages for each rule

## 5. JSON Converter
- [x] 5.1 Create src/core/converters/json-converter.ts
- [x] 5.2 Implement spec-to-JSON conversion
- [x] 5.3 Implement change-to-JSON conversion
- [x] 5.4 Add metadata fields (version, format, sourcePath)

## 6. Archive Command Enhancement
- [x] 6.1 Add pre-archive validation check using new validators
- [x] 6.2 Add --no-validate flag with required confirmation prompt and warning message: "âš ï¸  WARNING: Skipping validation may archive invalid specs. Continue? (y/N)"
- [x] 6.3 Display validation errors before aborting
- [x] 6.4 Log all --no-validate usages to console with timestamp and affected files
- [x] 6.5 Add tests for validation scenarios including --no-validate confirmation flow

## 7. Diff Command Enhancement
- [x] 7.1 Add validation check before diff using new validators
- [x] 7.2 Show validation warnings (non-blocking)
- [x] 7.3 Continue with diff even if warnings present

## 8. Testing
- [x] 8.1 Unit tests for all schemas
- [x] 8.2 Unit tests for parser
- [x] 8.3 Unit tests for validation rules
- [x] 8.4 Integration tests for validation reports
- [x] 8.5 Test various invalid spec/change formats
- [x] 8.6 Test strict mode behavior
- [x] 8.7 Test pre-archive validation
- [x] 8.8 Test validation report JSON output

## 9. Documentation
- [x] 9.1 Document schema structure and validation rules (openspec/VALIDATION.md)
- [x] 9.2 Update CLI help for archive (document --no-validate flag and its warnings)
- [x] 9.3 Update CLI help for diff (document validation warnings behavior)
- [x] 9.4 Create migration guide for future command integration (openspec/MIGRATION.md)


================================================
FILE: openspec/changes/archive/2025-08-19-add-zod-validation/specs/cli-archive/spec.md
================================================
## ADDED Requirements

### Requirement: Archive Validation

The archive command SHALL validate changes before applying them to ensure data integrity.

#### Scenario: Pre-archive validation

- **WHEN** executing `openspec archive change-name`
- **THEN** validate the change structure first
- **AND** only proceed if validation passes
- **AND** show validation errors if it fails

#### Scenario: Force archive without validation

- **WHEN** executing `openspec archive change-name --no-validate`
- **THEN** skip validation (unsafe mode)
- **AND** show warning about skipping validation


================================================
FILE: openspec/changes/archive/2025-08-19-add-zod-validation/specs/cli-diff/spec.md
================================================
## ADDED Requirements

### Requirement: Diff Command Enhancement

The diff command SHALL validate change structure before displaying differences.

#### Scenario: Validate before diff

- **WHEN** executing `openspec diff change-name`
- **THEN** validate change structure
- **AND** show validation warnings if present
- **AND** continue with diff display


================================================
FILE: openspec/changes/archive/2025-08-19-adopt-delta-based-changes/proposal.md
================================================
# Adopt Delta-Based Changes for Specifications

## Why

The current approach of storing complete future states in change proposals creates a poor review experience. When reviewing changes on GitHub, reviewers see entire spec files (often 100+ lines) as "added" in green, making it impossible to identify what actually changed. With the recent structured format adoption, we now have clear section boundaries that enable a better approach: storing only additions and modifications.

## What Changes

Store only the requirements that actually change, not complete future states:

- **ADDED Requirements**: New capabilities being introduced
- **MODIFIED Requirements**: Existing requirements being changed (must match current header)
- **REMOVED Requirements**: Deprecated capabilities
- **RENAMED Requirements**: Explicit header changes (e.g., `FROM: Old Name` â†’ `TO: New Name`)

The archive command will programmatically apply these deltas using normalized header matching (trim leading/trailing whitespace) instead of manually copying entire files.

## Impact

**Affected specs**: openspec-conventions, cli-archive, cli-diff

**Benefits**:
- GitHub diffs show only actual changes (25 lines instead of 150+)
- Reviewers immediately see what's being added, modified, or removed
- Conflicts are more apparent when two changes modify the same requirement
- Archive command can programmatically apply changes

**Format**: Delta format only - all changes must use ADDED/MODIFIED/REMOVED sections.

## Example

Instead of storing a 150-line complete future spec, store only:

```markdown
# User Authentication - Changes

## ADDED Requirements

### Requirement: OAuth Support
Users SHALL authenticate via OAuth providers including Google and GitHub.

#### Scenario: OAuth login flow
- **WHEN** user selects OAuth provider
- **THEN** redirect to provider authorization
- **AND** exchange authorization code for tokens

## MODIFIED Requirements

### Requirement: Session Management
Sessions SHALL expire after 30 minutes of inactivity.

#### Scenario: Inactive session timeout  
- **WHEN** no activity for 30 minutes â† (was 60 minutes)
- **THEN** invalidate session token
- **AND** require re-authentication

## RENAMED Requirements
- FROM: `### Requirement: Basic Authentication`
- TO: `### Requirement: Email Authentication`
```

This makes reviews focused and changes explicit.

## Conflict Resolution

Git naturally detects conflicts when two changes modify the same requirement header. This is actually better than full-state storage where Git might silently merge incompatible changes.

## Decisions and Product Guidelines

To keep the archive flow lean and predictable, the following decisions apply:

- New spec creation: When a target spec does not exist, auto-generate a minimal skeleton and insert ADDED requirements only. Skeleton format:
  - `# [Spec Name] Specification`
  - `## Purpose` with placeholder: "TBD â€” created by archiving change [change-name]. Update Purpose after archive."
  - `## Requirements`
  - If a non-existent spec includes MODIFIED/REMOVED/RENAMED, abort with guidance to create via ADDED-only first.

- Requirement identification: Match requirements by exact header `### Requirement: [Name]` with trim-only normalization and case-sensitive comparison. Use a requirement-block extractor that preserves the exact header and captures full content (including scenarios) for both main specs and delta files.

- Application order and atomicity: Apply deltas in order RENAMED â†’ REMOVED â†’ MODIFIED â†’ ADDED. Validate all operations first, apply in-memory, and write each spec once. On any validation failure, abort without writing partial results. An aggregated totals line is displayed across all specs: `Totals: + A, ~ M, - R, â†’ N`.

- Validation matrix: Enforce that MODIFIED/REMOVED exist; ADDED do not exist; RENAMED FROM exists and TO does not; no duplicates after all operations; and no cross-section conflicts (e.g., same item in MODIFIED and REMOVED). When a rename and modify apply to the same item, MODIFIED must reference the NEW header.

- Idempotency: Keep v1 simple. Abort on precondition failures (e.g., ADDED already exists) with clear errors. Do not implement no-op detection in v1.

- Output and UX: For each spec, display operation counts using standard symbols `+ ~ - â†’`. Optionally include a short aggregated totals line at the end. Keep messages concise and actionable.

- Error messaging: Standardize messages as `[spec] [operation] failed for header "### Requirement: X" â€” reason`. On abort, explicitly state: `Aborted. No files were changed.`
- Subsections: Any subsections under a requirement (e.g., `#### Scenario: ...`) are preserved verbatim during parsing and application.

- Backward compatibility: Reject full future-state spec copies for existing specs with guidance to convert to deltas. Allow brand-new specs to be created via ADDED-only deltas using the skeleton above.

- Dry-run: Deferred for v1 to keep scope minimal.


================================================
FILE: openspec/changes/archive/2025-08-19-adopt-delta-based-changes/tasks.md
================================================
# Implementation Tasks

## 1. Update Conventions
- [x] 1.1 Update openspec-conventions spec with delta-based approach
- [x] 1.2 Add Header-Based Requirement Identification
- [x] 1.3 Define ADDED/MODIFIED/REMOVED/RENAMED sections
- [x] 1.4 Document standard output symbols (+ ~ - â†’)
- [x] 1.5 Update openspec/README.md with delta-based conventions
- [x] 1.6 Update examples to use delta format

## 2. Update Diff Command
- [ ] 2.1 Update cli-diff spec with requirement-level comparison
- [ ] 2.2 Parse specs into requirement-level structures
- [ ] 2.3 Apply deltas to generate future state
- [ ] 2.4 Implement side-by-side comparison view (changes only)
- [ ] 2.5 Add tests for requirement-level comparison
- [ ] 2.6 Add tests for side-by-side view formatting

## 3. Update Archive Command
- [x] 3.1 Update cli-archive spec with delta processing behavior
- [x] 3.2 Implement requirement-block extractor that preserves exact headers (`### Requirement: [Name]`) and captures full content (including scenarios)
- [x] 3.3 Implement normalized header matching (trim-only, case-sensitive)
- [x] 3.4 Parse delta sections (ADDED/MODIFIED/REMOVED/RENAMED)
- [x] 3.5 New spec creation when target spec does not exist
  - [x] 3.5.1 Auto-generate minimal skeleton: `# [Spec Name] Specification`, `## Purpose` placeholder, `## Requirements`
  - [x] 3.5.2 Allow only ADDED operations for non-existent specs; abort if MODIFIED/REMOVED/RENAMED present
- [x] 3.6 Apply changes in order: RENAMED â†’ REMOVED â†’ MODIFIED â†’ ADDED
- [x] 3.7 Validation and conflict checks
  - [x] 3.7.1 MODIFIED/REMOVED requirements exist (after applying rename mappings)
  - [x] 3.7.2 ADDED requirements don't already exist (consider post-rename state)
  - [x] 3.7.3 RENAMED FROM headers exist; TO headers don't (including collisions with ADDED)
  - [x] 3.7.4 No duplicate headers within specs after all operations
  - [x] 3.7.5 Detect cross-section conflicts (e.g., same requirement in MODIFIED and REMOVED)
  - [x] 3.7.6 When a rename exists, require MODIFIED to reference the NEW header
- [x] 3.8 Atomic updates
  - [x] 3.8.1 Validate all deltas first; stage updates in-memory per spec
  - [x] 3.8.2 Single write per spec; abort entire archive on any validation failure (no partial writes)
- [x] 3.9 Output and error messaging
  - [x] 3.9.1 Display per-spec operation counts with symbols: `+` added, `~` modified, `-` removed, `â†’` renamed
  - [x] 3.9.2 Optionally display an aggregated totals line across all specs
  - [x] 3.9.3 Standardize error message format: `[spec] [operation] failed for header "### Requirement: X" â€” reason`; end with `Aborted. No files were changed.` on failure
- [x] 3.10 Idempotency behavior (v1): abort on precondition failures (e.g., ADDED already exists); do not implement no-op detection
- [x] 3.11 Tests
  - [x] 3.11.1 Header normalization (trim-only) matching
  - [x] 3.11.2 Apply in correct order (RENAMED â†’ REMOVED â†’ MODIFIED â†’ ADDED)
  - [x] 3.11.3 Validation edge cases (missing headers, duplicates, rename collisions, conflicting sections)
  - [x] 3.11.4 Rename + modify interplay (MODIFIED uses new header)
  - [x] 3.11.5 New spec creation via skeleton
  - [x] 3.11.6 Multi-spec mixed operations with independent validation and write

## Notes
- Archive command is critical path - must work reliably
- All new changes must use delta format
- Header normalization: normalize(header) = trim(header)
- Diff command shows only changed requirements in side-by-side comparison


================================================
FILE: openspec/changes/archive/2025-08-19-adopt-delta-based-changes/specs/cli-archive/spec.md
================================================
# CLI Archive Command - Changes

## MODIFIED Requirements

### Requirement: Spec Update Process

Before moving the change to archive, the command SHALL apply delta changes to main specs to reflect the deployed reality.

#### Scenario: Applying delta changes

- **WHEN** archiving a change with delta-based specs
- **THEN** parse and apply delta changes as defined in openspec-conventions
- **AND** validate all operations before applying

#### Scenario: Validating delta changes

- **WHEN** processing delta changes
- **THEN** perform validations as specified in openspec-conventions
- **AND** if validation fails, show specific errors and abort

#### Scenario: Conflict detection

- **WHEN** applying deltas would create duplicate requirement headers
- **THEN** abort with error message showing the conflict
- **AND** suggest manual resolution

## ADDED Requirements

### Requirement: Display Output

The command SHALL provide clear feedback about delta operations.

#### Scenario: Showing delta application

- **WHEN** applying delta changes
- **THEN** display for each spec:
  - Number of requirements added
  - Number of requirements modified
  - Number of requirements removed
  - Number of requirements renamed
- **AND** use standard output symbols (+ ~ - â†’) as defined in openspec-conventions:
  ```
  Applying changes to specs/user-auth/spec.md:
    + 2 added
    ~ 3 modified
    - 1 removed
    â†’ 1 renamed
  ```


================================================
FILE: openspec/changes/archive/2025-08-19-adopt-delta-based-changes/specs/cli-diff/spec.md
================================================
# CLI Diff Command - Changes

## REMOVED Requirements

### Requirement: Display Format

The diff command SHALL display unified diff output in text format.

**Reason for removal**: The standard unified diff format is replaced by requirement-level side-by-side comparison that better shows semantic changes rather than line-by-line text differences.

#### Scenario: Unified diff output (deprecated)

- **WHEN** running `openspec diff <change>`
- **THEN** show a unified text diff of files
- **AND** include `+`/`-` prefixed lines representing additions and removals

## MODIFIED Requirements

### Requirement: Diff Output

The command SHALL show a requirement-level comparison displaying only changed requirements.

#### Scenario: Side-by-side comparison of changes

- **WHEN** running `openspec diff <change>`
- **THEN** display only requirements that have changed
- **AND** show them in a side-by-side format that:
  - Clearly shows the current version on the left
  - Shows the future version on the right
  - Indicates new requirements (not in current)
  - Indicates removed requirements (not in future)
  - Aligns modified requirements for easy comparison

## ADDED Requirements

### Requirement: Validation

The command SHALL validate that changes can be applied successfully.

#### Scenario: Invalid delta references

- **WHEN** delta references non-existent requirement
- **THEN** show error message with specific requirement
- **AND** continue showing other valid changes
- **AND** clearly mark failed changes in the output


================================================
FILE: openspec/changes/archive/2025-08-19-adopt-delta-based-changes/specs/openspec-conventions/spec.md
================================================
# OpenSpec Conventions - Changes

## MODIFIED Requirements

### Requirement: Header-Based Requirement Identification

Requirement headers SHALL serve as unique identifiers for programmatic matching between current specs and proposed changes.

#### Scenario: Matching requirements programmatically

- **WHEN** processing delta changes
- **THEN** use the `### Requirement: [Name]` header as the unique identifier
- **AND** match using normalized headers: `normalize(header) = trim(header)`
- **AND** compare headers with case-sensitive equality after normalization

#### Scenario: Handling requirement renames

- **WHEN** renaming a requirement
- **THEN** use a special `## RENAMED Requirements` section
- **AND** specify both old and new names explicitly:
  ```markdown
  ## RENAMED Requirements
  - FROM: `### Requirement: Old Name`
  - TO: `### Requirement: New Name`
  ```
- **AND** if content also changes, include under MODIFIED using the NEW header

#### Scenario: Validating header uniqueness

- **WHEN** creating or modifying requirements
- **THEN** ensure no duplicate headers exist within a spec
- **AND** validation tools SHALL flag duplicate headers as errors

### Requirement: Change Storage Convention

Change proposals SHALL store only the additions, modifications, and removals to specifications, not complete future states.

#### Scenario: Creating change proposals with additions

- **WHEN** creating a change proposal that adds new requirements
- **THEN** include only the new requirements under `## ADDED Requirements`
- **AND** each requirement SHALL include its complete content
- **AND** use the standard structured format for requirements and scenarios

#### Scenario: Creating change proposals with modifications  

- **WHEN** creating a change proposal that modifies existing requirements
- **THEN** include the modified requirements under `## MODIFIED Requirements`
- **AND** use the same header text as in the current spec (normalized)
- **AND** include the complete modified requirement (not a diff)
- **AND** optionally annotate what changed with inline comments like `â† (was X)`

#### Scenario: Creating change proposals with removals

- **WHEN** creating a change proposal that removes requirements
- **THEN** list them under `## REMOVED Requirements`
- **AND** use the normalized header text for identification
- **AND** include reason for removal
- **AND** document any migration path if applicable


The `changes/[name]/specs/` directory SHALL contain:
- Delta files showing only what changes
- Sections for ADDED, MODIFIED, REMOVED, and RENAMED requirements
- Normalized header matching for requirement identification
- Complete requirements using the structured format
- Clear indication of change type for each requirement

#### Scenario: Using standard output symbols

- **WHEN** displaying delta operations in CLI output
- **THEN** use these standard symbols:
  - `+` for ADDED (green)
  - `~` for MODIFIED (yellow)
  - `-` for REMOVED (red)
  - `â†’` for RENAMED (cyan)

### Requirement: Archive Process Enhancement

The archive process SHALL programmatically apply delta changes to current specifications using header-based matching.

#### Scenario: Archiving changes with deltas

- **WHEN** archiving a completed change
- **THEN** the archive command SHALL:
  1. Parse RENAMED sections first and apply renames
  2. Parse REMOVED sections and remove by normalized header match
  3. Parse MODIFIED sections and replace by normalized header match (using new names if renamed)
  4. Parse ADDED sections and append new requirements
- **AND** validate that all MODIFIED/REMOVED headers exist in current spec
- **AND** validate that ADDED headers don't already exist
- **AND** generate the updated spec in the main specs/ directory

#### Scenario: Handling conflicts during archive

- **WHEN** delta changes conflict with current spec state
- **THEN** the archive command SHALL report specific conflicts
- **AND** require manual resolution before proceeding
- **AND** provide clear guidance on resolving conflicts

 


================================================
FILE: openspec/changes/archive/2025-08-19-adopt-verb-noun-cli-structure/design.md
================================================
# Design: Verbâ€“Noun CLI Structure Adoption

## Overview
We will make verb commands (`list`, `show`, `validate`, `diff`, `archive`) the primary interface and keep noun commands (`spec`, `change`) as deprecated aliases for one release.

## Decisions

1. Keep routing centralized in `src/cli/index.ts`.
2. Add `--specs`/`--changes` to `openspec list`, with `--changes` as default.
3. Show deprecation warnings for `openspec change list` and, more generally, for any `openspec change ...` and `openspec spec ...` subcommands.
4. Do not change `show`/`validate` behavior beyond help text; they already support `--type` for disambiguation.

## Backward Compatibility
All noun-based commands continue to work with clear deprecation warnings directing users to verb-first equivalents.

## Out of Scope
JSON output parity for `openspec list` across modes and `show --specs/--changes` discovery are follow-ups.





================================================
FILE: openspec/changes/archive/2025-08-19-adopt-verb-noun-cli-structure/proposal.md
================================================
# Change: Adopt Verbâ€“Noun CLI Structure (Deprecate Noun-Based Commands)

## Why

Most widely used CLIs (git, docker, kubectl) start with an action (verb) followed by the object (noun). This matches how users think: â€œdo X to Yâ€. Using verbs as top-level commands improves clarity, discoverability, and extensibility.

## What Changes

- Promote top-level verb commands as primary entry points: `list`, `show`, `validate`, `diff`, `archive`.
- Deprecate noun-based top-level commands: `openspec spec ...` and `openspec change ...`.
- Introduce consistent noun scoping via flags where applicable (e.g., `--changes`, `--specs`) and keep smart defaults.
- Clarify disambiguation for `show` and `validate` when names collide.

### Mappings (From â†’ To)

- **List**
  - From: `openspec change list`
  - To: `openspec list --changes` (default), or `openspec list --specs`

- **Show**
  - From: `openspec spec show <spec-id>` / `openspec change show <change-id>`
  - To: `openspec show <item-id>` with auto-detect, use `--type spec|change` if ambiguous

- **Validate**
  - From: `openspec spec validate <spec-id>` / `openspec change validate <change-id>`
  - To: `openspec validate <item-id> --type spec|change`, or bulk: `openspec validate --specs` / `--changes` / `--all`

### Backward Compatibility

- Keep `openspec spec` and `openspec change` available with deprecation warnings for one release cycle.
- Update help text to point users to the verbâ€“noun alternatives.

## Impact

- **Affected specs**:
  - `cli-list`: Add support for `--specs` and explicit `--changes` (default remains changes)
  - `openspec-conventions`: Add explicit requirement establishing verbâ€“noun CLI design and deprecation guidance
- **Affected code**:
  - `src/cli/index.ts`: Un-deprecate top-level `list`; mark `change list` as deprecated; ensure help text and warnings align
  - `src/core/list.ts`: Support listing specs via `--specs` and default to changes; shared output shape
  - Optional follow-ups: tighten `show`/`validate` help and ambiguity handling

## Explicit Changes

**CLI Design**
- From: Mixed model with nouns (`spec`, `change`) and some top-level verbs; `openspec list` currently deprecated
- To: Verbs as primary: `openspec list|show|validate|diff|archive`; nouns scoped via flags or item ids; noun commands deprecated
- Reason: Align with common CLIs; improve UX; simpler mental model
- Impact: Non-breaking with deprecation period; users migrate incrementally

**Listing Behavior**
- From: `openspec change list` (primary), `openspec list` (deprecated)
- To: `openspec list` as primary, defaulting to `--changes`; add `--specs` to list specs
- Reason: Consistent verbâ€“noun style; better discoverability
- Impact: New option; preserves existing behavior via default

## Rollout and Deprecation Policy

- Show deprecation warnings on noun-based commands for one release.
- Document new usage in `openspec/README.md` and CLI help.
- After one release, consider removing noun-based commands, or keep as thin aliases without warnings.

## Open Questions

- Should `show` also accept `--changes`/`--specs` for discovery without an id? (Out of scope here; current auto-detect and `--type` remain.)





================================================
FILE: openspec/changes/archive/2025-08-19-adopt-verb-noun-cli-structure/tasks.md
================================================
# Implementation Tasks

## 1. CLI Behavior and Help
- [x] 1.1 Un-deprecate top-level `openspec list`; mark `change list` as deprecated with warning that points to `openspec list`
- [x] 1.2 Add support to list specs via `openspec list --specs` and keep `--changes` as default
- [x] 1.3 Update command descriptions and `--help` output to emphasize verbâ€“noun pattern
- [x] 1.4 Keep `openspec spec ...` and `openspec change ...` commands working but print deprecation notices

## 2. Core List Logic
- [x] 2.1 Extend `src/core/list.ts` to accept a mode: `changes` (default) or `specs`
- [x] 2.2 Implement `specs` listing: scan `openspec/specs/*/spec.md`, compute requirement count via parser, format output consistently
- [x] 2.3 Share output structure for both modes; preserve current text table; ensure JSON parity in future change

## 3. Specs and Conventions
- [x] 3.1 Update `openspec/specs/cli-list/spec.md` to document `--specs` (and default to changes)
- [x] 3.2 Update `openspec/specs/openspec-conventions/spec.md` with a requirement for verbâ€“noun CLI design and deprecation guidance

## 4. Tests and Docs
- [x] 4.1 Update tests: ensure `openspec list` works for changes and specs; keep `change list` tests but assert warning
- [ ] 4.2 Update README and any usage docs to show new primary commands
- [ ] 4.3 Add migration notes in repo CHANGELOG or README

## 5. Follow-ups (Optional, not in this change)
- [ ] 5.1 Consider `openspec show --specs/--changes` for discovery without ids
- [ ] 5.2 Consider JSON output for `openspec list` with `--json` for both modes





================================================
FILE: openspec/changes/archive/2025-08-19-adopt-verb-noun-cli-structure/specs/cli-list/spec.md
================================================
# Delta: CLI List Command

## MODIFIED Requirements

### Requirement: Command Execution
The command SHALL scan and analyze either active changes or specs based on the selected mode.

#### Scenario: Scanning for changes (default)
- **WHEN** `openspec list` is executed without flags
- **THEN** scan the `openspec/changes/` directory for change directories
- **AND** exclude the `archive/` subdirectory from results
- **AND** parse each change's `tasks.md` file to count task completion

#### Scenario: Scanning for specs
- **WHEN** `openspec list --specs` is executed
- **THEN** scan the `openspec/specs/` directory for capabilities
- **AND** read each capability's `spec.md`
- **AND** parse requirements to compute requirement counts

### Requirement: Output Format
The command SHALL display items in a clear, readable table format with mode-appropriate progress or counts.

#### Scenario: Displaying change list (default)
- **WHEN** displaying the list of changes
- **THEN** show a table with columns:
  - Change name (directory name)
  - Task progress (e.g., "3/5 tasks" or "âœ“ Complete")

#### Scenario: Displaying spec list
- **WHEN** displaying the list of specs
- **THEN** show a table with columns:
  - Spec id (directory name)
  - Requirement count (e.g., "requirements 12")

### Requirement: Empty State
The command SHALL provide clear feedback when no items are present for the selected mode.

#### Scenario: Handling empty state (changes)
- **WHEN** no active changes exist (only archive/ or empty changes/)
- **THEN** display: "No active changes found."

#### Scenario: Handling empty state (specs)
- **WHEN** no specs directory exists or contains no capabilities
- **THEN** display: "No specs found."

### Requirement: Flags
The command SHALL accept flags to select the noun being listed.

#### Scenario: Selecting specs
- **WHEN** `--specs` is provided
- **THEN** list specs instead of changes

#### Scenario: Selecting changes
- **WHEN** `--changes` is provided
- **THEN** list changes explicitly (same as default behavior)





================================================
FILE: openspec/changes/archive/2025-08-19-adopt-verb-noun-cli-structure/specs/openspec-conventions/spec.md
================================================
# Delta: OpenSpec Conventions â€” Verbâ€“Noun CLI Design

## ADDED Requirements

### Requirement: Verbâ€“Noun CLI Command Structure
OpenSpec CLI design SHALL use verbs as top-level commands with nouns provided as arguments or flags for scoping.

#### Scenario: Verb-first command discovery
- **WHEN** a user runs a command like `openspec list`
- **THEN** the verb communicates the action clearly
- **AND** nouns refine scope via flags or arguments (e.g., `--changes`, `--specs`)

#### Scenario: Backward compatibility for noun commands
- **WHEN** users run noun-prefixed commands such as `openspec spec ...` or `openspec change ...`
- **THEN** the CLI SHALL continue to support them for at least one release
- **AND** display a deprecation warning that points to verb-first alternatives

#### Scenario: Disambiguation guidance
- **WHEN** item names are ambiguous between changes and specs
- **THEN** `openspec show` and `openspec validate` SHALL accept `--type spec|change`
- **AND** the help text SHALL document this clearly





================================================
FILE: openspec/changes/archive/2025-08-19-bulk-validation-interactive-selection/proposal.md
================================================
## Why

Currently, users must validate changes and specs individually by specifying each ID. This creates friction when:
- Teams want to validate all changes/specs before a release
- Developers need to ensure consistency across multiple related changes  
- Users run validation commands without arguments and receive errors instead of helpful guidance
- The subcommand structure requires users to know in advance whether they're validating a change or spec

## What Changes

- Add new top-level `validate` command with intuitive flags (--all, --changes, --specs)
- Enhance existing `change validate` and `spec validate` to support interactive selection (backwards compatibility)
- Interactive selection by default when no arguments provided
- Support direct item validation: `openspec validate <item>` with automatic type detection

## Impact

- New specs to create: cli-validate
- Specs to enhance: cli-change, cli-spec (for backwards compatibility)
- Affected code: src/cli/index.ts, src/commands/validate.ts (new), src/commands/spec.ts, src/commands/change.ts


================================================
FILE: openspec/changes/archive/2025-08-19-bulk-validation-interactive-selection/tasks.md
================================================
# Implementation Tasks

## 1. Change Command: Interactive Validation Selection
- [x] 1.1 Add `--no-interactive` flag to `change validate` in `src/cli/index.ts`
- [x] 1.2 Implement interactivity gate respecting TTY and `OPEN_SPEC_INTERACTIVE=0` in `src/commands/change.ts`
- [x] 1.3 When no `[change-name]` is provided and interactivity is allowed, prompt with a list of active changes (exclude `archive/`) and validate the selected one
- [x] 1.4 Preserve current non-interactive fallback: print available change IDs and hint, set `process.exitCode = 1`
- [x] 1.5 Tests: add coverage for interactive and non-interactive flows
  - Added `test/commands/change.interactive-validate.test.ts`

## 2. Spec Command: Interactive Validation Selection
- [x] 2.1 Make `spec validate` accept optional `[spec-id]` in `src/commands/spec.ts` registration
- [x] 2.2 Add `--no-interactive` flag to `spec validate`
- [x] 2.3 Implement interactivity gate respecting TTY and `OPEN_SPEC_INTERACTIVE=0`
- [x] 2.4 When no `[spec-id]` provided and interactivity allowed, prompt to select from `openspec/specs/*/spec.md` and validate the selected spec
- [x] 2.5 Preserve current non-interactive fallback when no spec-id and no interactivity: print existing error and exit code non-zero
- [x] 2.6 Tests: add coverage for interactive and non-interactive flows
  - Added `test/commands/spec.interactive-validate.test.ts`

## 3. New Top-level `validate` Command
- [x] 3.1 Add `validate` command in `src/cli/index.ts`
  - Options: `--all`, `--changes`, `--specs`, `--type <change|spec>`, `--strict`, `--json`, `--no-interactive`
  - Usage: `openspec validate [item-name]`
- [x] 3.2 Create `src/commands/validate.ts` implementing:
  - [x] 3.2.1 Interactive selector when no args (choices: All, Changes, Specs, Specific item)
  - [x] 3.2.2 Non-interactive fallback with helpful hint and exit code 1
  - [x] 3.2.3 Direct item validation with automatic type detection
  - [x] 3.2.4 Ambiguity error when name exists as both change and spec; suggest `--type` or subcommands
  - [x] 3.2.5 Unknown item handling with nearest-match suggestions
  - [x] 3.2.6 Bulk validation for `--all`, `--changes`, `--specs` (exclude `openspec/changes/archive/`)
  - [x] 3.2.7 Respect `--strict` and `--json` options; JSON shape per spec
  - [x] 3.2.8 Exit with code 1 if any validation fails
  - [x] 3.2.9 Bounded concurrency (default 4â€“8) for bulk validation
  - [x] 3.2.10 Progress indication during bulk runs (current item, running counts)

## 4. Utilities and Shared Helpers
- [x] 4.1 Add `src/utils/interactive.ts` with `isInteractive(stdin: NodeJS.ReadStream, noInteractiveFlag?: boolean): boolean`
  - Considers: `process.stdin.isTTY`, `--no-interactive`, `OPEN_SPEC_INTERACTIVE=0`
- [x] 4.2 Add `src/utils/item-discovery.ts` with:
  - `getActiveChangeIds(root = process.cwd()): Promise<string[]>` (exclude `archive/`)
  - `getSpecIds(root = process.cwd()): Promise<string[]>` (folders with `spec.md`)
- [ ] 4.3 Optional: `src/utils/concurrency.ts` helper for bounded parallelism
- [x] 4.4 Reuse `src/core/validation/validator.ts` for item validation

## 5. JSON Output (Bulk Validation)
- [x] 5.1 Implement JSON schema:
  - `items: Array<{ id: string, type: "change"|"spec", valid: boolean, issues: Issue[], durationMs: number }>`
  - `summary: { totals: { items: number, passed: number, failed: number }, byType: { change?: { items: number, passed: number, failed: number }, spec?: { items: number, passed: number, failed: number } } }`
  - `version: "1.0"`
- [x] 5.2 Ensure process exit code is 1 if any `items[].valid === false`
- [x] 5.3 Tests for JSON shape (keys, types, counts) and exit code behavior
  - Added `test/commands/validate.test.ts`

## 6. Progress and UX
- [x] 6.1 Use `ora` or minimal console progress to show current item and running counts
- [x] 6.2 Keep output stable in `--json` mode (no extra logs to stdout; use stderr for progress if needed)
- [x] 6.3 Ensure responsiveness with concurrency limits

## 7. Tests
- [x] 7.1 Add top-level validate tests: `test/commands/validate.test.ts`
  - Includes non-interactive hint, --all JSON, --specs with concurrency, ambiguity error
- [ ] 7.2 Add unit tests for `isInteractive` and item discovery helpers
- [x] 7.3 Extend existing change/spec command tests to cover interactive `validate`
  - Added `test/commands/change.interactive-validate.test.ts`, `test/commands/spec.interactive-validate.test.ts`

## 8. CLI Help and Docs
- [x] 8.1 Update command descriptions/options in `src/cli/index.ts`
- [x] 8.2 Verify help output includes `validate` command and flags
- [x] 8.3 Ensure existing specs under `openspec/changes/bulk-validation-interactive-selection/specs/*` remain satisfied

## 9. Non-functional
- [x] 9.1 Code style and types: explicit types for exported APIs; avoid `any`
- [x] 9.2 No linter errors; stable formatting; avoid unrelated refactors
- [x] 9.3 Maintain existing behavior for unaffected commands

## 10. Acceptance Criteria Mapping
- [x] AC-1: `openspec change validate` interactive selection when no arg (TTY only; respects `--no-interactive`/env) â€” matches cli-change spec
- [x] AC-2: `openspec spec validate` interactive selection when no arg (TTY only; respects `--no-interactive`/env) â€” matches cli-spec spec
- [x] AC-3: New `openspec validate` supports interactive selection, bulk/filtered validation, JSON schema, progress, concurrency, exit codes â€” matches cli-validate spec





================================================
FILE: openspec/changes/archive/2025-08-19-bulk-validation-interactive-selection/specs/cli-change/spec.md
================================================
# CLI Change Command Spec

## ADDED Requirements

### Requirement: Interactive validation selection

The change validate command SHALL support interactive selection when no change name is provided.

#### Scenario: Interactive change selection for validation

- **WHEN** executing `openspec change validate` without arguments
- **THEN** display an interactive list of available changes
- **AND** allow the user to select a change to validate
- **AND** validate the selected change

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec change validate` without a change name
- **THEN** do not prompt interactively
- **AND** print the existing hint including available change IDs
- **AND** set `process.exitCode = 1`


================================================
FILE: openspec/changes/archive/2025-08-19-bulk-validation-interactive-selection/specs/cli-spec/spec.md
================================================
# CLI Spec Command Spec

## ADDED Requirements

### Requirement: Interactive spec validation

The spec validate command SHALL support interactive selection when no spec-id is provided.

#### Scenario: Interactive spec selection for validation

- **WHEN** executing `openspec spec validate` without arguments
- **THEN** display an interactive list of available specs
- **AND** allow the user to select a spec to validate
- **AND** validate the selected spec
- **AND** maintain all existing validation options (--strict, --json)

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec spec validate` without a spec-id
- **THEN** do not prompt interactively
- **AND** print the existing error message for missing spec-id
- **AND** set non-zero exit code


================================================
FILE: openspec/changes/archive/2025-08-19-bulk-validation-interactive-selection/specs/cli-validate/spec.md
================================================
# CLI Validate Command Spec

## ADDED Requirements

### Requirement: Top-level validate command

The CLI SHALL provide a top-level `validate` command for validating changes and specs with flexible selection options.

#### Scenario: Interactive validation selection

- **WHEN** executing `openspec validate` without arguments
- **THEN** prompt user to select what to validate (all, changes, specs, or specific item)
- **AND** perform validation based on selection
- **AND** display results with appropriate formatting

#### Scenario: Non-interactive environments do not prompt

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec validate` without arguments
- **THEN** do not prompt interactively
- **AND** print a helpful hint listing available commands/flags and exit with code 1

#### Scenario: Direct item validation

- **WHEN** executing `openspec validate <item-name>`
- **THEN** automatically detect if item is a change or spec
- **AND** validate the specified item
- **AND** display validation results

### Requirement: Bulk and filtered validation

The validate command SHALL support flags for bulk validation (--all) and filtered validation by type (--changes, --specs).

#### Scenario: Validate everything

- **WHEN** executing `openspec validate --all`
- **THEN** validate all changes in openspec/changes/ (excluding archive)
- **AND** validate all specs in openspec/specs/
- **AND** display a summary showing passed/failed items
- **AND** exit with code 1 if any validation fails

#### Scenario: Scope of bulk validation

- **WHEN** validating with `--all` or `--changes`
- **THEN** include all change proposals under `openspec/changes/`
- **AND** exclude the `openspec/changes/archive/` directory

- **WHEN** validating with `--specs`
- **THEN** include all specs that have a `spec.md` under `openspec/specs/<id>/spec.md`

#### Scenario: Validate all changes

- **WHEN** executing `openspec validate --changes`
- **THEN** validate all changes in openspec/changes/ (excluding archive)
- **AND** display results for each change
- **AND** show summary statistics

#### Scenario: Validate all specs

- **WHEN** executing `openspec validate --specs`
- **THEN** validate all specs in openspec/specs/
- **AND** display results for each spec
- **AND** show summary statistics

### Requirement: Validation options and progress indication

The validate command SHALL support standard validation options (--strict, --json) and display progress during bulk operations.

#### Scenario: Strict validation

- **WHEN** executing `openspec validate --all --strict`
- **THEN** apply strict validation to all items
- **AND** treat warnings as errors
- **AND** fail if any item has warnings or errors

#### Scenario: JSON output

- **WHEN** executing `openspec validate --all --json`
- **THEN** output validation results as JSON
- **AND** include detailed issues for each item
- **AND** include summary statistics

#### Scenario: JSON output schema for bulk validation

- **WHEN** executing `openspec validate --all --json` (or `--changes` / `--specs`)
- **THEN** output a JSON object with the following shape:
  - `items`: Array of objects with fields `{ id: string, type: "change"|"spec", valid: boolean, issues: Issue[], durationMs: number }`
  - `summary`: Object `{ totals: { items: number, passed: number, failed: number }, byType: { change?: { items: number, passed: number, failed: number }, spec?: { items: number, passed: number, failed: number } } }`
  - `version`: String identifier for the schema (e.g., `"1.0"`)
- **AND** exit with code 1 if any `items[].valid === false`

Where `Issue` follows the existing per-item validation report shape `{ level: "ERROR"|"WARNING"|"INFO", path: string, message: string }`.

#### Scenario: Show validation progress

- **WHEN** validating multiple items (--all, --changes, or --specs)
- **THEN** show progress indicator or status updates
- **AND** indicate which item is currently being validated
- **AND** display running count of passed/failed items

#### Scenario: Concurrency limits for performance

- **WHEN** validating multiple items
- **THEN** run validations with a bounded concurrency (e.g., 4â€“8 in parallel)
- **AND** ensure progress indicators remain responsive

### Requirement: Item type detection and ambiguity handling

The validate command SHALL handle ambiguous names and explicit type overrides to ensure clear, deterministic behavior.

#### Scenario: Direct item validation with automatic type detection

- **WHEN** executing `openspec validate <item-name>`
- **THEN** if `<item-name>` uniquely matches a change or a spec, validate that item

#### Scenario: Ambiguity between change and spec names

- **GIVEN** `<item-name>` exists both as a change and as a spec
- **WHEN** executing `openspec validate <item-name>`
- **THEN** print an ambiguity error explaining both matches
- **AND** suggest passing `--type change` or `--type spec`, or using `openspec change validate` / `openspec spec validate`
- **AND** exit with code 1 without performing validation

#### Scenario: Unknown item name

- **WHEN** the `<item-name>` matches neither a change nor a spec
- **THEN** print a not-found error
- **AND** show nearest-match suggestions when available
- **AND** exit with code 1

#### Scenario: Explicit type override

- **WHEN** executing `openspec validate --type change <item>`
- **THEN** treat `<item>` as a change ID and validate it (skipping auto-detection)

- **WHEN** executing `openspec validate --type spec <item>`
- **THEN** treat `<item>` as a spec ID and validate it (skipping auto-detection)

### Requirement: Interactivity controls

- The CLI SHALL respect `--no-interactive` to disable prompts.
- The CLI SHALL respect `OPEN_SPEC_INTERACTIVE=0` to disable prompts globally.
- Interactive prompts SHALL only be shown when stdin is a TTY and interactivity is not disabled.

#### Scenario: Disabling prompts via flags or environment

- **WHEN** `openspec validate` is executed with `--no-interactive` or with environment `OPEN_SPEC_INTERACTIVE=0`
- **THEN** the CLI SHALL not display interactive prompts
- **AND** SHALL print non-interactive hints or chosen outputs as appropriate


================================================
FILE: openspec/changes/archive/2025-08-19-fix-update-tool-selection/proposal.md
================================================
# Fix Update Command Tool Selection

## Problem

The `openspec update` command currently forces the creation/update of CLAUDE.md regardless of which AI tool was selected during initialization. This violates the tool-agnostic design principle and creates confusion for users who selected different AI assistants.

Additionally, different team members may use different AI tools, so we cannot rely on a shared configuration file.

## Solution

Modify the update command to:
1. Only update AI tool configuration files that already exist
2. Never create new AI tool configuration files
3. Always update the core OpenSpec files (README.md, etc.)

## Implementation

- Remove hardcoded CLAUDE.md update from update command
- Implement file existence check before updating any AI tool config
- Update each existing AI tool config file with its appropriate markers
- No configuration file needed (avoids team conflicts)

## Success Criteria

- Update command only modifies existing AI tool configuration files
- No new AI tool files created during update
- Team members can use different AI tools without conflicts
- Existing projects continue to work (backward compatibility)

## Why

Users need predictable, tool-agnostic behavior from `openspec update`. Creating or forcing updates for AI tool files that a project does not use causes confusion and merge conflicts. Restricting updates to existing files and always updating core OpenSpec files keeps the workflow consistent for mixed-tool teams.

## What Changes

- **cli-update:** Modify update behavior to update only existing AI tool configuration files and never create new ones; always update core OpenSpec files and display an ASCII-safe success message.

## ADDED Requirements

Removed from proposal to follow conventions. See `specs/cli-update/spec.md` for the delta requirements content.


================================================
FILE: openspec/changes/archive/2025-08-19-fix-update-tool-selection/tasks.md
================================================
# Implementation Tasks

## 1. Update Update Command
- [x] Remove hardcoded CLAUDE.md update from `src/core/update.ts`
- [x] Add logic to check for existing AI tool configuration files
- [x] Update only existing files using their appropriate configurators
- [x] Iterate through all registered configurators to check for existing files

## 2. Update Configurator Registry
- [x] Add method to get all configurators for update command
- [x] Ensure each configurator can check if its file exists

## 3. Add Tests
- [x] Test update command with only CLAUDE.md present
- [x] Test update command with no AI tool files present
- [x] Test update command with multiple AI tool files present
- [x] Test that update never creates new AI tool files

## 4. Update Documentation
- [x] Update README to clarify team-friendly behavior
- [x] Document that update only modifies existing files


================================================
FILE: openspec/changes/archive/2025-08-19-fix-update-tool-selection/specs/cli-update/spec.md
================================================
## ADDED Requirements

### Requirement: Tool-Agnostic Updates

The update command SHALL update only existing AI tool configuration files and SHALL NOT create new ones.

#### Scenario: Updating existing tool files

- **WHEN** a user runs `openspec update`
- **THEN** update each AI tool configuration file that exists (e.g., CLAUDE.md, COPILOT.md)
- **AND** do not create missing tool configuration files
- **AND** preserve user content outside OpenSpec markers

### Requirement: Core Files Always Updated

The update command SHALL always update the core OpenSpec files and display an ASCII-safe success message.

#### Scenario: Successful update

- **WHEN** the update completes successfully
- **THEN** replace `openspec/README.md` with the latest template
- **AND** update existing AI tool configuration files within markers
- **AND** display the message: "Updated OpenSpec instructions"


================================================
FILE: openspec/changes/archive/2025-08-19-improve-validate-error-messages/proposal.md
================================================
# improve-validate-error-messages

## Why

Developers struggle to resolve validation failures because current errors lack actionable guidance. Common issues include: missing deltas, missing required sections, and misformatted scenarios that are silently ignored. Without clear remediation steps, users cannot quickly correct structure or formatting, leading to frustration and rework. Improving error messages with concrete fixes, file/section hints, and suggested commands will significantly reduce time-to-green and make OpenSpec more approachable.

## What Changes

- Validation errors SHALL include specific remediation steps (what to change and where).
- "No deltas found" error SHALL guide users to create `specs/` with proper delta headers and suggest debug commands.
- Missing required sections (Spec: Purpose/Requirements; Change: Why/What Changes) SHALL include expected header names and a minimal skeleton example.
- Likely misformatted scenarios (bulleted WHEN/THEN/AND) SHALL emit a targeted warning explaining the `#### Scenario:` format and show a conversion template.
- All reported issues SHALL include the source file path and structured location (e.g., `deltas[0].requirements[0]`).
- Non-JSON output SHOULD end with a short "Next steps" footer when invalid.

## Impact

- Affected CLI: validate
- Affected code:
  - `src/commands/validate.ts`
  - `src/core/validation/validator.ts`
  - `src/core/validation/constants.ts`
  - `src/core/parsers/*` (wrapping thrown errors with richer context)





================================================
FILE: openspec/changes/archive/2025-08-19-improve-validate-error-messages/tasks.md
================================================
## 1. Enhance validation messages
- [x] 1.1 Add remediation guidance for "No deltas found"
- [x] 1.2 Include file path and structured path in all issues
- [x] 1.3 Improve messages for missing required sections (Spec, Change)
- [x] 1.4 Detect likely misformatted scenarios and warn with conversion example
- [x] 1.5 Add "Next steps" footer for non-JSON invalid output

## 2. Update constants and helpers
- [x] 2.1 Centralize guidance snippets in `VALIDATION_MESSAGES`
- [x] 2.2 Provide minimal skeleton examples for missing sections

## 3. Parser integration
- [x] 3.1 Capture parser-thrown errors and wrap with richer context
- [x] 3.2 Add file/section references to surfaced parser errors

## 4. Tests
- [x] 4.1 Unit tests for validator message composition
- [x] 4.2 CLI integration tests for human-readable output (with footer)
- [x] 4.3 JSON mode tests (structure unchanged, content enriched)





================================================
FILE: openspec/changes/archive/2025-08-19-improve-validate-error-messages/specs/cli-validate/spec.md
================================================
# Validate Command

## ADDED Requirements

### Requirement: Validation SHALL provide actionable remediation steps
Validation output SHALL include specific guidance to fix each error, including expected structure, example headers, and suggested commands to verify fixes.

#### Scenario: No deltas found in change
- **WHEN** validating a change with zero parsed deltas
- **THEN** show error "No deltas found" with guidance:
  - Ensure `openspec/changes/{id}/specs/` exists with `.md` files
  - Use delta headers: `## ADDED Requirements`, `## MODIFIED Requirements`, `## REMOVED Requirements`, `## RENAMED Requirements`
  - Each requirement must include at least one `#### Scenario:` block
  - Try: `openspec change show {id} --json --deltas-only` to inspect what was parsed

#### Scenario: Missing required sections
- **WHEN** a required section is missing
- **THEN** the validator SHALL include expected header names and a minimal skeleton:
  - For Spec: `## Purpose`, `## Requirements`
  - For Change: `## Why`, `## What Changes`
  - Show an example snippet of the missing section

### Requirement: Validator SHALL detect likely misformatted scenarios and warn with a fix
The validator SHALL recognize bulleted lines that look like scenarios (e.g., lines beginning with WHEN/THEN/AND) and emit a targeted warning with a conversion example to `#### Scenario:`.

#### Scenario: Bulleted WHEN/THEN under a Requirement
- **WHEN** bullets that start with WHEN/THEN/AND are found under a requirement without any `#### Scenario:` headers
- **THEN** emit warning: "Scenarios must use '#### Scenario:' headers", and show a conversion template:
```
#### Scenario: Short name
- **WHEN** ...
- **THEN** ...
- **AND** ...
```

### Requirement: All issues SHALL include file paths and structured locations
Error, warning, and info messages SHALL include:
- Source file path (`openspec/changes/{id}/proposal.md`, `.../specs/{cap}/spec.md`)
- Structured path (e.g., `deltas[0].requirements[0].scenarios`)

#### Scenario: Zod validation error
- **WHEN** a schema validation fails
- **THEN** the message SHALL include `file`, `path`, and a remediation hint if applicable

### Requirement: Invalid results SHALL include a Next steps footer in human-readable output
The CLI SHALL append a Next steps footer when the item is invalid and not using `--json`, including:
- Summary line with counts
- Top-3 guidance bullets (contextual to the most frequent or blocking errors)
- A suggestion to re-run with `--json` and/or the debug command

#### Scenario: Change invalid summary
- **WHEN** a change validation fails
- **THEN** print "Next steps" with 2-3 targeted bullets and suggest `openspec change show <id> --json --deltas-only`





================================================
FILE: openspec/changes/archive/2025-08-19-structured-spec-format/proposal.md
================================================
## Why

OpenSpec specifications lack a consistent structure that makes sections visually identifiable and programmatically parseable across different specs. This makes it harder to maintain consistency and build tooling.

## What Changes

**Specification Format Section**
- From: No formal structure requirements for specifications
- To: Structured format with `### Requirement:` and `#### Scenario:` headers
- Reason: Visual consistency and parseability across all specs
- Impact: Non-breaking - existing specs can migrate gradually

**Keyword Formatting**
- From: Inconsistent use of WHEN/THEN/AND keywords
- To: Bold keywords (**WHEN**, **THEN**, **AND**) in scenario bullets
- Reason: Improved readability and consistent visual hierarchy
- Impact: Non-breaking - formatting enhancement only

**Format Flexibility**
- From: Implicit understanding that different content needs different formats
- To: Explicit allowance for alternative formats (OpenAPI, JSON Schema, etc.)
- Reason: Address concern that not all specs fit requirement/scenario pattern
- Impact: Non-breaking - clarifies existing practice

**Migration Guidelines**
- From: No migration guidance
- To: Documented gradual migration approach
- Reason: Allows incremental adoption without disrupting existing specs
- Impact: Non-breaking - opt-in migration as specs are modified

## Impact

- Affected specs: openspec-conventions (enhancement to existing capability)
- Affected code: None initially - this is a documentation standard enhancement
- Migration: Gradual - existing specs migrate as they're modified
- Tooling: Enables future parsing tools but doesn't require them



================================================
FILE: openspec/changes/archive/2025-08-19-structured-spec-format/tasks.md
================================================
## 1. Update OpenSpec Conventions Spec

- [x] 1.1 Add "Specification Format" section to openspec-conventions
- [x] 1.2 Document structured format with Requirement/Scenario headers
- [x] 1.3 Define bold keyword usage (WHEN/THEN/AND) for scenarios
- [x] 1.4 Include examples demonstrating the format within the spec itself

## 2. Update Documentation

- [x] 2.1 Update the "Why This Approach" section with structured format benefits
- [x] 2.2 Ensure spec follows its own format as a demonstration

## 3. Update Existing Specs

- [x] 3.1 Update cli-init spec to use structured format in Behavior section
- [x] 3.2 Update cli-list spec to use structured format in Behavior section
- [x] 3.3 Update cli-update spec to use structured format in Behavior section
- [x] 3.4 Update cli-diff spec to use structured format in Behavior section
- [x] 3.5 Update cli-archive spec to use structured format in Behavior section


================================================
FILE: openspec/changes/archive/2025-08-19-structured-spec-format/specs/openspec-conventions/spec.md
================================================
# OpenSpec Conventions Specification

## ADDED Requirements

### Requirement: Structured Format Adoption

Behavioral specifications SHALL adopt the structured format with `### Requirement:` and `#### Scenario:` headers as the default.

#### Scenario: Use structured headings for behavior

- **WHEN** documenting behavioral requirements
- **THEN** use `### Requirement:` for requirements
- **AND** use `#### Scenario:` for scenarios with bold WHEN/THEN/AND keywords

## Purpose

OpenSpec conventions SHALL define how system capabilities are documented, how changes are proposed and tracked, and how specifications evolve over time. This meta-specification serves as the source of truth for OpenSpec's own conventions.

## Core Principles

The system SHALL follow these principles:
- Specs reflect what IS currently built and deployed
- Changes contain proposals for what SHOULD be changed
- AI drives the documentation process
- Specs are living documentation kept in sync with deployed code

## Directory Structure

WHEN an OpenSpec project is initialized
THEN it SHALL have this structure:
```
openspec/
â”œâ”€â”€ project.md              # Project-specific context
â”œâ”€â”€ README.md               # AI assistant instructions
â”œâ”€â”€ specs/                  # Current deployed capabilities
â”‚   â””â”€â”€ [capability]/       # Single, focused capability
â”‚       â”œâ”€â”€ spec.md         # WHAT and WHY
â”‚       â””â”€â”€ design.md       # HOW (optional, for established patterns)
â””â”€â”€ changes/                # Proposed changes
    â”œâ”€â”€ [change-name]/      # Descriptive change identifier
    â”‚   â”œâ”€â”€ proposal.md     # Why, what, and impact
    â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
    â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional)
    â”‚   â””â”€â”€ specs/          # Complete future state
    â”‚       â””â”€â”€ [capability]/
    â”‚           â””â”€â”€ spec.md # Clean markdown (no diff syntax)
    â””â”€â”€ archive/            # Completed changes
        â””â”€â”€ YYYY-MM-DD-[name]/
```

## Specification Format

### Requirement: Structured Format for Behavioral Specs

Behavioral specifications SHALL use a structured format with consistent section headers and keywords to ensure visual consistency and parseability.

#### Scenario: Writing requirement sections

- **WHEN** documenting a requirement in a behavioral specification
- **THEN** use a level-3 heading with format `### Requirement: [Name]`
- **AND** immediately follow with a SHALL statement describing core behavior
- **AND** keep requirement names descriptive and under 50 characters

#### Scenario: Documenting scenarios

- **WHEN** documenting specific behaviors or use cases
- **THEN** use level-4 headings with format `#### Scenario: [Description]`
- **AND** use bullet points with bold keywords for steps:
  - **GIVEN** for initial state (optional)
  - **WHEN** for conditions or triggers
  - **THEN** for expected outcomes
  - **AND** for additional outcomes or conditions

#### Scenario: Adding implementation details

- **WHEN** a step requires additional detail
- **THEN** use sub-bullets under the main step
- **AND** maintain consistent indentation
  - Sub-bullets provide examples or specifics
  - Keep sub-bullets concise

### Requirement: Format Flexibility

The structured format SHALL be the default for behavioral specifications, but alternative formats MAY be used when more appropriate for the content type.

#### Scenario: Documenting API specifications

- **WHEN** documenting REST API endpoints or GraphQL schemas
- **THEN** OpenAPI, GraphQL SDL, or similar formats MAY be used
- **AND** the spec SHALL clearly indicate the format being used
- **AND** behavioral aspects SHALL still follow the structured format

#### Scenario: Documenting data schemas

- **WHEN** documenting data structures, database schemas, or configurations
- **THEN** JSON Schema, SQL DDL, or similar formats MAY be used
- **AND** include the structured format for behavioral rules and constraints

#### Scenario: Using simplified format

- **WHEN** documenting simple capabilities without complex scenarios
- **THEN** a simplified WHEN/THEN format without full structure MAY be used
- **AND** this should be consistent within the capability

## Change Storage Convention

### Future State Storage

WHEN creating a change proposal
THEN store the complete future state of affected specs
AND use clean markdown without diff syntax

The `changes/[name]/specs/` directory SHALL contain:
- Complete spec files as they will exist after the change
- Clean markdown without `+` or `-` prefixes
- All formatting and structure of the final intended state

### Proposal Format

WHEN documenting what changes
THEN the proposal SHALL explicitly describe each change:

```markdown
**[Section or Behavior Name]**
- From: [current state/requirement]
- To: [future state/requirement]
- Reason: [why this change is needed]
- Impact: [breaking/non-breaking, who's affected]
```

This explicit format compensates for not having inline diffs and ensures reviewers understand exactly what will change.

## Change Lifecycle

The change process SHALL follow these states:

1. **Propose**: AI creates change with future state specs and explicit proposal
2. **Review**: Humans review proposal and future state
3. **Approve**: Change is approved for implementation
4. **Implement**: Follow tasks.md checklist (can span multiple PRs)
5. **Deploy**: Changes are deployed to production
6. **Update**: Specs in `specs/` are updated to match deployed reality
7. **Archive**: Change is moved to `archive/YYYY-MM-DD-[name]/`

## Viewing Changes

WHEN reviewing proposed changes
THEN reviewers can compare using:
- GitHub PR diff view when changes are committed
- Command line: `diff -u specs/[capability]/spec.md changes/[name]/specs/[capability]/spec.md`
- Any visual diff tool comparing current vs future state

The system relies on tools to generate diffs rather than storing them.

## Capability Naming

Capabilities SHALL use:
- Verb-noun patterns (e.g., `user-auth`, `payment-capture`)
- Hyphenated lowercase names
- Singular focus (one responsibility per capability)
- No nesting (flat structure under `specs/`)

## When Changes Require Proposals

A proposal SHALL be created for:
- New features or capabilities
- Breaking changes to existing behavior
- Architecture or pattern changes
- Performance optimizations that change behavior
- Security updates affecting access patterns

A proposal is NOT required for:
- Bug fixes restoring intended behavior
- Typos or formatting fixes
- Non-breaking dependency updates
- Adding tests for existing behavior
- Documentation clarifications

## Why This Approach

Clean future state storage provides:
- **Readability**: No diff syntax pollution
- **AI-compatibility**: Standard markdown that AI tools understand
- **Simplicity**: No special parsing or processing needed
- **Tool-agnostic**: Any diff tool can show changes
- **Clear intent**: Explicit proposals document reasoning

The structured format adds:
- **Visual Consistency**: Requirement and Scenario prefixes make sections instantly recognizable
- **Parseability**: Consistent structure enables tooling and automation
- **Flexibility**: Alternative formats supported where appropriate
- **Gradual Adoption**: Existing specs can migrate incrementally


================================================
FILE: openspec/changes/archive/2025-09-12-add-view-dashboard-command/proposal.md
================================================
# Change: Add View Dashboard Command

## Why

Users need a quick, at-a-glance overview of their OpenSpec project status without running multiple commands. Currently, users must run `openspec list --changes` and `openspec list --specs` separately to understand the project state. A unified dashboard view would improve developer experience and provide immediate insight into project progress.

## What Changes

### Added `openspec view` Command

The new command provides an interactive dashboard displaying:
- Summary metrics (total specs, requirements, changes, task progress)
- Active changes with visual progress bars
- Completed changes
- Specifications with requirement counts

### Specifications Affected

- **cli-view** (NEW): Complete specification for the view dashboard command

## Implementation Details

### File Structure
- Created `/src/core/view.ts` implementing the `ViewCommand` class
- Registered command in `/src/cli/index.ts`
- Reuses existing utilities from `task-progress.ts` and `MarkdownParser`

### Visual Design
- Uses Unicode box drawing characters for borders
- Color coding: cyan for specs, yellow for active, green for completed
- Progress bars using filled (â–ˆ) and empty (â–‘) blocks
- Clean alignment with proper padding

### Technical Approach
- Async data fetching from changes and specs directories
- Parallel processing of specs and changes
- Error handling for missing or invalid data
- Maintains consistency with existing list command output


================================================
FILE: openspec/changes/archive/2025-09-12-add-view-dashboard-command/tasks.md
================================================
# Implementation Tasks

## Design Phase
- [x] Research existing list command implementation
- [x] Design dashboard layout and information architecture
- [x] Choose appropriate command verb (`view`)
- [x] Define visual elements (progress bars, colors, layout)

## Core Implementation
- [x] Create ViewCommand class in `/src/core/view.ts`
- [x] Implement getChangesData method for fetching change information
- [x] Implement getSpecsData method for fetching spec information
- [x] Implement displaySummary method for summary metrics
- [x] Add progress bar visualization with Unicode characters
- [x] Implement color coding using chalk

## Integration
- [x] Import ViewCommand in CLI index
- [x] Register `openspec view` command with commander
- [x] Add proper error handling and ora spinner integration
- [x] Ensure command appears in help documentation

## Data Processing
- [x] Reuse TaskProgress utilities for change progress
- [x] Integrate MarkdownParser for spec requirement counting
- [x] Handle async operations for file system access
- [x] Sort specifications by requirement count

## Testing and Validation
- [x] Build project successfully with new command
- [x] Test command with sample data
- [x] Verify correct requirement counts match list --specs
- [x] Test progress bar display for various completion states
- [x] Run existing test suite to ensure no regressions
- [x] Verify TypeScript compilation with no errors

## Documentation
- [x] Add command description in CLI help
- [x] Create change proposal documentation
- [x] Update README with view command example (if needed)
- [x] Add view command to user documentation (if exists)

## Polish
- [x] Ensure consistent formatting and alignment
- [x] Add helpful footer text referencing list commands
- [x] Optimize for terminal width considerations
- [x] Review and refine color choices for accessibility


================================================
FILE: openspec/changes/archive/2025-09-12-add-view-dashboard-command/specs/cli-view/spec.md
================================================
# CLI View Command - Changes

## ADDED Requirements

### Requirement: Dashboard Display

The system SHALL provide a `view` command that displays a dashboard overview of specs and changes.

#### Scenario: Basic dashboard display

- **WHEN** user runs `openspec view`
- **THEN** system displays a formatted dashboard with sections for summary, active changes, completed changes, and specifications

#### Scenario: No OpenSpec directory

- **WHEN** user runs `openspec view` in a directory without OpenSpec
- **THEN** system displays error message "âœ— No openspec directory found"

### Requirement: Summary Section

The dashboard SHALL display a summary section with key project metrics.

#### Scenario: Complete summary display

- **WHEN** dashboard is rendered with specs and changes
- **THEN** system shows total number of specifications and requirements
- **AND** shows number of active changes in progress
- **AND** shows number of completed changes
- **AND** shows overall task progress percentage

#### Scenario: Empty project summary

- **WHEN** no specs or changes exist
- **THEN** summary shows zero counts for all metrics

### Requirement: Active Changes Display

The dashboard SHALL show active changes with visual progress indicators.

#### Scenario: Active changes with progress bars

- **WHEN** there are in-progress changes with tasks
- **THEN** system displays each change with change name left-aligned
- **AND** visual progress bar using Unicode characters
- **AND** percentage completion on the right

#### Scenario: No active changes

- **WHEN** all changes are completed or no changes exist
- **THEN** active changes section is omitted from display

### Requirement: Completed Changes Display

The dashboard SHALL list completed changes in a separate section.

#### Scenario: Completed changes listing

- **WHEN** there are completed changes (all tasks done)
- **THEN** system shows them with checkmark indicators in a dedicated section

#### Scenario: Mixed completion states

- **WHEN** some changes are complete and others active
- **THEN** system separates them into appropriate sections

### Requirement: Specifications Display

The dashboard SHALL display specifications sorted by requirement count.

#### Scenario: Specs listing with counts

- **WHEN** specifications exist in the project
- **THEN** system shows specs sorted by requirement count (descending) with count labels

#### Scenario: Specs with parsing errors

- **WHEN** a spec file cannot be parsed
- **THEN** system includes it with 0 requirement count

### Requirement: Visual Formatting

The dashboard SHALL use consistent visual formatting with colors and symbols.

#### Scenario: Color coding

- **WHEN** dashboard elements are displayed
- **THEN** system uses cyan for specification items
- **AND** yellow for active changes
- **AND** green for completed items
- **AND** dim gray for supplementary text

#### Scenario: Progress bar rendering

- **WHEN** displaying progress bars
- **THEN** system uses filled blocks (â–ˆ) for completed portions and light blocks (â–‘) for remaining

### Requirement: Error Handling

The view command SHALL handle errors gracefully.

#### Scenario: File system errors

- **WHEN** file system operations fail
- **THEN** system continues with available data and omits inaccessible items

#### Scenario: Invalid data structures

- **WHEN** specs or changes have invalid format
- **THEN** system skips invalid items and continues rendering


================================================
FILE: openspec/changes/archive/2025-09-29-add-agents-md-config/proposal.md
================================================
# Add AGENTS.md Standard Support To Init/Update

## Summary
- Teach `openspec init` to manage a root-level `AGENTS.md` file using the same marker system as `CLAUDE.md`.
- Allow `openspec update` to refresh or scaffold that root `AGENTS.md` so AGENTS-compatible tools always receive current instructions.
- Keep the existing `openspec/AGENTS.md` template as the canonical source while ensuring assistants that read `AGENTS.md` opt-in instructions get the latest guidance automatically.

## Motivation
The README now points teams to AGENTS.md-compatible assistants, but the CLI only manages `CLAUDE.md`. Projects must hand-roll a root `AGENTS.md` file to benefit from the standard, and updates will drift unless maintainers remember to copy content manually. Extending `init` and `update` closes that gap so OpenSpec actually delivers on the promise of first-class AGENTS support.

## Proposal
1. Extend the `openspec init` selection flow with an "AGENTS.md standard" option that creates or refreshes a root `AGENTS.md` file wrapped in OpenSpec markers, mirroring the existing CLAUDE integration.
2. When generating the file, pull the managed content from the same template used in `openspec/AGENTS.md`, ensuring both locations stay in sync.
3. Update `openspec update` so it always refreshes the root `AGENTS.md` (creating it if missing) alongside `openspec/AGENTS.md` and any other configured assistants.
4. Document the new behavior in CLI specs and verify marker handling (no duplicates, preserve user content outside the block) with tests for both commands.

## Out of Scope
- Adding additional AGENTS-specific prompts or workflows beyond the shared instructions block.
- Non-interactive flags or bulk configuration for multiple standards in one run.
- Broader restructuring of how templates are stored or loaded.

## Risks & Mitigations
- **Risk:** Accidentally overwriting user-edited content surrounding the managed block.
  - **Mitigation:** Reuse the existing marker-update helper shared with `CLAUDE.md`, and add tests that cover files containing custom text before and after the block.
- **Risk:** Divergence between `openspec/AGENTS.md` and the root file.
  - **Mitigation:** Source the root file content from the canonical template rather than duplicating strings inline.
- **Risk:** Confusion about when the file is created.
  - **Mitigation:** Log creation vs update, and ensure help text references the AGENTS option during `init`.



================================================
FILE: openspec/changes/archive/2025-09-29-add-agents-md-config/tasks.md
================================================
# Implementation Tasks

## 1. Extend Init Workflow
- [x] 1.1 Add an "AGENTS.md standard" option to the `openspec init` tool-selection prompt, respecting the existing UI conventions.
- [x] 1.2 Generate or refresh a root-level `AGENTS.md` file using the OpenSpec markers when that option is selected, sourcing content from the canonical template.

## 2. Enhance Update Command
- [x] 2.1 Ensure `openspec update` writes the root `AGENTS.md` from the latest template (creating it if missing) alongside `openspec/AGENTS.md`.
- [x] 2.2 Update success messaging and logging to reflect creation vs refresh of the AGENTS standard file.

## 3. Shared Template Handling
- [x] 3.1 Refactor template utilities if necessary so both commands reuse the same content without duplication.
- [x] 3.2 Add automated tests covering init/update flows for projects with and without an existing `AGENTS.md`, ensuring markers behave correctly.

## 4. Documentation
- [x] 4.1 Update CLI specs and user-facing docs to describe AGENTS standard support.
- [x] 4.2 Run `openspec validate add-agents-md-config --strict` and document any notable behavior changes.



================================================
FILE: openspec/changes/archive/2025-09-29-add-agents-md-config/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration
The command SHALL configure AI coding assistants with OpenSpec instructions based on user selection.

#### Scenario: Prompting for AI tool selection

- **WHEN** run
- **THEN** prompt user to select AI tools to configure:
  - Claude Code (âœ… OpenSpec custom slash commands available)
  - Cursor (âœ… OpenSpec custom slash commands available)
  - AGENTS.md (works with Codex, Amp, Copilot, â€¦)

### Requirement: AI Tool Configuration Details
The command SHALL properly configure selected AI tools with OpenSpec-specific instructions using a marker system.

#### Scenario: Configuring Claude Code

- **WHEN** Claude Code is selected
- **THEN** create or update `CLAUDE.md` in the project root directory (not inside openspec/)

#### Scenario: Configuring AGENTS standard

- **WHEN** the AGENTS.md standard is selected
- **THEN** create or update `AGENTS.md` in the project root directory (not inside openspec/)

#### Scenario: Creating new CLAUDE.md

- **WHEN** CLAUDE.md does not exist
- **THEN** create new file with OpenSpec content wrapped in markers:
```markdown
<!-- OPENSPEC:START -->
# OpenSpec Project

This document provides instructions for AI coding assistants on how to use OpenSpec conventions for spec-driven development. Follow these rules precisely when working on OpenSpec-enabled projects.

This project uses OpenSpec for spec-driven development. Specifications are the source of truth.

See @openspec/AGENTS.md for detailed conventions and guidelines.
<!-- OPENSPEC:END -->
```

#### Scenario: Creating new AGENTS.md

- **WHEN** AGENTS.md does not exist in the project root
- **THEN** create new file with OpenSpec content wrapped in markers using the same template as CLAUDE.md

#### Scenario: Updating existing CLAUDE.md

- **WHEN** CLAUDE.md already exists
- **THEN** preserve all existing content
- **AND** insert OpenSpec content at the beginning of the file using markers
- **AND** ensure markers don't duplicate if they already exist

#### Scenario: Updating existing AGENTS.md

- **WHEN** AGENTS.md already exists in the project root
- **THEN** preserve all existing content
- **AND** ensure the OpenSpec-managed block at the beginning of the file is refreshed without duplicating markers

#### Scenario: Managing content with markers

- **WHEN** using the marker system
- **THEN** use `<!-- OPENSPEC:START -->` to mark the beginning of managed content
- **AND** use `<!-- OPENSPEC:END -->` to mark the end of managed content
- **AND** allow OpenSpec to update its content without affecting user customizations
- **AND** preserve all content outside the markers intact

WHY use markers:
- Users may have existing CLAUDE.md or AGENTS.md instructions they want to keep
- OpenSpec can update its instructions in future versions
- Clear boundary between OpenSpec-managed and user-managed content



================================================
FILE: openspec/changes/archive/2025-09-29-add-agents-md-config/specs/cli-update/spec.md
================================================
## MODIFIED Requirements
### Requirement: Update Behavior
The update command SHALL update OpenSpec instruction files to the latest templates in a team-friendly manner.

#### Scenario: Running update command

- **WHEN** a user runs `openspec update`
- **THEN** the command SHALL:
  - Check if the `openspec` directory exists
  - Replace `openspec/AGENTS.md` with the latest template (complete replacement)
  - Create or refresh a root-level `AGENTS.md` file using the managed marker block (create if missing)
  - Update **only existing** AI tool configuration files (e.g., CLAUDE.md)
    - Check each registered AI tool configurator
    - For each configurator, check if its file exists
    - Update only files that already exist using their markers
    - Preserve user content outside markers
  - Display success message listing updated files

### Requirement: Tool-Agnostic Updates
The update command SHALL handle file updates in a predictable and safe manner while respecting team tool choices.

#### Scenario: Updating files

- **WHEN** updating files
- **THEN** completely replace `openspec/AGENTS.md` with the latest template
- **AND** create or update the root-level `AGENTS.md` using the OpenSpec markers
- **AND** update only the OpenSpec-managed blocks in **existing** AI tool files using markers
- **AND** use the default directory name `openspec`
- **AND** be idempotent (repeated runs have no additional effect)
- **AND** respect team members' AI tool choices by not creating additional tool files beyond the root `AGENTS.md`

### Requirement: Core Files Always Updated
The update command SHALL always update the core OpenSpec files and display an ASCII-safe success message.

#### Scenario: Successful update

- **WHEN** the update completes successfully
- **THEN** replace `openspec/AGENTS.md` with the latest template
- **AND** ensure the root-level `AGENTS.md` matches the latest template via the marker block
- **AND** update existing AI tool configuration files within markers
- **AND** display the message: "Updated OpenSpec instructions"



================================================
FILE: openspec/changes/archive/2025-09-29-add-multi-agent-init/proposal.md
================================================
# Allow Additional AI Tool Initialization After Setup

## Summary
- Let `openspec init` configure new AI coding tools for projects that already contain an OpenSpec structure.
- Keep the initialization flow safe by skipping structure creation and only generating files for tools the user explicitly selects.
- Provide clear feedback so users know which tool files were added versus already present.

## Motivation
Today `openspec init` exits with an error once an `openspec/` directory exists. That protects the directory layout, but it blocks
teams that start with one assistant (for example, Claude Code) and later want to add another such as Cursor. They have to create
those files by hand or rerun `init` in a clean clone, which undermines the "easy onboarding" promise. Letting the command extend
an existing installation keeps the workflow consistent and avoids manual file management.

## Proposal
1. Detect an existing OpenSpec structure at the start of `openspec init` and branch into an "extend" mode instead of exiting.
   - Announce that the base structure already exists and that the command will only manage AI tool configuration files.
   - Keep the existing guard for directories or files we must not overwrite.
2. Present the usual AI tool selection prompt even in extend mode, showing which tools are already configured.
   - Skip disabled options that remain "coming soon".
   - Mark already configured tools as such so users know whether selecting them will refresh or add files.
3. When the user selects additional tools, generate the same initialization files that a fresh run would create (e.g., Cursor
   workspace files) while leaving untouched tools intact apart from marker-managed sections.
   - Do nothing when the user selects no new tools and keep the previous error messaging to avoid silently succeeding.
4. Summarize the outcome (created, refreshed, skipped) before exiting with code 0 when work was performed.
   - Include friendly guidance that future updates to shared content still come from `openspec update`.

## Out of Scope
- Changing how `openspec update` discovers or updates AI tool files.
- Supporting brand-new AI tools beyond those already wired into the CLI.
- Adding non-interactive flags for selecting multiple tools in one run (follow-up if needed).

## Risks & Mitigations
- **User confusion about extend mode** â†’ Explicitly log what will happen before prompting and summarise results afterward.
- **Accidental overwrites** â†’ Continue using marker-based updates and skip files unless the user chooses that tool.
- **Inconsistent state if init fails mid-run** â†’ Reuse existing rollback/transaction logic so partial writes clean up.



================================================
FILE: openspec/changes/archive/2025-09-29-add-multi-agent-init/tasks.md
================================================
# Implementation Tasks

## 1. Extend Init Guard
- [x] 1.1 Detect existing OpenSpec structures at the start of `openspec init` and enter an extend mode instead of failing.
- [x] 1.2 Log that core scaffolding will be skipped while still protecting against missing write permissions.

## 2. Update AI Tool Selection
- [x] 2.1 Present AI tool choices even in extend mode, indicating which tools are already configured.
- [x] 2.2 Ensure disabled "coming soon" tools remain non-selectable.

## 3. Generate Additional Tool Files
- [x] 3.1 Create configuration files for newly selected tools while leaving untouched tools unaffected apart from marker-managed sections.
- [x] 3.2 Summarize created, refreshed, and skipped tools before exiting with the appropriate code.

## 4. Verification
- [x] 4.1 Add tests covering rerunning `openspec init` to add another tool and the scenario where the user declines to add anything.



================================================
FILE: openspec/changes/archive/2025-09-29-add-multi-agent-init/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: Safety Checks
The command SHALL perform safety checks to prevent overwriting existing structures and ensure proper permissions.

#### Scenario: Detecting existing initialization
- **WHEN** the `openspec/` directory already exists
- **THEN** inform the user that OpenSpec is already initialized, skip recreating the base structure, and enter an extend mode
- **AND** continue to the AI tool selection step so additional tools can be configured
- **AND** display the existing-initialization error message only when the user declines to add any AI tools

### Requirement: Interactive Mode
The command SHALL provide an interactive menu for AI tool selection with clear navigation instructions.

#### Scenario: Displaying interactive menu
- **WHEN** run in fresh or extend mode
- **THEN** present a looping select menu that lets users toggle tools with Enter and finish via a "Done" option
- **AND** label already configured tools with "(already configured)" while keeping disabled options marked "coming soon"
- **AND** change the prompt copy in extend mode to "Which AI tools would you like to add or refresh?"
- **AND** display inline instructions clarifying that Enter toggles a tool and selecting "Done" confirms the list

## ADDED Requirements
### Requirement: Additional AI Tool Initialization
`openspec init` SHALL allow users to add configuration files for new AI coding assistants after the initial setup.

#### Scenario: Configuring an extra tool after initial setup
- **GIVEN** an `openspec/` directory already exists and at least one AI tool file is present
- **WHEN** the user runs `openspec init` and selects a different supported AI tool
- **THEN** generate that tool's configuration files with OpenSpec markers the same way as during first-time initialization
- **AND** leave existing tool configuration files unchanged except for managed sections that need refreshing
- **AND** exit with code 0 and display a success summary highlighting the newly added tool files

### Requirement: Success Output Enhancements
`openspec init` SHALL summarize tool actions when initialization or extend mode completes.

#### Scenario: Showing tool summary
- **WHEN** the command completes successfully
- **THEN** display a categorized summary of tools that were created, refreshed, or skipped (including already-configured skips)
- **AND** personalize the "Next steps" header using the names of the selected tools, defaulting to a generic label when none remain

### Requirement: Exit Code Adjustments
`openspec init` SHALL treat extend mode with no selected tools as a guarded error.

#### Scenario: Preventing empty extend runs
- **WHEN** OpenSpec is already initialized and the user selects no additional tools
- **THEN** exit with code 1 after showing the existing-initialization guidance message



================================================
FILE: openspec/changes/archive/2025-09-29-add-slash-command-support/proposal.md
================================================
# Add Slash Command Support for Coding Agents

## Summary
- Enable OpenSpec to generate and update custom slash commands for supported coding agents (Claude Code and Cursor).
- Provide three slash commands aligned with OpenSpec's workflow: proposal (start a change proposal), apply (implement), and archive.
- Share slash command templating between agents to make future extensions simple.

## Motivation
Developers use different coding agents and editors. Having consistent slash commands across tools for the OpenSpec workflow reduces friction and ensures a standard way to trigger the workflow. Supporting both Claude Code and Cursor now lays a foundation for future agents that introduce slash command features.

## Proposal
1. During `openspec init`, when a user selects a supported tool, generate slash command configuration for three OpenSpec workflow stages:
   - Claude (namespaced): `/openspec/proposal`, `/openspec/apply`, `/openspec/archive`.
   - Cursor (flat, prefixed): `/openspec-proposal`, `/openspec-apply`, `/openspec-archive`.
   - Semantics:
     - Create â€“ scaffold a change (ID, `proposal.md`, `tasks.md`, delta specs); validate strictly.
     - Apply â€“ implement an approved change; complete tasks; validate strictly.
     - Archive â€“ archive after deployment; update specs if needed.
   - Each command file MUST embed concise, step-by-step instructions sourced from `openspec/README.md` (see Template Content section).
2. Store slash command files per tool:
   - Claude Code: `.claude/commands/openspec/{proposal,apply,archive}.md`
   - Cursor: `.cursor/commands/{openspec-proposal,openspec-apply,openspec-archive}.md`
   - Ensure nested directories are created.
3. Command file format and metadata:
   - Use Markdown with optional YAML frontmatter for tool metadata (name/title, description, category/tags) when supported by the tool.
   - Place OpenSpec markers around the body only, never inside frontmatter.
   - Keep the visible slash name, file name, and any frontmatter `name`/`id` consistently aligned (e.g., `proposal`, `openspec-proposal`).
   - Namespacing: categorize these under â€œOpenSpecâ€ and prefer unique IDs (e.g., `openspec-proposal`) to avoid collisions.
4. Centralize templates: define command bodies once and reuse across tools; apply minimal per-tool wrappers (frontmatter, categories, filenames).
5. During `openspec update`, refresh only existing slash command files (per-file basis) within markers; do not create missing files or new tools.

## Design Ideas
- Introduce `SlashCommandConfigurator` to manage multiple files per tool.
  - Expose targets rather than a single `configFileName` (e.g., `getTargets(): Array<{ path: string; kind: 'slash'; id: string }>`).
  - Provide `generateAll(projectPath, openspecDir)` for init and `updateExisting(projectPath, openspecDir)` for update.
- Per-tool adapters add only frontmatter and pathing; bodies come from shared templates.
- Templates live in `TemplateManager` with helpers that extract concise, authoritative snippets from `openspec/README.md`.
- Update flow logs per-file results so users see exactly which slash files were refreshed.

### Marker Placement
- Markers MUST wrap only the Markdown body contents:
  - Frontmatter (if present) goes first.
  - Then `<!-- OPENSPEC:START -->` â€¦ body â€¦ `<!-- OPENSPEC:END -->`.
  - Avoid inserting markers into the YAML block to prevent parse errors.

### Idempotency and Creation Rules
- `init`: create all three files for the chosen tool(s) once; subsequent `init` runs are no-ops for existing files.
- `update`: refresh only files that exist; skip missing ones without creating new files.
- Directory creation for `.claude/commands/openspec/` and `.cursor/commands/` is the configuratorâ€™s responsibility.

### Command Naming & UX
- Claude Code: use namespacing in the slash itself for readability and grouping: `/openspec/proposal`, `/openspec/apply`, `/openspec/archive`.
- Cursor: use flat names with an `openspec-` prefix: `/openspec-proposal`, `/openspec-apply`, `/openspec-archive`. Group via `category: OpenSpec` when supported.
- Consistency: align file names, visible slash names, and any frontmatter `id` (e.g., `id: openspec-apply`).
- Migration: do not rename existing commands during `update`; apply new naming only on `init` (or via an explicit migrate step).

## Open Questions
- Validate exact metadata/frontmatter supported by each tool version; if unsupported, omit frontmatter and ship Markdown body only.
- Confirm the final Cursor command file location for the targeted versions; fall back to Markdown-only if Cursor does not parse frontmatter.
- Evaluate additional commands beyond the initial three (e.g., `/show-change`, `/validate-all`) based on user demand.

## Alternatives
- Hard-code slash command text per tool (rejected: duplicates content; increases maintenance).
- Delay Cursor support until its config stabilizes (partial accept): gate Cursor behind a feature flag until verified in real environments.

## Risks
- Tool configuration formats may change, requiring updates to wrappers/frontmatter.
- Incorrect paths or categories can hide commands; add path existence checks and clear logging.
- Marker misuse (inside frontmatter) can break parsing; enforce placement rules in tests.

## Future Work
- Support additional editors/agents that expose slash command APIs.
- Allow users to customize command names and categories during `openspec init`.
- Provide a dedicated command to regenerate slash commands without running full `update`.

## File Format Examples
The following examples illustrate expected structure. If a tool does not support frontmatter, omit the YAML block and keep only the markers + body.

### Claude Code: `.claude/commands/openspec/proposal.md`
```markdown
---
name: OpenSpec: Proposal
description: Scaffold a new OpenSpec change and validate strictly.
category: OpenSpec
tags: [openspec, change]
---
<!-- OPENSPEC:START -->
...command body from shared template...
<!-- OPENSPEC:END -->
```

Slash invocation: `/openspec/proposal` (namespaced)

### Cursor: `.cursor/commands/openspec-proposal.md`
```markdown
---
name: /openspec-proposal
id: openspec-proposal
category: OpenSpec
description: Scaffold a new OpenSpec change and validate strictly.
---
<!-- OPENSPEC:START -->
...command body from shared template...
<!-- OPENSPEC:END -->
```

Slash invocation: `/openspec-proposal` (flat, prefixed)

## Template Content
Templates should be brief, actionable, and sourced from `openspec/README.md` to avoid duplication. Each command body includes:
- Guardrails: ask 1â€“2 clarifying questions if needed; follow minimal-complexity rules; use `pnpm` for Node projects.
- Step list tailored to the workflow stage (proposal, apply, archive), including strict validation commands.
- Pointers to `openspec show`, `openspec list`, and troubleshooting tips when validation fails.

## Testing Strategy
- Golden snapshots for generated files per tool (frontmatter + markers + body).
- Partial presence tests: if 1â€“2 files exist, `update` only refreshes those and does not create missing ones.
- Marker placement tests: ensure markers never appear inside frontmatter; cover missing/duplicated marker recovery behavior.
- Logging tests: `update` reports per-file updates for slash commands.



================================================
FILE: openspec/changes/archive/2025-09-29-add-slash-command-support/tasks.md
================================================
# Implementation Tasks

## 1. Templates and Configurators
- [x] 1.1 Create shared templates for the Proposal, Apply, and Archive commands with instructions for each workflow stage from `openspec/README.md`.
- [x] 1.2 Implement a `SlashCommandConfigurator` base and tool-specific configurators for Claude Code and Cursor.

## 2. Claude Code Integration
- [x] 2.1 Generate `.claude/commands/openspec/{proposal,apply,archive}.md` during `openspec init` using shared templates.
- [x] 2.2 Update existing `.claude/commands/openspec/*` files during `openspec update`.

## 3. Cursor Integration
- [x] 3.1 Generate `.cursor/commands/{openspec-proposal,openspec-apply,openspec-archive}.md` during `openspec init` using shared templates.
- [x] 3.2 Update existing `.cursor/commands/*` files during `openspec update`.

## 4. Verification
- [x] 4.1 Add tests verifying slash command files are created and updated correctly.

## 5. OpenCode Integration
- [x] 5.1 Generate `.opencode/commands/{openspec-proposal,openspec-apply,openspec-archive}.md` during `openspec init` using shared templates.
- [x] 5.2 Update existing `.opencode/commands/*` files during `openspec update`.



================================================
FILE: openspec/changes/archive/2025-09-29-add-slash-command-support/specs/cli-init/spec.md
================================================
## ADDED Requirements
### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-09-29-add-slash-command-support/specs/cli-update/spec.md
================================================
## ADDED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones.

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-09-29-improve-cli-e2e-plan/proposal.md
================================================
## Why
Recent cross-shell regressions for `openspec` commands revealed that our existing unit/integration tests do not exercise the packaged CLI or shell-specific behavior. The prior attempt at Vitest spawn tests stalled because it coupled e2e coverage with `pnpm pack` installs, which fail in network-restricted environments. With those findings incorporated, we now need an approved plan to realign the work.

## What Changes
- Adopt a phased strategy that first stabilizes direct spawn testing of the built CLI (`node dist/cli/index.js`) using lightweight fixtures and a shared `runCLI` helper.
- Expand coverage once the spawn harness is stable, keeping the initial matrix focused on bash jobs for Linux/macOS and `pwsh` on Windows while exercising both the direct `node dist/cli/index.js` invocation and the bin shim with non-TTY defaults and captured diagnostics.
- Treat packaging/install validation as an optional CI safeguard: when a runner has registry access, run a simple pnpm-based packâ†’installâ†’smoke-test flow; otherwise document it as out of scope while closing remaining hardening items.
- Close out the remaining cross-shell hardening items: ensure `.gitattributes` covers packaged assets, enforce executable bits for CLI shims during CI, and finish the pending SIGINT handling improvements.

## Impact
- Tests: add `test/cli-e2e` spawn suite, create the shared `runCLI` helper, and adjust `vitest.setup.ts` as needed.
- Tooling: update GitHub Actions workflows with the lightweight matrix above and (optionally) a packaging install check where network is available.
- Docs: note phase progress and any limitations inline in this proposal (or the relevant spec) so future phases have clear context.

### Phase 1 Status
- Shared `test/helpers/run-cli.ts` guarantees the CLI bundle exists before spawning and enforces non-TTY defaults for every invocation.
- New `test/cli-e2e/basic.test.ts` covers `--help`, `--version`, a successful `validate --all --json`, and an unknown-item error path against the `tmp-init` fixture copy.
- Legacy top-level `validate` exec tests now rely on `runCLI`, avoiding manual `execSync` usage while keeping their fixture authoring intact.
- CI matrix groundwork is in place (bash on Linux/macOS, pwsh on Windows) so the spawn suite runs the same way the helper does across supported shells.



================================================
FILE: openspec/changes/archive/2025-09-29-improve-cli-e2e-plan/tasks.md
================================================
## 1. Phase 1 â€“ Stabilize Local Spawn Coverage
- [x] 1.1 Add `test/helpers/run-cli.ts` that ensures the build runs once and executes `node dist/cli/index.js` with non-TTY defaults; update `vitest.setup.ts` to reuse the shared build step.
- [x] 1.2 Seed `test/cli-e2e` using the minimal fixture set (`tmp-init` or copy) to cover help/version, a happy-path `validate`, and a representative error flow via the new helper.
- [x] 1.3 Migrate the highest-value existing CLI exec tests (e.g., validate) onto `runCLI` and summarize Phase 1 coverage in this proposal for the next phase.

## 2. Phase 2 â€“ Expand Cross-Shell Validation
- [x] 2.1 Exercise both entry points (`node dist/cli/index.js`, `bin/openspec.js`) in the spawn suite and add diagnostics for shell/OS context.
- [x] 2.2 Extend GitHub Actions to run the spawn suite on bash jobs for Linux/macOS and a `pwsh` job on Windows; capture shell/OS diagnostics and note follow-ups for additional shells.




================================================
FILE: openspec/changes/archive/2025-09-29-improve-deterministic-tests/proposal.md
================================================
# Change: Improve Deterministic Tests (Isolate From Repo State)

## Problem

Some unit tests (e.g., ChangeCommand.show/validate) read the live repository
state via `process.cwd()` and `openspec/changes`. This makes outcomes depend on
whatever directories happen to exist and the order returned by `fs.readdir`,
causing flaky success/failure across environments.

Symptoms observed:
- Tests sometimes select a partial or unrelated change folder.
- Failures like missing `proposal.md` when a stray change directory is picked.
- Environment/sandbox differences alter `readdir` ordering and worker behavior.

## Goals

- Make tests deterministic and hermetic.
- Remove dependence on real repo contents and directory ordering.
- Keep runtime behavior unchanged for end users.

## Nonâ€‘Goals

- Introduce heavy frameworks or test harness complexity.
- Redesign CLI behavior or change default paths for users.

## Approach

1) Test-local fixture root
- Each suite that touches filesystem discovery creates a temporary directory:
  - `openspec/changes/sample-change/proposal.md`
  - `openspec/changes/sample-change/specs/sample/spec.md`
- `beforeAll`: `process.chdir(tmpRoot)`; `afterAll`: restore original cwd.
- Use a constant `changeName = 'sample-change'`; remove reliance on
  `readdir` order.

2) Optional thin DI for commands (minimal, if needed)
- Allow `ChangeCommand` (and similar) to accept an optional `root` path
  (default `process.cwd()`), used for path resolution.
- Tests pass the temp root explicitly; production code remains unchanged.

3) Harden discovery helpers (safe enhancement)
- Update `getActiveChangeIds()`/`getActiveChanges()` to include only
  directories containing `proposal.md` (and optionally at least one
  `specs/*/spec.md`).
- Prevents incomplete/stray change folders from being treated as active.

## Rationale

- Small, focused changes eliminate flakiness without altering user workflows.
- Temporary fixtures are a well-understood testing pattern and keep tests fast.
- Optional constructor root param is a minimal DI surface that avoids global
  stubbing and keeps code simple.

## Risks & Mitigations

- Risk: Tests forget to restore `process.cwd()`.
  - Mitigation: Add `afterAll` guard restoring cwd; reset `process.exitCode` in
    `afterEach` where modified.
- Risk: Behavior divergence if DI root is misused.
  - Mitigation: Default to `process.cwd()`; only tests pass custom roots.

## Acceptance Criteria

- Tests that previously depended on repo state now:
  - Create and use a temp fixture root.
  - Do not read real `openspec/changes` during execution.
  - Pass consistently regardless of directory order or stray folders.
- No change to CLI behavior for end users (paths still default to cwd).

## Rollout

- Phase 1: Convert the suites that hit `ChangeCommand.show/validate` to
  isolated fixtures; verify stability locally and in CI.
- Phase 2: Apply the same pattern to any remaining suites that touch file
  discovery (`list`, `show`, `validate`, `diff`).
- Phase 3 (optional): Introduce the constructor `root` param and discovery
  hardening, if Phase 1 alone isnâ€™t sufficient.




================================================
FILE: openspec/changes/archive/2025-09-29-improve-deterministic-tests/tasks.md
================================================
# Implementation Tasks

## 1. Test Isolation
- [x] 1.1 Create temp fixture roots per suite (openspec/changes, openspec/specs)
- [x] 1.2 Use process.chdir to temp root within tests
- [x] 1.3 Restore original cwd and clean temp dirs after each

## 2. Deterministic Discovery
- [x] 2.1 Implement getActiveChangeIds(root?) to only include dirs with proposal.md
- [x] 2.2 Implement getSpecIds(root?) to only include dirs with spec.md
- [x] 2.3 Return sorted results to avoid fs.readdir ordering variance

## 3. Command Integration
- [x] 3.1 Ensure change/show/validate rely on cwd and discovery helpers
- [x] 3.2 Keep runtime behavior unchanged for end users

## 4. Validation
- [x] 4.1 Convert affected command tests (show, spec, validate, change) to isolated fixtures
- [x] 4.2 Verify tests pass consistently across environments
- [x] 4.3 Confirm no reads from real repo state during tests

## 5. Optional (Not Needed Now)
- [x] 5.1 Add optional root param to discovery helpers (default process.cwd())





================================================
FILE: openspec/changes/archive/2025-09-29-improve-init-onboarding/proposal.md
================================================
## Why
The current `openspec init` flow assumes a single assistant selection and stops once an OpenSpec structure already exists. That makes onboarding feel rigid: teams cannot configure multiple tools in one pass, they do not learn which files were refreshed, and the success copy always references Claude even when other assistants are involved.

## What Changes
- Allow selecting multiple assistants during `openspec init`, including refreshing existing configurations in a single run.
- Provide richer onboarding copy that summarizes which tool files were created or refreshed and guides users on next steps for each assistant.
- Align generated AI-instruction content and specs so CLAUDE.md and AGENTS.md share the same OpenSpec guidance.
- Update specs and tests to cover the multi-select prompt, improved summaries, and extend-mode coordination.

## Impact
- Specs: `cli-init`
- Code: `src/core/init.ts`, `src/core/config.ts`, `src/core/templates/*`, `src/core/configurators/*`
- Tests: `test/core/init.test.ts`, `test/core/update.test.ts`



================================================
FILE: openspec/changes/archive/2025-09-29-improve-init-onboarding/tasks.md
================================================
## 1. Planning & Spec Updates
- [x] 1.1 Confirm overlap with `add-multi-agent-init` and coordinate extend-mode flow
- [x] 1.2 Update `openspec/specs/cli-init/spec.md` to capture multi-select onboarding requirements

## 2. Implementation
- [x] 2.1 Add multi-select support to the `openspec init` prompt, including indicators for existing tool configs
- [x] 2.2 Enhance success messaging to summarize created/refreshed assets per tool
- [x] 2.3 Ensure shared instruction template is applied consistently (CLAUDE.md, AGENTS.md, slash commands)

## 3. Quality
- [x] 3.1 Expand unit tests for init/update flows covering multi-select and summaries
- [x] 3.2 Perform `openspec init` smoke test in a temp directory (document output)



================================================
FILE: openspec/changes/archive/2025-09-29-improve-init-onboarding/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration

The command SHALL configure AI coding assistants with OpenSpec instructions based on user selection.

#### Scenario: Prompting for AI tool selection

- **WHEN** run interactively
- **THEN** prompt the user with "Which AI tools do you use?" using a multi-select menu
- **AND** list every available tool with a checkbox:
  - Claude Code (creates or refreshes CLAUDE.md and slash commands)
  - Cursor (creates or refreshes `.cursor/commands/*` slash commands)
  - AGENTS.md standard (creates or refreshes AGENTS.md with OpenSpec markers)
- **AND** show "(already configured)" beside tools whose managed files exist so users understand selections will refresh content
- **AND** treat disabled tools as "coming soon" and keep them unselectable
- **AND** allow confirming with Enter after selecting one or more tools

### Requirement: AI Tool Configuration Details

The command SHALL properly configure selected AI tools with OpenSpec-specific instructions using a marker system.

#### Scenario: Configuring Claude Code

- **WHEN** Claude Code is selected
- **THEN** create or update `CLAUDE.md` in the project root directory (not inside openspec/)

#### Scenario: Creating new CLAUDE.md

- **WHEN** CLAUDE.md does not exist
- **THEN** create new file with OpenSpec content wrapped in markers:
```markdown
<!-- OPENSPEC:START -->
# OpenSpec Instructions

Instructions for AI coding assistants using OpenSpec for spec-driven development.

## TL;DR Quick Checklist
- Search existing work: `openspec spec list --long`, `openspec list`
- Decide scope: new capability vs modify existing capability
- Pick a unique `change-id`: verb-led kebab-case (`add-`, `update-`, `remove-`, `refactor-`)
- Scaffold: `proposal.md`, `tasks.md`, optional `design.md`, and spec deltas
- Validate with `openspec validate [change-id] --strict`
- Request approval before implementation
<!-- OPENSPEC:END -->
```

#### Scenario: Updating existing CLAUDE.md

- **WHEN** CLAUDE.md already exists
- **THEN** preserve all existing content
- **AND** insert OpenSpec content at the beginning of the file using markers
- **AND** ensure markers don't duplicate if they already exist

#### Scenario: Managing content with markers

- **WHEN** using the marker system
- **THEN** use `<!-- OPENSPEC:START -->` to mark the beginning of managed content
- **AND** use `<!-- OPENSPEC:END -->` to mark the end of managed content
- **AND** allow OpenSpec to update its content without affecting user customizations
- **AND** preserve all content outside the markers intact

### Requirement: Interactive Mode

The command SHALL provide an interactive menu for AI tool selection with clear navigation instructions.

#### Scenario: Displaying interactive menu

- **WHEN** run
- **THEN** prompt the user with: "Which AI tools do you use?"
- **AND** show a checkbox-based multi-select menu with available tools (Claude Code, Cursor, AGENTS.md standard)
- **AND** show disabled options as "coming soon" (not selectable)
- **AND** display inline help indicating Space toggles selections and Enter confirms

#### Scenario: Navigating the menu

- **WHEN** the user is in the menu
- **THEN** allow arrow keys to move between options
- **AND** allow Spacebar to toggle the highlighted option
- **AND** allow Enter key to confirm all current selections

### Requirement: Success Output

The command SHALL provide clear, actionable next steps upon successful initialization.

#### Scenario: Displaying success message

- **WHEN** initialization completes successfully
- **THEN** display a success banner followed by actionable prompts tailored to the selected tools
- **AND** summarize which assistant files were created versus refreshed (e.g., `CLAUDE.md (created)`, `.cursor/commands/openspec-apply.md (refreshed)`)
- **AND** include copy-pasteable onboarding prompts for each configured assistant, replacing placeholder text ([YOUR FEATURE HERE]) with real guidance to customize
- **AND** reference AGENTS.md-compatible assistants when no tool-specific file exists (e.g., when only AGENTS.md standard is selected)




================================================
FILE: openspec/changes/archive/2025-09-29-remove-diff-command/proposal.md
================================================
# Remove Diff Command

## Problem

The `openspec diff` command adds unnecessary complexity to the OpenSpec CLI for several reasons:

1. **Redundant functionality**: The `openspec show` command already provides comprehensive visualization of changes through structured JSON output and markdown rendering
2. **Maintenance burden**: The diff command requires a separate dependency (jest-diff) and additional code complexity (~227 lines)
3. **Limited value**: Developers can achieve better diff visualization using existing tools:
   - Git diff for actual file changes
   - The `show` command for structured change viewing
   - Standard diff utilities for comparing spec files directly
4. **Inconsistent with verb-noun pattern**: The command doesn't follow the preferred verb-first command structure that other commands are migrating to

## Solution

Remove the `openspec diff` command entirely and guide users to more appropriate alternatives:

1. **For viewing change content**: Use `openspec show <change-name>` which provides:
   - Structured JSON output with `--json` flag
   - Markdown rendering for human-readable format
   - Delta-only views with `--deltas-only` flag
   - Full spec content visualization

2. **For comparing files**: Use standard tools:
   - `git diff` for version control comparisons
   - System diff utilities for file-by-file comparisons
   - IDE diff viewers for visual comparisons

## Benefits

- **Reduced complexity**: Removes ~227 lines of code and the jest-diff dependency
- **Clearer user journey**: Directs users to the canonical `show` command for viewing changes
- **Lower maintenance**: Fewer commands to maintain and test
- **Better alignment**: Focuses on the core OpenSpec workflow without redundant features

## Implementation

### Files to Remove
- `/src/core/diff.ts` - The entire diff command implementation
- `/openspec/specs/cli-diff/spec.md` - The diff command specification

### Files to Update
- `/src/cli/index.ts` - Remove diff command registration (lines 8, 84-96)
- `/package.json` - Remove jest-diff dependency
- `/README.md` - Remove diff command documentation
- `/openspec/README.md` - Remove diff command references
- Various documentation files mentioning `openspec diff`

### Migration Guide for Users

Users currently using `openspec diff` should transition to:

```bash
# Before
openspec diff add-feature

# After - view the change proposal
openspec show add-feature

# After - view only the deltas
openspec show add-feature --json --deltas-only

# After - use git for file comparisons
git diff openspec/specs openspec/changes/add-feature/specs
```

## Risks

- **User disruption**: Existing users may have workflows depending on the diff command
  - Mitigation: Provide clear migration guide and deprecation period
  
- **Loss of visual diff**: The colored, unified diff format will no longer be available
  - Mitigation: Users can use git diff or other tools for visual comparisons

## Success Metrics

- Successful removal with no broken dependencies
- Documentation updated to reflect the change
- Tests passing without the diff command
- Reduced package size from removing jest-diff dependency


================================================
FILE: openspec/changes/archive/2025-09-29-remove-diff-command/tasks.md
================================================
# Remove Diff Command - Tasks

## 1. Remove Core Implementation
- [x] Delete `/src/core/diff.ts`
- [x] Remove DiffCommand import from `/src/cli/index.ts`
- [x] Remove diff command registration from CLI

## 2. Remove Specifications
- [x] Delete `/openspec/specs/cli-diff/spec.md`
- [x] Archive the spec for historical reference if needed

## 3. Update Dependencies
- [x] Remove jest-diff from package.json dependencies
- [x] Run pnpm install to update lock file

## 4. Update Documentation
- [x] Update main README.md to remove diff command references
- [x] Update openspec/README.md to remove diff command from command list
- [x] Update CLAUDE.md template if it mentions diff command
- [x] Update any example workflows that use diff command

## 5. Update Related Files
- [x] Search and update any remaining references to "openspec diff" in:
  - Template files
  - Test files (if any exist for diff command)
  - Archive documentation
  - Change proposals

## 7. Testing
- [x] Ensure all tests pass after removal
- [x] Verify CLI help text no longer shows diff command
- [x] Test that show command provides adequate replacement functionality

## 8. Documentation of Alternative Workflows
- [x] Document how to use `openspec show` for viewing changes
- [x] Document how to use git diff for file comparisons
- [x] Add migration guide to help text or documentation


================================================
FILE: openspec/changes/archive/2025-09-29-sort-active-changes-by-progress/proposal.md
================================================
# Change: Sort Active Changes by Progress

## Problem
- The dashboard currently lists active changes in filesystem discovery order.
- Users cannot quickly spot proposals that have not started or are nearly complete.
- Inconsistent ordering between runs makes it harder to track progress when many changes exist.

## Proposal
1. Update the Active Changes list in the dashboard to sort by percentage of completion in ascending order so 0% items show first.
2. When two changes share the same completion percentage, break ties deterministically by change identifier (alphabetical).

## Benefits
- Highlights work that has not started yet, enabling quicker prioritization.
- Provides consistent ordering across machines and repeated runs.
- Keeps the dashboard compact while communicating the most important status signal.

## Risks & Mitigations
- **Risk:** Sorting logic could regress rendering when progress data is missing.
  - **Mitigation:** Treat missing progress as 0% so items still surface and document behavior in tests.
- **Risk:** Additional sorting could impact performance for large change sets.
  - **Mitigation:** The number of active changes is typically small; sorting a few entries is negligible.

## Success Criteria
- Dashboard output shows active changes ordered by ascending completion percentage with deterministic tie-breaking.
- Unit coverage verifying the sort when percentages vary and when ties occur.



================================================
FILE: openspec/changes/archive/2025-09-29-sort-active-changes-by-progress/tasks.md
================================================
# Implementation Tasks

## 1. Dashboard Sorting Logic
- [x] 1.1 Update the Active Changes rendering to sort by completion percentage ascending.
- [x] 1.2 Treat missing progress as 0% and break ties alphabetically by change identifier.

## 2. Verification
- [x] 2.1 Add tests that cover different completion percentages and tie cases to confirm deterministic ordering.



================================================
FILE: openspec/changes/archive/2025-09-29-sort-active-changes-by-progress/specs/cli-view/spec.md
================================================
## MODIFIED Requirements
### Requirement: Active Changes Display
The dashboard SHALL show active changes with visual progress indicators.

#### Scenario: Active changes ordered by completion percentage
- **WHEN** multiple active changes are displayed with progress information
- **THEN** list them sorted by completion percentage ascending so 0% items appear first
- **AND** treat missing progress values as 0% for ordering
- **AND** break ties by change identifier in ascending alphabetical order to keep output deterministic



================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-file-name/proposal.md
================================================
# Update Agent Instruction File Name

## Problem
The agent instructions live in `openspec/README.md`, which clashes with conventional project README usage and creates confusion for tooling and contributors.

## Solution
Rename the agent instruction file to `openspec/AGENTS.md` and update OpenSpec tooling to use the new filename:
- `openspec init` generates `AGENTS.md` instead of `README.md`
- Templates and code reference `AGENTS.md`
- Specifications and documentation are updated accordingly

## Benefits
- Clear separation from project documentation
- Consistent naming with other agent instruction files
- Simplifies tooling and project onboarding

## Implementation
- Rename instruction file and template
- Update CLI commands (`init`, `update`) to read/write `AGENTS.md`
- Adjust specs and documentation to reference the new path

## Risks
- Existing projects may still rely on `README.md`
- Tooling may miss lingering references to the old filename

## Success Metrics
- `openspec init` creates `openspec/AGENTS.md`
- `openspec update` refreshes `AGENTS.md`
- All specs reference `openspec/AGENTS.md`



================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-file-name/tasks.md
================================================
# Update Agent Instruction File Name - Tasks

## 1. Rename Instruction File
- [x] Rename `openspec/README.md` to `openspec/AGENTS.md`
- [x] Update root references to new path

## 2. Update Templates
- [x] Rename `src/core/templates/readme-template.ts` to `agents-template.ts`
- [x] Update exported constant from `readmeTemplate` to `agentsTemplate`

## 3. Adjust CLI Commands
- [x] Modify `openspec init` to generate `AGENTS.md`
- [x] Update `openspec update` to refresh `AGENTS.md`
- [x] Ensure CLAUDE.md markers link to `@openspec/AGENTS.md`

## 4. Update Specifications
- [x] Modify `cli-init` spec to reference `AGENTS.md`
- [x] Modify `cli-update` spec to reference `AGENTS.md`
- [x] Modify `openspec-conventions` spec to include `AGENTS.md` in project structure

## 5. Validation
- [x] `pnpm test`



================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-file-name/specs/cli-init/spec.md
================================================
## MODIFIED Requirements

### Requirement: Directory Creation
The command SHALL create the complete OpenSpec directory structure with all required directories and files.

#### Scenario: Creating OpenSpec structure
- **WHEN** `openspec init` is executed
- **THEN** create the following directory structure:
```
openspec/
â”œâ”€â”€ project.md
â”œâ”€â”€ AGENTS.md
â”œâ”€â”€ specs/
â””â”€â”€ changes/
    â””â”€â”€ archive/
```

### Requirement: File Generation
The command SHALL generate required template files with appropriate content for immediate use.

#### Scenario: Generating template files
- **WHEN** initializing OpenSpec
- **THEN** generate `AGENTS.md` containing complete OpenSpec instructions for AI assistants
- **AND** generate `project.md` with project context template

### Requirement: AI Tool Configuration Details

The command SHALL properly configure selected AI tools with OpenSpec-specific instructions using a marker system.

#### Scenario: Creating new CLAUDE.md
- **WHEN** CLAUDE.md does not exist
- **THEN** create new file with OpenSpec content wrapped in markers including reference to `@openspec/AGENTS.md`

### Requirement: Success Output

The command SHALL provide clear, actionable next steps upon successful initialization.

#### Scenario: Displaying success message
- **WHEN** initialization completes successfully
- **THEN** include prompt: "Please explain the OpenSpec workflow from openspec/AGENTS.md and how I should work with you on this project"



================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-file-name/specs/cli-update/spec.md
================================================
## MODIFIED Requirements

### Requirement: Update Behavior
The update command SHALL update OpenSpec instruction files to the latest templates in a team-friendly manner.

#### Scenario: Running update command
- **WHEN** a user runs `openspec update`
- **THEN** replace `openspec/AGENTS.md` with the latest template

### Requirement: File Handling
The update command SHALL handle file updates in a predictable and safe manner.

#### Scenario: Updating files
- **WHEN** updating files
- **THEN** completely replace `openspec/AGENTS.md` with the latest template

### Requirement: Core Files Always Updated
The update command SHALL always update the core OpenSpec files and display an ASCII-safe success message.

#### Scenario: Successful update
- **WHEN** the update completes successfully
- **THEN** replace `openspec/AGENTS.md` with the latest template



================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-file-name/specs/openspec-conventions/spec.md
================================================
## MODIFIED Requirements

### Requirement: Project Structure
An OpenSpec project SHALL maintain a consistent directory structure for specifications and changes.

#### Scenario: Initializing project structure
- **WHEN** an OpenSpec project is initialized
- **THEN** it SHALL have this structure:
```
openspec/
â”œâ”€â”€ project.md              # Project-specific context
â”œâ”€â”€ AGENTS.md               # AI assistant instructions
â”œâ”€â”€ specs/                  # Current deployed capabilities
â”‚   â””â”€â”€ [capability]/       # Single, focused capability
â”‚       â”œâ”€â”€ spec.md         # WHAT and WHY
â”‚       â””â”€â”€ design.md       # HOW (optional, for established patterns)
â””â”€â”€ changes/                # Proposed changes
    â”œâ”€â”€ [change-name]/      # Descriptive change identifier
    â”‚   â”œâ”€â”€ proposal.md     # Why, what, and impact
    â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
    â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional)
    â”‚   â””â”€â”€ specs/          # Complete future state
    â”‚       â””â”€â”€ [capability]/
    â”‚           â””â”€â”€ spec.md # Clean markdown (no diff syntax)
    â””â”€â”€ archive/            # Completed changes
        â””â”€â”€ YYYY-MM-DD-[name]/
```



================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-instructions/design.md
================================================
# Design: Agent Instructions Update

## Approach

### Information Architecture
- **Front-load critical information** - Three-stage workflow comes first
- **Clear hierarchy** - Core Workflow â†’ Quick Start â†’ Commands â†’ Details â†’ Edge Cases
- **50% length reduction** - Target ~285 lines from current ~575 lines
- **Imperative mood** - "Create proposal" vs "You should create a proposal"
- **Bullet points over paragraphs** - Scannable, concise information

### Three-Stage Workflow Documentation
The workflow is now prominently featured as a core concept:
1. **Creating** - Proposal generation phase
2. **Implementing** - Code development phase with explicit steps:
   - Read proposal.md for understanding
   - Read design.md for technical context
   - Read tasks.md for checklist
   - Implement tasks sequentially
   - Mark complete immediately after each task
3. **Archiving** - Post-deployment finalization phase

This structure helps agents understand the lifecycle and their role at each stage. The implementation phase is particularly detailed to prevent common mistakes like skipping documentation or batching task completion.

### CLI Documentation Updates
- **Comprehensive command coverage** - All 9 primary commands documented
- **`openspec list` prominence** - Essential for discovering changes and specs
- **Interactive mode documentation** - How agents can use prompts effectively
- **Complete flag documentation** - All options like --json, --type, --skip-specs
- **Deprecation cleanup** - Remove noun-first patterns (openspec change show)

### Agent-Specific Enhancements
Based on industry best practices for coding agents (Claude Code, Cursor, etc.):

**Implementation Workflow**
- Explicit steps prevent skipping critical context
- Reading proposal/design first ensures understanding before coding
- Sequential task completion maintains focus
- Immediate marking prevents losing track of progress
- Addresses common failure mode: jumping straight to code

**Spec Discovery Workflow**
- Always check existing specs before creating new ones
- Use `openspec list --specs` to discover current capabilities
- Prefer modifying existing specs over creating duplicates
- Prevents fragmentation and maintains coherent architecture

**Decision Clarity**
- Clear decision trees eliminating ambiguous conditions
- Concrete examples for each decision branch
- Simplified bug vs feature determination

**Tool Usage Guidance**
- Tool selection matrix (when to use Grep vs Glob vs Read)
- Error recovery patterns for common failures
- Verification workflows to confirm correctness

**Context Management**
- "Before Any Task" checklist for gathering context
- What to read before starting any work
- How to maintain state across interactions

**Spec File Structure Documentation**
- Complete examples with ADDED/MODIFIED/REMOVED sections
- Critical scenario formatting (#### Scenario: headers)
- Delta file location clarity (changes/{name}/specs/)
- Addresses most common creation errors from retrospective

**Troubleshooting and Debugging**
- Common error messages with solutions
- Delta detection debugging steps
- Validation best practices
- JSON output for inspection
- Prevents hours of frustration from silent failures

**Best Practices**
- Be concise (one-line answers when appropriate)
- Be specific (file.ts:42 line references)
- Start simple (<100 lines, single-file defaults)
- Justify complexity (require metrics/data)

## Design Rationale

### Why These Changes Matter

**Cognitive Load Reduction**
- Agents process instructions better with clear structure
- Front-loading critical info reduces scanning time
- Decision trees eliminate analysis paralysis

**Industry Alignment**
- Follows patterns proven effective in Claude Code, Cursor, GitHub Copilot
- Addresses common failure modes (ambiguous decisions, missing context)
- Optimizes for LLM strengths (pattern matching) vs weaknesses (calculations)

**Addressing Critical Pain Points (from Retrospective)**
- **Scenario formatting** - Biggest struggle, now explicitly documented with examples
- **Complete spec structure** - Full examples prevent structural errors
- **Delta detection issues** - Debugging commands help diagnose problems
- **Silent parsing failures** - Troubleshooting section explains common issues

**Practical Impact**
- Faster agent comprehension of tasks
- Fewer misinterpretations of requirements
- More consistent implementation quality
- Better error recovery when things go wrong
- Prevents the most common errors identified in user experience

## Trade-offs

### What We're Removing
- Lengthy explanations of concepts that can be inferred
- Redundant examples that don't add clarity
- Verbose edge case documentation (moved to reference section)
- Deprecated command documentation

### What We're Keeping
- All critical workflow steps
- Complete CLI command reference
- Complexity management principles
- Directory structure visualization
- Quick reference summary

## Implementation Notes

The CLAUDE.md template is intentionally more concise than README.md since:
- It appears in every project root
- Agents can reference the full README.md for details
- It needs to load quickly in AI context windows
- Focus is on immediate actionable guidance


================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-instructions/proposal.md
================================================
# Update OpenSpec Agent Instructions

## Why

The current OpenSpec agent instructions need updates to follow best practices for AI assistant instructions (brevity, clarity, removing ambiguity), ensure CLI commands are current with the actual implementation, and properly document the three-stage workflow pattern that agents should follow.

## What Changes

### Core Structure Improvements
- **Front-load the 3-stage workflow** as the primary mental model:
  1. Creating a change proposal (proposal.md, spec deltas, design.md, tasks.md)
  2. Implementing a change proposal:
     - First read proposal.md to understand the change
     - Read design.md if it exists for technical context
     - Read tasks.md for the implementation checklist
     - Complete tasks one by one
     - Mark each task complete immediately after finishing
  3. Archiving the change proposal (using archive command after deployment)
- **Reduce instruction length by 50%** while maintaining all critical information
- **Restructure with clear hierarchy**: Core Workflow â†’ Quick Start â†’ Commands â†’ Details â†’ Edge Cases

### Decision Clarity Enhancements
- **Add clear decision trees** for common scenarios (bug vs feature, proposal needed vs not)
- **Remove ambiguous conditions** that confuse agent decision-making
- **Add "Before Any Task" checklist** for context gathering
- **Add "Before Creating Specs" rule** - Always check existing specs first to avoid duplicates

### CLI Documentation Updates
- **Complete command documentation** with all current functionality:
  - `openspec init [path]` - Initialize OpenSpec in a project
  - `openspec list` - List all active changes (default)
  - `openspec list --specs` - List all specifications
  - `openspec show [item]` - Display change or spec with auto-detection
  - `openspec show` - Interactive mode for selection
  - `openspec diff [change]` - Show spec differences for a change
  - `openspec validate [item]` - Validate changes or specs
  - `openspec archive [change]` - Archive completed change after deployment
  - `openspec update [path]` - Update OpenSpec instruction files
- **Document all flags and options**:
  - `--json` output format for programmatic use
  - `--type change|spec` for disambiguation
  - `--skip-specs` for tooling-only archives
  - `--strict` for strict validation mode
  - `--no-interactive` to disable prompts
- **Remove deprecated command references** (noun-first patterns like `openspec change show`)
- **Add concrete examples** for each command variation
- **Document debugging commands**:
  - `openspec show [change] --json --deltas-only` for inspecting deltas
  - `openspec validate [change] --strict` for comprehensive validation

### Spec File Structure Documentation
- **Complete spec file examples** showing proper structure:
  ```markdown
  ## ADDED Requirements
  ### Requirement: Clear requirement statement
  The system SHALL provide the functionality...
  
  #### Scenario: Descriptive scenario name
  - **WHEN** condition occurs
  - **THEN** expected outcome
  - **AND** additional outcomes
  ```
- **Scenario formatting requirements** (critical - most common error):
  - MUST use `#### Scenario:` headers (4 hashtags)
  - NOT bullet lists or bold text
  - Each requirement MUST have at least one scenario
- **Delta file location** - Clear explanation:
  - Spec files go in `changes/{name}/specs/` directory
  - Deltas are automatically extracted from these files
  - Use operation prefixes: ADDED, MODIFIED, REMOVED, RENAMED

### Troubleshooting Section
- **Common errors and solutions**:
  - "Change must have at least one delta" â†’ Check specs/ directory exists with .md files
  - "Requirement must have at least one scenario" â†’ Check scenario uses `#### Scenario:` format
  - Silent scenario parsing failures â†’ Verify exact header format
- **Delta detection debugging**:
  - Use `openspec show [change] --json --deltas-only` to inspect parsed deltas
  - Check that spec files have operation prefixes (## ADDED Requirements)
  - Verify specs/ subdirectory structure
- **Validation best practices**:
  - Always use `--strict` flag for comprehensive checks
  - Use JSON output for debugging: `--json | jq '.deltas'`

### Agent-Specific Improvements
- **Implementation workflow** - Clear step-by-step process:
  1. Read proposal.md to understand what's being built
  2. Read design.md (if exists) for technical decisions
  3. Read tasks.md for the implementation checklist
  4. Implement tasks one by one in order
  5. Mark each task complete immediately: `- [x] Task completed`
  6. Never skip ahead or batch task completion
- **Spec discovery workflow** - Always check existing specs before creating new ones:
  - Use `openspec list --specs` to see all current specs
  - Check if capability already exists before creating
  - Prefer modifying existing specs over creating duplicates
- **Tool selection matrix** - When to use Grep vs Glob vs Read
- **Error recovery patterns** - How to handle common failures
- **Context management guide** - What to read before starting tasks
- **Verification workflows** - How to confirm changes are correct

### Best Practices Section
- **Be concise** - One-line answers when appropriate
- **Be specific** - Use exact file paths and line numbers (file.ts:42)
- **Start simple** - Default to <100 lines, single-file implementations
- **Justify complexity** - Require data/metrics for any optimization

## Impact

- Affected specs: None (this is a tooling/documentation change)
- Affected code: 
  - `src/core/templates/claude-template.ts` - Update CLAUDE.md template
- Affected documentation:
  - `openspec/README.md` - Main OpenSpec instructions
  - CLAUDE.md files generated by `openspec init` command

Note: This is a tooling/infrastructure change that doesn't require spec updates. When archiving, use `openspec archive update-agent-instructions --skip-specs`.


================================================
FILE: openspec/changes/archive/2025-09-29-update-agent-instructions/tasks.md
================================================
# Implementation Tasks

## 1. Restructure OpenSpec README.md
- [x] 1.1 Front-load the three-stage workflow as primary content
- [x] 1.2 Restructure with hierarchy: Core Workflow â†’ Quick Start â†’ Commands â†’ Details â†’ Edge Cases
- [x] 1.3 Reduce total length by 50% (target: ~285 lines from current ~575)
- [x] 1.4 Add "Before Any Task" context-gathering checklist
- [x] 1.5 Add "Before Creating Specs" rule to check existing specs first

## 2. Add Decision Clarity  
- [x] 2.1 Create clear decision trees for "Create Proposal?" scenarios
- [x] 2.2 Remove ambiguous conditions that confuse agents
- [x] 2.3 Add concrete examples for each decision branch
- [x] 2.4 Simplify bug vs feature determination logic
- [x] 2.5 Add explicit Stage 2 implementation steps (read â†’ implement â†’ mark complete)

## 3. Update CLI Documentation
- [x] 3.1 Document `openspec list` and `openspec list --specs` commands
- [x] 3.2 Document `openspec show` with all flags and interactive mode
- [x] 3.3 Document `openspec diff [change]` for viewing spec differences
- [x] 3.4 Document `openspec archive` with --skip-specs option
- [x] 3.5 Document `openspec validate` with --strict and batch modes
- [x] 3.6 Document `openspec init` and `openspec update` commands
- [x] 3.7 Remove all deprecated noun-first command references
- [x] 3.8 Add concrete usage examples for each command variation
- [x] 3.9 Document all flags: --json, --type, --no-interactive, etc.
- [x] 3.10 Document debugging commands: `show --json --deltas-only`

## 4. Add Spec File Documentation
- [x] 4.1 Add complete spec file structure example with ADDED/MODIFIED sections
- [x] 4.2 Document scenario formatting requirements (#### Scenario: headers)
- [x] 4.3 Explain delta file location (changes/{name}/specs/ directory)
- [x] 4.4 Show how deltas are automatically extracted
- [x] 4.5 Include warning about most common error (scenario formatting)

## 5. Add Troubleshooting Section
- [x] 5.1 Document common errors and their solutions
- [x] 5.2 Add delta detection debugging steps
- [x] 5.3 Include validation best practices (--strict flag)
- [x] 5.4 Show how to use JSON output for debugging
- [x] 5.5 Add examples of silent parsing failures

## 6. Add Agent-Specific Sections
- [x] 6.1 Add implementation workflow (read docs â†’ implement tasks â†’ mark complete)
- [x] 6.2 Add spec discovery workflow (check existing before creating)
- [x] 6.3 Create tool selection matrix (Grep vs Glob vs Read)
- [x] 6.4 Add error recovery patterns section
- [x] 6.5 Add context management guide
- [x] 6.6 Add verification workflows section
- [x] 6.7 Add best practices section (concise, specific, simple)

## 7. Update CLAUDE.md Template
- [x] 7.1 Update `src/core/templates/claude-template.ts` with streamlined content
- [x] 7.2 Include three-stage workflow prominently
- [x] 7.3 Add comprehensive CLI quick reference (list, show, diff, archive, etc.)
- [x] 7.4 Add "Before Any Task" checklist
- [x] 7.5 Add "Before Creating Specs" rule
- [x] 7.6 Keep complexity management principles
- [x] 7.7 Add critical scenario formatting note (#### Scenario: headers)
- [x] 7.8 Include debugging command reference

## 8. Testing and Validation
- [x] 8.1 Test all documented CLI commands for accuracy
- [x] 8.2 Run `openspec init` to verify CLAUDE.md generation
- [x] 8.3 Validate instruction clarity with example scenarios
- [x] 8.4 Ensure no critical information was lost in streamlining
- [x] 8.5 Verify decision trees eliminate ambiguity
- [x] 8.6 Test scenario formatting examples work correctly
- [x] 8.7 Verify troubleshooting steps resolve common errors


================================================
FILE: openspec/changes/archive/2025-09-29-update-markdown-parser-crlf/proposal.md
================================================
# Update Markdown Parser CRLF Handling

## Problem
Windows users report that `openspec validate` raises â€œChange must have a Why sectionâ€ even when the section exists (see GitHub issue #77). The CLI currently splits markdown on `\n` and compares headers without stripping `\r`, so files saved with CRLF line endings keep a trailing carriage return in the header token. As a result the parser fails to detect `## Why`/`## What Changes`, triggering false validation errors and breaking the workflow on Windows-default editors.

## Solution
- Normalize markdown content inside the parser so CRLF and lone-CR inputs are treated as `\n` before section detection, trimming any carriage returns from titles and content comparisons.
- Reuse the normalized reader everywhere `MarkdownParser` is constructed to keep behavior consistent for validation, view, spec, and list flows.
- Add regression coverage that reproduces the failure (unit test around `parseChange` and a CLI spawn/e2e test that writes a CRLF change then runs `openspec validate`).
- Update the `cli-validate` spec to codify the expectation that required sections are recognized regardless of line-ending style.

## Benefits
- Restores correct validation behavior for Windows editors without requiring manual line-ending conversion.
- Locks in the fix with targeted tests so future parser refactors keep cross-platform support.
- Clarifies the spec so downstream work (e.g., cross-shell e2e plan) understands the non-negotiable behavior.

## Risks
- Low: parser normalization touches shared code paths that parse specs and changes; need to ensure no regressions in other command consumers (mitigated by existing parser tests plus the new CRLF fixtures).




================================================
FILE: openspec/changes/archive/2025-09-29-update-markdown-parser-crlf/tasks.md
================================================
## 1. Guard the regression
- [x] 1.1 Add a unit test that feeds a CRLF change document into `MarkdownParser.parseChange` and asserts `Why`/`What Changes` are detected.
- [x] 1.2 Add a CLI spawn/e2e test that writes a CRLF change, runs `openspec validate`, and expects success.

## 2. Normalize parsing
- [x] 2.1 Normalize line endings when constructing `MarkdownParser` so headers and content comparisons ignore `\r`.
- [x] 2.2 Ensure all CLI entry points (validate, view, spec conversion) reuse the normalized parser path.

## 3. Document and verify
- [x] 3.1 Update the `cli-validate` spec with a scenario covering CRLF line endings.
- [x] 3.2 Run the parser and CLI test suites (`pnpm test`, relevant spawn tests) to confirm the fix.



================================================
FILE: openspec/changes/archive/2025-09-29-update-markdown-parser-crlf/specs/cli-validate/spec.md
================================================
## ADDED Requirements
### Requirement: Parser SHALL handle cross-platform line endings
The markdown parser SHALL correctly identify sections regardless of line ending format (LF, CRLF, CR).

#### Scenario: Required sections parsed with CRLF line endings
- **GIVEN** a change proposal markdown saved with CRLF line endings
- **AND** the document contains `## Why` and `## What Changes`
- **WHEN** running `openspec validate <change-id>`
- **THEN** validation SHALL recognize the sections and NOT raise parsing errors



================================================
FILE: openspec/changes/archive/2025-10-14-add-codex-slash-command-support/proposal.md
================================================
## Why
- Codex (the VS Code extension formerly known as Codeium Chat) exposes "slash commands" by reading Markdown prompt files from `~/.codex/prompts/`. Each file name becomes the `/command` users can run, with YAML frontmatter for metadata (`description`, `argument-hint`) and `$ARGUMENTS` to capture user input. The workflow screenshot shared by Kevin Kern ("Codex problem analyzer") shows the format OpenSpec should target so teams can invoke curated workflows straight from the chat palette.
- Teams already rely on OpenSpec to manage the slash-command surface area for Claude, Cursor, OpenCode, Kilo Code, and Windsurf. Leaving Codex out forces them to manually copy/paste OpenSpec guardrails into `~/.codex/prompts/*.md`, which drifts quickly and undermines the "single source of truth" promise of the CLI.
- Codex commands live outside the repository (under the user's home directory), so shipping an automated configurator that both scaffolds the prompts and keeps them refreshed via `openspec update` eliminates error-prone manual steps and keeps OpenSpec instructions synchronized across assistants.

## What Changes
- Add Codex to the `openspec init` tool picker with the same "already configured" detection we use for other editors, wiring an implementation that writes managed Markdown prompts directly to Codex's global directory (`~/.codex/prompts` or `$CODEX_HOME/prompts`) with OpenSpec marker blocks.
- Produce three Codex prompt filesâ€”`openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`â€”whose content mirrors the shared slash-command templates while using YAML frontmatter (`description` and `argument-hint` fields) and `$ARGUMENTS` to capture all arguments as a single string (matching the GitHub Copilot pattern and official Codex specification).
- Document Codex's global-only discovery and that OpenSpec writes prompts directly to `~/.codex/prompts` (or `$CODEX_HOME/prompts`).
- Teach `openspec update` to refresh existing Codex prompts in-place (and only when they already exist) in the global directory, updating both frontmatter and body.
- Document Codex support alongside other slash-command integrations and add regression coverage that exercises init/update behaviour against a temporary global prompts directory via `CODEX_HOME`.

## Impact
- Specs: `cli-init`, `cli-update`
- Code: `src/core/config.ts`, `src/core/configurators/slash/*`, `src/core/templates/slash-command-templates.ts`, CLI tool summaries, docs
- Tests: integration coverage for Codex prompt scaffolding and refresh logic
- Docs: README and CHANGELOG entries announcing Codex slash-command support

## Current Spec Reference
- `specs/cli-init/spec.md`
  - Requirements cover init UX, directory scaffolding, AI tool configuration, and the existing slash-command support for Claude Code, Cursor, and OpenCode.
  - Our `## MODIFIED` delta in `changes/.../specs/cli-init/spec.md` copies the full "Slash Command Configuration" requirement (header, description, and all scenarios) before appending the new Codex scenario so archiving will retain every prior scenario.
- `specs/cli-update/spec.md`
  - Requirements define update preconditions, template refresh behavior, and slash-command refresh logic for Claude Code, Cursor, and OpenCode.
  - The corresponding delta preserves the entire "Slash Command Updates" requirement while adding the Codex refresh scenario, ensuring the archive workflow replaces the block without losing the existing scenarios or the "Missing slash command file" guardrail.



================================================
FILE: openspec/changes/archive/2025-10-14-add-codex-slash-command-support/tasks.md
================================================
## 1. CLI integration
- [x] 1.1 Add Codex to the init tool picker with display text that clarifies prompts live in the global `.codex/prompts/` directory and implement "already configured" detection by checking for managed Codex prompt files.
- [x] 1.2 Implement a `CodexSlashCommandConfigurator` that writes `.codex/prompts/openspec-{proposal,apply,archive}.md`, ensuring the prompt directory exists and wrapping content in OpenSpec markers.
// (No helper command required)
- [x] 1.3 Register the configurator with the slash-command registry and include Codex in init/update wiring so both commands invoke the new configurator when appropriate.

## 2. Prompt templates
- [x] 2.1 Extend the shared slash-command templates (or add a Codex-specific wrapper) to inject numbered placeholders (`$1`, `$2`, â€¦) where Codex expects user-supplied arguments.
- [x] 2.2 Verify generated Markdown stays within Codex's formatting expectations (no front matter, heading-first layout) and matches the problem-analyzer style shown in the reference screenshot.

## 3. Update support & tests
- [x] 3.1 Update the `openspec update` flow to refresh existing Codex prompts without creating new ones when files are missing.
- [x] 3.2 Add integration coverage that exercises init/update against a temporary global Codex prompts directory by setting `CODEX_HOME`, asserting marker preservation and idempotent updates.
- [x] 3.3 Document Codex's global-only discovery and automatic installation in README and CHANGELOG.
- [x] 3.3 Confirm error handling surfaces clear paths when the CLI cannot write to the Codex prompt directory (permissions, missing home directory, etc.).

## 4. Documentation
- [x] 4.1 Document Codex slash-command support in the README and changelog alongside other assistant integrations.
- [x] 4.2 Add a release note snippet that points Codex users to the generated `/openspec-proposal`, `/openspec-apply`, and `/openspec-archive` commands.



================================================
FILE: openspec/changes/archive/2025-10-14-add-codex-slash-command-support/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration
The command SHALL configure AI coding assistants with OpenSpec instructions using a marker system.
#### Scenario: Prompting for AI tool selection
- **WHEN** run interactively
- **THEN** prompt the user with "Which AI tools do you use?" using a multi-select menu
- **AND** list every available tool with a checkbox:
  - Claude Code (creates or refreshes CLAUDE.md and slash commands)
  - Cursor (creates or refreshes `.cursor/commands/*` slash commands)
  - OpenCode (creates or refreshes `.opencode/command/openspec-*.md` slash commands)
  - Windsurf (creates or refreshes `.windsurf/workflows/openspec-*.md` workflows)
  - Kilo Code (creates or refreshes `.kilocode/workflows/openspec-*.md` workflows)
  - Codex (creates or refreshes global prompts at `~/.codex/prompts/openspec-*.md`)
  - AGENTS.md standard (creates or refreshes AGENTS.md with OpenSpec markers)
- **AND** show "(already configured)" beside tools whose managed files exist so users understand selections will refresh content
- **AND** treat disabled tools as "coming soon" and keep them unselectable
- **AND** allow confirming with Enter after selecting one or more tools

### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/command/openspec-proposal.md`, `.opencode/command/openspec-apply.md`, and `.opencode/command/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes



================================================
FILE: openspec/changes/archive/2025-10-14-add-codex-slash-command-support/specs/cli-update/spec.md
================================================
## MODIFIED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones.

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Codex
- **GIVEN** the global Codex prompt directory contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **WHEN** a user runs `openspec update`
- **THEN** refresh each file using the shared slash-command templates (including placeholder guidance)
- **AND** preserve any unmanaged content outside the OpenSpec marker block
- **AND** skip creation when a Codex prompt file is missing

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-10-14-add-github-copilot-prompts/proposal.md
================================================
## Why
- GitHub Copilot supports custom slash commands through markdown files in `.github/prompts/<name>.prompt.md`. Each file includes YAML frontmatter with a `description` label and uses `$ARGUMENTS` to capture user input. This format allows teams to expose curated workflows directly in Copilot's chat interface.
- Teams already rely on OpenSpec to manage slash-command configurations for Claude Code, Cursor, OpenCode, Codex, Kilo Code, and Windsurf. Excluding GitHub Copilot forces developers to manually maintain OpenSpec prompts in `.github/prompts/`, which leads to drift and undermines OpenSpec's "single source of truth" promise.
- GitHub Copilot discovers prompts from the repository's `.github/prompts/` directory, making it straightforward to version control and share across the team. Adding automated generation and refresh through `openspec init` and `openspec update` eliminates manual synchronization and keeps OpenSpec instructions consistent across all AI assistants.

## What Changes
- Add GitHub Copilot to the `openspec init` tool picker with "already configured" detection similar to other editors, wiring an implementation that writes managed Markdown prompt files to `.github/prompts/` with OpenSpec marker blocks.
- Generate three GitHub Copilot prompt filesâ€”`openspec-proposal.prompt.md`, `openspec-apply.prompt.md`, and `openspec-archive.prompt.md`â€”whose content mirrors shared slash-command templates while conforming to Copilot's frontmatter and `$ARGUMENTS` placeholder convention.
- Document GitHub Copilot's repository-based discovery and that OpenSpec writes prompts to `.github/prompts/` with managed blocks.
- Teach `openspec update` to refresh existing GitHub Copilot prompts in-place (only when they already exist) in the repository's `.github/prompts/` directory.
- Document GitHub Copilot support alongside other slash-command integrations and add test coverage that exercises init/update behavior for `.github/prompts/` files.

## Impact
- Specs: `cli-init`, `cli-update`
- Code: `src/core/configurators/slash/github-copilot.ts` (new), `src/core/configurators/slash/registry.ts`, `src/core/templates/slash-command-templates.ts`, CLI tool summaries, docs
- Tests: integration coverage for GitHub Copilot prompt scaffolding and refresh logic
- Docs: README and CHANGELOG entries announcing GitHub Copilot slash-command support

## Current Spec Reference
- `specs/cli-init/spec.md`
  - Requirements cover init UX, directory scaffolding, AI tool configuration, and existing slash-command support for Claude Code, Cursor, OpenCode, Codex, Kilo Code, and Windsurf.
  - Our `## MODIFIED` delta in `changes/.../specs/cli-init/spec.md` will copy the full "Slash Command Configuration" requirement (header, description, and all scenarios) before appending the new GitHub Copilot scenario so archiving retains every prior scenario.
- `specs/cli-update/spec.md`
  - Requirements define update preconditions, template refresh behavior, and slash-command refresh logic for existing tools.
  - The corresponding delta preserves the entire "Slash Command Updates" requirement while adding the GitHub Copilot refresh scenario, ensuring the archive workflow replaces the block without losing existing scenarios or the "Missing slash command file" guardrail.



================================================
FILE: openspec/changes/archive/2025-10-14-add-github-copilot-prompts/tasks.md
================================================
## Implementation Tasks

- [x] Create `src/core/configurators/slash/github-copilot.ts` implementing `SlashCommandConfigurator` base class
  - Implement `getRelativePath()` to return `.github/prompts/openspec-{proposal,apply,archive}.prompt.md`
  - Implement `getFrontmatter()` to generate YAML frontmatter with `description` field and include `$ARGUMENTS` placeholder
  - Implement `generateAll()` to create `.github/prompts/` directory and write three prompt files with frontmatter, markers, and shared template bodies
  - Implement `updateExisting()` to refresh only the managed block between markers while preserving frontmatter
  - Set `toolId = "github-copilot"` and `isAvailable = true`

- [x] Register GitHub Copilot configurator in `src/core/configurators/slash/registry.ts`
  - Import `GitHubCopilotSlashCommandConfigurator`
  - Add to `SLASH_COMMAND_CONFIGURATORS` array
  - Update tool picker display name to "GitHub Copilot"

- [x] Update `src/core/init.ts` to include GitHub Copilot in the AI tool selection prompt
  - Add GitHub Copilot to the available tools list with detection for existing `.github/prompts/openspec-*.prompt.md` files
  - Display "(already configured)" when prompt files exist

- [x] Update `src/core/update.ts` to refresh GitHub Copilot prompts when they exist
  - Call `updateExisting()` for GitHub Copilot configurator when `.github/prompts/` contains OpenSpec prompt files

- [x] Add integration tests for GitHub Copilot slash command generation
  - Test `generateAll()` creates three prompt files with correct structure (frontmatter + markers + body)
  - Test `updateExisting()` preserves frontmatter and only updates managed blocks
  - Test that missing prompt files are not created during update

- [x] Update documentation
  - Add GitHub Copilot to README slash-command support table
  - Document `.github/prompts/` as the discovery location
  - Add CHANGELOG entry for GitHub Copilot support



================================================
FILE: openspec/changes/archive/2025-10-14-add-github-copilot-prompts/specs/cli-init/spec.md
================================================
## MODIFIED Requirements

### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-10-14-add-github-copilot-prompts/specs/cli-update/spec.md
================================================
## MODIFIED Requirements

### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones.

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Codex
- **GIVEN** the global Codex prompt directory contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **WHEN** a user runs `openspec update`
- **THEN** refresh each file using the shared slash-command templates (including placeholder guidance)
- **AND** preserve any unmanaged content outside the OpenSpec marker block
- **AND** skip creation when a Codex prompt file is missing

#### Scenario: Updating slash commands for GitHub Copilot
- **WHEN** `.github/prompts/` contains `openspec-proposal.prompt.md`, `openspec-apply.prompt.md`, and `openspec-archive.prompt.md`
- **THEN** refresh each file using shared templates while preserving the YAML frontmatter
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-10-14-add-kilocode-workflows/proposal.md
================================================
## Why
- Kilo Code executes \"slash commands\" by loading markdown workflows from `.kilocode/workflows/` (or the global `~/.kilocode/workflows/`) and running them when a user types `/workflow-name.md`, making project-local workflow files the analogue to the slash-command files we already ship for other tools.\\
  ([Workflows | Kilo Code Docs](https://kilocode.ai/docs/features/slash-commands/workflows))
- Those workflows are plain markdown with step-by-step instructions that can call built-in tools and MCP integrations, so reusing OpenSpec's shared proposal/apply/archive bodies keeps behaviour aligned across assistants without inventing new content.
- OpenSpec already detects configured tools and refreshes marker-wrapped files during `init`/`update`; extending the same mechanism to `.kilocode/workflows/openspec-*.md` ensures Kilo Code stays in sync with one source of truth.

## What Changes
- Add Kilo Code to the `openspec init` tool picker with \"already configured\" detection, including wiring for extend mode so teams can refresh Kilo Code assets.
- Implement a `KiloCodeSlashCommandConfigurator` that creates `.kilocode/workflows/openspec-{proposal,apply,archive}.md`, ensuring the workflow directory exists and wrapping shared content in OpenSpec markers (no front matter required).
- Teach `openspec update` to refresh existing Kilo Code workflows (and only those that already exist) using the shared slash-command templates.
- Update documentation, release notes, and integration tests so the new workflow support is covered alongside Claude, Cursor, OpenCode, and Windsurf.

## Impact
- Specs: `cli-init`, `cli-update`
- Code: `src/core/config.ts`, `src/core/configurators/(registry|slash/*)`, `src/core/templates/slash-command-templates.ts`, CLI wiring for tool summaries
- Tests: init/update workflow coverage, regression for marker preservation in `.kilocode/workflows/`
- Docs: README / CHANGELOG updates advertising Kilo Code workflow support



================================================
FILE: openspec/changes/archive/2025-10-14-add-kilocode-workflows/tasks.md
================================================
## 1. CLI wiring
- [x] 1.1 Add Kilo Code to the selectable AI tools in `openspec init`, including "already configured" detection and success summaries.
- [x] 1.2 Register a `KiloCodeSlashCommandConfigurator` alongside other slash-command tools.

## 2. Workflow generation
- [x] 2.1 Implement the configurator so it creates `.kilocode/workflows/` (if needed) and writes `openspec-{proposal,apply,archive}.md` with OpenSpec markers.
- [x] 2.2 Reuse the shared slash-command bodies without front matter; verify resulting files stay Markdown-only with no extra metadata.

## 3. Update support
- [x] 3.1 Ensure `openspec update` refreshes existing Kilo Code workflows while skipping ones that are absent.
- [x] 3.2 Add regression coverage confirming marker content is replaced (not duplicated) during updates.

## 4. Documentation
- [x] 4.1 Update README / docs to note Kilo Code workflow support and path (`.kilocode/workflows/`).
- [x] 4.2 Mention the integration in CHANGELOG or release notes if applicable.



================================================
FILE: openspec/changes/archive/2025-10-14-add-kilocode-workflows/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration
The command SHALL configure AI coding assistants with OpenSpec instructions using a marker system.
#### Scenario: Prompting for AI tool selection
- **WHEN** run interactively
- **THEN** prompt the user with "Which AI tools do you use?" using a multi-select menu
- **AND** list every available tool with a checkbox:
  - Claude Code (creates or refreshes CLAUDE.md and slash commands)
  - Cursor (creates or refreshes `.cursor/commands/*` slash commands)
  - OpenCode (creates or refreshes `.opencode/command/openspec-*.md` slash commands)
  - Windsurf (creates or refreshes `.windsurf/workflows/openspec-*.md` workflows)
  - Kilo Code (creates or refreshes `.kilocode/workflows/openspec-*.md` workflows)
  - AGENTS.md standard (creates or refreshes AGENTS.md with OpenSpec markers)
- **AND** show "(already configured)" beside tools whose managed files exist so users understand selections will refresh content
- **AND** treat disabled tools as "coming soon" and keep them unselectable
- **AND** allow confirming with Enter after selecting one or more tools

### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-10-14-add-kilocode-workflows/specs/cli-update/spec.md
================================================
## MODIFIED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones.

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-10-14-add-non-interactive-init-options/proposal.md
================================================
## Why
The current `openspec init` command requires interactive prompts, preventing automation in CI/CD pipelines and scripted setups. Adding non-interactive options will enable programmatic initialization for automated workflows while maintaining the existing interactive experience as the default.

## What Changes
- Replace the multiple flag design with a single `--tools` option that accepts `all`, `none`, or a comma-separated list of tool IDs
- Update InitCommand to bypass interactive prompts when `--tools` is supplied and apply single-flag validation rules
- Document the non-interactive behavior via the CLI init spec delta (scenarios for `all`, `none`, list parsing, and invalid entries)
- Generate CLI help text dynamically from `AI_TOOLS` so supported tools stay in sync

## Impact
- Affected specs: `specs/cli-init/spec.md`
- Affected code: `src/cli/index.ts`, `src/core/init.ts`



================================================
FILE: openspec/changes/archive/2025-10-14-add-non-interactive-init-options/tasks.md
================================================
## 1. CLI Option Registration
- [x] 1.1 Replace the multiple flag design with a single `--tools <value>` option supporting `all|none|a,b,c` and keep strict argument validation.
- [x] 1.2 Populate the `--tools` help text dynamically from the `AI_TOOLS` registry.

## 2. InitCommand Modifications
- [x] 2.1 Accept the single tools option in the InitCommand constructor and plumb it through existing flows.
- [x] 2.2 Update tool selection logic to shortcut prompts for `all`, `none`, and explicit lists.
- [x] 2.3 Fail fast with exit code 1 and a helpful message when the parsed list contains unsupported tool IDs.

## 3. Specification Updates
- [x] 3.1 Capture the non-interactive scenarios (`all`, `none`, list, invalid) in the change delta without modifying `specs/cli-init/spec.md` directly.
- [x] 3.2 Document that CLI help reflects the available tool IDs managed by `AI_TOOLS`.

## 4. Testing
- [x] 4.1 Add unit coverage for parsing `--tools` values, including invalid entries.
- [x] 4.2 Add integration coverage ensuring non-interactive runs generate the expected files and exit codes.
- [x] 4.3 Verify the interactive flow remains unchanged when `--tools` is omitted.



================================================
FILE: openspec/changes/archive/2025-10-14-add-non-interactive-init-options/specs/cli-init/spec.md
================================================
# Delta for CLI Init Specification

## ADDED Requirements
### Requirement: Non-Interactive Mode
The command SHALL support non-interactive operation through command-line options for automation and CI/CD use cases.

#### Scenario: Select all tools non-interactively
- **WHEN** run with `--tools all`
- **THEN** automatically select every available AI tool without prompting
- **AND** proceed with initialization using the selected tools

#### Scenario: Select specific tools non-interactively
- **WHEN** run with `--tools claude,cursor`
- **THEN** parse the comma-separated tool IDs and validate against available tools
- **AND** proceed with initialization using only the specified valid tools

#### Scenario: Skip tool configuration non-interactively
- **WHEN** run with `--tools none`
- **THEN** skip AI tool configuration entirely
- **AND** only create the OpenSpec directory structure and template files

#### Scenario: Invalid tool specification
- **WHEN** run with `--tools` containing any IDs not present in the AI tool registry
- **THEN** exit with code 1 and display available values (`all`, `none`, or the supported tool IDs)

#### Scenario: Help text lists available tool IDs
- **WHEN** displaying CLI help for `openspec init`
- **THEN** show the `--tools` option description with the valid values derived from the AI tool registry

## MODIFIED Requirements
### Requirement: Interactive Mode
The command SHALL provide an interactive menu for AI tool selection with clear navigation instructions.

#### Scenario: Displaying interactive menu
- **WHEN** run in fresh or extend mode without non-interactive options
- **THEN** present a looping select menu that lets users toggle tools with Enter and finish via a "Done" option
- **AND** label already configured tools with "(already configured)" while keeping disabled options marked "coming soon"
- **AND** change the prompt copy in extend mode to "Which AI tools would you like to add or refresh?"
- **AND** display inline instructions clarifying that Enter toggles a tool and selecting "Done" confirms the list



================================================
FILE: openspec/changes/archive/2025-10-14-add-windsurf-workflows/proposal.md
================================================
## Why
- Windsurf exposes "Workflows" as the vehicle for slash-like automation: saved Markdown files under `.windsurf/workflows/` that Cascade discovers across the workspace (including subdirectories and up to the git root), then executes when a user types `/workflow-name`. These files can be team-authored, must stay under 12k characters, and can call other workflows, making them the natural place to publish OpenSpec guidance for Windsurf users.\
  ([Windsurf Workflows documentation](https://docs.windsurf.com/windsurf/cascade/workflows))
- The Wave 12 changelog reiterates that workflows are invoked via slash commands and that Windsurf stores them in `.windsurf/workflows`, so the OpenSpec CLI just needs to generate Markdown there to participate in Windsurf's command palette.\
  ("Custom Workflows" section, [Windsurf changelog](https://windsurf.com/changelog))
- OpenSpec already ships shared command bodies for proposal/apply/archive and uses markers so commands stay up to date. Extending the same templates to Windsurf keeps behaviour consistent with Claude, Cursor, and OpenCode without inventing new content flows.

## What Changes
- Add Windsurf to the CLI tool picker (`openspec init`) and the slash-command registry so selecting it scaffolds `.windsurf/workflows/openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md` with marker-managed bodies.
- Shape each Windsurf workflow with a short heading/description plus the existing OpenSpec guardrails/steps wrapped in markers, ensuring the total payload remains well below the 12,000 character limit.
- Ensure `openspec update` refreshes existing Windsurf workflows (and only those that already exist) in-place, mirroring current behaviour for other editors.
- Extend unit tests for init/update to cover Windsurf generation and updates, and update the README/tooling docs to advertise Windsurf support.

## Impact
- Specs: `cli-init`, `cli-update`
- Code: `src/core/configurators/slash/*`, `src/core/templates/slash-command-templates.ts`, CLI prompts, README
- Tests: init/update integration coverage for Windsurf workflows



================================================
FILE: openspec/changes/archive/2025-10-14-add-windsurf-workflows/tasks.md
================================================
## 1. CLI wiring
- [x] 1.1 Add Windsurf to the selectable AI tools in `openspec init`, including "already configured" detection.
- [x] 1.2 Register a `WindsurfSlashCommandConfigurator` that writes workflows to `.windsurf/workflows/` and ensures the directory exists.
- [x] 1.3 Ensure `openspec update` pulls the Windsurf configurator when winds is selected and skips creation when files are absent.

## 2. Workflow templates
- [x] 2.1 Reuse the shared proposal/apply/archive bodies, adding Windsurf-specific headings/description before the OpenSpec markers.
- [x] 2.2 Confirm generated Markdown (per file) stays comfortably under the 12k character ceiling noted in the Windsurf docs.

## 3. Tests & safeguards
- [x] 3.1 Extend init tests to assert creation of `.windsurf/workflows/openspec-*.md` when Windsurf is chosen.
- [x] 3.2 Extend update tests to assert existing Windsurf workflows are refreshed and non-existent files are ignored.
- [x] 3.3 Add regression coverage for marker preservation inside Windsurf workflow files.

## 4. Documentation
- [x] 4.1 Update README (and any user-facing docs) to list Windsurf under native slash/workflow integrations.
- [x] 4.2 Call out Windsurf workflow support in release notes or CHANGELOG if applicable.



================================================
FILE: openspec/changes/archive/2025-10-14-add-windsurf-workflows/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration
The command SHALL configure AI coding assistants with OpenSpec instructions using a marker system.
#### Scenario: Prompting for AI tool selection
- **WHEN** run interactively
- **THEN** prompt the user with "Which AI tools do you use?" using a multi-select menu
- **AND** list every available tool with a checkbox:
  - Claude Code (creates or refreshes CLAUDE.md and slash commands)
  - Cursor (creates or refreshes `.cursor/commands/*` slash commands)
  - OpenCode (creates or refreshes `.opencode/command/openspec-*.md` slash commands)
  - Windsurf (creates or refreshes `.windsurf/workflows/openspec-*.md` workflows)
  - AGENTS.md standard (creates or refreshes AGENTS.md with OpenSpec markers)
- **AND** show "(already configured)" beside tools whose managed files exist so users understand selections will refresh content
- **AND** treat disabled tools as "coming soon" and keep them unselectable
- **AND** allow confirming with Enter after selecting one or more tools

### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-10-14-add-windsurf-workflows/specs/cli-update/spec.md
================================================
## MODIFIED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones.

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-10-14-enhance-validation-error-messages/proposal.md
================================================
## Why
Validation errors like "no deltas found" or "missing requirement text" do not tell agents how to recover, leading to repeated failures. Making error output specific about headers, required text, and next actions will help assistants fix issues in a single pass.

## What Changes
- Extend `openspec validate` error reporting so each failure names the exact header, file, and expected structure, including concrete examples of compliant Markdown.
- Tailor messages for the most common mistakes (missing delta sections, absent descriptive requirement text, missing scenarios) with actionable fixes and suggested debug commands.
- Update docs/help output so the improved messaging is discoverable (e.g., `--help`, troubleshooting section).
- Add regression coverage to lock in the richer messaging for the top validation paths.

## Impact
- Affected specs: `specs/cli-validate`
- Affected code: `src/commands/validate.ts`, `src/core/validation`, `docs/`



================================================
FILE: openspec/changes/archive/2025-10-14-enhance-validation-error-messages/tasks.md
================================================
## 1. Messaging enhancements
- [x] 1.1 Inventory current validation failures and map each to the desired message improvements.
- [x] 1.2 Implement structured error builders that include file paths, normalized header names, and example fixes.
- [x] 1.3 Ensure `openspec validate --help` and troubleshooting docs mention the richer messages and debug tips.

## 2. Tests
- [x] 2.1 Add unit tests for representative errors (no deltas, missing requirement body, missing scenarios) asserting the new wording.
- [x] 2.2 Add integration coverage verifying the Next steps footer reflects contextual guidance.

## 3. Documentation
- [x] 3.1 Update troubleshooting sections and CLI docs with sample output from the enhanced errors.
- [x] 3.2 Note the change in CHANGELOG or release notes if applicable.



================================================
FILE: openspec/changes/archive/2025-10-14-enhance-validation-error-messages/specs/cli-validate/spec.md
================================================
## MODIFIED Requirements
### Requirement: Validation SHALL provide actionable remediation steps
Validation output SHALL include specific guidance to fix each error, including expected structure, example headers, and suggested commands to verify fixes.

#### Scenario: No deltas found in change
- **WHEN** validating a change with zero parsed deltas
- **THEN** show error "No deltas found" with guidance:
  - Explain that change specs must include `## ADDED Requirements`, `## MODIFIED Requirements`, `## REMOVED Requirements`, or `## RENAMED Requirements`
  - Remind authors that files must live under `openspec/changes/{id}/specs/<capability>/spec.md`
  - Include an explicit note: "Spec delta files cannot start with titles before the operation headers"
  - Suggest running `openspec change show {id} --json --deltas-only` for debugging

#### Scenario: Missing required sections
- **WHEN** a required section is missing
- **THEN** include expected header names and a minimal skeleton:
  - For Spec: `## Purpose`, `## Requirements`
  - For Change: `## Why`, `## What Changes`
  - Provide an example snippet of the missing section with placeholder prose ready to copy
  - Mention the quick-reference section in `openspec/AGENTS.md` as the authoritative template

#### Scenario: Missing requirement descriptive text
- **WHEN** a requirement header lacks descriptive text before scenarios
- **THEN** emit an error explaining that `### Requirement:` lines must be followed by narrative text before any `#### Scenario:` headers
  - Show compliant example: "### Requirement: Foo" followed by "The system SHALL ..."
  - Suggest adding 1-2 sentences describing the normative behavior prior to listing scenarios
  - Reference the pre-validation checklist in `openspec/AGENTS.md`

### Requirement: Validator SHALL detect likely misformatted scenarios and warn with a fix
The validator SHALL recognize bulleted lines that look like scenarios (e.g., lines beginning with WHEN/THEN/AND) and emit a targeted warning with a conversion example to `#### Scenario:`.

#### Scenario: Bulleted WHEN/THEN under a Requirement
- **WHEN** bullets that start with WHEN/THEN/AND are found under a requirement without any `#### Scenario:` headers
- **THEN** emit warning: "Scenarios must use '#### Scenario:' headers", and show a conversion template:
```
#### Scenario: Short name
- **WHEN** ...
- **THEN** ...
- **AND** ...
```



================================================
FILE: openspec/changes/archive/2025-10-14-improve-agent-instruction-usability/proposal.md
================================================
## Why
Agents fumble proposal formatting because the essential Markdown templates and formatting rules are buried mid-document. Reorganizing `openspec/AGENTS.md` with a prominent quick-reference and embedded examples will help assistants follow the process without guesswork.

## What Changes
- Restructure `openspec/AGENTS.md` so file formats and scaffold templates appear in a top-level quick-reference section before workflow prose.
- Embed copy/paste templates for `proposal.md`, `tasks.md`, `design.md`, and spec deltas alongside inline examples within the workflow steps.
- Add a pre-validation checklist that highlights the most common formatting pitfalls before running `openspec validate`.
- Split content into beginner vs. advanced sections to progressively disclose complexity while keeping advanced guidance accessible.

## Impact
- Affected specs: `specs/docs-agent-instructions`
- Affected code: `openspec/AGENTS.md`, `docs/`



================================================
FILE: openspec/changes/archive/2025-10-14-improve-agent-instruction-usability/tasks.md
================================================
## 1. Instruction redesign
- [x] 1.1 Draft a quick-reference section that surfaces file templates and formatting rules at the top of `openspec/AGENTS.md`.
- [x] 1.2 Reorganize the workflow narrative with inline examples and progressive disclosure for advanced topics.

## 2. Templates and checklists
- [x] 2.1 Add copy/paste templates for proposal, tasks, design, and spec delta files.
- [x] 2.2 Insert a pre-validation checklist capturing common lint failures before running `openspec validate`.

## 3. Documentation updates
- [x] 3.1 Update supporting docs or README pointers so contributors find the redesigned instructions.
- [x] 3.2 Confirm examples and references stay in sync with the new scaffold command guidance.



================================================
FILE: openspec/changes/archive/2025-10-14-improve-agent-instruction-usability/specs/docs-agent-instructions/spec.md
================================================
## ADDED Requirements
### Requirement: Quick Reference Placement
The AI instructions SHALL begin with a quick-reference section that surfaces required file structures, templates, and formatting rules before any narrative guidance.

#### Scenario: Loading templates at the top
- **WHEN** `openspec/AGENTS.md` is regenerated or updated
- **THEN** the first substantive section after the title SHALL provide copy-ready headings for `proposal.md`, `tasks.md`, spec deltas, and scenario formatting
- **AND** link each template to the corresponding workflow step for deeper reading

### Requirement: Embedded Templates and Examples
`openspec/AGENTS.md` SHALL include complete copy/paste templates and inline examples exactly where agents make corresponding edits.

#### Scenario: Providing file templates
- **WHEN** authors reach the workflow guidance for drafting proposals and deltas
- **THEN** provide fenced Markdown templates that match the required structure (`## Why`, `## ADDED Requirements`, `#### Scenario:` etc.)
- **AND** accompany each template with a brief example showing correct header usage and scenario bullets

### Requirement: Pre-validation Checklist
`openspec/AGENTS.md` SHALL offer a concise pre-validation checklist that highlights common formatting mistakes before running `openspec validate`.

#### Scenario: Highlighting common validation failures
- **WHEN** a reader reaches the validation guidance
- **THEN** present a checklist reminding them to verify requirement headers, scenario formatting, and delta sections
- **AND** include reminders about at least `#### Scenario:` usage and descriptive requirement text before scenarios

### Requirement: Progressive Disclosure of Workflow Guidance
The documentation SHALL separate beginner essentials from advanced topics so newcomers can focus on core steps without losing access to advanced workflows.

#### Scenario: Organizing beginner and advanced sections
- **WHEN** reorganizing `openspec/AGENTS.md`
- **THEN** keep an introductory section limited to the minimum steps (scaffold, draft, validate, request review)
- **AND** move advanced topics (multi-capability changes, archiving details, tooling deep dives) into clearly labeled later sections
- **AND** provide anchor links from the quick-reference to those advanced sections



================================================
FILE: openspec/changes/archive/2025-10-14-slim-root-agents-file/proposal.md
================================================
## Why
The project root currently receives a full copy of the OpenSpec agent instructions, duplicating the content that also lives in `openspec/AGENTS.md`. When teams edit one copy but not the other, the files drift and onboarding assistants see conflicting guidance.

## What Changes
- Keep generating the complete template in `openspec/AGENTS.md` during `openspec init` and follow-up updates.
- Replace the root-level file (`AGENTS.md` or `CLAUDE.md`, depending on tool selection) with a short hand-off that explains the project uses OpenSpec and points directly to `openspec/AGENTS.md`.
- Add a dedicated stub template so both the init and update flows reuse the same minimal copy instructions.
- Update CLI tests and documentation to reflect the new root-level messaging and ensure the OpenSpec marker block still protects future updates.

## Impact
- Affected specs: `cli-init`, `cli-update`
- Affected code: `src/core/init.ts`, `src/core/update.ts`, `src/core/templates/agents-template.ts`
- Update assets/readmes that mention the root `AGENTS.md` contents to reference the new stub message.



================================================
FILE: openspec/changes/archive/2025-10-14-slim-root-agents-file/tasks.md
================================================
## 1. Templates
- [x] 1.1 Add a shared stub template that renders the root agent instructions hand-off message.
- [x] 1.2 Ensure the stub covers both `AGENTS.md` and `CLAUDE.md` variants.

## 2. Init Flow
- [x] 2.1 Update `createInitArtifacts` to write the stub to the project root instead of the full instructions.
- [x] 2.2 Preserve the managed block markers so future updates can overwrite the stub safely.

## 3. Update Flow
- [x] 3.1 Make the update command refresh the root stub rather than the full instructions.
- [x] 3.2 Confirm the update log output still reflects the files that changed.

## 4. Tests & Docs
- [x] 4.1 Adjust CLI/init tests to match the new root content.
- [x] 4.2 Document the stub message in `openspec/specs/cli-init` and `openspec/specs/cli-update` (and any relevant README snippets).



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-enter-selection/proposal.md
================================================
## Why
- Users frequently scroll to a tool and press Enter without toggling it, resulting in no configuration changes.
- The current workflow deviates from common CLI expectations where Enter confirms the highlighted item.
- Aligning behavior with user expectations reduces friction during onboarding.

## What Changes
- Update the init wizard so pressing Enter on a highlighted tool selects it before moving to the review step.
- Adjust interactive instructions to clarify Enter selects the current tool and Space still toggles selections.
- Refresh specs to capture the clarified behavior for the interactive menu.

## Impact
- Users who press Enter without toggling now configure the highlighted tool instead of exiting with no selections.
- Spacebar multi-select support remains unchanged for power users.
- Documentation better reflects how the wizard behaves.



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-enter-selection/tasks.md
================================================
## 1. Implementation
- [x] Update the tool selection wizard to auto-select the highlighted tool when Enter is pressed without prior toggles.
- [x] Refresh inline instructions copy so Enter behavior is clear.
- [x] Adjust or add tests if needed to cover the new selection flow.

## 2. Validation
- [x] Run `pnpm run build`.
- [x] Run `pnpm test` (or targeted suite) if applicable.



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-enter-selection/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: Interactive Mode
The command SHALL provide an interactive menu for AI tool selection with clear navigation instructions.
#### Scenario: Displaying interactive menu
- **WHEN** run in fresh or extend mode
- **THEN** present a looping select menu that lets users toggle tools with Space and review selections with Enter
- **AND** when Enter is pressed on a highlighted selectable tool that is not already selected, automatically add it to the selection before moving to review so the highlighted tool is configured
- **AND** label already configured tools with "(already configured)" while keeping disabled options marked "coming soon"
- **AND** change the prompt copy in extend mode to "Which AI tools would you like to add or refresh?"
- **AND** display inline instructions clarifying that Space toggles tools and Enter selects the highlighted tool before reviewing selections



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-root-agents/proposal.md
================================================
## Why
OpenSpec currently creates the root-level `AGENTS.md` stub only when teams explicitly select the "AGENTS.md standard" tool during `openspec init`. Projects that skip that checkbox never get a managed stub, so non-native assistants (Copilot, Codeium, etc.) have no entry point and later `openspec update` runs silently create the file without any context. We need to bake the stub into initialization, clarify the tool selection experience, and keep the update workflow aligned so every teammate lands on the right instructions from day one.

## What Changes
- Update `openspec init` so the root `AGENTS.md` stub is always generated (first run and extend mode) and refreshed from a shared utility instead of being tied to a tool selection.
- Redesign the AI tool selection wizard to split options into "Natively supported" (Claude, Cursor, OpenCode, â€¦) and an informational "Other tools" section that explains the always-on `AGENTS.md` hand-off.
- Adjust CLI specs, prompts, and success messaging to reflect the new categories while keeping extend-mode behaviour consistent.
- Update automated tests and fixtures to cover the unconditional stub creation and the reworked prompt flow.
- Refresh documentation and onboarding snippets so they no longer describe the stub as opt-in and instead call out the new grouping.
- Ensure `openspec update` continues to reconcile both `openspec/AGENTS.md` and the root stub, documenting the expected behaviour so mismatched setups self-heal.

## Impact
- Affected specs: `cli-init`, `cli-update`
- Affected code: `src/core/init.ts`, `src/core/config.ts`, `src/core/configurators/agents.ts`, `src/core/templates/agents-root-stub.ts`, `src/core/update.ts`, related tests under `test/core/`
- Docs & assets: README, CHANGELOG, any setup guides that reference choosing the "AGENTS.md standard" option



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-root-agents/tasks.md
================================================
## 1. Implementation
- [x] 1.1 Refactor `openspec init` to always generate the root `AGENTS.md` stub (initial run and extend mode) via shared helper logic.
- [x] 1.2 Rework the AI tool selection wizard to surface "Natively supported" vs "Other tools" groupings and make the stub non-optional.
- [x] 1.3 Update CLI messaging, templates, and configurators so the new flow stays in sync across init and update commands.
- [x] 1.4 Refresh unit/integration tests to cover the unconditional stub and the regrouped prompt layout.
- [x] 1.5 Update documentation, README snippets, and CHANGELOG entries that mention the opt-in `AGENTS.md` experience.

## 2. Validation
- [x] 2.1 Run `pnpm test` targeting CLI init/update suites.
- [x] 2.2 Execute `openspec validate update-cli-init-root-agents --strict`.
- [x] 2.3 Perform a manual smoke test: run `openspec init` in a temp directory, confirm stub + grouped prompts, rerun in extend mode.



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-root-agents/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration
The command SHALL configure AI coding assistants with OpenSpec instructions using a grouped selection experience so teams can enable native integrations while always provisioning guidance for other assistants.

#### Scenario: Prompting for AI tool selection
- **WHEN** run interactively
- **THEN** present a multi-select wizard that separates options into two headings:
  - **Natively supported providers** shows each available first-party integration (Claude Code, Cursor, OpenCode, â€¦) with checkboxes
  - **Other tools** explains that the root-level `AGENTS.md` stub is always generated for AGENTS-compatible assistants and cannot be deselected
- **AND** mark already configured native tools with "(already configured)" to signal that choosing them will refresh managed content
- **AND** keep disabled or unavailable providers labelled as "coming soon" so users know they cannot opt in yet
- **AND** allow confirming the selection even when no native provider is chosen because the root stub remains enabled by default
- **AND** change the base prompt copy in extend mode to "Which natively supported AI tools would you like to add or refresh?"

### Requirement: Exit Code Adjustments
`openspec init` SHALL treat extend mode without new native tool selections as a successful refresh.

#### Scenario: Allowing empty extend runs
- **WHEN** OpenSpec is already initialized and the user selects no additional natively supported tools
- **THEN** complete successfully while refreshing the root `AGENTS.md` stub
- **AND** exit with code 0

## ADDED Requirements
### Requirement: Root instruction stub
`openspec init` SHALL always scaffold the root-level `AGENTS.md` hand-off so every teammate finds the primary OpenSpec instructions.

#### Scenario: Creating root `AGENTS.md`
- **GIVEN** the project may or may not already contain an `AGENTS.md` file
- **WHEN** initialization completes in fresh or extend mode
- **THEN** create or refresh `AGENTS.md` at the repository root using the managed marker block from `TemplateManager.getAgentsStandardTemplate()`
- **AND** preserve any existing content outside the managed markers while replacing the stub text inside them
- **AND** create the stub regardless of which native AI tools are selected



================================================
FILE: openspec/changes/archive/2025-10-14-update-cli-init-root-agents/specs/cli-update/spec.md
================================================
## MODIFIED Requirements
### Requirement: Tool-Agnostic Updates
The update command SHALL refresh OpenSpec-managed files in a predictable manner while respecting each team's chosen tooling.

#### Scenario: Updating files
- **WHEN** updating files
- **THEN** completely replace `openspec/AGENTS.md` with the latest template
- **AND** create or refresh the root-level `AGENTS.md` stub using the managed marker block, even if the file was previously absent
- **AND** update only the OpenSpec-managed sections inside existing AI tool files, leaving user-authored content untouched
- **AND** avoid creating new native-tool configuration files (slash commands, CLAUDE.md, etc.) unless they already exist



================================================
FILE: openspec/changes/archive/2025-10-14-update-release-automation/proposal.md
================================================
## Why
Todayâ€™s process requires maintainers to merge the Changesets PR, cut a tag, and draft the GitHub release by hand. npm publish then runs from our existing workflow after the GitHub release is published. The human-in-the-loop steps (versioning, tagging, release notes) slow us down and risk drift between npm, tags, and changelog.

## What Changes
- Use the single `changesets/action` on pushes to `main` to either open/update the version PR or, when the release PR is merged, run our publish command automatically using repository secrets.
- Add a `release` script that builds and runs `changeset publish` so the action handles version bumps, changelog commits, npm publish, and GitHub releases end-to-end.
- Enable `createGithubReleases: true` so GitHub releases are created from the changeset data right after publishing.
- Document the automated flow, required secrets, guardrails, and recovery steps (rollback, hotfixes).

## Two-Phase Rollout (Two PRs)
1) Phase 1 â€” Dry run (no publish)
   - Update the existing `release-prepare.yml` to wire up `changesets/action` with `createGithubReleases: true` and a no-op `publish` command (e.g., `echo 'dry run'`).
   - Keep `.github/workflows/release-publish.yml` intact. This avoids any publish path changes while we verify that the version PR behavior and permissions are correct.
   - Add a repository guard (`if: github.repository == 'Fission-AI/OpenSpec'`) and a concurrency group for safety.

2) Phase 2 â€” Enable publish and consolidate
   - Add `"release": "pnpm run build && pnpm exec changeset publish"` to `package.json`.
   - Change `release-prepare.yml` to use `with: publish: pnpm run release` and `env: NPM_TOKEN: \\${{ secrets.NPM_TOKEN }}` plus the default `GITHUB_TOKEN`.
   - Remove `.github/workflows/release-publish.yml` to avoid double-publish. Publishing now happens when the version PR is merged.

## Guardrails
- Concurrency: `concurrency: { group: release-\\${{ github.ref }}, cancel-in-progress: false }` on the workflow to serialize releases.
- Repository/branch guard: run publish logic only on upstream `main` (`if: github.repository == 'Fission-AI/OpenSpec' && github.ref == 'refs/heads/main'`).
- Permissions: ensure `contents: write` and `pull-requests: write` for opening/updating the version PR; `packages: read` optional.

## Rollback and Hotfixes
- Rollback: revert the release PR merge (which reverts version bumps/changelog); if a tag or GitHub release was created, delete the tag and release; deprecate the npm version if necessary (`npm deprecate @fission-ai/openspec@x.y.z 'reason'`).
- Hotfix (urgent, no pending changesets): create a changeset for the fix and merge the release PR; in emergencies, run a manual bump/publish but reconcile with Changesets by adding a follow-up changeset to align versions.

## Required Secrets
- `NPM_TOKEN` with publish rights for the `@fission-ai` scope.
- Default `GITHUB_TOKEN` (provided by GitHub) for opening/updating the version PR and creating GitHub releases.

## How the Maintainer Flow Changes
| Step | Current process | Future process |
| --- | --- | --- |
| Prepare release | Merge changeset PR, then manually draft release notes and tags | Merge release PR; action updates versions and handles changelog automatically |
| Publish npm package | Happens automatically after GitHub release | Happens automatically via `changeset publish` invoked by the action |
| GitHub release | Draft manually and sync with changelog | Action creates GitHub releases from changeset data |
| Docs/process | Follow manual tagging/release steps | Docs describe automated flow + recovery and hotfix paths |

## Impact
- Automation: reuse `.github/workflows/release-prepare.yml` (phase 1: dry-run, phase 2: publish) and remove `.github/workflows/release-publish.yml` in phase 2.
- Package metadata: add `release` script to `package.json`.
- Docs: update README or `/docs` to show the automated flow, secrets, guardrails, and recovery steps.

## Acceptance Criteria
- Phase 1: merges to `main` open/update a version PR; on merge, the actionâ€™s `publish` step is a no-op; no npm publish occurs; logs confirm intended behavior; GitHub releases creation is wired but inert due to no publish.
- Phase 2: merges to `main` run `pnpm run release` from the action; npm package publishes successfully; GitHub release is created automatically; `.github/workflows/release-publish.yml` is removed; no duplicate publishes occur.



================================================
FILE: openspec/changes/archive/2025-10-14-update-release-automation/tasks.md
================================================
## 1. Release workflow automation
- [x] 1.1 Add a `.github/workflows/release.yml` that runs on pushes to `main`, sets up pnpm + Node 20, installs dependencies, and invokes `changesets/action@v1` with `publish: pnpm run release`.
- [x] 1.2 Configure the action with `createGithubReleases: true` and document required secrets (`NPM_TOKEN`, default `GITHUB_TOKEN`) plus recommended concurrency safeguards.
- [x] 1.3 Validate the workflow using `act` or a dry-run push to confirm the action opens release PRs when changesets exist and publishes when the release PR merge lands.

## 2. Package release script
- [x] 2.1 Add a `release` script to `package.json` that builds the project and runs `changeset publish` using pnpm.
- [x] 2.2 Ensure the script respects the existing `prepare`/`prepublishOnly` hooks to avoid duplicate builds and update documentation or scripts if adjustments are needed.

## 3. Documentation and recovery steps
- [x] 3.1 Update maintainer docs (e.g., README or `/docs`) with the end-to-end automated release flow, explicitly removing the manual tag/release steps that are no longer required and explaining how changesets drive the release PR.
- [x] 3.2 Document fallback steps for failed publishes (rerun workflow, manual publish) and the hotfix path when a release must be cut without pending changesets.



================================================
FILE: openspec/changes/archive/2025-10-22-add-archive-command-arguments/proposal.md
================================================
# Add Archive Command Arguments

## Why
The `/openspec:archive` slash command currently lacks argument support, forcing the AI to infer which change to archive from conversation context or by listing all changes. This creates a safety risk where the wrong proposal could be archived if the context is ambiguous or multiple changes exist. Users expect to specify the change ID explicitly, matching the behavior of the CLI command `openspec archive <id>`.

## What Changes
- Add `$ARGUMENTS` placeholder to the OpenCode archive slash command frontmatter (matching existing pattern for proposal command)
- Update archive command template steps to validate the specific change ID argument when provided
- Note: Codex, GitHub Copilot, and Amazon Q already have `$ARGUMENTS` for archive; Claude/Cursor/Windsurf/Kilocode don't support arguments

## Impact
- Affected specs: `cli-update` (slash command generation logic)
- Affected code:
  - `src/core/configurators/slash/opencode.ts` (add `$ARGUMENTS` to archive frontmatter)
  - `src/core/templates/slash-command-templates.ts` (archive template steps for argument validation)
- Breaking: No - this is additive functionality that makes the command safer
- User-facing: Yes - OpenCode users will be able to pass the change ID as an argument: `/openspec:archive <change-id>`



================================================
FILE: openspec/changes/archive/2025-10-22-add-archive-command-arguments/tasks.md
================================================
# Implementation Tasks

## 1. Update OpenCode Configurator
- [x] 1.1 Add `$ARGUMENTS` placeholder to OpenCode archive frontmatter (matching the proposal pattern)
- [x] 1.2 Format it as `<ChangeId>\n  $ARGUMENTS\n</ChangeId>` or similar structure for clarity
- [x] 1.3 Ensure `updateExisting` rewrites the archive frontmatter/body so `$ARGUMENTS` persists after `openspec update`

## 2. Update Slash Command Templates
- [x] 2.1 Modify archive steps to validate change ID argument when provided via `$ARGUMENTS`
- [x] 2.2 Keep backward compatibility - allow inferring from context if no argument provided
- [x] 2.3 Add step to validate the change ID exists using `openspec list` before archiving

## 3. Update Documentation
- [x] 3.1 Update AGENTS.md archive examples to show argument usage
- [x] 3.2 Document that OpenCode now supports `/openspec:archive <change-id>`



================================================
FILE: openspec/changes/archive/2025-10-22-add-archive-command-arguments/specs/cli-update/spec.md
================================================
# CLI Update Specification Delta

## MODIFIED Requirements

### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones, and ensure the OpenCode archive command accepts change ID arguments.

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** ensure the archive command includes `$ARGUMENTS` placeholder in frontmatter for accepting change ID arguments

### Requirement: Archive Command Argument Support
The archive slash command template SHALL support optional change ID arguments for tools that support `$ARGUMENTS` placeholder.

#### Scenario: Archive command with change ID argument
- **WHEN** a user invokes `/openspec:archive <change-id>` with a change ID
- **THEN** the template SHALL instruct the AI to validate the provided change ID against `openspec list`
- **AND** use the provided change ID for archiving if valid
- **AND** fail fast if the provided change ID doesn't match an archivable change

#### Scenario: Archive command without argument (backward compatibility)
- **WHEN** a user invokes `/openspec:archive` without providing a change ID
- **THEN** the template SHALL instruct the AI to identify the change ID from context or by running `openspec list`
- **AND** proceed with the existing behavior (maintaining backward compatibility)

#### Scenario: OpenCode archive template generation
- **WHEN** generating the OpenCode archive slash command file
- **THEN** include the `$ARGUMENTS` placeholder in the frontmatter
- **AND** wrap it in a clear structure like `<ChangeId>\n  $ARGUMENTS\n</ChangeId>` to indicate the expected argument
- **AND** include validation steps in the template body to check if the change ID is valid



================================================
FILE: openspec/changes/archive/2025-10-22-add-cline-support/proposal.md
================================================
## Why
Add support for Cline (VS Code extension) in OpenSpec to enable developers to use Cline's AI-powered coding capabilities for spec-driven development workflows.

## What Changes
- Add Cline slash command configurator for proposal, apply, and archive operations
- Add Cline root CLINE.md configurator for project-level instructions
- Add Cline template exports
- Update tool and slash command registries to include Cline
- Add comprehensive test coverage
- **BREAKING**: None - this is additive functionality

## Impact
- Affected specs: cli-init (new tool option)
- Affected code: src/core/configurators/slash/cline.ts, src/core/configurators/cline.ts, registry files
- New files: .clinerules/openspec-*.md, CLINE.md



================================================
FILE: openspec/changes/archive/2025-10-22-add-cline-support/tasks.md
================================================
## 1. Implementation
- [x] 1.1 Create ClineSlashCommandConfigurator class in src/core/configurators/slash/cline.ts
- [x] 1.2 Create ClineConfigurator class in src/core/configurators/cline.ts
- [x] 1.3 Create cline-template.ts for template exports
- [x] 1.4 Define file paths for Cline rules (.clinerules/)
- [x] 1.5 Create Cline-specific frontmatter (Markdown heading format)
- [x] 1.6 Register Cline in slash/registry.ts
- [x] 1.7 Register Cline in configurators/registry.ts
- [x] 1.8 Add Cline to AI_TOOLS in config.ts
- [x] 1.9 Add getClineTemplate() to templates/index.ts
- [x] 1.10 Update README with Cline documentation

## 2. Testing
- [x] 2.1 Add init tests for CLINE.md creation and updates
- [x] 2.2 Add init tests for .clinerules/ file creation
- [x] 2.3 Add update tests for CLINE.md updates
- [x] 2.4 Add update tests for .clinerules/ file refreshes
- [x] 2.5 Test integration with openspec init --tools cline
- [x] 2.6 Verify all 225 tests pass



================================================
FILE: openspec/changes/archive/2025-10-22-add-cline-support/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: AI Tool Configuration Details

The command SHALL properly configure selected AI tools with OpenSpec-specific instructions using a marker system.

#### Scenario: Configuring Claude Code

- **WHEN** Claude Code is selected
- **THEN** create or update `CLAUDE.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Configuring CodeBuddy Code

- **WHEN** CodeBuddy Code is selected
- **THEN** create or update `CODEBUDDY.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Configuring Cline

- **WHEN** Cline is selected
- **THEN** create or update `CLINE.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Creating new CLAUDE.md

- **WHEN** CLAUDE.md does not exist
- **THEN** create new file with stub instructions wrapped in markers so the full workflow stays in `openspec/AGENTS.md`:
```markdown
<!-- OPENSPEC:START -->
# OpenSpec Instructions

This project uses OpenSpec to manage AI assistant workflows.

- Full guidance lives in '@/openspec/AGENTS.md'.
- Keep this managed block so 'openspec update' can refresh the instructions.
<!-- OPENSPEC:END -->
```

### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for CodeBuddy Code
- **WHEN** the user selects CodeBuddy Code during initialization
- **THEN** create `.codebuddy/commands/openspec/proposal.md`, `.codebuddy/commands/openspec/apply.md`, and `.codebuddy/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cline
- **WHEN** the user selects Cline during initialization
- **THEN** create `.clinerules/openspec-proposal.md`, `.clinerules/openspec-apply.md`, and `.clinerules/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-10-22-add-crush-support/proposal.md
================================================
## Why
Add support for Crush AI assistant in OpenSpec to enable developers to use Crush's enhanced capabilities for spec-driven development workflows.

## What Changes
- Add Crush slash command configurator for proposal, apply, and archive operations
- Add Crush-specific AGENTS.md configuration template 
- Update tool registry to include Crush configurator
- **BREAKING**: None - this is additive functionality

## Impact
- Affected specs: cli-init (new tool option)
- Affected code: src/core/configurators/slash/crush.ts, registry.ts
- New files: .crush/commands/openspec/ (proposal.md, apply.md, archive.md)


================================================
FILE: openspec/changes/archive/2025-10-22-add-crush-support/tasks.md
================================================
## 1. Implementation
- [x] 1.1 Create CrushSlashCommandConfigurator class in src/core/configurators/slash/crush.ts
- [x] 1.2 Define file paths for Crush commands (.crush/commands/openspec/)
- [x] 1.3 Create Crush-specific frontmatter for proposal, apply, archive commands
- [x] 1.4 Register Crush configurator in slash/registry.ts
- [x] 1.5 Add Crush to available tools in cli-init command
- [x] 1.6 Test integration with openspec init --tool crush


================================================
FILE: openspec/changes/archive/2025-10-22-add-crush-support/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for CodeBuddy Code
- **WHEN** the user selects CodeBuddy Code during initialization
- **THEN** create `.codebuddy/commands/openspec/proposal.md`, `.codebuddy/commands/openspec/apply.md`, and `.codebuddy/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cline
- **WHEN** the user selects Cline during initialization
- **THEN** create `.clinerules/openspec-proposal.md`, `.clinerules/openspec-apply.md`, and `.clinerules/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Crush
- **WHEN** the user selects Crush during initialization
- **THEN** create `.crush/commands/openspec/proposal.md`, `.crush/commands/openspec/apply.md`, and `.crush/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-10-22-add-factory-slash-commands/proposal.md
================================================
## Why
Factory's Droid CLI recently shipped custom slash commands that mirror other native assistant integrations. Teams using OpenSpec want the same managed workflows they already get for Cursor, Windsurf, and others so init/update can provision and refresh Factory commands without manual setup.

## What Changes
- Extend the native tool registry so Factory/Droid appears alongside other slash-command integrations during `openspec init`.
- Add shared templates that generate the three Factory custom commands (proposal, apply, archive) and wrap them in OpenSpec markers for safe refreshes.
- Update the init and update command flows so they create or refresh Factory command files when the tool is selected or already present.
- Refresh CLI specs to document the Factory support and align validation expectations.

## Impact
- Affected specs: `specs/cli-init`, `specs/cli-update`
- Affected code (expected): tool registry, slash-command template manager, init/update command helpers, documentation snippets



================================================
FILE: openspec/changes/archive/2025-10-22-add-factory-slash-commands/tasks.md
================================================
## 1. Factory tool registration
- [x] 1.1 Add Factory/Droid metadata to the native tool registry used by init/update (ID, display name, command paths, availability flags).
- [x] 1.2 Surface Factory in interactive prompts and non-interactive `--tools` parsing alongside existing slash-command integrations.

## 2. Slash command templates
- [x] 2.1 Create shared templates for Factory's `openspec-proposal`, `openspec-apply`, and `openspec-archive` custom commands following Factory's CLI format.
- [x] 2.2 Wire the templates into init/update so generation happens on create and refresh respects OpenSpec markers.

## 3. Verification
- [x] 3.1 Update or add automated coverage that ensures Factory command files are scaffolded and refreshed correctly.
- [x] 3.2 Document the new option in any user-facing copy (help text, README snippets) if required by spec.



================================================
FILE: openspec/changes/archive/2025-10-22-add-factory-slash-commands/specs/cli-init/spec.md
================================================
## MODIFIED Requirements
### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Factory Droid
- **WHEN** the user selects Factory Droid during initialization
- **THEN** create `.factory/commands/openspec-proposal.md`, `.factory/commands/openspec-apply.md`, and `.factory/commands/openspec-archive.md`
- **AND** populate each file from shared templates that include Factory-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** include the `$ARGUMENTS` placeholder in the template body so droid receives any user-supplied input
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-10-22-add-factory-slash-commands/specs/cli-update/spec.md
================================================
## MODIFIED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones.

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Factory Droid
- **WHEN** `.factory/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using the shared Factory templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** ensure the template body retains the `$ARGUMENTS` placeholder so user input keeps flowing into droid
- **AND** update only the content inside the OpenSpec managed markers, leaving any unmanaged notes untouched
- **AND** skip creating missing files during update

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Codex
- **GIVEN** the global Codex prompt directory contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **WHEN** a user runs `openspec update`
- **THEN** refresh each file using the shared slash-command templates (including placeholder guidance)
- **AND** preserve any unmanaged content outside the OpenSpec marker block
- **AND** skip creation when a Codex prompt file is missing

#### Scenario: Updating slash commands for GitHub Copilot
- **WHEN** `.github/prompts/` contains `openspec-proposal.prompt.md`, `openspec-apply.prompt.md`, and `openspec-archive.prompt.md`
- **THEN** refresh each file using shared templates while preserving the YAML frontmatter
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-11-06-add-shell-completions/design.md
================================================
# Shell Completions Design

## Overview

This design establishes a plugin-based architecture for shell completions that prioritizes clean TypeScript patterns, scalability, and maintainability. The system separates concerns between shell-specific generation logic, dynamic completion data providers, and installation automation.

**Scope:** This proposal implements **Zsh completion only** (with Oh My Zsh priority). The architecture is designed to support bash, fish, and PowerShell in future proposals.

## Native Shell Completion Behaviors

**Design Philosophy:** We integrate with each shell's native completion system rather than attempting to customize or unify behaviors. This ensures familiar UX for users and reduces maintenance complexity.

**Note:** While all four shell behaviors are documented below for architectural reference, **only Zsh is implemented in this proposal**. Bash, Fish, and PowerShell are documented to guide future implementations.

### Bash Completion Behavior

**Interaction Pattern:**
- **Single TAB:** Completes if only one match exists, otherwise does nothing
- **Double TAB (TAB TAB):** Displays all possible completions as a list
- **Type more characters + TAB:** Narrows matches and completes or shows refined list

**OpenSpec Integration:**
```bash
# After installing: openspec completion install bash
openspec val<TAB>           # Completes to "openspec validate"
openspec validate <TAB><TAB>  # Shows: --all --changes --specs --strict --json [change-ids] [spec-ids]
openspec show add-<TAB><TAB>  # Shows all changes starting with "add-"
```

**Implementation:** Uses bash-completion framework with `_init_completion`, `compgen`, and `COMPREPLY` array.

### Zsh Completion Behavior (with Oh My Zsh)

**Interaction Pattern:**
- **Single TAB:** Shows interactive menu with all matches immediately
- **TAB / Arrow Keys:** Navigate through completion options
- **Enter:** Selects highlighted option
- **Ctrl+C / Esc:** Cancels completion menu

**OpenSpec Integration:**
```zsh
# After installing: openspec completion install zsh
openspec val<TAB>    # Shows menu with "validate" and "view" highlighted
openspec show <TAB>  # Shows menu with all change IDs and spec IDs, categorized
```

**Implementation:** Uses Zsh completion system with `_arguments`, `_describe`, and `compadd` built-ins. Oh My Zsh provides enhanced menu styling automatically.

### Fish Completion Behavior

**Interaction Pattern:**
- **As-you-type:** Gray suggestions appear automatically in real-time
- **Right Arrow / Ctrl+F:** Accepts the suggestion
- **TAB:** Shows menu with all matches if multiple exist
- **TAB again:** Cycles through options or navigates menu
- **Enter:** Accepts current selection

**OpenSpec Integration:**
```fish
# After installing: openspec completion install fish
openspec val       # Gray suggestion shows "validate" immediately
openspec show a    # Real-time suggestions for changes starting with "a"
openspec <TAB>     # Shows all commands with descriptions in paged menu
```

**Implementation:** Uses Fish's declarative `complete -c` syntax. Completions are auto-loaded from `~/.config/fish/completions/`.

### PowerShell Completion Behavior

**Interaction Pattern:**
- **TAB:** Cycles forward through completions one at a time (inline replacement)
- **Shift+TAB:** Cycles backward through completions
- **Ctrl+Space:** Shows IntelliSense-style menu (PSReadLine v2.2+)
- **Arrow Keys:** Navigate menu if shown

**OpenSpec Integration:**
```powershell
# After installing: openspec completion install powershell
openspec val<TAB>       # Cycles: validate â†’ view â†’ validate
openspec show <TAB>     # Cycles through change IDs one by one
openspec <Ctrl+Space>   # Shows IntelliSense menu with all commands
```

**Implementation:** Uses `Register-ArgumentCompleter` with custom script block that returns `[System.Management.Automation.CompletionResult]` objects.

### Comparison Table

| Shell       | Trigger         | Display Style          | Navigation           | Selection      |
|-------------|-----------------|------------------------|----------------------|----------------|
| Bash        | TAB TAB         | List (printed once)    | Type more + TAB      | Auto-complete  |
| Zsh         | TAB             | Interactive menu       | TAB/Arrows           | Enter          |
| Fish        | TAB/Auto        | Real-time + menu       | TAB/Arrows           | Enter/Right    |
| PowerShell  | TAB             | Inline cycling         | TAB/Shift+TAB        | Stop cycling   |

**Key Insight:** Each shell's completion UX reflects its design philosophy. We respect these conventions rather than forcing uniformity.

## Architectural Principles

### 1. Plugin-Based Generator System

Each shell has unique completion syntax and conventions. Rather than creating a monolithic generator with branching logic, we use a plugin pattern where each shell implements a common interface:

```typescript
interface CompletionGenerator {
  generate(): string;
  getInstallPath(): string;
  getConfigFile(): string;
}
```

**Benefits:**
- New shells can be added without modifying existing generators
- Shell-specific logic is isolated and testable
- Type safety ensures all generators implement required methods
- Easy to maintain and understand (single responsibility per generator)

**Implementation Classes:**
- `ZshCompletionGenerator` - Uses Zsh's `_arguments` and `_describe` functions
- `BashCompletionGenerator` - Uses `_init_completion` and `compgen` built-ins
- `FishCompletionGenerator` - Uses `complete -c` declarative syntax
- `PowerShellCompletionGenerator` - Uses `Register-ArgumentCompleter` cmdlet

### 2. Centralized Command Registry

Shell completions must stay synchronized with actual CLI commands. To avoid duplication and drift, we maintain a single source of truth:

```typescript
type CommandDefinition = {
  name: string;
  description: string;
  flags: FlagDefinition[];
  acceptsChangeId: boolean;
  acceptsSpecId: boolean;
  subcommands?: CommandDefinition[];
};

const COMMAND_REGISTRY: CommandDefinition[] = [
  {
    name: 'init',
    description: 'Initialize OpenSpec in your project',
    flags: [
      { name: '--tools', description: 'Configure AI tools non-interactively', hasValue: true }
    ],
    acceptsChangeId: false,
    acceptsSpecId: false
  },
  // ... all other commands
];
```

**Benefits:**
- All generators consume the same command definitions
- Adding a new command automatically propagates to all shells
- Flag changes only need to be made in one place
- Type safety prevents typos and missing fields
- Easier to test (mock the registry)

**TypeScript Sugar:**
- Use `const` assertions for readonly registry
- Leverage discriminated unions for command types
- Use `satisfies` operator to ensure registry matches interface

### 3. Dynamic Completion Provider

Change and spec IDs are project-specific and discovered at runtime. A dedicated provider encapsulates this logic:

```typescript
class CompletionProvider {
  private changeCache: { ids: string[]; timestamp: number } | null = null;
  private specCache: { ids: string[]; timestamp: number } | null = null;
  private readonly CACHE_TTL_MS = 2000;

  async getChangeIds(): Promise<string[]> {
    if (this.changeCache && Date.now() - this.changeCache.timestamp < this.CACHE_TTL_MS) {
      return this.changeCache.ids;
    }

    const ids = await discoverActiveChangeIds();
    this.changeCache = { ids, timestamp: Date.now() };
    return ids;
  }

  async getSpecIds(): Promise<string[]> {
    // Similar caching logic
  }

  isOpenSpecProject(): boolean {
    // Check for openspec/ directory
  }
}
```

**Benefits:**
- Caching reduces file system overhead during rapid tab completion
- Encapsulates project detection logic
- Easy to test with mocked file system
- Shared across all shell generators

**Design Decisions:**
- 2-second cache TTL balances freshness with performance
- Cache per-process (not persistent) to avoid stale data across sessions
- Graceful degradation when outside OpenSpec projects

### 4. Separate Installation Logic

Installation involves shell configuration file manipulation, which differs from generation. We separate this concern:

```typescript
interface CompletionInstaller {
  install(): Promise<InstallResult>;
  uninstall(): Promise<UninstallResult>;
  isInstalled(): Promise<boolean>;
}
```

**Shell-Specific Installers:**
- `ZshInstaller` - Handles both Oh My Zsh (custom completions) and standard Zsh (fpath)
- `BashInstaller` - Detects completion directories and sources from `.bashrc`
- `FishInstaller` - Writes to `~/.config/fish/completions/` (auto-loaded)
- `PowerShellInstaller` - Appends to PowerShell profile

**Benefits:**
- Installation logic doesn't pollute generator code
- Can test installation without generating completion scripts
- Easier to handle edge cases (missing directories, permissions, already installed)

### 5. Type-Safe Shell Detection

We use TypeScript's literal types and type guards for shell detection:

```typescript
type SupportedShell = 'bash' | 'zsh' | 'fish' | 'powershell';

function detectShell(): SupportedShell {
  const shellPath = process.env.SHELL || '';
  const shellName = path.basename(shellPath).toLowerCase();

  // PowerShell normalization
  if (shellName === 'pwsh' || shellName === 'powershell') {
    return 'powershell';
  }

  const supported: SupportedShell[] = ['bash', 'zsh', 'fish', 'powershell'];
  if (supported.includes(shellName as SupportedShell)) {
    return shellName as SupportedShell;
  }

  throw new Error(`Shell '${shellName}' is not supported. Supported: ${supported.join(', ')}`);
}
```

**Benefits:**
- Compile-time type checking prevents invalid shell names
- Easy to add new shells (add to union type)
- Type narrowing works in switch statements
- Clear error messages for unsupported shells

### 6. Factory Pattern for Instantiation

A factory function selects the appropriate generator/installer based on shell type:

```typescript
function createGenerator(shell: SupportedShell, provider: CompletionProvider): CompletionGenerator {
  switch (shell) {
    case 'bash': return new BashCompletionGenerator(COMMAND_REGISTRY, provider);
    case 'zsh': return new ZshCompletionGenerator(COMMAND_REGISTRY, provider);
    case 'fish': return new FishCompletionGenerator(COMMAND_REGISTRY, provider);
    case 'powershell': return new PowerShellCompletionGenerator(COMMAND_REGISTRY, provider);
  }
}
```

**Benefits:**
- Single point of instantiation
- Type safety ensures exhaustive switch (TypeScript error if shell type missing)
- Easy to inject dependencies (registry, provider)

## Command Structure

**This Proposal (Zsh-only):**
```
openspec completion
â”œâ”€â”€ zsh               # Generate Zsh completion script
â”œâ”€â”€ install [shell]   # Install Zsh completion (auto-detects or explicit zsh)
â””â”€â”€ uninstall [shell] # Remove Zsh completion (auto-detects or explicit zsh)
```

**Future (after follow-up proposals):**
```
openspec completion
â”œâ”€â”€ bash              # Generate Bash completion script (future)
â”œâ”€â”€ zsh               # Generate Zsh completion script (this proposal)
â”œâ”€â”€ fish              # Generate Fish completion script (future)
â”œâ”€â”€ powershell        # Generate PowerShell completion script (future)
â”œâ”€â”€ install [shell]   # Install completion (auto-detects or explicit shell)
â””â”€â”€ uninstall [shell] # Remove completion (auto-detects or explicit shell)
```

## File Organization

**This Proposal (Zsh-only):**
```
src/
â”œâ”€â”€ commands/
â”‚   â””â”€â”€ completion.ts              # CLI command registration (zsh, install, uninstall)
â”œâ”€â”€ core/
â”‚   â””â”€â”€ completions/
â”‚       â”œâ”€â”€ types.ts               # Interfaces: CompletionGenerator, CommandDefinition, etc.
â”‚       â”œâ”€â”€ command-registry.ts    # Single source of truth for OpenSpec commands
â”‚       â”œâ”€â”€ completion-provider.ts # Dynamic change/spec ID discovery with caching
â”‚       â”œâ”€â”€ factory.ts             # Factory for instantiating Zsh generator/installer
â”‚       â”œâ”€â”€ generators/
â”‚       â”‚   â””â”€â”€ zsh-generator.ts   # Zsh completion script generator
â”‚       â””â”€â”€ installers/
â”‚           â””â”€â”€ zsh-installer.ts   # Handles Oh My Zsh + standard Zsh installation
â””â”€â”€ utils/
    â””â”€â”€ shell-detection.ts         # Shell detection (returns 'zsh' or throws)
```

**Future additions (bash, fish, powershell):**
- `generators/bash-generator.ts`, `fish-generator.ts`, `powershell-generator.ts`
- `installers/bash-installer.ts`, `fish-installer.ts`, `powershell-installer.ts`
- Update `shell-detection.ts` to support additional shell types

## Oh My Zsh Priority

Zsh implementation prioritizes Oh My Zsh because:
1. **Popularity** - Oh My Zsh is the most popular Zsh configuration framework
2. **Convention** - Has standard completion directory (`~/.oh-my-zsh/custom/completions/`)
3. **Detection** - Easy to detect via `$ZSH` environment variable
4. **Fallback** - Standard Zsh support provides compatibility when Oh My Zsh isn't installed

**Installation Strategy:**
```typescript
if (isOhMyZshInstalled()) {
  // Install to ~/.oh-my-zsh/custom/completions/_openspec
  // Automatically loaded by Oh My Zsh
} else {
  // Install to ~/.zsh/completions/_openspec
  // Update ~/.zshrc with fpath and compinit if needed
}
```

## Caching Strategy

Dynamic completions cache results for 2 seconds to balance freshness with performance:

**Why 2 seconds?**
- Typical tab completion sessions last < 2 seconds
- Prevents repeated file system scans during rapid tabbing
- Short enough to feel "live" when changes/specs are added
- Automatic per-process expiration (no stale data across sessions)

**Implementation:**
```typescript
private changeCache: { ids: string[]; timestamp: number } | null = null;
private readonly CACHE_TTL_MS = 2000;

if (this.changeCache && Date.now() - this.changeCache.timestamp < this.CACHE_TTL_MS) {
  return this.changeCache.ids; // Use cached
}
// Refresh cache
```

## Error Handling Philosophy

Completions should degrade gracefully rather than break workflows:

1. **Unsupported shell** - Clear error with list of supported shells
2. **Not in OpenSpec project** - Skip dynamic completions, only offer static commands
3. **Permission errors** - Suggest alternative installation methods
4. **Missing config directories** - Auto-create with user notification
5. **Already installed** - Offer to reinstall/update
6. **Not installed (during uninstall)** - Exit gracefully with informational message

## Testing Strategy

Each component is independently testable:

1. **Unit Tests**
   - Shell detection with mocked `$SHELL` environment variable
   - Generator output verification (regex pattern matching)
   - Completion provider caching behavior
   - Command registry structure validation

2. **Integration Tests**
   - Installation to temporary test directories
   - Configuration file modifications
   - End-to-end command flow (generate â†’ install â†’ verify)

3. **Manual Testing**
   - Real shell environments (Oh My Zsh, Bash, Fish, PowerShell)
   - Tab completion behavior in OpenSpec projects
   - Dynamic change/spec ID suggestions
   - Installation/uninstallation workflows

## TypeScript Sugar Patterns

### 1. Const Assertions for Immutable Data
```typescript
const COMMAND_REGISTRY = [
  { name: 'init', ... },
  { name: 'list', ... }
] as const;
```

### 2. Discriminated Unions for Command Types
```typescript
type Command =
  | { type: 'simple'; name: string }
  | { type: 'with-subcommands'; name: string; subcommands: Command[] };
```

### 3. Template Literal Types for Strings
```typescript
type ShellConfigFile = `~/.${SupportedShell}rc` | `~/.${SupportedShell}_profile`;
```

### 4. Satisfies Operator for Type Validation
```typescript
const config = {
  shell: 'zsh',
  path: '~/.zshrc'
} satisfies ShellConfig;
```

### 5. Optional Chaining and Nullish Coalescing
```typescript
const path = process.env.ZSH ?? `${os.homedir()}/.oh-my-zsh`;
```

### 6. Async/Await with Promise.all for Parallel Operations
```typescript
const [changes, specs] = await Promise.all([
  provider.getChangeIds(),
  provider.getSpecIds()
]);
```

## Scalability Considerations

### Adding a New Shell

1. Define shell in `SupportedShell` union type
2. Create generator class implementing `CompletionGenerator`
3. Create installer class implementing `CompletionInstaller`
4. Add cases to factory functions
5. Add command registration in CLI
6. Write tests

**TypeScript will enforce** that all switch statements are updated (exhaustiveness checking).

### Adding a New Command

1. Add to `COMMAND_REGISTRY` with appropriate metadata
2. All generators automatically include it
3. Update tests to verify new command appears

### Changing Completion Behavior

Dynamic completion logic is centralized in `CompletionProvider`, making behavior changes trivial without touching shell-specific code.

## Trade-offs and Decisions

### Decision: Separate Generators vs. Template Engine

**Chosen:** Separate generator classes per shell

**Alternative:** Template engine with shell-specific templates

**Rationale:**
- Shell completion syntax is fundamentally different (not just text substitution)
- Type safety is better with classes than templates
- Logic complexity (caching, dynamic completions) doesn't fit template paradigm
- Easier to debug and test dedicated classes

### Decision: 2-Second Cache TTL

**Chosen:** 2-second cache

**Alternatives:** No cache (slow), longer cache (stale), persistent cache (complex)

**Rationale:**
- Balances performance with freshness
- Matches typical user interaction patterns
- Simple implementation (no invalidation complexity)
- Automatic cleanup on process exit

### Decision: Oh My Zsh Detection

**Chosen:** Check `$ZSH` env var first, then `~/.oh-my-zsh/` directory

**Rationale:**
- `$ZSH` is set by Oh My Zsh initialization (reliable)
- Directory check is fallback for non-interactive scenarios
- Standard Zsh serves as ultimate fallback

### Decision: Installation Automation vs. Manual Instructions

**Chosen:** Automated installation with install/uninstall commands

**Alternative:** Generate script and provide manual installation instructions

**Rationale:**
- Better user experience (one command vs. multiple manual steps)
- Reduces errors from manual configuration
- Aligns with user expectations for modern CLI tools
- Still supports manual workflow via script generation to stdout

## Future Enhancements

1. **Contextual Flag Completion** - Suggest only valid flags for current command
2. **Fuzzy Matching** - Allow partial matching for change/spec IDs
3. **Rich Descriptions** - Include "why" section in completion suggestions (shell-dependent)
4. **Completion Stats** - Track completion usage for analytics
5. **Custom Completion Hooks** - Allow projects to extend completions
6. **MCP Integration** - Provide completions via Model Context Protocol

## References

- [Bash Programmable Completion](https://www.gnu.org/software/bash/manual/html_node/Programmable-Completion.html)
- [Zsh Completion System](https://zsh.sourceforge.io/Doc/Release/Completion-System.html)
- [Fish Completions](https://fishshell.com/docs/current/completions.html)
- [PowerShell Argument Completers](https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/register-argumentcompleter)
- [Oh My Zsh Custom Completions](https://github.com/ohmyzsh/ohmyzsh/wiki/Customization#adding-custom-completions)



================================================
FILE: openspec/changes/archive/2025-11-06-add-shell-completions/proposal.md
================================================
# Add Shell Completions

## Why

OpenSpec CLI commands lack shell completion, forcing users to remember all commands, subcommands, flags, and change/spec IDs manually. This creates friction during daily use and slows developer workflows. Shell completions are a standard expectation for modern CLI tools and significantly improve user experience through:
- Faster command discovery via tab completion
- Reduced cognitive load by removing memorization requirements
- Fewer typos through validated suggestions
- Professional polish expected of production-grade tools

## What Changes

This change adds shell completion support for the OpenSpec CLI, starting with **Zsh (including Oh My Zsh)** and establishing a scalable architecture for future shells (bash, fish, PowerShell). The implementation provides:

1. **New `openspec completion` command** with Zsh generation and installation/uninstallation capabilities
2. **Native Zsh integration** that respects standard Zsh tab completion behavior (single-TAB menu navigation)
3. **Dynamic completion providers** that discover active changes and specs from the current project
4. **Plugin-based architecture** using TypeScript interfaces for easy extension to additional shells in future proposals
5. **Installation automation** for Oh My Zsh (priority) and standard Zsh configurations
6. **Context-aware suggestions** that only activate within OpenSpec-enabled projects

The architecture emphasizes clean TypeScript patterns, composable generators, separation of concerns between shell-specific logic and shared completion data providers, and integration with native shell completion systems. Other shells (bash, fish, PowerShell) are architecturally documented but not implemented in this proposalâ€”they will be added in follow-up changes.

## Deltas

### Delta: New CLI completion specification
- **Spec:** cli-completion
- **Operation:** ADDED
- **Description:** Defines requirements for the new `openspec completion` command including generation, installation, and shell-specific behaviors for Oh My Zsh, bash, fish, and PowerShell.


================================================
FILE: openspec/changes/archive/2025-11-06-add-shell-completions/tasks.md
================================================
# Implementation Tasks

## Phase 1: Foundation & Architecture

- [x] Create `src/utils/shell-detection.ts` with `SupportedShell` type and `detectShell()` function
- [x] Create `src/core/completions/types.ts` with interfaces: `CompletionGenerator`, `CommandDefinition`, `FlagDefinition`
- [x] Create `src/core/completions/command-registry.ts` with `COMMAND_REGISTRY` constant defining all OpenSpec commands, flags, and metadata
- [x] Create `src/core/completions/completion-provider.ts` with `CompletionProvider` class for dynamic change/spec ID discovery with 2-second caching
- [x] Write tests for shell detection (`test/utils/shell-detection.test.ts`)
- [x] Write tests for completion provider (`test/core/completions/completion-provider.test.ts`)

## Phase 2: Zsh Completion (Oh My Zsh Priority)

- [x] Create `src/core/completions/generators/zsh-generator.ts` implementing `CompletionGenerator` interface
- [x] Implement Zsh script generation using `_arguments` and `_describe` patterns
- [x] Add dynamic completion logic for change/spec IDs using completion provider
- [x] Test Zsh generator output (`test/core/completions/generators/zsh-generator.test.ts`)
- [x] Create `src/core/completions/installers/zsh-installer.ts` with Oh My Zsh and standard Zsh support
- [x] Implement Oh My Zsh detection (`$ZSH` env var or `~/.oh-my-zsh/` directory)
- [x] Implement installation to `~/.oh-my-zsh/custom/completions/_openspec` for Oh My Zsh
- [x] Implement fallback installation to `~/.zsh/completions/_openspec` with `fpath` updates
- [x] Test Zsh installer logic with mocked file system (`test/core/completions/installers/zsh-installer.test.ts`)

## Phase 3: CLI Command Implementation

- [x] Create `src/commands/completion.ts` with `CompletionCommand` class
- [x] Register `completion` command in `src/cli/index.ts` with subcommands: generate, install, uninstall
- [x] Implement `generateSubcommand()` that outputs Zsh script to stdout
- [x] Implement `installSubcommand(shell?: 'zsh')` with auto-detection for Zsh-only
- [x] Implement `uninstallSubcommand(shell?: 'zsh')` for removing Zsh completions
- [x] Add `--verbose` flag support for detailed installation output
- [x] Add error handling with clear messages: "Shell '<name>' is not supported yet. Currently supported: zsh"
- [x] Test completion command integration (`test/commands/completion.test.ts`)

## Phase 4: Integration & Polish

- [x] Create factory pattern in `src/core/completions/factory.ts` to instantiate Zsh generator/installer (extensible for future shells)
- [x] Add `completion` command to command registry for self-referential completion
- [x] Implement dynamic completion helper functions in Zsh generator (`_openspec_complete_changes`, `_openspec_complete_specs`, `_openspec_complete_items`)
- [x] Add 'shell' positional type for completion command arguments
- [x] Test completion generation with dynamic helpers
- [x] Test completion install/uninstall flow
- [x] Verify all tests pass (97 completion tests, 340 total tests)
- [x] Implement auto-install via npm postinstall script
- [x] Add safety checks (CI detection, opt-out flag)
- [x] Handle Oh My Zsh vs standard Zsh installation paths
- [x] Add test script for postinstall validation
- [x] Document auto-install behavior and opt-out in README
- [ ] Manually test Zsh completion in Oh My Zsh environment (install, test tab completion, uninstall)
- [ ] Manually test Zsh completion in standard Zsh environment
- [ ] Test dynamic change/spec ID completion in real OpenSpec projects
- [ ] Verify completion cache behavior (2-second TTL)
- [ ] Test behavior outside OpenSpec projects (should skip dynamic completions)
- [x] Update `openspec --help` output to include completion command (automatically done via Commander)

## Phase 5: Edge Cases & Error Handling

- [ ] Test and handle permission errors during installation
- [ ] Test and handle missing shell configuration directories (auto-create with notification)
- [ ] Test "already installed" detection and reinstall flow
- [ ] Test "not installed" detection during uninstall
- [ ] Verify `--no-color` flag is respected in completion command output
- [ ] Test shell detection failure scenarios with helpful error messages
- [ ] Ensure graceful handling when `$SHELL` is unset or invalid
- [ ] Test non-Zsh shells get clear "not supported yet" error messages
- [ ] Test generator output can be redirected to files without corruption

## Dependencies

- Phase 2 depends on Phase 1 (foundation must exist first)
- Phase 3 depends on Phase 2 (CLI needs Zsh generator working)
- Phase 4 depends on Phase 3 (integration requires CLI + Zsh implementation)
- Phase 5 depends on Phase 4 (edge case testing after core functionality works)

## Future Work (Not in This Proposal)

- **Bash completions** - Create bash-generator.ts and bash-installer.ts in follow-up proposal
- **Fish completions** - Create fish-generator.ts and fish-installer.ts in follow-up proposal
- **PowerShell completions** - Create powershell-generator.ts and powershell-installer.ts in follow-up proposal

The architecture is designed to make adding these shells straightforward by implementing the `CompletionGenerator` interface.



================================================
FILE: openspec/changes/archive/2025-11-06-add-shell-completions/specs/cli-completion/spec.md
================================================
# CLI Completion Specification

## Purpose

The `openspec completion` command SHALL provide shell completion functionality for all OpenSpec CLI commands, flags, and dynamic values (change IDs, spec IDs), with support for Zsh (including Oh My Zsh) and a scalable architecture ready for future shells (bash, fish, PowerShell). The completion system SHALL integrate with Zsh's native completion behavior rather than attempting to customize the user experience.

## ADDED Requirements

### Requirement: Native Shell Behavior Integration

The completion system SHALL respect and integrate with Zsh's native completion patterns and user interaction model.

#### Scenario: Zsh native completion

- **WHEN** generating Zsh completion scripts
- **THEN** use Zsh completion system with `_arguments`, `_describe`, and `compadd`
- **AND** completions SHALL trigger on single TAB (standard Zsh behavior)
- **AND** display as an interactive menu that users navigate with TAB/arrow keys
- **AND** support Oh My Zsh's enhanced menu styling automatically

#### Scenario: No custom UX patterns

- **WHEN** implementing Zsh completion
- **THEN** do NOT attempt to customize completion trigger behavior
- **AND** do NOT override Zsh-specific navigation patterns
- **AND** ensure completions feel native to experienced Zsh users

### Requirement: Command Structure

The completion command SHALL follow a subcommand pattern for generating and managing completion scripts.

#### Scenario: Available subcommands

- **WHEN** user executes `openspec completion --help`
- **THEN** display available subcommands:
  - `zsh` - Generate Zsh completion script
  - `install [shell]` - Install completion for Zsh (auto-detects or requires explicit shell)
  - `uninstall [shell]` - Remove completion for Zsh (auto-detects or requires explicit shell)

### Requirement: Shell Detection

The completion system SHALL automatically detect the user's current shell environment.

#### Scenario: Detecting Zsh from environment

- **WHEN** no shell is explicitly specified
- **THEN** read the `$SHELL` environment variable
- **AND** extract the shell name from the path (e.g., `/bin/zsh` â†’ `zsh`)
- **AND** validate the shell is `zsh`
- **AND** throw an error if the shell is not `zsh`, with message indicating only Zsh is currently supported

#### Scenario: Non-Zsh shell detection

- **WHEN** shell path indicates bash, fish, powershell, or other non-Zsh shell
- **THEN** throw error: "Shell '<name>' is not supported yet. Currently supported: zsh"

### Requirement: Completion Generation

The completion command SHALL generate Zsh completion scripts on demand.

#### Scenario: Generating Zsh completion

- **WHEN** user executes `openspec completion zsh`
- **THEN** output a complete Zsh completion script to stdout
- **AND** include completions for all commands: init, list, show, validate, archive, view, update, change, spec, completion
- **AND** include all command-specific flags and options
- **AND** use Zsh's `_arguments` and `_describe` built-in functions
- **AND** support dynamic completion for change and spec IDs

### Requirement: Dynamic Completions

The completion system SHALL provide context-aware dynamic completions for project-specific values.

#### Scenario: Completing change IDs

- **WHEN** completing arguments for commands that accept change names (show, validate, archive)
- **THEN** discover active changes from `openspec/changes/` directory
- **AND** exclude archived changes in `openspec/changes/archive/`
- **AND** return change IDs as completion suggestions
- **AND** only provide suggestions when inside an OpenSpec-enabled project

#### Scenario: Completing spec IDs

- **WHEN** completing arguments for commands that accept spec names (show, validate)
- **THEN** discover specs from `openspec/specs/` directory
- **AND** return spec IDs as completion suggestions
- **AND** only provide suggestions when inside an OpenSpec-enabled project

#### Scenario: Completion caching

- **WHEN** dynamic completions are requested
- **THEN** cache discovered change and spec IDs for 2 seconds
- **AND** reuse cached values for subsequent requests within cache window
- **AND** automatically refresh cache after expiration

#### Scenario: Project detection

- **WHEN** user requests completions outside an OpenSpec project
- **THEN** skip dynamic change/spec ID completions
- **AND** only suggest static commands and flags

### Requirement: Installation Automation

The completion command SHALL automatically install completion scripts into shell configuration files.

#### Scenario: Installing for Oh My Zsh

- **WHEN** user executes `openspec completion install zsh`
- **THEN** detect if Oh My Zsh is installed by checking for `$ZSH` environment variable or `~/.oh-my-zsh/` directory
- **AND** create custom completions directory at `~/.oh-my-zsh/custom/completions/` if it doesn't exist
- **AND** write completion script to `~/.oh-my-zsh/custom/completions/_openspec`
- **AND** ensure `~/.oh-my-zsh/custom/completions` is in `$fpath` by updating `~/.zshrc` if needed
- **AND** display success message with instruction to run `exec zsh` or restart terminal

#### Scenario: Installing for standard Zsh

- **WHEN** user executes `openspec completion install zsh` and Oh My Zsh is not detected
- **THEN** create completions directory at `~/.zsh/completions/` if it doesn't exist
- **AND** write completion script to `~/.zsh/completions/_openspec`
- **AND** add `fpath=(~/.zsh/completions $fpath)` to `~/.zshrc` if not already present
- **AND** add `autoload -Uz compinit && compinit` to `~/.zshrc` if not already present
- **AND** display success message with instruction to run `exec zsh` or restart terminal

#### Scenario: Auto-detecting Zsh for installation

- **WHEN** user executes `openspec completion install` without specifying a shell
- **THEN** detect current shell using shell detection logic
- **AND** install completion if detected shell is Zsh
- **AND** throw error if detected shell is not Zsh
- **AND** display which shell was detected

#### Scenario: Already installed

- **WHEN** completion is already installed for the target shell
- **THEN** display message indicating completion is already installed
- **AND** offer to reinstall/update by overwriting existing files
- **AND** exit with code 0

### Requirement: Uninstallation

The completion command SHALL remove installed completion scripts and configuration.

#### Scenario: Uninstalling Oh My Zsh completion

- **WHEN** user executes `openspec completion uninstall zsh`
- **THEN** remove `~/.oh-my-zsh/custom/completions/_openspec` if Oh My Zsh is detected
- **AND** remove `~/.zsh/completions/_openspec` if standard Zsh setup is detected
- **AND** optionally remove fpath modifications from `~/.zshrc` (with confirmation)
- **AND** display success message

#### Scenario: Auto-detecting Zsh for uninstallation

- **WHEN** user executes `openspec completion uninstall` without specifying a shell
- **THEN** detect current shell and uninstall completion if shell is Zsh
- **AND** throw error if detected shell is not Zsh

#### Scenario: Not installed

- **WHEN** attempting to uninstall completion that isn't installed
- **THEN** display message indicating completion is not installed
- **AND** exit with code 0

### Requirement: Architecture Patterns

The completion implementation SHALL follow clean architecture principles with TypeScript best practices.

#### Scenario: Shell-specific generators

- **WHEN** implementing completion generators
- **THEN** create `ZshCompletionGenerator` class for Zsh
- **AND** implement a common `CompletionGenerator` interface with methods:
  - `generate(): string` - Returns complete shell script
  - `getInstallPath(): string` - Returns target installation path
  - `getConfigFile(): string` - Returns shell configuration file path
- **AND** design interface to be extensible for future shells (bash, fish, powershell)

#### Scenario: Dynamic completion providers

- **WHEN** implementing dynamic completions
- **THEN** create a `CompletionProvider` class that encapsulates project discovery logic
- **AND** implement methods:
  - `getChangeIds(): Promise<string[]>` - Discovers active change IDs
  - `getSpecIds(): Promise<string[]>` - Discovers spec IDs
  - `isOpenSpecProject(): boolean` - Checks if current directory is OpenSpec-enabled
- **AND** implement caching with 2-second TTL using class properties

#### Scenario: Command registry

- **WHEN** defining completable commands
- **THEN** create a centralized `CommandDefinition` type with properties:
  - `name: string` - Command name
  - `description: string` - Help text
  - `flags: FlagDefinition[]` - Available flags
  - `acceptsChangeId: boolean` - Whether command takes change ID argument
  - `acceptsSpecId: boolean` - Whether command takes spec ID argument
  - `subcommands?: CommandDefinition[]` - Nested subcommands
- **AND** export a `COMMAND_REGISTRY` constant with all command definitions
- **AND** generators consume this registry to ensure consistency

#### Scenario: Type-safe shell detection

- **WHEN** implementing shell detection
- **THEN** define a `SupportedShell` type as literal type: `'zsh'`
- **AND** implement `detectShell()` function that returns 'zsh' or throws error
- **AND** design type to be extensible (e.g., future: `'bash' | 'zsh' | 'fish' | 'powershell'`)

### Requirement: Error Handling

The completion command SHALL provide clear error messages for common failure scenarios.

#### Scenario: Unsupported shell

- **WHEN** user requests completion for unsupported shell (bash, fish, powershell, etc.)
- **THEN** display error message: "Shell '<name>' is not supported yet. Currently supported: zsh"
- **AND** exit with code 1

#### Scenario: Permission errors during installation

- **WHEN** installation fails due to file permission issues
- **THEN** display clear error message indicating permission problem
- **AND** suggest using appropriate permissions or alternative installation method
- **AND** exit with code 1

#### Scenario: Missing shell configuration directory

- **WHEN** expected shell configuration directory doesn't exist
- **THEN** create the directory automatically (with user notification)
- **AND** proceed with installation

#### Scenario: Shell not detected

- **WHEN** `openspec completion install` cannot detect current shell or detects non-Zsh shell
- **THEN** display error: "Could not detect Zsh. Please specify explicitly: openspec completion install zsh"
- **AND** exit with code 1

### Requirement: Output Format

The completion command SHALL provide machine-parseable and human-readable output.

#### Scenario: Script generation output

- **WHEN** generating completion script to stdout
- **THEN** output only the completion script content (no extra messages)
- **AND** allow redirection to files: `openspec completion zsh > /path/to/_openspec`

#### Scenario: Installation success output

- **WHEN** installation completes successfully
- **THEN** display formatted success message with:
  - Checkmark indicator
  - Installation location
  - Next steps (shell reload instructions)
- **AND** use colors when terminal supports it (unless `--no-color` is set)

#### Scenario: Verbose installation output

- **WHEN** user provides `--verbose` flag during installation
- **THEN** display detailed steps:
  - Shell detection result
  - Target file paths
  - Configuration modifications
  - File creation confirmations

### Requirement: Testing Support

The completion implementation SHALL be testable with unit and integration tests.

#### Scenario: Mock shell environment

- **WHEN** writing tests for shell detection
- **THEN** allow overriding `$SHELL` environment variable
- **AND** use dependency injection for file system operations

#### Scenario: Generator output verification

- **WHEN** testing completion generators
- **THEN** verify generated scripts contain expected patterns
- **AND** test that command registry is properly consumed
- **AND** ensure dynamic completion placeholders are present

#### Scenario: Installation simulation

- **WHEN** testing installation logic
- **THEN** use temporary test directories instead of actual home directories
- **AND** verify file creation without modifying real shell configurations
- **AND** test path resolution logic independently

## Not in Scope

The following shells are **architecturally documented but not implemented** in this proposal. They will be added in future proposals:

- **Bash completion** - Will use bash-completion framework with `_init_completion`, `compgen`, and `COMPREPLY`
- **Fish completion** - Will use Fish's declarative `complete -c` syntax
- **PowerShell completion** - Will use `Register-ArgumentCompleter` with completion result objects

The plugin-based architecture (CompletionGenerator interface, command registry, dynamic providers) is designed to make adding these shells straightforward in follow-up changes.

## Why

Shell completions are essential for professional CLI tools and significantly improve developer experience by reducing friction, errors, and cognitive load during daily workflows.



================================================
FILE: openspec/changes/archive/2025-12-20-add-global-config-dir/design.md
================================================
## Context

OpenSpec needs a standard location for user-level configuration that works across platforms and follows established conventions. This will serve as the foundation for settings, feature flags, and future artifacts like workflows or templates.

## Goals / Non-Goals

**Goals:**
- Provide a single, well-defined location for global config
- Follow XDG Base Directory Specification (widely adopted by CLI tools)
- Support cross-platform usage (Unix, macOS, Windows)
- Keep implementation minimal - just the foundation
- Enable future expansion (cache, state, workflows)

**Non-Goals:**
- Project-local config override (not in scope)
- Config file migration tooling
- Config validation CLI commands
- Multiple config profiles

## Decisions

### Path Resolution Strategy

**Decision:** Use XDG Base Directory Specification with platform fallbacks.

```
Unix/macOS: $XDG_CONFIG_HOME/openspec/ or ~/.config/openspec/
Windows:    %APPDATA%/openspec/
```

**Rationale:**
- XDG is the de facto standard for CLI tools (used by gh, bat, ripgrep, etc.)
- Environment variable override allows user customization
- Windows uses its native convention (%APPDATA%) for better integration

**Alternatives considered:**
- `~/.openspec/` - Simple but clutters home directory
- `~/Library/Application Support/` on macOS - Overkill for a CLI tool

### Config File Format

**Decision:** JSON (`config.json`)

**Rationale:**
- Native Node.js support (no dependencies)
- Human-readable and editable
- Type-safe with TypeScript
- Matches project.md's "minimal dependencies" principle

**Alternatives considered:**
- YAML - Requires dependency, more error-prone to edit
- TOML - Less common in Node.js ecosystem
- Environment variables only - Too limited for structured settings

### Config Schema

**Decision:** Flat structure with typed fields, start minimal.

```typescript
interface GlobalConfig {
  featureFlags?: Record<string, boolean>;
}
```

**Rationale:**
- `featureFlags` enables controlled rollout of new features
- Optional fields with defaults avoid breaking changes
- Flat structure is easy to understand and extend

### Loading Strategy

**Decision:** Read from disk on each call, no caching.

```typescript
export function getGlobalConfig(): GlobalConfig {
  return loadConfigFromDisk();
}
```

**Rationale:**
- CLI commands are short-lived; caching adds complexity without benefit
- Reading a small JSON file is ~1ms; negligible overhead
- Always returns fresh data; no cache invalidation concerns
- Simpler implementation

### Directory Creation

**Decision:** Create directory only when saving, not when reading.

**Rationale:**
- Don't create empty directories on read operations
- Users who never save config won't have unnecessary directories
- Aligns with principle of least surprise

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Config file corruption | Return defaults on parse error, log warning |
| Permissions issues | Check write permissions before save, clear error message |
| Future schema changes | Use optional fields, add version field if needed later |

## Open Questions

None - this proposal is intentionally minimal.



================================================
FILE: openspec/changes/archive/2025-12-20-add-global-config-dir/proposal.md
================================================
## Why

OpenSpec currently has no mechanism for user-level global settings or feature flags. As the CLI grows, we need a standard location to store user preferences, experimental features, and other configuration that persists across projects. Following XDG Base Directory Specification provides a well-understood, cross-platform approach.

## What Changes

- Add new `src/core/global-config.ts` module with:
  - Path resolution following XDG Base Directory spec (`$XDG_CONFIG_HOME/openspec/` or fallback)
  - Cross-platform support (Unix, macOS, Windows)
  - Lazy config loading with sensible defaults
  - TypeScript types for config shape
- Export a global config directory path getter for future use (workflows, templates, cache)
- Initial config schema supports 1-2 settings/feature flags only

## Impact

- Affected specs: New `global-config` capability (no existing specs modified)
- Affected code:
  - New `src/core/global-config.ts`
  - Update `src/core/index.ts` to export new module



================================================
FILE: openspec/changes/archive/2025-12-20-add-global-config-dir/tasks.md
================================================
## 1. Core Implementation

- [x] 1.1 Create `src/core/global-config.ts` with path resolution
  - Implement `getGlobalConfigDir()` following XDG spec
  - Support `$XDG_CONFIG_HOME` environment variable override
  - Platform-specific fallbacks (Unix: `~/.config/`, Windows: `%APPDATA%`)
- [x] 1.2 Define TypeScript interfaces for config shape
  - `GlobalConfig` interface with optional fields
  - Start minimal: just `featureFlags?: Record<string, boolean>`
- [x] 1.3 Implement config loading with defaults
  - `getGlobalConfig()` - reads config.json if exists, merges with defaults
  - No directory/file creation on read (lazy initialization)
- [x] 1.4 Implement config saving
  - `saveGlobalConfig(config)` - writes config.json, creates directory if needed

## 2. Integration

- [x] 2.1 Export new module from `src/core/index.ts`
- [x] 2.2 Add constants for config file name and directory name

## 3. Testing

- [x] 3.1 Manual testing of path resolution on current platform
- [x] 3.2 Test with/without `$XDG_CONFIG_HOME` set
- [x] 3.3 Test config load when file doesn't exist (should return defaults)
- [x] 3.4 Unit tests in `test/core/global-config.test.ts` (18 tests)



================================================
FILE: openspec/changes/archive/2025-12-20-add-global-config-dir/specs/global-config/spec.md
================================================
## ADDED Requirements

### Requirement: Global Config Directory Path

The system SHALL resolve the global configuration directory path following XDG Base Directory Specification with platform-specific fallbacks.

#### Scenario: Unix/macOS with XDG_CONFIG_HOME set
- **WHEN** `$XDG_CONFIG_HOME` environment variable is set to `/custom/config`
- **THEN** `getGlobalConfigDir()` returns `/custom/config/openspec`

#### Scenario: Unix/macOS without XDG_CONFIG_HOME
- **WHEN** `$XDG_CONFIG_HOME` environment variable is not set
- **AND** the platform is Unix or macOS
- **THEN** `getGlobalConfigDir()` returns `~/.config/openspec` (expanded to absolute path)

#### Scenario: Windows platform
- **WHEN** the platform is Windows
- **AND** `%APPDATA%` is set to `C:\Users\User\AppData\Roaming`
- **THEN** `getGlobalConfigDir()` returns `C:\Users\User\AppData\Roaming\openspec`

### Requirement: Global Config Loading

The system SHALL load global configuration from the config directory with sensible defaults when the config file does not exist or cannot be parsed.

#### Scenario: Config file exists and is valid
- **WHEN** `config.json` exists in the global config directory
- **AND** the file contains valid JSON matching the config schema
- **THEN** `getGlobalConfig()` returns the parsed configuration

#### Scenario: Config file does not exist
- **WHEN** `config.json` does not exist in the global config directory
- **THEN** `getGlobalConfig()` returns the default configuration
- **AND** no directory or file is created

#### Scenario: Config file is invalid JSON
- **WHEN** `config.json` exists but contains invalid JSON
- **THEN** `getGlobalConfig()` returns the default configuration
- **AND** a warning is logged to stderr

### Requirement: Global Config Saving

The system SHALL save global configuration to the config directory, creating the directory if it does not exist.

#### Scenario: Save config to new directory
- **WHEN** `saveGlobalConfig(config)` is called
- **AND** the global config directory does not exist
- **THEN** the directory is created
- **AND** `config.json` is written with the provided configuration

#### Scenario: Save config to existing directory
- **WHEN** `saveGlobalConfig(config)` is called
- **AND** the global config directory already exists
- **THEN** `config.json` is written (overwriting if exists)

### Requirement: Default Configuration

The system SHALL provide a default configuration that is used when no config file exists.

#### Scenario: Default config structure
- **WHEN** no config file exists
- **THEN** the default configuration includes an empty `featureFlags` object

### Requirement: Config Schema Evolution

The system SHALL merge loaded configuration with default values to ensure new config fields are available even when loading older config files.

#### Scenario: Config file missing new fields
- **WHEN** `config.json` exists with `{ "featureFlags": {} }`
- **AND** the current schema includes a new field `defaultAiTool`
- **THEN** `getGlobalConfig()` returns `{ featureFlags: {}, defaultAiTool: <default> }`
- **AND** the loaded values take precedence over defaults for fields that exist in both

#### Scenario: Config file has extra unknown fields
- **WHEN** `config.json` contains fields not in the current schema
- **THEN** the unknown fields are preserved in the returned configuration
- **AND** no error or warning is raised



================================================
FILE: openspec/changes/archive/2025-12-21-add-config-command/design.md
================================================
## Context

The `global-config` spec defines how OpenSpec reads/writes `config.json`, but users currently must edit it by hand. This command provides a CLI interface to that config.

## Goals / Non-Goals

**Goals:**
- Provide a discoverable CLI for config management
- Support scripting with machine-readable output
- Validate config changes with zod schema
- Handle nested keys gracefully

**Non-Goals:**
- Project-local config (reserved for future via `--scope` flag)
- Complex queries (JSONPath, filtering)
- Config file format migration

## Decisions

### Key Naming: camelCase with Dot Notation

**Decision:** Keys use camelCase matching the JSON structure, with dot notation for nesting.

**Rationale:**
- Matches the actual JSON keys (no translation layer)
- Dot notation is intuitive and widely used (lodash, jq, kubectl)
- Avoids complexity of supporting multiple casing styles

**Examples:**
```bash
openspec config get featureFlags              # Returns object
openspec config get featureFlags.experimental # Returns nested value
openspec config set featureFlags.newFlag true
```

### Type Coercion: Auto-detect with `--string` Override

**Decision:** Parse values automatically; provide `--string` flag to force string storage.

**Rationale:**
- Most intuitive for common cases (`true`, `false`, `123`)
- Explicit override for edge cases (storing literal string "true")
- Follows npm/yarn config patterns

**Coercion rules:**
| Input | Stored As |
|-------|-----------|
| `true`, `false` | boolean |
| Numeric string (`123`, `3.14`) | number |
| Everything else | string |
| Any value with `--string` | string |

### Output Format: Raw by Default

**Decision:** `get` prints raw value only. `list` prints YAML-like format by default, JSON with `--json`.

**Rationale:**
- Raw output enables piping: `VAR=$(openspec config get key)`
- YAML-like is human-readable for inspection
- JSON for automation/scripting

### Schema Validation: Zod with Unknown Field Passthrough

**Decision:** Use zod for validation but preserve unknown fields per `global-config` spec.

**Rationale:**
- Type safety for known fields
- Forward compatibility (old CLI doesn't break new config)
- Follows existing `global-config` spec requirement

### Reserved Flag: `--scope`

**Decision:** Reserve `--scope global|project` but only implement `global` initially.

**Rationale:**
- Avoids breaking change if project-local config is added later
- Clear error message if someone tries `--scope project`

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Dot notation conflicts with keys containing dots | Rare in practice; document limitation |
| Type coercion surprises | `--string` escape hatch; document rules |
| $EDITOR not set | Check and provide helpful error message |

## Open Questions

None - design is straightforward.



================================================
FILE: openspec/changes/archive/2025-12-21-add-config-command/proposal.md
================================================
## Why

Users need a way to view and modify their global OpenSpec settings without manually editing JSON files. The `global-config` spec provides the foundation, but there's no user-facing interface to interact with the config. A dedicated `openspec config` command provides discoverability and ease of use.

## What Changes

Add `openspec config` subcommand with the following operations:

```bash
openspec config path                          # Show config file location
openspec config list [--json]                 # Show all current settings
openspec config get <key>                     # Get a specific value (raw, scriptable)
openspec config set <key> <value> [--string]  # Set a value (auto-coerce types)
openspec config unset <key>                   # Remove a key (revert to default)
openspec config reset --all [-y]              # Reset everything to defaults
openspec config edit                          # Open config in $EDITOR
```

**Key design decisions:**
- **Key naming**: Use camelCase to match JSON structure (e.g., `featureFlags.someFlag`)
- **Nested keys**: Support dot notation for nested access
- **Type coercion**: Auto-detect types by default; `--string` flag forces string storage
- **Scriptable output**: `get` prints raw value only (no labels) for easy piping
- **Zod validation**: Use zod for config schema validation and type safety
- **Future-proofing**: Reserve `--scope global|project` flag for potential project-local config

**Example usage:**
```bash
$ openspec config path
/Users/me/.config/openspec/config.json

$ openspec config list
featureFlags: {}

$ openspec config set featureFlags.enableTelemetry false
Set featureFlags.enableTelemetry = false

$ openspec config get featureFlags.enableTelemetry
false

$ openspec config list --json
{
  "featureFlags": {}
}

$ openspec config unset featureFlags.enableTelemetry
Unset featureFlags.enableTelemetry (reverted to default)

$ openspec config edit
# Opens $EDITOR with config.json
```

## Impact

- Affected specs: New `cli-config` capability
- Affected code:
  - New `src/commands/config.ts`
  - New `src/core/config-schema.ts` (zod schema)
  - Update CLI entry point to register config command
- Dependencies: Requires `global-config` spec (already implemented)



================================================
FILE: openspec/changes/archive/2025-12-21-add-config-command/tasks.md
================================================
## 1. Core Infrastructure

- [x] 1.1 Create zod schema for global config in `src/core/config-schema.ts`
- [x] 1.2 Add utility functions for dot-notation key access (get/set nested values)
- [x] 1.3 Add type coercion logic (auto-detect boolean/number/string)

## 2. Config Command Implementation

- [x] 2.1 Create `src/commands/config.ts` with Commander.js subcommands
- [x] 2.2 Implement `config path` subcommand
- [x] 2.3 Implement `config list` subcommand with `--json` flag
- [x] 2.4 Implement `config get <key>` subcommand (raw output)
- [x] 2.5 Implement `config set <key> <value>` with `--string` flag
- [x] 2.6 Implement `config unset <key>` subcommand
- [x] 2.7 Implement `config reset --all` with `-y` confirmation flag
- [x] 2.8 Implement `config edit` subcommand (spawn $EDITOR)

## 3. Integration

- [x] 3.1 Register config command in CLI entry point
- [x] 3.2 Update shell completion registry to include config subcommands

## 4. Testing

- [x] 4.1 Manual testing of all subcommands
- [x] 4.2 Verify zod validation rejects invalid keys/values
- [x] 4.3 Test nested key access with dot notation
- [x] 4.4 Test type coercion edge cases (true/false, numbers, strings)



================================================
FILE: openspec/changes/archive/2025-12-21-add-config-command/specs/cli-config/spec.md
================================================
# cli-config Specification

## Purpose

Provide a CLI interface for viewing and modifying global OpenSpec configuration. Enables users to manage settings without manually editing JSON files, with support for scripting and automation.

## ADDED Requirements

### Requirement: Command Structure

The config command SHALL provide subcommands for all configuration operations.

#### Scenario: Available subcommands

- **WHEN** user executes `openspec config --help`
- **THEN** display available subcommands:
  - `path` - Show config file location
  - `list` - Show all current settings
  - `get <key>` - Get a specific value
  - `set <key> <value>` - Set a value
  - `unset <key>` - Remove a key (revert to default)
  - `reset` - Reset configuration to defaults
  - `edit` - Open config in editor

### Requirement: Config Path

The config command SHALL display the config file location.

#### Scenario: Show config path

- **WHEN** user executes `openspec config path`
- **THEN** print the absolute path to the config file
- **AND** exit with code 0

### Requirement: Config List

The config command SHALL display all current configuration values.

#### Scenario: List config in human-readable format

- **WHEN** user executes `openspec config list`
- **THEN** display all config values in YAML-like format
- **AND** show nested objects with indentation

#### Scenario: List config as JSON

- **WHEN** user executes `openspec config list --json`
- **THEN** output the complete config as valid JSON
- **AND** output only JSON (no additional text)

### Requirement: Config Get

The config command SHALL retrieve specific configuration values.

#### Scenario: Get top-level key

- **WHEN** user executes `openspec config get <key>` with a valid top-level key
- **THEN** print the raw value only (no labels or formatting)
- **AND** exit with code 0

#### Scenario: Get nested key with dot notation

- **WHEN** user executes `openspec config get featureFlags.someFlag`
- **THEN** traverse the nested structure using dot notation
- **AND** print the value at that path

#### Scenario: Get non-existent key

- **WHEN** user executes `openspec config get <key>` with a key that does not exist
- **THEN** print nothing (empty output)
- **AND** exit with code 1

#### Scenario: Get object value

- **WHEN** user executes `openspec config get <key>` where the value is an object
- **THEN** print the object as JSON

### Requirement: Config Set

The config command SHALL set configuration values with automatic type coercion.

#### Scenario: Set string value

- **WHEN** user executes `openspec config set <key> <value>`
- **AND** value does not match boolean or number patterns
- **THEN** store value as a string
- **AND** display confirmation message

#### Scenario: Set boolean value

- **WHEN** user executes `openspec config set <key> true` or `openspec config set <key> false`
- **THEN** store value as boolean (not string)
- **AND** display confirmation message

#### Scenario: Set numeric value

- **WHEN** user executes `openspec config set <key> <value>`
- **AND** value is a valid number (integer or float)
- **THEN** store value as number (not string)

#### Scenario: Force string with --string flag

- **WHEN** user executes `openspec config set <key> <value> --string`
- **THEN** store value as string regardless of content
- **AND** this allows storing literal "true" or "123" as strings

#### Scenario: Set nested key

- **WHEN** user executes `openspec config set featureFlags.newFlag true`
- **THEN** create intermediate objects if they don't exist
- **AND** set the value at the nested path

### Requirement: Config Unset

The config command SHALL remove configuration overrides.

#### Scenario: Unset existing key

- **WHEN** user executes `openspec config unset <key>`
- **AND** the key exists in the config
- **THEN** remove the key from the config file
- **AND** the value reverts to its default
- **AND** display confirmation message

#### Scenario: Unset non-existent key

- **WHEN** user executes `openspec config unset <key>`
- **AND** the key does not exist in the config
- **THEN** display message indicating key was not set
- **AND** exit with code 0

### Requirement: Config Reset

The config command SHALL reset configuration to defaults.

#### Scenario: Reset all with confirmation

- **WHEN** user executes `openspec config reset --all`
- **THEN** prompt for confirmation before proceeding
- **AND** if confirmed, delete the config file or reset to defaults
- **AND** display confirmation message

#### Scenario: Reset all with -y flag

- **WHEN** user executes `openspec config reset --all -y`
- **THEN** reset without prompting for confirmation

#### Scenario: Reset without --all flag

- **WHEN** user executes `openspec config reset` without `--all`
- **THEN** display error indicating `--all` is required
- **AND** exit with code 1

### Requirement: Config Edit

The config command SHALL open the config file in the user's editor.

#### Scenario: Open editor successfully

- **WHEN** user executes `openspec config edit`
- **AND** `$EDITOR` or `$VISUAL` environment variable is set
- **THEN** open the config file in that editor
- **AND** create the config file with defaults if it doesn't exist
- **AND** wait for the editor to close before returning

#### Scenario: No editor configured

- **WHEN** user executes `openspec config edit`
- **AND** neither `$EDITOR` nor `$VISUAL` is set
- **THEN** display error message suggesting to set `$EDITOR`
- **AND** exit with code 1

### Requirement: Key Naming Convention

The config command SHALL use camelCase keys matching the JSON structure.

#### Scenario: Keys match JSON structure

- **WHEN** accessing configuration keys via CLI
- **THEN** use camelCase matching the actual JSON property names
- **AND** support dot notation for nested access (e.g., `featureFlags.someFlag`)

### Requirement: Schema Validation

The config command SHALL validate configuration writes against the config schema using zod, while allowing unknown fields for forward compatibility.

#### Scenario: Unknown key accepted

- **WHEN** user executes `openspec config set someFutureKey 123`
- **THEN** the value is saved successfully
- **AND** exit with code 0

#### Scenario: Invalid feature flag value rejected

- **WHEN** user executes `openspec config set featureFlags.someFlag notABoolean`
- **THEN** display a descriptive error message
- **AND** do not modify the config file
- **AND** exit with code 1

### Requirement: Reserved Scope Flag

The config command SHALL reserve the `--scope` flag for future extensibility.

#### Scenario: Scope flag defaults to global

- **WHEN** user executes any config command without `--scope`
- **THEN** operate on global configuration (default behavior)

#### Scenario: Project scope not yet implemented

- **WHEN** user executes `openspec config --scope project <subcommand>`
- **THEN** display error message: "Project-local config is not yet implemented"
- **AND** exit with code 1



================================================
FILE: openspec/changes/archive/2025-12-23-extend-shell-completions/proposal.md
================================================
# Change Proposal: Extend Shell Completions

## Why

Zsh completions provide an excellent developer experience, but many developers use bash, fish, or PowerShell. Extending completion support to these shells removes friction for the majority of developers who don't use Zsh.

## What Changes

This change adds bash, fish, and PowerShell completion support following the same architectural patterns, documentation methodology, and testing rigor established for Zsh completions.

## Deltas

- **Spec:** `cli-completion`
  - **Operation:** MODIFIED
  - **Description:** Extend completion generation, installation, and testing requirements to support bash, fish, and PowerShell while maintaining the existing Zsh implementation and architectural patterns


================================================
FILE: openspec/changes/archive/2025-12-23-extend-shell-completions/tasks.md
================================================
# Implementation Tasks

## Phase 1: Foundation and Bash Support

- [x] Update `SupportedShell` type in `src/utils/shell-detection.ts` to include `'bash' | 'fish' | 'powershell'`
- [x] Extend shell detection logic to recognize bash, fish, and PowerShell from environment variables
- [x] Create `src/core/completions/generators/bash-generator.ts` implementing `CompletionGenerator` interface
- [x] Create `src/core/completions/installers/bash-installer.ts` implementing `CompletionInstaller` interface
- [x] Update `CompletionFactory.createGenerator()` to support bash
- [x] Update `CompletionFactory.createInstaller()` to support bash
- [x] Create test file `test/core/completions/generators/bash-generator.test.ts` mirroring zsh test structure
- [x] Create test file `test/core/completions/installers/bash-installer.test.ts` mirroring zsh test structure
- [x] Verify bash completions work manually: `openspec completion install bash && exec bash`

## Phase 2: Fish Support

- [x] Create `src/core/completions/generators/fish-generator.ts` implementing `CompletionGenerator` interface
- [x] Create `src/core/completions/installers/fish-installer.ts` implementing `CompletionInstaller` interface
- [x] Update `CompletionFactory.createGenerator()` to support fish
- [x] Update `CompletionFactory.createInstaller()` to support fish
- [x] Create test file `test/core/completions/generators/fish-generator.test.ts`
- [x] Create test file `test/core/completions/installers/fish-installer.test.ts`
- [x] Verify fish completions work manually: `openspec completion install fish`

## Phase 3: PowerShell Support

- [x] Create `src/core/completions/generators/powershell-generator.ts` implementing `CompletionGenerator` interface
- [x] Create `src/core/completions/installers/powershell-installer.ts` implementing `CompletionInstaller` interface
- [x] Update `CompletionFactory.createGenerator()` to support powershell
- [x] Update `CompletionFactory.createInstaller()` to support powershell
- [x] Create test file `test/core/completions/generators/powershell-generator.test.ts`
- [x] Create test file `test/core/completions/installers/powershell-installer.test.ts`
- [x] Verify PowerShell completions work manually on Windows or macOS PowerShell

## Phase 4: Documentation and Testing

- [x] Update `CLAUDE.md` or relevant documentation to mention all four supported shells
- [x] Add cross-shell consistency test verifying all shells support same commands
- [x] Run `pnpm test` to ensure all tests pass
- [x] Run `pnpm run build` to verify TypeScript compilation
- [x] Test all shells on different platforms (Linux for bash/fish/zsh, Windows/macOS for PowerShell)

## Phase 5: Validation and Cleanup

- [x] Run `openspec validate extend-shell-completions --strict` and resolve all issues
- [x] Update error messages to list all four supported shells
- [x] Verify `openspec completion --help` documentation is current
- [x] Test auto-detection works for all shells
- [x] Ensure uninstall works cleanly for all shells


================================================
FILE: openspec/changes/archive/2025-12-23-extend-shell-completions/specs/cli-completion/spec.md
================================================
# cli-completion Spec Delta

## MODIFIED Requirements

### Requirement: Native Shell Behavior Integration

The completion system SHALL respect and integrate with each supported shell's native completion patterns and user interaction model.

#### Scenario: Zsh native completion

- **WHEN** generating Zsh completion scripts
- **THEN** use Zsh completion system with `_arguments`, `_describe`, and `compadd`
- **AND** completions SHALL trigger on single TAB (standard Zsh behavior)
- **AND** display as an interactive menu that users navigate with TAB/arrow keys
- **AND** support Oh My Zsh's enhanced menu styling automatically

#### Scenario: Bash native completion

- **WHEN** generating Bash completion scripts
- **THEN** use Bash completion with `complete` builtin and `COMPREPLY` array
- **AND** completions SHALL trigger on double TAB (standard Bash behavior)
- **AND** display as space-separated list or column format
- **AND** support both bash-completion v1 and v2 patterns

#### Scenario: Fish native completion

- **WHEN** generating Fish completion scripts
- **THEN** use Fish's `complete` command with conditions
- **AND** completions SHALL trigger on single TAB with auto-suggestion preview
- **AND** display with Fish's native coloring and description alignment
- **AND** leverage Fish's built-in caching automatically

#### Scenario: PowerShell native completion

- **WHEN** generating PowerShell completion scripts
- **THEN** use `Register-ArgumentCompleter` with scriptblock
- **AND** completions SHALL trigger on TAB with cycling behavior
- **AND** display with PowerShell's native completion UI
- **AND** support both Windows PowerShell 5.1 and PowerShell Core 7+

#### Scenario: No custom UX patterns

- **WHEN** implementing completion for any shell
- **THEN** do NOT attempt to customize completion trigger behavior
- **AND** do NOT override shell-specific navigation patterns
- **AND** ensure completions feel native to experienced users of that shell

### Requirement: Shell Detection

The completion system SHALL automatically detect the user's current shell environment.

#### Scenario: Detecting Zsh from environment

- **WHEN** no shell is explicitly specified
- **THEN** read the `$SHELL` environment variable
- **AND** extract the shell name from the path (e.g., `/bin/zsh` â†’ `zsh`)
- **AND** validate the shell is one of: `zsh`, `bash`, `fish`, `powershell`
- **AND** throw an error if the shell is not supported

#### Scenario: Detecting Bash from environment

- **WHEN** `$SHELL` contains `bash` in the path
- **THEN** detect shell as `bash`
- **AND** proceed with bash-specific completion logic

#### Scenario: Detecting Fish from environment

- **WHEN** `$SHELL` contains `fish` in the path
- **THEN** detect shell as `fish`
- **AND** proceed with fish-specific completion logic

#### Scenario: Detecting PowerShell from environment

- **WHEN** `$PSModulePath` environment variable is present
- **THEN** detect shell as `powershell`
- **AND** proceed with PowerShell-specific completion logic

#### Scenario: Unsupported shell detection

- **WHEN** shell path indicates an unsupported shell
- **THEN** throw error: "Shell '<name>' is not supported. Supported shells: zsh, bash, fish, powershell"

### Requirement: Completion Generation

The completion command SHALL generate completion scripts for all supported shells on demand.

#### Scenario: Generating Zsh completion

- **WHEN** user executes `openspec completion generate zsh`
- **THEN** output a complete Zsh completion script to stdout
- **AND** include completions for all commands: init, list, show, validate, archive, view, update, change, spec, completion
- **AND** include all command-specific flags and options
- **AND** use Zsh's `_arguments` and `_describe` built-in functions
- **AND** support dynamic completion for change and spec IDs

#### Scenario: Generating Bash completion

- **WHEN** user executes `openspec completion generate bash`
- **THEN** output a complete Bash completion script to stdout
- **AND** include completions for all commands and subcommands
- **AND** use `complete -F` with custom completion function
- **AND** populate `COMPREPLY` with appropriate suggestions
- **AND** support dynamic completion for change and spec IDs via `openspec __complete`

#### Scenario: Generating Fish completion

- **WHEN** user executes `openspec completion generate fish`
- **THEN** output a complete Fish completion script to stdout
- **AND** use `complete -c openspec` with conditions
- **AND** include command-specific completions with `--condition` predicates
- **AND** support dynamic completion for change and spec IDs via `openspec __complete`
- **AND** include descriptions for each completion option

#### Scenario: Generating PowerShell completion

- **WHEN** user executes `openspec completion generate powershell`
- **THEN** output a complete PowerShell completion script to stdout
- **AND** use `Register-ArgumentCompleter -CommandName openspec`
- **AND** implement scriptblock that handles command context
- **AND** support dynamic completion for change and spec IDs via `openspec __complete`
- **AND** return `[System.Management.Automation.CompletionResult]` objects

### Requirement: Installation Automation

The completion command SHALL automatically install completion scripts into shell configuration files for all supported shells.

#### Scenario: Installing for Oh My Zsh

- **WHEN** user executes `openspec completion install zsh`
- **THEN** detect if Oh My Zsh is installed by checking for `$ZSH` environment variable or `~/.oh-my-zsh/` directory
- **AND** create custom completions directory at `~/.oh-my-zsh/custom/completions/` if it doesn't exist
- **AND** write completion script to `~/.oh-my-zsh/custom/completions/_openspec`
- **AND** ensure `~/.oh-my-zsh/custom/completions` is in `$fpath` by updating `~/.zshrc` if needed
- **AND** display success message with instruction to run `exec zsh` or restart terminal

#### Scenario: Installing for standard Zsh

- **WHEN** user executes `openspec completion install zsh` and Oh My Zsh is not detected
- **THEN** create completions directory at `~/.zsh/completions/` if it doesn't exist
- **AND** write completion script to `~/.zsh/completions/_openspec`
- **AND** add `fpath=(~/.zsh/completions $fpath)` to `~/.zshrc` if not already present
- **AND** add `autoload -Uz compinit && compinit` to `~/.zshrc` if not already present
- **AND** display success message with instruction to run `exec zsh` or restart terminal

#### Scenario: Installing for Bash with bash-completion

- **WHEN** user executes `openspec completion install bash`
- **THEN** detect if bash-completion is installed by checking for `/usr/share/bash-completion` or `/etc/bash_completion.d`
- **AND** if bash-completion is available, write to `/etc/bash_completion.d/openspec` (with sudo) or `~/.local/share/bash-completion/completions/openspec`
- **AND** if bash-completion is not available, write to `~/.bash_completion.d/openspec` and source it from `~/.bashrc`
- **AND** add sourcing line to `~/.bashrc` using marker-based updates if needed
- **AND** display success message with instruction to run `exec bash` or restart terminal

#### Scenario: Installing for Fish

- **WHEN** user executes `openspec completion install fish`
- **THEN** create Fish completions directory at `~/.config/fish/completions/` if it doesn't exist
- **AND** write completion script to `~/.config/fish/completions/openspec.fish`
- **AND** Fish automatically loads completions from this directory (no config file modification needed)
- **AND** display success message indicating completions are immediately available

#### Scenario: Installing for PowerShell

- **WHEN** user executes `openspec completion install powershell`
- **THEN** detect PowerShell profile location via `$PROFILE` environment variable or default paths
- **AND** create profile directory if it doesn't exist
- **AND** add completion script import to profile using marker-based updates
- **AND** write completion script to PowerShell modules directory or alongside profile
- **AND** display success message with instruction to restart PowerShell or run `. $PROFILE`

#### Scenario: Auto-detecting shell for installation

- **WHEN** user executes `openspec completion install` without specifying a shell
- **THEN** detect current shell using shell detection logic
- **AND** install completion for the detected shell (zsh, bash, fish, or powershell)
- **AND** display which shell was detected

#### Scenario: Already installed

- **WHEN** completion is already installed for the target shell
- **THEN** display message indicating completion is already installed
- **AND** offer to reinstall/update by overwriting existing files
- **AND** exit with code 0

### Requirement: Uninstallation

The completion command SHALL remove installed completion scripts and configuration for all supported shells.

#### Scenario: Uninstalling Zsh completion

- **WHEN** user executes `openspec completion uninstall zsh`
- **THEN** prompt for confirmation before proceeding (unless `--yes` flag provided)
- **AND** if user declines, cancel uninstall and display "Uninstall cancelled."
- **AND** if user confirms, remove `~/.oh-my-zsh/custom/completions/_openspec` if Oh My Zsh is detected
- **AND** remove `~/.zsh/completions/_openspec` if standard Zsh setup is detected
- **AND** remove fpath modifications from `~/.zshrc` using marker-based removal
- **AND** display success message

#### Scenario: Uninstalling Bash completion

- **WHEN** user executes `openspec completion uninstall bash`
- **THEN** prompt for confirmation (unless `--yes` flag provided)
- **AND** if user confirms, remove completion file from bash-completion directory or `~/.bash_completion.d/`
- **AND** remove sourcing lines from `~/.bashrc` using marker-based removal
- **AND** display success message

#### Scenario: Uninstalling Fish completion

- **WHEN** user executes `openspec completion uninstall fish`
- **THEN** prompt for confirmation (unless `--yes` flag provided)
- **AND** if user confirms, remove `~/.config/fish/completions/openspec.fish`
- **AND** display success message (no config file modification needed)

#### Scenario: Uninstalling PowerShell completion

- **WHEN** user executes `openspec completion uninstall powershell`
- **THEN** prompt for confirmation (unless `--yes` flag provided)
- **AND** if user confirms, remove completion import from PowerShell profile using marker-based removal
- **AND** remove completion script file
- **AND** display success message

#### Scenario: Auto-detecting shell for uninstallation

- **WHEN** user executes `openspec completion uninstall` without specifying a shell
- **THEN** detect current shell and uninstall completion for that shell

#### Scenario: Not installed

- **WHEN** attempting to uninstall completion that isn't installed
- **THEN** display error message indicating completion is not installed
- **AND** exit with code 1

### Requirement: Architecture Patterns

The completion implementation SHALL follow clean architecture principles with TypeScript best practices, supporting multiple shells through a plugin-based pattern.

#### Scenario: Shell-specific generators

- **WHEN** implementing completion generators
- **THEN** create generator classes for each shell: `ZshGenerator`, `BashGenerator`, `FishGenerator`, `PowerShellGenerator`
- **AND** implement a common `CompletionGenerator` interface with method:
  - `generate(commands: CommandDefinition[]): string` - Returns complete shell script
- **AND** each generator handles shell-specific syntax, escaping, and patterns
- **AND** all generators consume the same `CommandDefinition[]` from the command registry

#### Scenario: Shell-specific installers

- **WHEN** implementing completion installers
- **THEN** create installer classes for each shell: `ZshInstaller`, `BashInstaller`, `FishInstaller`, `PowerShellInstaller`
- **AND** implement a common `CompletionInstaller` interface with methods:
  - `install(script: string): Promise<InstallationResult>` - Installs completion script
  - `uninstall(): Promise<{ success: boolean; message: string }>` - Removes completion
- **AND** each installer handles shell-specific paths, config files, and installation patterns

#### Scenario: Factory pattern for shell selection

- **WHEN** selecting shell-specific implementation
- **THEN** use `CompletionFactory` class with static methods:
  - `createGenerator(shell: SupportedShell): CompletionGenerator`
  - `createInstaller(shell: SupportedShell): CompletionInstaller`
- **AND** factory uses switch statements with TypeScript exhaustiveness checking
- **AND** adding new shell requires updating `SupportedShell` type and factory cases

#### Scenario: Dynamic completion providers

- **WHEN** implementing dynamic completions
- **THEN** create a `CompletionProvider` class that encapsulates project discovery logic
- **AND** implement methods:
  - `getChangeIds(): Promise<string[]>` - Discovers active change IDs
  - `getSpecIds(): Promise<string[]>` - Discovers spec IDs
  - `isOpenSpecProject(): boolean` - Checks if current directory is OpenSpec-enabled
- **AND** implement caching with 2-second TTL using class properties

#### Scenario: Command registry

- **WHEN** defining completable commands
- **THEN** create a centralized `CommandDefinition` type with properties:
  - `name: string` - Command name
  - `description: string` - Help text
  - `flags: FlagDefinition[]` - Available flags
  - `acceptsPositional: boolean` - Whether command takes positional arguments
  - `positionalType: string` - Type of positional (change-id, spec-id, path, shell)
  - `subcommands?: CommandDefinition[]` - Nested subcommands
- **AND** export a `COMMAND_REGISTRY` constant with all command definitions
- **AND** all generators consume this registry to ensure consistency across shells

#### Scenario: Type-safe shell detection

- **WHEN** implementing shell detection
- **THEN** define a `SupportedShell` type as literal type: `'zsh' | 'bash' | 'fish' | 'powershell'`
- **AND** implement `detectShell()` function in `src/utils/shell-detection.ts`
- **AND** return detected shell or throw error with supported shells list

### Requirement: Testing Support

The completion implementation SHALL be testable with unit and integration tests for all supported shells.

#### Scenario: Mock shell environment

- **WHEN** writing tests for shell detection
- **THEN** allow overriding `$SHELL` and `$PSModulePath` environment variables
- **AND** use dependency injection for file system operations
- **AND** test detection for all four shells independently

#### Scenario: Generator output verification

- **WHEN** testing completion generators
- **THEN** create test suite for each shell generator (zsh, bash, fish, powershell)
- **AND** verify generated scripts contain expected patterns for that shell
- **AND** test that command registry is properly consumed
- **AND** ensure dynamic completion placeholders are present
- **AND** verify shell-specific syntax and escaping

#### Scenario: Installer simulation

- **WHEN** testing installation logic
- **THEN** create test suite for each shell installer
- **AND** use temporary test directories instead of actual home directories
- **AND** verify file creation without modifying real shell configurations
- **AND** test path resolution logic independently
- **AND** mock file system operations to avoid side effects

#### Scenario: Cross-shell consistency

- **WHEN** testing completion behavior
- **THEN** verify all shells support the same commands and flags
- **AND** verify dynamic completions work consistently across shells
- **AND** ensure error messages are consistent across shells


================================================
FILE: openspec/changes/archive/2025-12-24-add-artifact-graph-core/design.md
================================================
## Context

This implements "Slice 1: What's Ready?" from the artifact POC analysis. The core insight is using the filesystem as a database - artifact completion is detected by file existence, making the system stateless and version-control friendly.

This module will coexist with the current OpenSpec system as a parallel capability, potentially enabling future migration or integration.

## Goals / Non-Goals

**Goals:**
- Pure dependency graph logic with no side effects
- Stateless state detection (rescan filesystem each query)
- Support glob patterns for multi-file artifacts (e.g., `specs/*.md`)
- Load artifact definitions from YAML schemas
- Calculate topological build order
- Determine "ready" artifacts based on dependency completion

**Non-Goals:**
- CLI commands (Slice 4)
- Multi-change management (Slice 2)
- Template resolution and enrichment (Slice 3)
- Agent integration or Claude commands
- Replacing existing OpenSpec functionality

## Decisions

### Decision: Filesystem as Database
Use file existence for state detection rather than a separate state file.

**Rationale:**
- Stateless - no state corruption possible
- Git-friendly - state derived from committed files
- Simple - no sync issues between state file and actual files

**Alternatives considered:**
- JSON/SQLite state file: More complex, sync issues, not git-friendly
- Git metadata: Too coupled to git, complex implementation

### Decision: Kahn's Algorithm for Topological Sort
Use Kahn's algorithm for computing build order.

**Rationale:**
- Well-understood, O(V+E) complexity
- Naturally detects cycles during execution
- Produces a stable, deterministic order

### Decision: Glob Pattern Support
Support glob patterns like `specs/*.md` in artifact `generates` field.

**Rationale:**
- Allows multiple files to satisfy a single artifact requirement
- Common pattern for spec directories with multiple files
- Uses standard glob syntax

### Decision: Immutable Completed Set
Represent completion state as an immutable Set of completed artifact IDs.

**Rationale:**
- Functional style, easier to reason about
- State derived fresh each query, no mutation needed
- Clear separation between graph structure and runtime state
- Filesystem can only detect binary existence (complete vs not complete)

**Note:** `inProgress` and `failed` states are deferred to future slices. They would require external state tracking (e.g., a status file) since file existence alone cannot distinguish these states.

### Decision: Zod for Schema Validation
Use Zod for validating YAML schema structure and deriving TypeScript types.

**Rationale:**
- Already a project dependency (v4.0.17) used in `src/core/schemas/`
- Type inference via `z.infer<>` - single source of truth for types
- Runtime validation with detailed error messages
- Consistent with existing project patterns (`base.schema.ts`, `config-schema.ts`)

**Alternatives considered:**
- Manual validation: More code, error-prone, no type inference
- JSON Schema: Would require additional dependency, less TypeScript integration
- io-ts: Not already in project, steeper learning curve

### Decision: Two-Level Schema Resolution
Schemas resolve from global user data directory, falling back to package built-ins.

**Resolution order:**
1. `${XDG_DATA_HOME:-~/.local/share}/openspec/schemas/<name>.yaml` - Global user override
2. `<package>/schemas/<name>.yaml` - Built-in defaults

**Rationale:**
- Follows XDG Base Directory Specification (schemas are data, not config)
- Mirrors existing `getGlobalConfigDir()` pattern in `src/core/global-paths.ts`
- Built-ins baked into package, never auto-copied
- Users customize by creating files in global data dir
- Simple - no project-level overrides (can add later if needed)

**XDG compliance:**
- Uses `XDG_DATA_HOME` env var when set (all platforms)
- Unix/macOS fallback: `~/.local/share/openspec/`
- Windows fallback: `%LOCALAPPDATA%/openspec/`

**Alternatives considered:**
- Project-level overrides: Added complexity, not needed initially
- Auto-copy to user space: Creates drift, harder to update defaults
- Config directory (`XDG_CONFIG_HOME`): Schemas are workflow definitions (data), not user preferences (config)

### Decision: Template Field Parsed But Not Resolved
The `template` field is required in schema YAML for completeness, but template resolution is deferred to Slice 3.

**Rationale:**
- Slice 1 focuses on "What's Ready?" - dependency and completion queries only
- Template paths are validated syntactically (non-empty string) but not resolved
- Keeps Slice 1 focused and independently testable

### Decision: Cycle Error Format
Cycle errors list all artifact IDs in the cycle for easy debugging.

**Format:** `"Cyclic dependency detected: A â†’ B â†’ C â†’ A"`

**Rationale:**
- Shows the full cycle path, not just that a cycle exists
- Actionable - developer can see exactly which artifacts to fix
- Consistent with Kahn's algorithm which naturally identifies cycle participants

## Data Structures

**Zod Schemas (source of truth):**

```typescript
import { z } from 'zod';

// Artifact definition schema
export const ArtifactSchema = z.object({
  id: z.string().min(1, 'Artifact ID is required'),
  generates: z.string().min(1),      // e.g., "proposal.md" or "specs/*.md"
  description: z.string(),
  template: z.string(),              // path to template file
  requires: z.array(z.string()).default([]),
});

// Full schema YAML structure
export const SchemaYamlSchema = z.object({
  name: z.string().min(1, 'Schema name is required'),
  version: z.number().int().positive(),
  description: z.string().optional(),
  artifacts: z.array(ArtifactSchema).min(1, 'At least one artifact required'),
});

// Derived TypeScript types
export type Artifact = z.infer<typeof ArtifactSchema>;
export type SchemaYaml = z.infer<typeof SchemaYamlSchema>;
```

**Runtime State (not Zod - internal only):**

```typescript
// Slice 1: Simple completion tracking via filesystem
type CompletedSet = Set<string>;

// Return type for blocked query
interface BlockedArtifacts {
  [artifactId: string]: string[];  // artifact â†’ list of unmet dependencies
}

interface ArtifactGraphResult {
  completed: string[];
  ready: string[];
  blocked: BlockedArtifacts;
  buildOrder: string[];
}
```

## File Structure

```
src/core/artifact-graph/
â”œâ”€â”€ index.ts           # Public exports
â”œâ”€â”€ types.ts           # Zod schemas and type definitions
â”œâ”€â”€ graph.ts           # ArtifactGraph class
â”œâ”€â”€ state.ts           # State detection logic
â”œâ”€â”€ resolver.ts        # Schema resolution (global â†’ built-in)
â””â”€â”€ schemas/           # Built-in schema definitions (package level)
    â”œâ”€â”€ spec-driven.yaml   # Default: proposal â†’ specs â†’ design â†’ tasks
    â””â”€â”€ tdd.yaml           # Alternative: tests â†’ implementation â†’ docs
```

**Schema Resolution Paths:**
- Global user override: `${XDG_DATA_HOME:-~/.local/share}/openspec/schemas/<name>.yaml`
- Package built-in: `src/core/artifact-graph/schemas/<name>.yaml` (bundled with package)

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Glob pattern edge cases | Use well-tested glob library (fast-glob or similar) |
| Cycle detection | Kahn's algorithm naturally fails on cycles; provide clear error |
| Schema evolution | Version field in schema, validate on load |

## Open Questions

None - all questions resolved in Decisions section.



================================================
FILE: openspec/changes/archive/2025-12-24-add-artifact-graph-core/proposal.md
================================================
## Why

The current OpenSpec system relies on conventions and AI inference for artifact ordering. A formal artifact graph with dependency awareness would enable deterministic "what's ready?" queries, making the system more predictable and enabling future features like automated pipeline execution.

## What Changes

- Add `ArtifactGraph` class to model artifacts as a DAG with dependency relationships
- Add `ArtifactState` type to track completion status (completed, in_progress, failed)
- Add filesystem-based state detection using file existence and glob patterns
- Add schema YAML parser to load artifact definitions
- Implement topological sort (Kahn's algorithm) for build order calculation
- Add `getNextArtifacts()` to find artifacts ready for creation

## Impact

- Affected specs: New `artifact-graph` capability
- Affected code: `src/core/artifact-graph/` (new directory)
- No changes to existing functionality - this is a parallel module



================================================
FILE: openspec/changes/archive/2025-12-24-add-artifact-graph-core/tasks.md
================================================
## 1. Type Definitions
- [x] 1.1 Create `src/core/artifact-graph/types.ts` with Zod schemas (`ArtifactSchema`, `SchemaYamlSchema`) and inferred types via `z.infer<>`
- [x] 1.2 Define `CompletedSet` (Set<string>), `BlockedArtifacts`, and `ArtifactGraphResult` types for runtime state

## 2. Schema Parser
- [x] 2.1 Create `src/core/artifact-graph/schema.ts` with YAML loading and Zod validation via `.safeParse()`
- [x] 2.2 Implement dependency reference validation (ensure `requires` references valid artifact IDs)
- [x] 2.3 Implement duplicate artifact ID detection
- [x] 2.4 Add cycle detection during schema load (error format: "Cyclic dependency detected: A â†’ B â†’ C â†’ A")

## 3. Artifact Graph Core
- [x] 3.1 Create `src/core/artifact-graph/graph.ts` with ArtifactGraph class
- [x] 3.2 Implement `fromYaml(path)` - load graph from schema file
- [x] 3.3 Implement `getBuildOrder()` - topological sort via Kahn's algorithm
- [x] 3.4 Implement `getArtifact(id)` - retrieve single artifact definition
- [x] 3.5 Implement `getAllArtifacts()` - list all artifacts

## 4. State Detection
- [x] 4.1 Create `src/core/artifact-graph/state.ts` with state detection logic
- [x] 4.2 Implement file existence checking for simple paths
- [x] 4.3 Implement glob pattern matching for multi-file artifacts
- [x] 4.4 Implement `detectCompleted(graph, changeDir)` - scan filesystem and return CompletedSet
- [x] 4.5 Handle missing changeDir gracefully (return empty CompletedSet)

## 5. Ready Calculation
- [x] 5.1 Implement `getNextArtifacts(graph, completed)` - find artifacts with all deps completed
- [x] 5.2 Implement `isComplete(graph, completed)` - check if all artifacts done
- [x] 5.3 Implement `getBlocked(graph, completed)` - return BlockedArtifacts map (artifact â†’ unmet deps)

## 6. Schema Resolution
- [x] 6.1 Create `src/core/artifact-graph/resolver.ts` with schema resolution logic
- [x] 6.2 Add `getGlobalDataDir()` to `src/core/global-config.ts` (XDG_DATA_HOME with platform fallbacks)
- [x] 6.3 Implement `resolveSchema(name)` - global (`${XDG_DATA_HOME}/openspec/schemas/`) â†’ built-in fallback

## 7. Built-in Schemas
- [x] 7.1 Create `src/core/artifact-graph/schemas/spec-driven.yaml` (default: proposal â†’ specs â†’ design â†’ tasks)
- [x] 7.2 Create `src/core/artifact-graph/schemas/tdd.yaml` (alternative: tests â†’ implementation â†’ docs)

## 8. Integration
- [x] 8.1 Create `src/core/artifact-graph/index.ts` with public exports

## 9. Testing
- [x] 9.1 Test: Parse valid schema YAML returns correct artifact graph
- [x] 9.2 Test: Parse invalid schema (missing fields) throws descriptive error
- [x] 9.3 Test: Duplicate artifact IDs throws error
- [x] 9.4 Test: Invalid `requires` reference throws error identifying the invalid ID
- [x] 9.5 Test: Cycle in schema throws error listing cycle path (e.g., "A â†’ B â†’ C â†’ A")
- [x] 9.6 Test: Compute build order returns correct topological ordering (linear chain)
- [x] 9.7 Test: Compute build order handles diamond dependencies correctly
- [x] 9.8 Test: Independent artifacts return in stable order
- [x] 9.9 Test: Empty/missing changeDir returns empty CompletedSet
- [x] 9.10 Test: File existence marks artifact as completed
- [x] 9.11 Test: Glob pattern specs/*.md detected as complete when files exist
- [x] 9.12 Test: Glob pattern with empty directory not marked complete
- [x] 9.13 Test: getNextArtifacts returns only root artifacts when nothing completed
- [x] 9.14 Test: getNextArtifacts includes artifact when all deps completed
- [x] 9.15 Test: getBlocked returns artifact with all unmet dependencies listed
- [x] 9.16 Test: isComplete() returns true when all artifacts completed
- [x] 9.17 Test: isComplete() returns false when some artifacts incomplete
- [x] 9.18 Test: Schema resolution finds global override before built-in
- [x] 9.19 Test: Schema resolution falls back to built-in when no global



================================================
FILE: openspec/changes/archive/2025-12-24-add-artifact-graph-core/specs/artifact-graph/spec.md
================================================
## ADDED Requirements

### Requirement: Schema Loading
The system SHALL load artifact graph definitions from YAML schema files.

#### Scenario: Valid schema loaded
- **WHEN** a valid schema YAML file is provided
- **THEN** the system returns an ArtifactGraph with all artifacts and dependencies

#### Scenario: Invalid schema rejected
- **WHEN** a schema YAML file is missing required fields
- **THEN** the system throws an error with a descriptive message

#### Scenario: Cyclic dependencies detected
- **WHEN** a schema contains cyclic artifact dependencies
- **THEN** the system throws an error listing the artifact IDs in the cycle

#### Scenario: Invalid dependency reference
- **WHEN** an artifact's `requires` array references a non-existent artifact ID
- **THEN** the system throws an error identifying the invalid reference

#### Scenario: Duplicate artifact IDs rejected
- **WHEN** a schema contains multiple artifacts with the same ID
- **THEN** the system throws an error identifying the duplicate

### Requirement: Build Order Calculation
The system SHALL compute a valid topological build order for artifacts.

#### Scenario: Linear dependency chain
- **WHEN** artifacts form a linear chain (A â†’ B â†’ C)
- **THEN** getBuildOrder() returns [A, B, C]

#### Scenario: Diamond dependency
- **WHEN** artifacts form a diamond (A â†’ B, A â†’ C, B â†’ D, C â†’ D)
- **THEN** getBuildOrder() returns A before B and C, and D last

#### Scenario: Independent artifacts
- **WHEN** artifacts have no dependencies
- **THEN** getBuildOrder() returns them in a stable order

### Requirement: State Detection
The system SHALL detect artifact completion state by scanning the filesystem.

#### Scenario: Simple file exists
- **WHEN** an artifact generates "proposal.md" and the file exists
- **THEN** the artifact is marked as completed

#### Scenario: Simple file missing
- **WHEN** an artifact generates "proposal.md" and the file does not exist
- **THEN** the artifact is not marked as completed

#### Scenario: Glob pattern with files
- **WHEN** an artifact generates "specs/*.md" and the specs/ directory contains .md files
- **THEN** the artifact is marked as completed

#### Scenario: Glob pattern empty
- **WHEN** an artifact generates "specs/*.md" and the specs/ directory is empty or missing
- **THEN** the artifact is not marked as completed

#### Scenario: Missing change directory
- **WHEN** the change directory does not exist
- **THEN** all artifacts are marked as not completed (empty state)

### Requirement: Ready Artifact Query
The system SHALL identify which artifacts are ready to be created based on dependency completion.

#### Scenario: Root artifacts ready initially
- **WHEN** no artifacts are completed
- **THEN** getNextArtifacts() returns artifacts with no dependencies

#### Scenario: Dependent artifact becomes ready
- **WHEN** an artifact's dependencies are all completed
- **THEN** getNextArtifacts() includes that artifact

#### Scenario: Blocked artifacts excluded
- **WHEN** an artifact has uncompleted dependencies
- **THEN** getNextArtifacts() does not include that artifact

### Requirement: Completion Check
The system SHALL determine when all artifacts in a graph are complete.

#### Scenario: All complete
- **WHEN** all artifacts in the graph are in the completed set
- **THEN** isComplete() returns true

#### Scenario: Partially complete
- **WHEN** some artifacts in the graph are not completed
- **THEN** isComplete() returns false

### Requirement: Blocked Query
The system SHALL identify which artifacts are blocked and return all their unmet dependencies.

#### Scenario: Artifact blocked by single dependency
- **WHEN** artifact B requires artifact A and A is not complete
- **THEN** getBlocked() returns `{ B: ['A'] }`

#### Scenario: Artifact blocked by multiple dependencies
- **WHEN** artifact C requires A and B, and only A is complete
- **THEN** getBlocked() returns `{ C: ['B'] }`

#### Scenario: Artifact blocked by all dependencies
- **WHEN** artifact C requires A and B, and neither is complete
- **THEN** getBlocked() returns `{ C: ['A', 'B'] }`



================================================
FILE: openspec/changes/archive/2025-12-25-add-change-manager/design.md
================================================
## Context

This is Slice 2 of the artifact tracker POC. The goal is to provide utilities for creating change directories programmatically.

**Current state:** No programmatic way to create changes. Users must manually create directories.

**Proposed state:** Utility functions for change creation with name validation.

## Goals / Non-Goals

### Goals
- **Add** `createChange()` function to create change directories
- **Add** `validateChangeName()` function for kebab-case validation
- **Enable** automation (Claude commands, scripts) to create changes

### Non-Goals
- Refactor existing CLI commands (they work fine)
- Create abstraction layers or manager classes
- Change how `ListCommand` or `ChangeCommand` work

## Decisions

### Decision 1: Simple Utility Functions

**Choice**: Add functions to `src/utils/change-utils.ts` - no class.

```typescript
// src/utils/change-utils.ts

export function validateChangeName(name: string): { valid: boolean; error?: string }

export async function createChange(
  projectRoot: string,
  name: string
): Promise<void>
```

**Why**:
- Simple, no abstraction overhead
- Easy to test
- Easy to import where needed
- Matches existing utility patterns in `src/utils/`

**Alternatives considered**:
- ChangeManager class: Rejected - over-engineered for 2 functions
- Add to existing command: Rejected - mixes CLI with reusable logic

### Decision 2: Kebab-Case Validation Pattern

**Choice**: Validate names with `^[a-z][a-z0-9]*(-[a-z0-9]+)*$`

Valid: `add-auth`, `refactor-db`, `add-feature-2`, `refactor`
Invalid: `Add-Auth`, `add auth`, `add_auth`, `-add-auth`, `add-auth-`, `add--auth`

**Why**:
- Filesystem-safe (no special characters)
- URL-safe (for future web UI)
- Consistent with existing change naming in repo

## File Changes

### New Files
- `src/utils/change-utils.ts` - Utility functions
- `src/utils/change-utils.test.ts` - Unit tests

### Modified Files
- None

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Function might not cover all use cases | Start simple, extend if needed |
| Naming conflicts with future work | Using clear, specific function names |



================================================
FILE: openspec/changes/archive/2025-12-25-add-change-manager/proposal.md
================================================
## Why

There's no programmatic way to create a new change directory. Users must manually:
1. Create `openspec/changes/<name>/` directory
2. Create a `proposal.md` file
3. Hope they got the naming right

This is error-prone and blocks automation (e.g., Claude commands, scripts).

**This proposal adds:**
1. `createChange(projectRoot, name)` - Create change directories programmatically
2. `validateChangeName(name)` - Enforce kebab-case naming conventions

## What Changes

### New Utilities

| Function | Description |
|----------|-------------|
| `createChange(projectRoot, name)` | Creates `openspec/changes/<name>/` directory |
| `validateChangeName(name)` | Returns `{ valid: boolean; error?: string }` |

### Name Validation Rules

Pattern: `^[a-z][a-z0-9]*(-[a-z0-9]+)*$`

| Valid | Invalid |
|-------|---------|
| `add-auth` | `Add-Auth` (uppercase) |
| `refactor-db` | `add auth` (spaces) |
| `add-feature-2` | `add_auth` (underscores) |
| `refactor` | `-add-auth` (leading hyphen) |

### Location

New file: `src/utils/change-utils.ts`

Simple utility functions - no class, no abstraction layer.

## Impact

- **Affected specs**: None
- **Affected code**: None (new utilities only)
- **New files**: `src/utils/change-utils.ts`
- **Breaking changes**: None



================================================
FILE: openspec/changes/archive/2025-12-25-add-change-manager/tasks.md
================================================
## Phase 1: Implement Name Validation

- [x] 1.1 Create `src/utils/change-utils.ts`
- [x] 1.2 Implement `validateChangeName()` with kebab-case pattern
- [x] 1.3 Pattern: `^[a-z][a-z0-9]*(-[a-z0-9]+)*$`
- [x] 1.4 Return `{ valid: boolean; error?: string }`
- [x] 1.5 Add test: valid names accepted (`add-auth`, `refactor`, `add-feature-2`)
- [x] 1.6 Add test: uppercase rejected
- [x] 1.7 Add test: spaces rejected
- [x] 1.8 Add test: underscores rejected
- [x] 1.9 Add test: special characters rejected
- [x] 1.10 Add test: leading/trailing hyphens rejected
- [x] 1.11 Add test: consecutive hyphens rejected

## Phase 2: Implement Change Creation

- [x] 2.1 Implement `createChange(projectRoot, name)`
- [x] 2.2 Validate name before creating
- [x] 2.3 Create parent directories if needed (`openspec/changes/`)
- [x] 2.4 Throw if change already exists
- [x] 2.5 Add test: creates directory
- [x] 2.6 Add test: duplicate change throws error
- [x] 2.7 Add test: invalid name throws validation error
- [x] 2.8 Add test: creates parent directories if needed

## Phase 3: Integration

- [x] 3.1 Export functions from `src/utils/index.ts`
- [x] 3.2 Add JSDoc comments
- [x] 3.3 Run all tests to verify no regressions



================================================
FILE: openspec/changes/archive/2025-12-25-add-change-manager/specs/change-creation/spec.md
================================================
## ADDED Requirements

### Requirement: Change Creation
The system SHALL provide a function to create new change directories programmatically.

#### Scenario: Create change
- **WHEN** `createChange(projectRoot, 'add-auth')` is called
- **THEN** the system creates `openspec/changes/add-auth/` directory

#### Scenario: Duplicate change rejected
- **WHEN** `createChange(projectRoot, 'add-auth')` is called and `openspec/changes/add-auth/` already exists
- **THEN** the system throws an error indicating the change already exists

#### Scenario: Creates parent directories if needed
- **WHEN** `createChange(projectRoot, 'add-auth')` is called and `openspec/changes/` does not exist
- **THEN** the system creates the full path including parent directories

#### Scenario: Invalid change name rejected
- **WHEN** `createChange(projectRoot, 'Add Auth')` is called with an invalid name
- **THEN** the system throws a validation error

### Requirement: Change Name Validation
The system SHALL validate change names follow kebab-case conventions.

#### Scenario: Valid kebab-case name accepted
- **WHEN** a change name like `add-user-auth` is validated
- **THEN** validation returns `{ valid: true }`

#### Scenario: Numeric suffixes accepted
- **WHEN** a change name like `add-feature-2` is validated
- **THEN** validation returns `{ valid: true }`

#### Scenario: Single word accepted
- **WHEN** a change name like `refactor` is validated
- **THEN** validation returns `{ valid: true }`

#### Scenario: Uppercase characters rejected
- **WHEN** a change name like `Add-Auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Spaces rejected
- **WHEN** a change name like `add auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Underscores rejected
- **WHEN** a change name like `add_auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Special characters rejected
- **WHEN** a change name like `add-auth!` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Leading hyphen rejected
- **WHEN** a change name like `-add-auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Trailing hyphen rejected
- **WHEN** a change name like `add-auth-` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Consecutive hyphens rejected
- **WHEN** a change name like `add--auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`



================================================
FILE: openspec/changes/archive/2025-12-28-add-artifact-workflow-cli/design.md
================================================
## Context

Slice 4 of the artifact workflow POC. The core functionality (ArtifactGraph, InstructionLoader, change-utils) is complete. This slice adds CLI commands to expose the artifact workflow to users.

**Key constraint**: This is experimental. Commands must be isolated for easy removal if the feature doesn't work out.

## Goals / Non-Goals

- **Goals:**
  - Expose artifact workflow status and instructions via CLI
  - Provide fluid UX with top-level verb commands
  - Support both human-readable and JSON output
  - Enable agents to programmatically query workflow state
  - Keep implementation isolated for easy removal

- **Non-Goals:**
  - Interactive artifact creation wizards (future work)
  - Schema management commands (deferred)
  - Auto-detection of active change (CLI is deterministic, agents infer)

## Decisions

### Command Structure: Top-Level Verbs

Commands are top-level for maximum fluidity:

```
openspec status --change <id>
openspec next --change <id>
openspec instructions <artifact> --change <id>
openspec templates [--schema <name>]
openspec new change <name>
```

**Rationale:**
- Most fluid UX - fewest keystrokes
- Commands are unique enough to avoid conflicts
- Simple mental model for users

**Trade-off accepted:** Slight namespace pollution, but commands are distinct and can be removed cleanly.

### Experimental Isolation

All artifact workflow commands are implemented in a single file:

```
src/commands/artifact-workflow.ts
```

**To remove the feature:**
1. Delete `src/commands/artifact-workflow.ts`
2. Remove ~5 lines from `src/cli/index.ts`

No other files touched, no risk to stable functionality.

### Deterministic CLI with Explicit `--change`

All change-specific commands require `--change <id>`:

```bash
openspec status --change add-auth   # explicit, works
openspec status                      # error: missing --change
```

**Rationale:**
- CLI is pure, testable, no hidden state
- Agents infer change from conversation and pass explicitly
- No config file tracking "active change"
- Consistent with POC design philosophy

### New Change Command Structure

Creating changes uses explicit subcommand:

```bash
openspec new change add-feature
```

**Rationale:**
- `openspec new <name>` is ambiguous (new what?)
- `openspec new change <name>` is clear and extensible
- Can add `openspec new spec <name>` later if needed

### Output Formats

- **Default**: Human-readable text with visual indicators
  - Status: `[x]` done, `[ ]` ready, `[-]` blocked
  - Colors: green (done), yellow (ready), red (blocked)
- **JSON** (`--json`): Machine-readable for scripts and agents

### Error Handling

- Missing `--change`: Error listing available changes
- Unknown change: Error with suggestion
- Unknown artifact: Error listing valid artifacts
- Missing schema: Error with schema resolution details

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Top-level commands pollute namespace | Commands are distinct; isolated for easy removal |
| `status` confused with git | Context (`--change`) makes it clear |
| Feature doesn't work out | Single file deletion removes everything |

## Implementation Notes

- All commands in `src/commands/artifact-workflow.ts`
- Imports from `src/core/artifact-graph/` for all operations
- Uses `getActiveChangeIds()` from `item-discovery.ts` for change listing
- Follows existing CLI patterns (ora spinners, commander.js options)
- Help text marks commands as "Experimental"



================================================
FILE: openspec/changes/archive/2025-12-28-add-artifact-workflow-cli/proposal.md
================================================
## Why

The ArtifactGraph (Slice 1) and InstructionLoader (Slice 3) provide programmatic APIs for artifact-based workflow management. Users currently have no CLI interface to:
- See artifact completion status for a change
- Discover what artifacts are ready to create
- Get enriched instructions for creating artifacts
- Create new changes with proper validation

This proposal adds CLI commands that expose the artifact workflow functionality to users and agents.

## What Changes

- **NEW**: `openspec status --change <id>` shows artifact completion state
- **NEW**: `openspec next --change <id>` shows artifacts ready to create
- **NEW**: `openspec instructions <artifact> --change <id>` outputs enriched template
- **NEW**: `openspec templates [--schema <name>]` shows resolved template paths
- **NEW**: `openspec new change <name>` creates a new change directory

All commands are top-level for fluid UX. They integrate with existing core modules:
- Uses `loadChangeContext()`, `formatChangeStatus()`, `generateInstructions()` from instruction-loader
- Uses `ArtifactGraph`, `detectCompleted()` from artifact-graph
- Uses `createChange()`, `validateChangeName()` from change-utils

**Experimental isolation**: All commands are implemented in a single file (`src/commands/artifact-workflow.ts`) for easy removal if the feature doesn't work out. Help text marks them as experimental.

## Impact

- Affected specs: NEW `cli-artifact-workflow` capability
- Affected code:
  - `src/cli/index.ts` - register new commands
  - `src/commands/artifact-workflow.ts` - new command implementations
- No changes to existing commands or specs
- Builds on completed Slice 1, 2, and 3 implementations



================================================
FILE: openspec/changes/archive/2025-12-28-add-artifact-workflow-cli/tasks.md
================================================
## 1. Core Command Implementation

- [x] 1.1 Create `src/commands/artifact-workflow.ts` with all commands
- [x] 1.2 Implement `status` command with text output
- [x] 1.3 Implement `next` command with text output
- [x] 1.4 Implement `instructions` command with text output
- [x] 1.5 Implement `templates` command with text output
- [x] 1.6 Implement `new change` subcommand using createChange()

## 2. CLI Registration

- [x] 2.1 Register `status` command in `src/cli/index.ts`
- [x] 2.2 Register `next` command in `src/cli/index.ts`
- [x] 2.3 Register `instructions` command in `src/cli/index.ts`
- [x] 2.4 Register `templates` command in `src/cli/index.ts`
- [x] 2.5 Register `new` command group with `change` subcommand

## 3. Output Formatting

- [x] 3.1 Add `--json` flag support to all commands
- [x] 3.2 Add color-coded status indicators (done/ready/blocked)
- [x] 3.3 Add progress spinner for loading operations
- [x] 3.4 Support `--no-color` flag

## 4. Error Handling

- [x] 4.1 Handle missing `--change` parameter with helpful error
- [x] 4.2 Handle unknown change names with list of available changes
- [x] 4.3 Handle unknown artifact names with valid options
- [x] 4.4 Handle schema resolution errors

## 5. Options and Flags

- [x] 5.1 Add `--schema` option for custom schema selection
- [x] 5.2 Add `--description` option to `new change` command
- [x] 5.3 Ensure options follow existing CLI patterns

## 6. Testing

- [x] 6.1 Add smoke tests for each command
- [x] 6.2 Test error cases (missing change, unknown artifact)
- [x] 6.3 Test JSON output format
- [x] 6.4 Test with different schemas

## 7. Documentation

- [x] 7.1 Add help text for all commands marked as "Experimental"
- [ ] 7.2 Update AGENTS.md with new commands (post-archive)



================================================
FILE: openspec/changes/archive/2025-12-28-add-artifact-workflow-cli/specs/cli-artifact-workflow/spec.md
================================================
# cli-artifact-workflow Specification

## Purpose
CLI commands for artifact workflow operations, exposing the artifact graph and instruction loader functionality to users and agents. Commands are top-level for fluid UX and implemented in isolation for easy removal.

## ADDED Requirements

### Requirement: Status Command
The system SHALL display artifact completion status for a change.

#### Scenario: Show status with all states
- **WHEN** user runs `openspec status --change <id>`
- **THEN** the system displays each artifact with status indicator:
  - `[x]` for completed artifacts
  - `[ ]` for ready artifacts
  - `[-]` for blocked artifacts (with missing dependencies listed)

#### Scenario: Status shows completion summary
- **WHEN** user runs `openspec status --change <id>`
- **THEN** output includes completion percentage and count (e.g., "2/4 artifacts complete")

#### Scenario: Status JSON output
- **WHEN** user runs `openspec status --change <id> --json`
- **THEN** the system outputs JSON with changeName, schemaName, isComplete, and artifacts array

#### Scenario: Missing change parameter
- **WHEN** user runs `openspec status` without `--change`
- **THEN** the system displays an error with list of available changes

#### Scenario: Unknown change
- **WHEN** user runs `openspec status --change unknown-id`
- **THEN** the system displays an error indicating the change does not exist

### Requirement: Next Command
The system SHALL show which artifacts are ready to be created.

#### Scenario: Show ready artifacts
- **WHEN** user runs `openspec next --change <id>`
- **THEN** the system lists artifacts whose dependencies are all satisfied

#### Scenario: No artifacts ready
- **WHEN** all artifacts are either completed or blocked
- **THEN** the system indicates no artifacts are ready (with explanation)

#### Scenario: All artifacts complete
- **WHEN** all artifacts in the change are completed
- **THEN** the system indicates the change is complete

#### Scenario: Next JSON output
- **WHEN** user runs `openspec next --change <id> --json`
- **THEN** the system outputs JSON array of ready artifact IDs

### Requirement: Instructions Command
The system SHALL output enriched instructions for creating an artifact.

#### Scenario: Show enriched instructions
- **WHEN** user runs `openspec instructions <artifact> --change <id>`
- **THEN** the system outputs:
  - Artifact metadata (ID, output path, description)
  - Template content
  - Dependency status (done/missing)
  - Unlocked artifacts (what becomes available after completion)

#### Scenario: Instructions JSON output
- **WHEN** user runs `openspec instructions <artifact> --change <id> --json`
- **THEN** the system outputs JSON matching ArtifactInstructions interface

#### Scenario: Unknown artifact
- **WHEN** user runs `openspec instructions unknown-artifact --change <id>`
- **THEN** the system displays an error listing valid artifact IDs for the schema

#### Scenario: Artifact with unmet dependencies
- **WHEN** user requests instructions for a blocked artifact
- **THEN** the system displays instructions with a warning about missing dependencies

### Requirement: Templates Command
The system SHALL show resolved template paths for all artifacts in a schema.

#### Scenario: List template paths with default schema
- **WHEN** user runs `openspec templates`
- **THEN** the system displays each artifact with its resolved template path using the default schema

#### Scenario: List template paths with custom schema
- **WHEN** user runs `openspec templates --schema tdd`
- **THEN** the system displays template paths for the specified schema

#### Scenario: Templates JSON output
- **WHEN** user runs `openspec templates --json`
- **THEN** the system outputs JSON mapping artifact IDs to template paths

#### Scenario: Template resolution source
- **WHEN** displaying template paths
- **THEN** the system indicates whether each template is from user override or package built-in

### Requirement: New Change Command
The system SHALL create new change directories with validation.

#### Scenario: Create valid change
- **WHEN** user runs `openspec new change add-feature`
- **THEN** the system creates `openspec/changes/add-feature/` directory

#### Scenario: Invalid change name
- **WHEN** user runs `openspec new change "Add Feature"` with invalid name
- **THEN** the system displays validation error with guidance

#### Scenario: Duplicate change name
- **WHEN** user runs `openspec new change existing-change` for an existing change
- **THEN** the system displays an error indicating the change already exists

#### Scenario: Create with description
- **WHEN** user runs `openspec new change add-feature --description "Add new feature"`
- **THEN** the system creates the change directory with description in README.md

### Requirement: Schema Selection
The system SHALL support custom schema selection for workflow commands.

#### Scenario: Default schema
- **WHEN** user runs workflow commands without `--schema`
- **THEN** the system uses the "spec-driven" schema

#### Scenario: Custom schema
- **WHEN** user runs `openspec status --change <id> --schema tdd`
- **THEN** the system uses the specified schema for artifact graph

#### Scenario: Unknown schema
- **WHEN** user specifies an unknown schema
- **THEN** the system displays an error listing available schemas

### Requirement: Output Formatting
The system SHALL provide consistent output formatting.

#### Scenario: Color output
- **WHEN** terminal supports colors
- **THEN** status indicators use colors: green (done), yellow (ready), red (blocked)

#### Scenario: No color output
- **WHEN** `--no-color` flag is used or NO_COLOR environment variable is set
- **THEN** output uses text-only indicators without ANSI colors

#### Scenario: Progress indication
- **WHEN** loading change state takes time
- **THEN** the system displays a spinner during loading

### Requirement: Experimental Isolation
The system SHALL implement artifact workflow commands in isolation for easy removal.

#### Scenario: Single file implementation
- **WHEN** artifact workflow feature is implemented
- **THEN** all commands are in `src/commands/artifact-workflow.ts`

#### Scenario: Help text marking
- **WHEN** user runs `--help` on any artifact workflow command
- **THEN** help text indicates the command is experimental



================================================
FILE: openspec/changes/archive/2025-12-28-add-instruction-loader/design.md
================================================
## Context

This is Slice 3 of the artifact-graph POC. We have:
- `ArtifactGraph` class with graph operations (Slice 1)
- `detectCompleted()` for filesystem-based state detection (Slice 1)
- `resolveSchema()` for XDG schema resolution (Slice 1)
- `createChange()` and `validateChangeName()` utilities (Slice 2)

After `restructure-schema-directories` is implemented, schemas will be self-contained directories:
```
schemas/<name>/
â”œâ”€â”€ schema.yaml
â””â”€â”€ templates/
    â””â”€â”€ *.md
```

This proposal adds template loading and instruction enrichment on top of that structure.

## Goals / Non-Goals

**Goals:**
- Load templates from schema directories
- Enrich templates with change-specific context (dependency status)
- Format change status for CLI output

**Non-Goals:**
- Template authoring UI
- Dynamic template compilation/execution
- Caching (keep it stateless like the rest)

## Decisions

### 1. Pure functions over classes

Follow the pattern in `resolver.ts` and `state.ts`. Use a simple `ChangeContext` interface with pure functions:

```typescript
interface ChangeContext {
  changeName: string;
  changeDir: string;
  schemaName: string;
  graph: ArtifactGraph;
  completed: CompletedSet;
}

function loadChangeContext(projectRoot: string, changeName: string, schemaName?: string): ChangeContext
function loadTemplate(schemaName: string, templatePath: string): string
function getInstructions(artifactId: string, context: ChangeContext): string
function formatStatus(context: ChangeContext): string
```

**Why:** Matches existing codebase patterns. Easier to test. No hidden state.

### 2. Template resolution from schema directory

Templates are loaded from the schema's `templates/` subdirectory:

```typescript
function loadTemplate(schemaName: string, templatePath: string): string {
  const schemaDir = getSchemaDir(schemaName);  // From resolver.ts
  const fullPath = path.join(schemaDir, 'templates', templatePath);
  return fs.readFileSync(fullPath, 'utf-8');
}
```

Resolution is handled by `getSchemaDir()` which already checks user override â†’ package built-in.

**Why:** Leverages existing schema resolution. Templates are co-located with schemas.

### 3. Template path from artifact definition

The artifact's `template` field is a path relative to the schema's `templates/` directory:

```yaml
artifacts:
  - id: proposal
    template: "proposal.md"  # â†’ schemas/<schema>/templates/proposal.md
```

**Why:** Explicit, simple, no magic.

### 4. Minimal context injection

Templates are markdown. Injection prepends a header section with context:

```markdown
---
change: add-auth
artifact: proposal
schema: spec-driven
output: openspec/changes/add-auth/proposal.md
---

## Dependencies
- [x] (none - this is a root artifact)

## Next Steps
After creating this artifact, you can work on: design, specs

---

[original template content...]
```

**Why:** Simple string concatenation. No template engine dependency. Clear separation.

### 5. Status output format

```markdown
## Change: add-auth (spec-driven)

| Artifact | Status | Output |
|----------|--------|--------|
| proposal | done | proposal.md |
| specs | ready | specs/*.md |
| design | blocked (needs: proposal) | design.md |
| tasks | blocked (needs: specs, design) | tasks.md |
```

**Why:** Markdown table is readable in terminal and docs. Matches CLI output style.

## File Structure

```
src/core/artifact-graph/
â”œâ”€â”€ index.ts              # Add new exports
â”œâ”€â”€ template.ts           # NEW: Template loading
â”œâ”€â”€ context.ts            # NEW: ChangeContext loading
â””â”€â”€ instructions.ts       # NEW: Enrichment and formatting
```

## Risks / Trade-offs

**Dependency on restructure-schema-directories:**
- This proposal requires the schema restructure to be done first
- Mitigation: Clear dependency documented, implement in order

**No template engine:**
- Pro: Zero dependencies, simple code
- Con: Limited expressiveness
- Mitigation: Current use case only needs static templates + header injection

## Migration Plan

N/A - new capability, no existing code to migrate.

## Open Questions

None.



================================================
FILE: openspec/changes/archive/2025-12-28-add-instruction-loader/proposal.md
================================================
## Why

Slice 1 (artifact-graph) provides graph operations and state detection. Slice 2 (change-utils) provides change creation. We now need the ability to load templates for artifacts and enrich them with change-specific context so users/agents know what to create next.

## What Changes

- Add template resolution from schema directories (uses structure from `restructure-schema-directories`)
- Add instruction enrichment that injects change context into templates
- Add status formatting for CLI output
- New `instruction-loader` capability

## Dependencies

- Requires `restructure-schema-directories` to be implemented first (schemas as directories with co-located templates)

## Impact

- Affected specs: New `instruction-loader` spec
- Affected code: `src/core/artifact-graph/` (new files)
- Builds on: `artifact-graph` (Slice 1), uses `ArtifactGraph`, `detectCompleted`, `resolveSchema`



================================================
FILE: openspec/changes/archive/2025-12-28-add-instruction-loader/tasks.md
================================================
# Tasks

## Implementation Tasks

- [x] Create `instruction-loader` spec in `openspec/specs/instruction-loader/spec.md`
- [x] Implement `loadTemplate` function to load templates from schema directories
- [x] Implement `loadChangeContext` function to combine graph and completion state
- [x] Implement `generateInstructions` function to enrich templates with change context
- [x] Implement `formatChangeStatus` function for readable status output
- [x] Export new functions from `src/core/artifact-graph/index.ts`
- [x] Add comprehensive tests in `test/core/artifact-graph/instruction-loader.test.ts`
- [x] Verify build passes
- [x] Verify all tests pass



================================================
FILE: openspec/changes/archive/2025-12-28-add-instruction-loader/specs/instruction-loader/spec.md
================================================
# instruction-loader Specification

## Purpose
Load templates from schema directories and enrich them with change-specific context for guiding artifact creation.

## ADDED Requirements

### Requirement: Template Loading
The system SHALL load templates from schema directories.

#### Scenario: Load template from schema directory
- **WHEN** `loadTemplate(schemaName, templatePath)` is called
- **THEN** the system loads the template from `schemas/<schemaName>/templates/<templatePath>`

#### Scenario: Template file not found
- **WHEN** a template file does not exist in the schema's templates directory
- **THEN** the system throws an error with the template path

### Requirement: Change Context Loading
The system SHALL load change context combining graph and completion state.

#### Scenario: Load context for existing change
- **WHEN** `loadChangeContext(projectRoot, changeName)` is called for an existing change
- **THEN** the system returns a context with graph, completed set, schema name, and change info

#### Scenario: Load context with custom schema
- **WHEN** `loadChangeContext(projectRoot, changeName, schemaName)` is called
- **THEN** the system uses the specified schema instead of default

#### Scenario: Load context for non-existent change directory
- **WHEN** `loadChangeContext` is called for a non-existent change directory
- **THEN** the system returns context with empty completed set

### Requirement: Template Enrichment
The system SHALL enrich templates with change-specific context.

#### Scenario: Include artifact metadata
- **WHEN** instructions are generated for an artifact
- **THEN** the output includes change name, artifact ID, schema name, and output path

#### Scenario: Include dependency status
- **WHEN** an artifact has dependencies
- **THEN** the output shows each dependency with completion status (done/missing)

#### Scenario: Include unlocked artifacts
- **WHEN** instructions are generated
- **THEN** the output includes which artifacts become available after this one

#### Scenario: Root artifact indicator
- **WHEN** an artifact has no dependencies
- **THEN** the dependency section indicates this is a root artifact

### Requirement: Status Formatting
The system SHALL format change status as readable output.

#### Scenario: All artifacts completed
- **WHEN** all artifacts are completed
- **THEN** status shows all artifacts as "done"

#### Scenario: Mixed completion status
- **WHEN** some artifacts are completed
- **THEN** status shows completed as "done", ready as "ready", blocked as "blocked"

#### Scenario: Blocked artifact details
- **WHEN** an artifact is blocked
- **THEN** status shows which dependencies are missing

#### Scenario: Include output paths
- **WHEN** status is formatted
- **THEN** each artifact shows its output path pattern



================================================
FILE: openspec/changes/archive/2025-12-28-restructure-schema-directories/design.md
================================================
[Binary file]


================================================
FILE: openspec/changes/archive/2025-12-28-restructure-schema-directories/proposal.md
================================================
## Why

Currently, built-in schemas are embedded as TypeScript objects in `builtin-schemas.ts`. This works for schemas but doesn't support co-located templates. To enable self-contained schema packages (schema + templates together), we need to restructure schemas as directories.

## What Changes

- **BREAKING (internal):** Move built-in schemas from embedded TS objects to actual directory structure
- Schemas become directories containing `schema.yaml` + `templates/`
- Update `resolveSchema()` to load from directory structure
- Remove `builtin-schemas.ts` (replaced by file-based schemas)
- Update resolution to check user dir â†’ package dir

## Impact

- Affected specs: `artifact-graph` (schema resolution changes)
- Affected code:
  - Remove `src/core/artifact-graph/builtin-schemas.ts`
  - Update `src/core/artifact-graph/resolver.ts`
  - Add `schemas/` directory at package root
- No external API changes (resolution still returns `SchemaYaml`)



================================================
FILE: openspec/changes/archive/2025-12-28-restructure-schema-directories/tasks.md
================================================
## 1. Create Schema Directories

- [ ] 1.1 Create `schemas/` directory at package root
- [ ] 1.2 Create `schemas/spec-driven/schema.yaml` from `SPEC_DRIVEN_SCHEMA`
- [ ] 1.3 Create `schemas/spec-driven/templates/` with placeholder templates
- [ ] 1.4 Create `schemas/tdd/schema.yaml` from `TDD_SCHEMA`
- [ ] 1.5 Create `schemas/tdd/templates/` with placeholder templates

## 2. Update Schema Resolution

- [ ] 2.1 Add `getPackageSchemasDir()` function using `import.meta.url`
- [ ] 2.2 Add `getSchemaDir(name)` to resolve schema directory path
- [ ] 2.3 Update `resolveSchema()` to load from directory structure
- [ ] 2.4 Update `listSchemas()` to scan directories instead of object keys
- [ ] 2.5 Add tests for user override resolution
- [ ] 2.6 Add tests for built-in fallback

## 3. Cleanup

- [ ] 3.1 Remove `builtin-schemas.ts`
- [ ] 3.2 Update `index.ts` exports (remove `BUILTIN_SCHEMAS`, `SPEC_DRIVEN_SCHEMA`, `TDD_SCHEMA`)
- [ ] 3.3 Update any code that imports removed exports

## 4. Package Distribution

- [ ] 4.1 Add `schemas/` to `files` array in `package.json`
- [ ] 4.2 Verify schemas are included in built package

## 5. Fix Template Paths

- [ ] 5.1 Update `template` field in schema.yaml files (remove `templates/` prefix)
- [ ] 5.2 Ensure template paths are relative to schema's templates directory



================================================
FILE: openspec/changes/archive/2025-12-28-restructure-schema-directories/specs/artifact-graph/spec.md
================================================
## MODIFIED Requirements

### Requirement: Schema Loading
The system SHALL load artifact graph definitions from YAML schema files within schema directories.

#### Scenario: Valid schema loaded
- **WHEN** a schema directory contains a valid `schema.yaml` file
- **THEN** the system returns an ArtifactGraph with all artifacts and dependencies

#### Scenario: Invalid schema rejected
- **WHEN** a schema YAML file is missing required fields
- **THEN** the system throws an error with a descriptive message

#### Scenario: Cyclic dependencies detected
- **WHEN** a schema contains cyclic artifact dependencies
- **THEN** the system throws an error listing the artifact IDs in the cycle

#### Scenario: Invalid dependency reference
- **WHEN** an artifact's `requires` array references a non-existent artifact ID
- **THEN** the system throws an error identifying the invalid reference

#### Scenario: Duplicate artifact IDs rejected
- **WHEN** a schema contains multiple artifacts with the same ID
- **THEN** the system throws an error identifying the duplicate

#### Scenario: Schema directory not found
- **WHEN** resolving a schema name that has no corresponding directory
- **THEN** the system throws an error listing available schemas

## ADDED Requirements

### Requirement: Schema Directory Structure
The system SHALL support self-contained schema directories with co-located templates.

#### Scenario: Schema with templates
- **WHEN** a schema directory contains `schema.yaml` and `templates/` subdirectory
- **THEN** artifacts can reference templates relative to the schema's templates directory

#### Scenario: User schema override
- **WHEN** a schema directory exists at `${XDG_DATA_HOME}/openspec/schemas/<name>/`
- **THEN** the system uses that directory instead of the built-in

#### Scenario: Built-in schema fallback
- **WHEN** no user override exists for a schema
- **THEN** the system uses the package built-in schema directory

#### Scenario: List available schemas
- **WHEN** listing schemas
- **THEN** the system returns schema names from both user and package directories



================================================
FILE: openspec/changes/archive/2025-12-29-unify-change-state-model/design.md
================================================
# Design: Unify Change State Model

## Overview

This change fixes two bugs with minimal disruption to the existing system:

1. **View bug**: Empty changes incorrectly shown as "Completed"
2. **Artifact workflow bug**: Commands fail on scaffolded changes

## Key Design Decision: Two Systems, Two Purposes

The task-based and artifact-based systems serve **different purposes** and should coexist:

| System | Purpose | Used By |
|--------|---------|---------|
| **Task Progress** | Track implementation work | `openspec view`, `openspec list` |
| **Artifact Progress** | Track planning/spec work | `openspec status`, `openspec next` |

We do NOT merge these systems. Instead, we fix each to work correctly in its domain.

## Change 1: Fix View Command

### Current Logic (Buggy)

```typescript
// view.ts line 90
if (progress.total === 0 || progress.completed === progress.total) {
  completed.push({ name: entry.name });
}
```

Problem: `total === 0` means "no tasks defined yet", not "all tasks done".

### New Logic

```typescript
if (progress.total === 0) {
  draft.push({ name: entry.name });
} else if (progress.completed === progress.total) {
  completed.push({ name: entry.name });
} else {
  active.push({ name: entry.name, progress });
}
```

### View Output Change

**Before:**
```
Completed Changes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ“ add-feature        (all tasks done - correct)
  âœ“ test-workflow      (no tasks - WRONG)
```

**After:**
```
Draft Changes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â—‹ test-workflow      (no tasks yet)

Active Changes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â—‰ add-scaffold       [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 3/7 tasks

Completed Changes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ“ add-feature        (all tasks done)
```

## Change 2: Fix Artifact Workflow Discovery

### Current Logic (Buggy)

```typescript
// artifact-workflow.ts - validateChangeExists()
const activeChanges = await getActiveChangeIds(projectRoot);
if (!activeChanges.includes(changeName)) {
  throw new Error(`Change '${changeName}' not found...`);
}
```

Problem: `getActiveChangeIds()` requires `proposal.md`, but artifact workflow should work on empty directories to help create the first artifact.

### New Logic

```typescript
async function validateChangeExists(changeName: string, projectRoot: string): Promise<string> {
  const changePath = path.join(projectRoot, 'openspec', 'changes', changeName);

  // Check directory existence directly, not proposal.md
  if (!fs.existsSync(changePath) || !fs.statSync(changePath).isDirectory()) {
    // List available changes for helpful error message
    const entries = await fs.promises.readdir(
      path.join(projectRoot, 'openspec', 'changes'),
      { withFileTypes: true }
    );
    const available = entries
      .filter(e => e.isDirectory() && e.name !== 'archive' && !e.name.startsWith('.'))
      .map(e => e.name);

    if (available.length === 0) {
      throw new Error('No changes found. Create one with: openspec new change <name>');
    }
    throw new Error(`Change '${changeName}' not found. Available:\n  ${available.join('\n  ')}`);
  }

  return changeName;
}
```

### Behavior Change

```bash
# Before
$ openspec new change foo
$ openspec status --change foo
Error: Change 'foo' not found.

# After
$ openspec new change foo
$ openspec status --change foo
Change: foo
Progress: 0/4 artifacts complete

[ ] proposal
[-] specs (blocked by: proposal)
[-] design (blocked by: proposal)
[-] tasks (blocked by: specs, design)
```

## What Stays the Same

1. **`getActiveChangeIds()`** - Still requires `proposal.md` (used by validate, show)
2. **`getArchivedChangeIds()`** - Unchanged
3. **Active/Completed semantics** - Still based on task checkboxes
4. **Validation** - Still requires `proposal.md` to have something to validate

## File Changes

| File | Change |
|------|--------|
| `src/core/view.ts` | Add draft category, fix completion logic |
| `src/commands/artifact-workflow.ts` | Update `validateChangeExists()` to use directory existence |
| `test/commands/artifact-workflow.test.ts` | Add tests for scaffolded changes |

## Testing Strategy

1. **Unit test**: `validateChangeExists()` with scaffolded change
2. **View test**: Verify three categories render correctly
3. **Manual test**: Full workflow from `new change` â†’ `status` â†’ `view`



================================================
FILE: openspec/changes/archive/2025-12-29-unify-change-state-model/proposal.md
================================================
# Proposal: Unify Change State Model

## Problem Statement

Two bugs create inconsistent behavior when working with changes:

### Bug 1: Empty changes shown as "Completed" in view

```typescript
// view.ts line 90
if (progress.total === 0 || progress.completed === progress.total) {
  completed.push({ name: entry.name });  // BUG: total === 0 â‰  completed
}
```

Result: `openspec new change foo && openspec view` shows `foo` as "Completed" when it has no content.

### Bug 2: Artifact workflow commands can't find scaffolded changes

```typescript
// item-discovery.ts - getActiveChangeIds()
const proposalPath = path.join(changesPath, entry.name, 'proposal.md');
await fs.access(proposalPath);  // Only returns changes WITH proposal.md
```

Result: `openspec status --change foo` says "not found" even though the directory exists.

## Root Cause

The system conflates two different concepts:

| Concept | Question | Source of Truth |
|---------|----------|-----------------|
| **Planning Progress** | Are all spec documents created? | File existence (ArtifactGraph) |
| **Implementation Progress** | Is the coding work done? | Task checkboxes (tasks.md) |

## Proposed Solution

### Fix 1: Add "Draft" state to view command

Keep Active/Completed with their existing meanings, but fix the bug:

| State | Criteria | Meaning |
|-------|----------|---------|
| **Draft** | No tasks.md OR `tasks.total === 0` | Still planning |
| **Active** | `tasks.total > 0` AND `completed < total` | Implementing |
| **Completed** | `tasks.total > 0` AND `completed === total` | Done |

### Fix 2: Artifact workflow uses directory existence

Update `validateChangeExists()` to check if the directory exists, not if `proposal.md` exists. This allows the artifact workflow to guide users through creating their first artifact.

### Keep existing discovery functions

`getActiveChangeIds()` continues to require `proposal.md` for backward compatibility with validation and other commands.

## What Changes

| Command | Before | After |
|---------|--------|-------|
| `openspec view` | Empty = "Completed" | Empty = "Draft" |
| `openspec status --change X` | Requires proposal.md | Works on any directory |
| `openspec validate X` | Requires proposal.md | Unchanged (still requires it) |

## Breaking Changes

### Minimal Breaking Change

1. **`openspec view` output**: Empty changes move from "Completed" section to new "Draft" section

### Non-Breaking

- Active/Completed semantics unchanged (still task-based)
- `getActiveChangeIds()` unchanged
- `openspec validate` unchanged
- Archived changes unaffected

## Out of Scope

- Merging task-based and artifact-based progress (they serve different purposes)
- Changing what "Completed" means (it stays = all tasks done)
- Adding artifact progress to view command (separate enhancement)
- Shell tab completions for artifact workflow commands (not yet registered)

## Related Commands Analysis

| Command | Uses `getActiveChangeIds()` | Should include scaffolded? | Change needed? |
|---------|-----------------------------|-----------------------------|----------------|
| `openspec view` | No (reads dirs directly) | Yes â†’ Draft section | **Yes** |
| `openspec list` | No (reads dirs directly) | Yes (shows "No tasks") | No |
| `openspec status/next/instructions` | Yes | Yes | **Yes** |
| `openspec validate` | Yes | No (can't validate empty) | No |
| `openspec show` | Yes | No (nothing to show) | No |
| Tab completions | Yes | Future enhancement | No |

## Success Criteria

1. `openspec new change foo && openspec view` shows `foo` in "Draft" section
2. `openspec new change foo && openspec status --change foo` works
3. Changes with all tasks done still show as "Completed"
4. All existing tests pass



================================================
FILE: openspec/changes/archive/2025-12-29-unify-change-state-model/tasks.md
================================================
# Tasks: Unify Change State Model

## Phase 1: Fix Artifact Workflow Discovery

- [x] Update `validateChangeExists()` in `artifact-workflow.ts` to check directory existence instead of using `getActiveChangeIds()`
- [x] Update error message to list all change directories (not just those with proposal.md)
- [x] Add test for `openspec status --change <scaffolded-change>`
- [x] Add test for `openspec next --change <scaffolded-change>`
- [x] Add test for `openspec instructions proposal --change <scaffolded-change>`

## Phase 2: Fix View Command

- [x] Update `getChangesData()` in `view.ts` to return three categories: draft, active, completed
- [x] Fix completion logic: `total === 0` â†’ draft, not completed
- [x] Add "Draft Changes" section to dashboard rendering
- [x] Update summary to include draft count
- [x] Add test for draft changes appearing correctly in view

## Phase 3: Cleanup and Validation

- [x] Clean up test changes (`test-workflow`, `test-workflow-2`)
- [x] Run full test suite
- [x] Manual test: `openspec new change foo && openspec status --change foo`
- [x] Manual test: `openspec new change foo && openspec view` shows foo in Draft
- [x] Validate with `openspec validate unify-change-state-model --strict`



================================================
FILE: openspec/changes/archive/2025-12-29-unify-change-state-model/specs/cli-artifact-workflow/spec.md
================================================
# cli-artifact-workflow Specification Delta

## MODIFIED Requirements

### Requirement: Status Command

The system SHALL display artifact completion status for a change, including scaffolded (empty) changes.

> **Fixes bug**: Previously required `proposal.md` to exist via `getActiveChangeIds()`.

#### Scenario: Show status with all states

- **WHEN** user runs `openspec status --change <id>`
- **THEN** the system displays each artifact with status indicator:
  - `[x]` for completed artifacts
  - `[ ]` for ready artifacts
  - `[-]` for blocked artifacts (with missing dependencies listed)

#### Scenario: Status shows completion summary

- **WHEN** user runs `openspec status --change <id>`
- **THEN** output includes completion percentage and count (e.g., "2/4 artifacts complete")

#### Scenario: Status JSON output

- **WHEN** user runs `openspec status --change <id> --json`
- **THEN** the system outputs JSON with changeName, schemaName, isComplete, and artifacts array

#### Scenario: Status on scaffolded change

- **WHEN** user runs `openspec status --change <id>` on a change with no artifacts
- **THEN** system displays all artifacts with their status
- **AND** root artifacts (no dependencies) show as ready `[ ]`
- **AND** dependent artifacts show as blocked `[-]`

#### Scenario: Missing change parameter

- **WHEN** user runs `openspec status` without `--change`
- **THEN** the system displays an error with list of available changes
- **AND** includes scaffolded changes (directories without proposal.md)

#### Scenario: Unknown change

- **WHEN** user runs `openspec status --change unknown-id`
- **AND** directory `openspec/changes/unknown-id/` does not exist
- **THEN** the system displays an error listing all available change directories

### Requirement: Next Command

The system SHALL show which artifacts are ready to be created, including for scaffolded changes.

#### Scenario: Show ready artifacts

- **WHEN** user runs `openspec next --change <id>`
- **THEN** the system lists artifacts whose dependencies are all satisfied

#### Scenario: No artifacts ready

- **WHEN** all artifacts are either completed or blocked
- **THEN** the system indicates no artifacts are ready (with explanation)

#### Scenario: All artifacts complete

- **WHEN** all artifacts in the change are completed
- **THEN** the system indicates the change is complete

#### Scenario: Next JSON output

- **WHEN** user runs `openspec next --change <id> --json`
- **THEN** the system outputs JSON array of ready artifact IDs

#### Scenario: Next on scaffolded change

- **WHEN** user runs `openspec next --change <id>` on a change with no artifacts
- **THEN** system shows root artifacts (e.g., "proposal") as ready to create

### Requirement: Instructions Command

The system SHALL output enriched instructions for creating an artifact, including for scaffolded changes.

#### Scenario: Show enriched instructions

- **WHEN** user runs `openspec instructions <artifact> --change <id>`
- **THEN** the system outputs:
  - Artifact metadata (ID, output path, description)
  - Template content
  - Dependency status (done/missing)
  - Unlocked artifacts (what becomes available after completion)

#### Scenario: Instructions JSON output

- **WHEN** user runs `openspec instructions <artifact> --change <id> --json`
- **THEN** the system outputs JSON matching ArtifactInstructions interface

#### Scenario: Unknown artifact

- **WHEN** user runs `openspec instructions unknown-artifact --change <id>`
- **THEN** the system displays an error listing valid artifact IDs for the schema

#### Scenario: Artifact with unmet dependencies

- **WHEN** user requests instructions for a blocked artifact
- **THEN** the system displays instructions with a warning about missing dependencies

#### Scenario: Instructions on scaffolded change

- **WHEN** user runs `openspec instructions proposal --change <id>` on a scaffolded change
- **THEN** system outputs template and metadata for creating the proposal
- **AND** does not require any artifacts to already exist



================================================
FILE: openspec/changes/archive/2025-12-29-unify-change-state-model/specs/cli-view/spec.md
================================================
# cli-view Specification Delta

## ADDED Requirements

### Requirement: Draft Changes Display

The dashboard SHALL display changes without tasks in a separate "Draft" section.

#### Scenario: Draft changes listing

- **WHEN** there are changes with no tasks.md or zero tasks defined
- **THEN** system shows them in a "Draft Changes" section
- **AND** uses a distinct indicator (e.g., `â—‹`) to show draft status

#### Scenario: Draft section ordering

- **WHEN** multiple draft changes exist
- **THEN** system sorts them alphabetically by name

## MODIFIED Requirements

### Requirement: Completed Changes Display

The dashboard SHALL list completed changes in a separate section, only showing changes with ALL tasks completed.

> **Fixes bug**: Previously, changes with `total === 0` were incorrectly shown as completed.

#### Scenario: Completed changes listing

- **WHEN** there are changes with `tasks.total > 0` AND `tasks.completed === tasks.total`
- **THEN** system shows them with checkmark indicators in a dedicated section

#### Scenario: Mixed completion states

- **WHEN** some changes are complete and others active
- **THEN** system separates them into appropriate sections

#### Scenario: Empty changes not completed

- **WHEN** a change has no tasks.md or zero tasks defined
- **THEN** system does NOT show it in "Completed Changes" section
- **AND** shows it in "Draft Changes" section instead

### Requirement: Summary Section

The dashboard SHALL display a summary section with key project metrics, including draft change count.

#### Scenario: Complete summary display

- **WHEN** dashboard is rendered with specs and changes
- **THEN** system shows total number of specifications and requirements
- **AND** shows number of draft changes
- **AND** shows number of active changes in progress
- **AND** shows number of completed changes
- **AND** shows overall task progress percentage

#### Scenario: Empty project summary

- **WHEN** no specs or changes exist
- **THEN** summary shows zero counts for all metrics



================================================
FILE: openspec/changes/archive/2025-12-30-add-antigravity-support/proposal.md
================================================
## Why
Google is rolling out Antigravity, a Windsurf-derived IDE that discovers workflows from `.agent/workflows/*.md`. Today OpenSpec can only scaffold slash commands for Windsurf directories, so Antigravity users cannot run the proposal/apply/archive flows from the IDE.

## What Changes
- Add Antigravity as a selectable native tool in `openspec init` so it creates `.agent/workflows/openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md` with YAML frontmatter containing only a `description` field plus the standard OpenSpec-managed body.
- Ensure `openspec update` refreshes the body of any existing Antigravity workflows inside `.agent/workflows/` without creating missing files, mirroring the Windsurf behavior.
- Share e2e/template coverage confirming the generator writes the proper directory, filename casing, and frontmatter format so Antigravity picks up the workflows.

## Impact
- Affected specs: `specs/cli-init`, `specs/cli-update`
- Expected code: CLI init/update tool registries, slash-command templates, associated tests



================================================
FILE: openspec/changes/archive/2025-12-30-add-antigravity-support/tasks.md
================================================
## 1. CLI init support
- [x] 1.1 Surface Antigravity in the native-tool picker (interactive + `--tools`) so it toggles alongside other IDEs.
- [x] 1.2 Generate `.agent/workflows/openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md` with YAML frontmatter restricted to a single `description` field for each stage and wrap the body in OpenSpec markers.
- [x] 1.3 Confirm workspace scaffolding covers missing directory creation and re-run scenarios so repeated init refreshes the managed block.

## 2. CLI update support
- [x] 2.1 Detect existing Antigravity workflow files during `openspec update` and refresh only the managed body, skipping creation when files are missing.
- [x] 2.2 Ensure update logic preserves the `description` frontmatter block exactly as written by init, including case and spacing, and refreshes body templates alongside other tools.

## 3. Templates and tests
- [x] 3.1 Add shared template entries for Antigravity that reuse the Windsurf copy but target `.agent/workflows` plus the description-only frontmatter requirement.
- [x] 3.2 Expand automated coverage (unit or integration) verifying init and update produce the expected file paths and frontmatter + body markers for Antigravity.



================================================
FILE: openspec/changes/archive/2025-12-30-add-antigravity-support/specs/cli-init/spec.md
================================================
# Delta for CLI Init

## MODIFIED Requirements
### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Antigravity
- **WHEN** the user selects Antigravity during initialization
- **THEN** create `.agent/workflows/openspec-proposal.md`, `.agent/workflows/openspec-apply.md`, and `.agent/workflows/openspec-archive.md`
- **AND** ensure each file begins with YAML frontmatter that contains only a `description: <stage summary>` field followed by the shared OpenSpec workflow instructions wrapped in managed markers
- **AND** populate the workflow body with the same proposal/apply/archive guidance used for other tools so Antigravity behaves like Windsurf while pointing to the `.agent/workflows/` directory

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for CodeBuddy Code
- **WHEN** the user selects CodeBuddy Code during initialization
- **THEN** create `.codebuddy/commands/openspec/proposal.md`, `.codebuddy/commands/openspec/apply.md`, and `.codebuddy/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cline
- **WHEN** the user selects Cline during initialization
- **THEN** create `.clinerules/openspec-proposal.md`, `.clinerules/openspec-apply.md`, and `.clinerules/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Crush
- **WHEN** the user selects Crush during initialization
- **THEN** create `.crush/commands/openspec/proposal.md`, `.crush/commands/openspec/apply.md`, and `.crush/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Factory Droid
- **WHEN** the user selects Factory Droid during initialization
- **THEN** create `.factory/commands/openspec-proposal.md`, `.factory/commands/openspec-apply.md`, and `.factory/commands/openspec-archive.md`
- **AND** populate each file from shared templates that include Factory-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** include the `$ARGUMENTS` placeholder in the template body so droid receives any user-supplied input
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Gemini CLI
- **WHEN** the user selects Gemini CLI during initialization
- **THEN** create `.gemini/commands/openspec/proposal.toml`, `.gemini/commands/openspec/apply.toml`, and `.gemini/commands/openspec/archive.toml`
- **AND** populate each file as TOML that sets a stage-specific `description = "<summary>"` and a multi-line `prompt = """` block with the shared OpenSpec template
- **AND** wrap the OpenSpec managed markers (`<!-- OPENSPEC:START -->` / `<!-- OPENSPEC:END -->`) inside the `prompt` value so `openspec update` can safely refresh the body between markers without touching the TOML framing
- **AND** ensure the slash-command copy matches the existing proposal/apply/archive templates used by other tools

#### Scenario: Generating slash commands for iFlow CLI
- **WHEN** the user selects iFlow CLI during initialization
- **THEN** create `.iflow/commands/openspec-proposal.md`, `.iflow/commands/openspec-apply.md`, and `.iflow/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include YAML frontmatter with `name`, `id`, `category`, and `description` fields for each command
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for RooCode
- **WHEN** the user selects RooCode during initialization
- **THEN** create `.roo/commands/openspec-proposal.md`, `.roo/commands/openspec-apply.md`, and `.roo/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include simple Markdown headings (e.g., `# OpenSpec: Proposal`) without YAML frontmatter
- **AND** wrap the generated content in OpenSpec managed markers where applicable so `openspec update` can safely refresh the commands
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-12-30-add-antigravity-support/specs/cli-update/spec.md
================================================
# Delta for CLI Update

## MODIFIED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones, and ensure the OpenCode archive command accepts change ID arguments.

#### Scenario: Updating slash commands for Antigravity
- **WHEN** `.agent/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh the OpenSpec-managed portion of each file so the workflow copy matches other tools while preserving the existing single-field `description` frontmatter
- **AND** skip creating any missing workflow files during update, mirroring the behavior for Windsurf and other IDEs

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for CodeBuddy Code
- **WHEN** `.codebuddy/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cline
- **WHEN** `.clinerules/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Crush
- **WHEN** `.crush/commands/` contains `openspec/proposal.md`, `openspec/apply.md`, and `openspec/archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Factory Droid
- **WHEN** `.factory/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using the shared Factory templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** ensure the template body retains the `$ARGUMENTS` placeholder so user input keeps flowing into droid
- **AND** update only the content inside the OpenSpec managed markers, leaving any unmanaged notes untouched
- **AND** skip creating missing files during update

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** ensure the archive command includes `$ARGUMENTS` placeholder in frontmatter for accepting change ID arguments

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Codex
- **GIVEN** the global Codex prompt directory contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **WHEN** a user runs `openspec update`
- **THEN** refresh each file using the shared slash-command templates (including placeholder guidance)
- **AND** preserve any unmanaged content outside the OpenSpec marker block
- **AND** skip creation when a Codex prompt file is missing

#### Scenario: Updating slash commands for GitHub Copilot
- **WHEN** `.github/prompts/` contains `openspec-proposal.prompt.md`, `openspec-apply.prompt.md`, and `openspec-archive.prompt.md`
- **THEN** refresh each file using shared templates while preserving the YAML frontmatter
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Gemini CLI
- **WHEN** `.gemini/commands/openspec/` contains `proposal.toml`, `apply.toml`, and `archive.toml`
- **THEN** refresh the body of each file using the shared proposal/apply/archive templates
- **AND** replace only the content between `<!-- OPENSPEC:START -->` and `<!-- OPENSPEC:END -->` markers inside the `prompt = """` block so the TOML framing (`description`, `prompt`) stays intact
- **AND** skip creating any missing `.toml` files during update; only pre-existing Gemini commands are refreshed

#### Scenario: Updating slash commands for iFlow CLI
- **WHEN** `.iflow/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** preserve the YAML frontmatter with `name`, `id`, `category`, and `description` fields
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2025-12-30-fix-cline-workflows-implementation/proposal.md
================================================
## Why
The Cline implementation was architecturally incorrect. According to Cline's official documentation, Cline uses workflows for on-demand automation and rules for behavioral guidelines. The OpenSpec slash commands are procedural workflows (scaffold â†’ implement â†’ archive), not behavioral rules, so they should be placed in `.clinerules/workflows/` instead of `.clinerules/`.

## What Changes
- Update ClineSlashCommandConfigurator to use `.clinerules/workflows/` paths instead of `.clinerules/` paths
- Update all tests to expect the correct workflow file locations
- Update README.md documentation to reflect workflows instead of rules
- **BREAKING**: Existing Cline users will need to re-run `openspec init` to get the corrected workflow files

## Impact
- Affected specs: cli-init, cli-update (corrected Cline workflow paths)
- Affected code: `src/core/configurators/slash/cline.ts`, test files, README.md
- Modified files: `.clinerules/workflows/openspec-*.md` (moved from `.clinerules/openspec-*.md`)



================================================
FILE: openspec/changes/archive/2025-12-30-fix-cline-workflows-implementation/tasks.md
================================================
## 1. Update ClineSlashCommandConfigurator
- [x] Change FILE_PATHS in `src/core/configurators/slash/cline.ts` from `.clinerules/openspec-*.md` to `.clinerules/workflows/openspec-*.md`

## 2. Update Tests
- [x] Update "should refresh existing Cline rule files" test in `test/core/update.test.ts` to use workflow paths
- [x] Update "should create Cline rule files with templates" test in `test/core/init.test.ts` to use workflow paths

## 3. Update Documentation
- [x] Update README.md table to show "Workflows in `.clinerules/workflows/` directory" for Cline

## 4. Validate Changes
- [x] Ensure all tests pass with the new paths
- [x] Verify the change follows OpenSpec conventions



================================================
FILE: openspec/changes/archive/2025-12-30-fix-cline-workflows-implementation/specs/cli-init/spec.md
================================================
# Delta for CLI Init

## MODIFIED Requirements
### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Antigravity
- **WHEN** the user selects Antigravity during initialization
- **THEN** create `.agent/workflows/openspec-proposal.md`, `.agent/workflows/openspec-apply.md`, and `.agent/workflows/openspec-archive.md`
- **AND** ensure each file begins with YAML frontmatter that contains only a `description: <stage summary>` field followed by the shared OpenSpec workflow instructions wrapped in managed markers
- **AND** populate the workflow body with the same proposal/apply/archive guidance used for other tools so Antigravity behaves like Windsurf while pointing to the `.agent/workflows/` directory

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for CodeBuddy Code
- **WHEN** the user selects CodeBuddy Code during initialization
- **THEN** create `.codebuddy/commands/openspec/proposal.md`, `.codebuddy/commands/openspec/apply.md`, and `.codebuddy/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cline
- **WHEN** the user selects Cline during initialization
- **THEN** create `.clinerules/workflows/openspec-proposal.md`, `.clinerules/workflows/openspec-apply.md`, and `.clinerules/workflows/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Crush
- **WHEN** the user selects Crush during initialization
- **THEN** create `.crush/commands/openspec/proposal.md`, `.crush/commands/openspec/apply.md`, and `.crush/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Factory Droid
- **WHEN** the user selects Factory Droid during initialization
- **THEN** create `.factory/commands/openspec-proposal.md`, `.factory/commands/openspec-apply.md`, and `.factory/commands/openspec-archive.md`
- **AND** populate each file from shared templates that include Factory-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** include the `$ARGUMENTS` placeholder in the template body so droid receives any user-supplied input
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Gemini CLI
- **WHEN** the user selects Gemini CLI during initialization
- **THEN** create `.gemini/commands/openspec/proposal.toml`, `.gemini/commands/openspec/apply.toml`, and `.gemini/commands/openspec/archive.toml`
- **AND** populate each file as TOML that sets a stage-specific `description = "<summary>"` and a multi-line `prompt = """` block with the shared OpenSpec template
- **AND** wrap the OpenSpec managed markers (`<!-- OPENSPEC:START -->` / `<!-- OPENSPEC:END -->`) inside the `prompt` value so `openspec update` can safely refresh the body between markers without touching the TOML framing
- **AND** ensure the slash-command copy matches the existing proposal/apply/archive templates used by other tools

#### Scenario: Generating slash commands for iFlow CLI
- **WHEN** the user selects iFlow CLI during initialization
- **THEN** create `.iflow/commands/openspec-proposal.md`, `.iflow/commands/openspec-apply.md`, and `.iflow/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include YAML frontmatter with `name`, `id`, `category`, and `description` fields for each command
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for RooCode
- **WHEN** the user selects RooCode during initialization
- **THEN** create `.roo/commands/openspec-proposal.md`, `.roo/commands/openspec-apply.md`, and `.roo/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include simple Markdown headings (e.g., `# OpenSpec: Proposal`) without YAML frontmatter
- **AND** wrap the generated content in OpenSpec managed markers where applicable so `openspec update` can safely refresh the commands
- **AND** each template includes instructions for the relevant OpenSpec workflow stage



================================================
FILE: openspec/changes/archive/2025-12-30-fix-cline-workflows-implementation/specs/cli-update/spec.md
================================================
# Delta for CLI Update

## MODIFIED Requirements
### Requirement: Slash Command Updates
The update command SHALL refresh existing slash command files for configured tools without creating new ones, and ensure the OpenCode archive command accepts change ID arguments.

#### Scenario: Updating slash commands for Antigravity
- **WHEN** `.agent/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh the OpenSpec-managed portion of each file so the workflow copy matches other tools while preserving the existing single-field `description` frontmatter
- **AND** skip creating any missing workflow files during update, mirroring the behavior for Windsurf and other IDEs

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for CodeBuddy Code
- **WHEN** `.codebuddy/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cline
- **WHEN** `.clinerules/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Crush
- **WHEN** `.crush/commands/` contains `openspec/proposal.md`, `openspec/apply.md`, and `openspec/archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Factory Droid
- **WHEN** `.factory/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using the shared Factory templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** ensure the template body retains the `$ARGUMENTS` placeholder so user input keeps flowing into droid
- **AND** update only the content inside the OpenSpec managed markers, leaving any unmanaged notes untouched
- **AND** skip creating missing files during update

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** ensure the archive command includes `$ARGUMENTS` placeholder in frontmatter for accepting change ID arguments

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Codex
- **GIVEN** the global Codex prompt directory contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **WHEN** a user runs `openspec update`
- **THEN** refresh each file using the shared slash-command templates (including placeholder guidance)
- **AND** preserve any unmanaged content outside the OpenSpec marker block
- **AND** skip creation when a Codex prompt file is missing

#### Scenario: Updating slash commands for GitHub Copilot
- **WHEN** `.github/prompts/` contains `openspec-proposal.prompt.md`, `openspec-apply.prompt.md`, and `openspec-archive.prompt.md`
- **THEN** refresh each file using shared templates while preserving the YAML frontmatter
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Gemini CLI
- **WHEN** `.gemini/commands/openspec/` contains `proposal.toml`, `apply.toml`, and `archive.toml`
- **THEN** refresh the body of each file using the shared proposal/apply/archive templates
- **AND** replace only the content between `<!-- OPENSPEC:START -->` and `<!-- OPENSPEC:END -->` markers inside the `prompt = """` block so the TOML framing (`description`, `prompt`) stays intact
- **AND** skip creating any missing `.toml` files during update; only pre-existing Gemini commands are refreshed

#### Scenario: Updating slash commands for iFlow CLI
- **WHEN** `.iflow/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** preserve the YAML frontmatter with `name`, `id`, `category`, and `description` fields
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update



================================================
FILE: openspec/changes/archive/2026-01-06-add-agent-schema-selection/proposal.md
================================================
## Why

With per-change schema metadata in place (see `add-per-change-schema-metadata`), agents can now create changes with different workflow schemas. However, the agent skills are still hardcoded to `spec-driven` artifacts and don't offer schema selection to users.

## What Changes

**Scope: Experimental artifact workflow agent skills**

**Depends on:** `add-per-change-schema-metadata` (must be implemented first)

- Update `openspec-new-change` skill to prompt user for schema selection
- Update `openspec-continue-change` skill to work with any schema's artifacts
- Update `openspec-apply-change` skill to handle schema-specific task structures
- Add schema descriptions to help users choose appropriate workflow

## Capabilities

### Modified Capabilities
- `cli-artifact-workflow`: Agent skills support dynamic schema selection

## Impact

- **Affected code**: `src/core/templates/skill-templates.ts`
- **User experience**: Users can choose TDD, spec-driven, or future workflows when starting a change
- **Agent behavior**: Skills read artifact list from schema rather than hardcoding
- **Backward compatible**: Default remains `spec-driven` if user doesn't choose



================================================
FILE: openspec/changes/archive/2026-01-06-add-agent-schema-selection/tasks.md
================================================
## Prerequisites

- [x] 0.1 Implement `add-per-change-schema-metadata` change first

## 1. Schema Discovery

- [x] 1.1 Add CLI command or helper to list schemas with descriptions (for agent use)
- [x] 1.2 Ensure `openspec templates --schema <name>` returns artifact list for any schema

## 2. Update New Change Skill

- [x] 2.1 Add schema selection prompt using AskUserQuestion tool
- [x] 2.2 Present available schemas with descriptions (spec-driven, tdd, etc.)
- [x] 2.3 Pass selected schema to `openspec new change --schema <name>`
- [x] 2.4 Update output to show which schema/workflow was selected

## 3. Update Continue Change Skill

- [x] 3.1 Remove hardcoded artifact references (proposal, specs, design, tasks)
- [x] 3.2 Read artifact list dynamically from `openspec status --json`
- [x] 3.3 Adjust artifact creation guidelines to be schema-agnostic
- [x] 3.4 Handle schema-specific artifact types (e.g., TDD's `tests` artifact)

## 4. Update Apply Change Skill

- [x] 4.1 Make task detection work with different schema structures
- [x] 4.2 Adjust context file reading for schema-specific artifacts

## 5. Documentation

- [x] 5.1 Add schema descriptions to help text or skill instructions
- [x] 5.2 Document when to use each schema (TDD for bug fixes, spec-driven for features, etc.)



================================================
FILE: openspec/changes/archive/2026-01-06-add-per-change-schema-metadata/design.md
================================================
## Context

The experimental artifact workflow supports multiple schemas (`spec-driven`, `tdd`), but schema selection must be passed on every command. This creates friction for agents and users.

We need a lightweight metadata file to persist the schema choice per change.

## Goals / Non-Goals

**Goals:**
- Store schema choice once at change creation
- Auto-detect schema in experimental workflow commands
- Maintain backward compatibility (no metadata = default)
- Validate metadata with Zod schema

**Non-Goals:**
- Migrate existing changes (they use default)
- Extend to legacy commands
- Store additional metadata beyond schema (keep minimal for now)

## Decisions

### Decision: Zod Schema Design

The metadata file (`.openspec.yaml`) will be validated with this Zod schema:

```typescript
// src/core/artifact-graph/types.ts (or new metadata.ts)

import { z } from 'zod';
import { listSchemas } from './resolver.js';

/**
 * Schema for per-change metadata stored in .openspec.yaml
 */
export const ChangeMetadataSchema = z.object({
  // Required: which workflow schema this change uses
  schema: z.string().min(1, { message: 'schema is required' }).refine(
    (val) => listSchemas().includes(val),
    (val) => ({ message: `Unknown schema '${val}'. Available: ${listSchemas().join(', ')}` })
  ),

  // Optional: creation timestamp (ISO date string)
  created: z.string().regex(/^\d{4}-\d{2}-\d{2}$/, {
    message: 'created must be YYYY-MM-DD format'
  }).optional(),
});

export type ChangeMetadata = z.infer<typeof ChangeMetadataSchema>;
```

**Rationale:**
- `schema` is required and validated against available schemas at parse time
- `created` is optional, ISO date format for consistency
- Minimal fields - can extend later without breaking existing files
- Follows existing codebase pattern (see `ArtifactSchema`, `SchemaYamlSchema`)

### Decision: File Location and Format

**Location:** `openspec/changes/<name>/.openspec.yaml`

**Format:**
```yaml
schema: tdd
created: 2025-01-05
```

**Alternatives considered:**
- `change.yaml` - less hidden, but clutters directory
- Frontmatter in `proposal.md` - couples to proposal existence
- `openspec.json` - YAML matches existing schema files

### Decision: Read/Write Functions

```typescript
// src/utils/change-metadata.ts

import * as fs from 'node:fs';
import * as path from 'node:path';
import * as yaml from 'yaml';
import { ChangeMetadataSchema, type ChangeMetadata } from '../core/artifact-graph/types.js';

const METADATA_FILENAME = '.openspec.yaml';

export function writeChangeMetadata(
  changeDir: string,
  metadata: ChangeMetadata
): void {
  // Validate before writing
  const validated = ChangeMetadataSchema.parse(metadata);
  const content = yaml.stringify(validated);
  fs.writeFileSync(path.join(changeDir, METADATA_FILENAME), content);
}

export function readChangeMetadata(
  changeDir: string
): ChangeMetadata | null {
  const metaPath = path.join(changeDir, METADATA_FILENAME);

  if (!fs.existsSync(metaPath)) {
    return null;
  }

  const content = fs.readFileSync(metaPath, 'utf-8');
  const parsed = yaml.parse(content);

  // Validate and return (throws ZodError if invalid)
  return ChangeMetadataSchema.parse(parsed);
}
```

### Decision: Schema Resolution Order

When determining which schema to use:

1. **Explicit `--schema` flag** (highest priority - user override)
2. **`.openspec.yaml` metadata** (persisted choice)
3. **Default `spec-driven`** (fallback)

```typescript
function resolveSchemaForChange(
  changeDir: string,
  explicitSchema?: string
): string {
  if (explicitSchema) return explicitSchema;

  const metadata = readChangeMetadata(changeDir);
  if (metadata?.schema) return metadata.schema;

  return 'spec-driven';
}
```

## Risks / Trade-offs

- **Extra file per change** â†’ Minimal overhead, hidden file
- **YAML parsing dependency** â†’ Already using `yaml` package for schema files
- **Schema validation at read time** â†’ Fail fast with clear error if corrupted

## Migration Plan

No migration needed:
- Existing changes without `.openspec.yaml` continue to work (use default)
- New changes created with `openspec new change --schema X` get metadata file

## Open Questions

- Should `openspec new change` prompt for schema interactively if not specified? (Leaning no - default is fine)



================================================
FILE: openspec/changes/archive/2026-01-06-add-per-change-schema-metadata/proposal.md
================================================
## Why

Currently, the schema (workflow type) must be passed via `--schema` flag on every experimental workflow command. This is repetitive and error-prone. Agents have no way to know which schema a change uses, so they default to `spec-driven` and cannot leverage alternative workflows like `tdd`.

## What Changes

**Scope: Experimental artifact workflow only** (`openspec new change`, `openspec status`, `openspec instructions`, `openspec templates`)

- Store schema choice in `.openspec.yaml` metadata file when creating a change via `openspec new change`
- Auto-detect schema from metadata in experimental workflow commands
- Make `--schema` flag optional (override only, metadata takes precedence)
- Add `--schema` option to `openspec new change` command

**Not affected**: Legacy commands (`openspec validate`, `openspec archive`, `openspec list`, `openspec show`)

## Capabilities

### New Capabilities
- `change-metadata`: Reading/writing per-change metadata files

### Modified Capabilities
- `cli-artifact-workflow`: Commands auto-detect schema from change metadata

## Impact

- **Affected code**: `src/utils/change-utils.ts`, `src/core/artifact-graph/instruction-loader.ts`, `src/commands/artifact-workflow.ts`
- **Agent skills**: Can be simplified - no longer need to pass schema explicitly
- **Backward compatible**: Changes without `.openspec.yaml` fall back to `spec-driven` default
- **Isolation**: All changes contained within experimental workflow code; legacy commands untouched



================================================
FILE: openspec/changes/archive/2026-01-06-add-per-change-schema-metadata/tasks.md
================================================
## 1. Zod Schema and Types

- [x] 1.1 Add `ChangeMetadataSchema` Zod schema to `src/core/artifact-graph/types.ts`
- [x] 1.2 Export `ChangeMetadata` type inferred from schema

## 2. Core Metadata Functions

- [x] 2.1 Create `src/utils/change-metadata.ts` with `writeChangeMetadata()` function
- [x] 2.2 Add `readChangeMetadata()` function with Zod validation
- [x] 2.3 Update `createChange()` to accept optional `schema` param and write metadata

## 3. Auto-Detection in Instruction Loader

- [x] 3.1 Modify `loadChangeContext()` to read schema from `.openspec.yaml`
- [x] 3.2 Make `schemaName` parameter optional (fall back to metadata, then default)

## 4. CLI Updates

- [x] 4.1 Add `--schema <name>` option to `openspec new change` command
- [x] 4.2 Verify existing commands (`status`, `instructions`) work with auto-detection

## 5. Tests

- [x] 5.1 Test `ChangeMetadataSchema` validates correctly (valid/invalid cases)
- [x] 5.2 Test `writeChangeMetadata()` creates valid YAML
- [x] 5.3 Test `readChangeMetadata()` parses and validates schema
- [x] 5.4 Test `loadChangeContext()` auto-detects schema from metadata
- [x] 5.5 Test fallback to default when no metadata exists
- [x] 5.6 Test `--schema` flag overrides metadata



================================================
FILE: openspec/changes/archive/2026-01-06-add-per-change-schema-metadata/specs/cli-artifact-workflow/spec.md
================================================
## ADDED Requirements

### Requirement: Change Metadata

The system SHALL store and validate per-change metadata in `.openspec.yaml` files using a Zod schema.

#### Scenario: Metadata file created with new change

- **WHEN** user runs `openspec new change add-feature --schema tdd`
- **THEN** the system creates `.openspec.yaml` in the change directory
- **AND** the file contains `schema: tdd` and `created: <YYYY-MM-DD>`

#### Scenario: Metadata validated on read

- **WHEN** the system reads `.openspec.yaml`
- **AND** the `schema` field references an unknown schema
- **THEN** the system displays a validation error listing available schemas

#### Scenario: Metadata schema validation

- **WHEN** `.openspec.yaml` contains invalid YAML or missing required fields
- **THEN** the system displays a Zod validation error with details

#### Scenario: Missing metadata file

- **WHEN** a change directory has no `.openspec.yaml` file
- **THEN** the system falls back to the default schema (`spec-driven`)

## MODIFIED Requirements

### Requirement: New Change Command

The system SHALL create new change directories with validation and optional schema metadata.

#### Scenario: Create valid change

- **WHEN** user runs `openspec new change add-feature`
- **THEN** the system creates `openspec/changes/add-feature/` directory
- **AND** creates `.openspec.yaml` with `schema: spec-driven` (default)

#### Scenario: Create change with schema

- **WHEN** user runs `openspec new change add-feature --schema tdd`
- **THEN** the system creates `openspec/changes/add-feature/` directory
- **AND** creates `.openspec.yaml` with `schema: tdd`

#### Scenario: Invalid schema on create

- **WHEN** user runs `openspec new change add-feature --schema unknown`
- **THEN** the system displays an error listing available schemas
- **AND** does not create the change directory

#### Scenario: Invalid change name

- **WHEN** user runs `openspec new change "Add Feature"` with invalid name
- **THEN** the system displays validation error with guidance

#### Scenario: Duplicate change name

- **WHEN** user runs `openspec new change existing-change` for an existing change
- **THEN** the system displays an error indicating the change already exists

#### Scenario: Create with description

- **WHEN** user runs `openspec new change add-feature --description "Add new feature"`
- **THEN** the system creates the change directory with description in README.md

### Requirement: Schema Selection

The system SHALL support custom schema selection for workflow commands, with automatic detection from change metadata.

#### Scenario: Schema auto-detected from metadata

- **WHEN** user runs `openspec status --change <id>` without `--schema`
- **AND** the change has `.openspec.yaml` with `schema: tdd`
- **THEN** the system uses the `tdd` schema

#### Scenario: Explicit schema overrides metadata

- **WHEN** user runs `openspec status --change <id> --schema spec-driven`
- **AND** the change has `.openspec.yaml` with `schema: tdd`
- **THEN** the system uses `spec-driven` (explicit flag wins)

#### Scenario: Default schema fallback

- **WHEN** user runs workflow commands without `--schema`
- **AND** the change has no `.openspec.yaml` file
- **THEN** the system uses the "spec-driven" schema

#### Scenario: Custom schema via flag

- **WHEN** user runs `openspec status --change <id> --schema tdd`
- **THEN** the system uses the specified schema for artifact graph

#### Scenario: Unknown schema

- **WHEN** user specifies an unknown schema
- **THEN** the system displays an error listing available schemas



================================================
FILE: openspec/changes/archive/2026-01-06-add-specs-apply-command/design.md
================================================
## Context

Currently, delta specs are only applied to main specs when running `openspec archive`. This bundles two concerns:
1. Applying spec changes (delta â†’ main)
2. Archiving the change (move to archive folder)

Users want flexibility to sync specs earlier, especially when iterating. The archive command already contains the reconciliation logic in `buildUpdatedSpec()`.

## Goals / Non-Goals

**Goals:**
- Decouple spec syncing from archiving
- Provide `/opsx:sync` skill for agents to sync specs on demand
- Keep operation idempotent (safe to run multiple times)

**Non-Goals:**
- Tracking whether specs have been synced (no state)
- Changing archive behavior (it will continue to apply specs)
- Supporting partial application (all deltas sync together)

## Decisions

### 1. Reuse existing reconciliation logic

**Decision**: Extract `buildUpdatedSpec()` logic from `ArchiveCommand` into a shared module.

**Rationale**: The archive command already implements delta parsing and application. Rather than duplicate, we extract and reuse.

**Alternatives considered**:
- Duplicate logic in new command (rejected: maintenance burden)
- Have sync call archive with flags (rejected: coupling)

### 2. No state tracking

**Decision**: Don't track whether specs have been synced. Each invocation reads delta and main specs, reconciles.

**Rationale**:
- Idempotent operations don't need state
- Avoids sync issues between flag and reality
- Simpler implementation and mental model

**Alternatives considered**:
- Track `specsSynced: true` in `.openspec.yaml` (rejected: unnecessary complexity)
- Store snapshot of synced deltas (rejected: over-engineering)

### 3. Agent-driven approach (no CLI command)

**Decision**: The `/opsx:sync` skill is fully agent-driven - the agent reads delta specs and directly edits main specs.

**Rationale**:
- Allows intelligent merging (add scenarios without copying entire requirements)
- Delta represents *intent*, not wholesale replacement
- More flexible and natural editing workflow
- Archive still uses programmatic merge (for finalized changes)

### 4. Archive behavior unchanged

**Decision**: Archive continues to apply specs as part of its flow. If specs are already reconciled, the operation is a no-op.

**Rationale**: Backward compatibility. Users who don't use `/opsx:sync` get the same experience.

## Risks / Trade-offs

**[Risk] Multiple changes modify same spec**
â†’ Last to sync wins. Same as today with archive. Users should coordinate or use sequential archives.

**[Risk] User syncs specs then continues editing deltas**
â†’ Running `/opsx:sync` again reconciles. Idempotent design handles this.

**[Trade-off] No undo mechanism**
â†’ Users can `git checkout` main specs if needed. Explicit undo command is out of scope.

## Implementation Approach

1. Extract spec application logic from `ArchiveCommand.buildUpdatedSpec()` into `src/core/specs-apply.ts`
2. Add skill template for `/opsx:sync` in `skill-templates.ts`
3. Register skill in managed skills



================================================
FILE: openspec/changes/archive/2026-01-06-add-specs-apply-command/proposal.md
================================================
## Why

Spec application is currently bundled with archive - users must run `openspec archive` to apply delta specs to main specs. This couples two distinct concerns (applying specs vs. archiving the change) and forces users to wait until they're "done" to see main specs updated. Users want the flexibility to sync specs earlier in the workflow while iterating.

## What Changes

- Add `/opsx:sync` skill that syncs delta specs to main specs as a standalone action
- The operation is idempotent - safe to run multiple times, agent reconciles main specs to match deltas
- Archive continues to work as today (applies specs if not already reconciled, then moves to archive)
- No new state tracking - the agent reads delta and main specs, reconciles on each run
- Agent-driven approach allows intelligent merging (partial updates, adding scenarios)

**Workflow becomes:**
```
/opsx:new â†’ /opsx:continue â†’ /opsx:apply â†’ archive
                                  â”‚
                                  â””â”€â”€ /opsx:sync (optional, anytime)
```

## Capabilities

### New Capabilities
- `specs-sync-skill`: Skill template for `/opsx:sync` command that reconciles main specs with delta specs

### Modified Capabilities
- None (agent-driven, no CLI command needed)

## Impact

- **Skills**: New `openspec-sync-specs` skill in `skill-templates.ts`
- **Archive**: No changes needed - already does reconciliation, will continue to work
- **Agent workflow**: Users gain flexibility to sync specs before archive



================================================
FILE: openspec/changes/archive/2026-01-06-add-specs-apply-command/tasks.md
================================================
## Tasks

### Core Implementation

- [x] Extract spec application logic from `ArchiveCommand` into `src/core/specs-apply.ts`
  - Move `buildUpdatedSpec()`, `findSpecUpdates()`, `writeUpdatedSpec()` to shared module
  - Keep `ArchiveCommand` importing from the new module
  - Ensure all validation logic is preserved

### Skill Template

- [x] Add `getSyncSpecsSkillTemplate()` function in `src/core/templates/skill-templates.ts`
  - Skill name: `openspec-sync-specs`
  - Description: Sync delta specs to main specs
  - **Agent-driven**: Instructions for agent to read deltas and edit main specs directly

- [x] Add `/opsx:sync` slash command template in `skill-templates.ts`
  - Mirror the skill template for slash command format
  - **Agent-driven**: No CLI command, agent does the merge

### Registration

- [x] Register skill in managed skills (via `artifact-experimental-setup`)
  - Add to skill list with appropriate metadata
  - Ensure it appears in setup output

### Design Decision

**Why agent-driven instead of CLI-driven?**

The programmatic merge operates at requirement-level granularity:
- MODIFIED requires copying ALL scenarios, not just the changed ones
- If agent forgets a scenario, it gets deleted
- Delta specs become bloated with copied content

Agent-driven approach:
- Agent can apply partial updates (add a scenario without copying others)
- Delta represents *intent*, not wholesale replacement
- More flexible and natural editing workflow
- Archive still uses programmatic merge (for finalized changes)



================================================
FILE: openspec/changes/archive/2026-01-06-add-specs-apply-command/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-06



================================================
FILE: openspec/changes/archive/2026-01-06-add-specs-apply-command/specs/specs-sync-skill/spec.md
================================================
## ADDED Requirements

### Requirement: Specs Sync Skill
The system SHALL provide an `/opsx:sync` skill that syncs delta specs from a change to the main specs.

#### Scenario: Sync delta specs to main specs
- **WHEN** agent executes `/opsx:sync` with a change name
- **THEN** the agent reads delta specs from `openspec/changes/<name>/specs/`
- **AND** reads corresponding main specs from `openspec/specs/`
- **AND** reconciles main specs to match what the deltas describe

#### Scenario: Idempotent operation
- **WHEN** agent executes `/opsx:sync` multiple times on the same change
- **THEN** the result is the same as running it once
- **AND** no duplicate requirements are created

#### Scenario: Change selection prompt
- **WHEN** agent executes `/opsx:sync` without specifying a change
- **THEN** the agent prompts user to select from available changes
- **AND** shows changes that have delta specs

### Requirement: Delta Reconciliation Logic
The agent SHALL reconcile main specs with delta specs using the delta operation headers.

#### Scenario: ADDED requirements
- **WHEN** delta contains `## ADDED Requirements` with a requirement
- **AND** the requirement does not exist in main spec
- **THEN** add the requirement to main spec

#### Scenario: ADDED requirement already exists
- **WHEN** delta contains `## ADDED Requirements` with a requirement
- **AND** a requirement with the same name already exists in main spec
- **THEN** update the existing requirement to match the delta version

#### Scenario: MODIFIED requirements
- **WHEN** delta contains `## MODIFIED Requirements` with a requirement
- **AND** the requirement exists in main spec
- **THEN** replace the requirement in main spec with the delta version

#### Scenario: REMOVED requirements
- **WHEN** delta contains `## REMOVED Requirements` with a requirement name
- **AND** the requirement exists in main spec
- **THEN** remove the requirement from main spec

#### Scenario: RENAMED requirements
- **WHEN** delta contains `## RENAMED Requirements` with FROM:/TO: format
- **AND** the FROM requirement exists in main spec
- **THEN** rename the requirement to the TO name

#### Scenario: New capability spec
- **WHEN** delta spec exists for a capability not in main specs
- **THEN** create new main spec file at `openspec/specs/<capability>/spec.md`

### Requirement: Skill Output
The skill SHALL provide clear feedback on what was synced.

#### Scenario: Show synced changes
- **WHEN** reconciliation completes successfully
- **THEN** display summary of changes per capability:
  - Number of requirements added
  - Number of requirements modified
  - Number of requirements removed
  - Number of requirements renamed

#### Scenario: No changes needed
- **WHEN** main specs already match delta specs
- **THEN** display "Specs already in sync - no changes needed"



================================================
FILE: openspec/changes/archive/2026-01-06-make-apply-instructions-schema-aware/proposal.md
================================================
## Why

The `generateApplyInstructions` function is hardcoded to check for `spec-driven` artifacts (`proposal.md`, `specs/`, `design.md`, `tasks.md`). If a user selects a different schema like `tdd`, the apply instructions are meaningless - they check for files that don't exist in that schema.

This blocks the experimental workflow from supporting multiple schemas properly.

## What Changes

**Scope: Experimental artifact workflow** (`openspec instructions apply`)

**Depends on:** `add-per-change-schema-metadata` (to know which schema a change uses)

- Make `generateApplyInstructions` read artifact definitions from the schema
- Dynamically determine which artifacts exist based on schema
- Define when a change becomes "implementable" (see Design Decision below)
- Generate schema-appropriate context files and instructions

## Design Decision: When is a change implementable?

This is the key question. Different approaches:

### Option A: Explicit `apply` artifact in schema

Add a field to mark which artifact is the "implementation gate":

```yaml
artifacts:
  - id: tasks
    generates: tasks.md
    apply: true  # â† This artifact triggers apply mode
```

**Pros:** Explicit, flexible
**Cons:** Another field to maintain, what if multiple artifacts are `apply: true`?

### Option B: Leaf artifacts are implementable

The artifact(s) with no dependents (nothing depends on them) are the apply target.

- `spec-driven`: `tasks` is a leaf â†’ apply = execute tasks
- `tdd`: `docs` is a leaf â†’ but that doesn't make sense for TDD...

**Pros:** No extra schema field, derived from graph
**Cons:** Doesn't match TDD semantics (implementation is the action, not docs)

### Option C: Schema-level `apply_phase` definition

Add a top-level field to the schema:

```yaml
name: spec-driven
apply_phase:
  requires: [tasks]  # Must exist before apply
  tracks: tasks.md   # File with checkboxes to track
  instruction: "Work through tasks, mark complete as you go"
```

```yaml
name: tdd
apply_phase:
  requires: [tests]  # Must have tests before implementing
  tracks: null       # No checkbox tracking - just make tests pass
  instruction: "Run tests, implement until green, refactor"
```

**Pros:** Full flexibility, schema controls its own apply semantics
**Cons:** More complex schema format

### Option D: Convention-based (artifact ID matching)

If artifact ID is `tasks` or `implementation`, it's the apply target.

**Pros:** Simple, no schema changes
**Cons:** Brittle, doesn't work for custom schemas

### Option E: All artifacts complete â†’ apply available

Apply becomes available when ALL schema artifacts exist. Implementation is whatever the user does after planning.

**Pros:** Simple, no schema changes
**Cons:** Doesn't guide what "apply" means for different workflows

---

## Decision: Add `apply` block to schema.yaml

Add a top-level `apply` field to schema definitions:

```yaml
name: spec-driven
version: 1
description: Default OpenSpec workflow

artifacts:
  # ... existing artifacts ...

apply:
  requires: [tasks]           # Artifacts that must exist before apply
  tracks: tasks.md            # File with checkboxes for progress (optional)
  instruction: |              # Guidance shown to agent
    Read context files, work through pending tasks, mark complete as you go.
    Pause if you hit blockers or need clarification.
```

```yaml
name: tdd
version: 1
description: Test-driven development workflow

artifacts:
  # ... existing artifacts ...

apply:
  requires: [tests]           # Must have tests before implementing
  tracks: null                # No checkbox tracking
  instruction: |
    Run tests to see failures. Implement minimal code to pass each test.
    Refactor while keeping tests green.
```

**Key properties:**
- `requires`: Array of artifact IDs that must exist before apply is available
- `tracks`: Path to file with checkboxes (relative to change dir), or `null` if no tracking
- `instruction`: Custom guidance for the apply phase

**Fallback behavior:** Schemas without `apply` block default to "all artifacts must exist"

## Capabilities

### Modified Capabilities
- `cli-artifact-workflow`: Apply instructions become schema-aware

## Impact

- **Affected code**: `src/commands/artifact-workflow.ts` (generateApplyInstructions)
- **Schema format**: May need new `apply_phase` field
- **Existing schemas**: Need to add apply_phase to `spec-driven` and `tdd`
- **Backward compatible**: Schemas without apply_phase can use default behavior



================================================
FILE: openspec/changes/archive/2026-01-06-make-apply-instructions-schema-aware/tasks.md
================================================
## Prerequisites

- [x] 0.1 Implement `add-per-change-schema-metadata` first (to auto-detect schema)

## 1. Schema Format

- [x] 1.1 Add `ApplyPhaseSchema` Zod schema to `src/core/artifact-graph/types.ts`
- [x] 1.2 Update `SchemaYamlSchema` to include optional `apply` field
- [x] 1.3 Export `ApplyPhase` type

## 2. Update Existing Schemas

- [x] 2.1 Add `apply` block to `schemas/spec-driven/schema.yaml`
- [x] 2.2 Add `apply` block to `schemas/tdd/schema.yaml`

## 3. Refactor generateApplyInstructions

- [x] 3.1 Load schema via `resolveSchema(schemaName)`
- [x] 3.2 Read `apply.requires` to determine required artifacts
- [x] 3.3 Check artifact existence dynamically (not hardcoded paths)
- [x] 3.4 Use `apply.tracks` for progress tracking (or skip if null)
- [x] 3.5 Use `apply.instruction` for the instruction text
- [x] 3.6 Build `contextFiles` from all existing artifacts in schema

## 4. Handle Fallback

- [x] 4.1 If schema has no `apply` block, require all artifacts to exist
- [x] 4.2 Default instruction: "All artifacts complete. Proceed with implementation."

## 5. Tests

- [x] 5.1 Test apply instructions with spec-driven schema
- [x] 5.2 Test apply instructions with tdd schema
- [x] 5.3 Test fallback when schema has no apply block
- [x] 5.4 Test blocked state when required artifacts missing



================================================
FILE: openspec/changes/archive/2026-01-06-make-apply-instructions-schema-aware/specs/cli-artifact-workflow/spec.md
================================================
## ADDED Requirements

### Requirement: Schema Apply Block

The system SHALL support an `apply` block in schema definitions that controls when and how implementation begins.

#### Scenario: Schema with apply block

- **WHEN** a schema defines an `apply` block
- **THEN** the system uses `apply.requires` to determine which artifacts must exist before apply
- **AND** uses `apply.tracks` to identify the file for progress tracking (or null if none)
- **AND** uses `apply.instruction` for guidance shown to the agent

#### Scenario: Schema without apply block

- **WHEN** a schema has no `apply` block
- **THEN** the system requires all artifacts to exist before apply is available
- **AND** uses default instruction: "All artifacts complete. Proceed with implementation."

### Requirement: Apply Instructions Command

The system SHALL generate schema-aware apply instructions via `openspec instructions apply`.

#### Scenario: Generate apply instructions

- **WHEN** user runs `openspec instructions apply --change <id>`
- **AND** all required artifacts (per schema's `apply.requires`) exist
- **THEN** the system outputs:
  - Context files from all existing artifacts
  - Schema-specific instruction text
  - Progress tracking file path (if `apply.tracks` is set)

#### Scenario: Apply blocked by missing artifacts

- **WHEN** user runs `openspec instructions apply --change <id>`
- **AND** required artifacts are missing
- **THEN** the system indicates apply is blocked
- **AND** lists which artifacts must be created first

#### Scenario: Apply instructions JSON output

- **WHEN** user runs `openspec instructions apply --change <id> --json`
- **THEN** the system outputs JSON with:
  - `contextFiles`: array of paths to existing artifacts
  - `instruction`: the apply instruction text
  - `tracks`: path to progress file or null
  - `applyRequires`: list of required artifact IDs

## MODIFIED Requirements

### Requirement: Status Command

The system SHALL display artifact completion status for a change, including apply readiness.

#### Scenario: Status JSON includes apply requirements

- **WHEN** user runs `openspec status --change <id> --json`
- **THEN** the system outputs JSON with:
  - `changeName`, `schemaName`, `isComplete`, `artifacts` array
  - `applyRequires`: array of artifact IDs needed for apply phase



================================================
FILE: openspec/changes/archive/2026-01-06-opsx-archive-command/design.md
================================================
## Context

The experimental workflow (OPSX) provides a complete lifecycle for creating changes:
- `/opsx:new` - Scaffold a new change with schema
- `/opsx:continue` - Create next artifact
- `/opsx:ff` - Fast-forward all artifacts
- `/opsx:apply` - Implement tasks
- `/opsx:sync` - Sync delta specs to main

The missing piece is archiving. The existing `openspec archive` command works but:
1. Applies specs programmatically (not agent-driven)
2. Doesn't use the artifact graph for completion checking
3. Doesn't integrate with the OPSX workflow philosophy

## Goals / Non-Goals

**Goals:**
- Add `/opsx:archive` skill to complete the OPSX workflow lifecycle
- Use artifact graph for schema-aware completion checking
- Integrate with `/opsx:sync` for agent-driven spec syncing
- Preserve `.openspec.yaml` schema metadata in archive

**Non-Goals:**
- Replacing the existing `openspec archive` CLI command
- Changing how specs are applied in the CLI command
- Modifying the artifact graph or schema system

## Decisions

### Decision 1: Skill-only implementation (no new CLI command)

The `/opsx:archive` will be a slash command/skill only, not a new CLI command.

**Rationale**: The existing `openspec archive` CLI command already handles the core archive functionality (moving to archive folder, date prefixing). The OPSX version just needs different pre-archive checks and optional sync prompting, which are agent behaviors better suited to a skill.

**Alternatives considered**:
- Adding flags to `openspec archive` (e.g., `--experimental`) - Rejected: adds complexity to CLI, harder to maintain two code paths
- New CLI command `openspec archive-experimental` - Rejected: unnecessary duplication, agent skills are the OPSX pattern

### Decision 2: Prompt for sync before archive

The skill will check for unsynced delta specs and prompt the user before archiving.

**Rationale**: The OPSX philosophy is agent-driven intelligent merging via `/opsx:sync`. Rather than programmatically applying specs like the regular archive command, we prompt the user to sync first if needed. This maintains workflow flexibility (user can decline and just archive).

**Flow**:
1. Check if `specs/` directory exists in the change
2. If yes, ask: "This change has delta specs. Would you like to sync them to main specs before archiving?"
3. If user says yes, execute `/opsx:sync` logic
4. Proceed with archive regardless of answer

### Decision 3: Use artifact graph for completion checking

The skill will use `openspec status --change "<name>" --json` to check artifact completion instead of just validating proposal.md and specs.

**Rationale**: The experimental workflow is schema-aware. Different schemas have different required artifacts. The artifact graph knows which artifacts are complete/incomplete for the current schema.

**Behavior**:
- Show warning if any artifacts are not `done`
- Don't block archive (user may have valid reasons to archive early)
- List incomplete artifacts so user can make informed decision

### Decision 4: Reuse tasks.md completion check from regular archive

The skill will parse tasks.md and warn about incomplete tasks, same as regular archive.

**Rationale**: Task completion checking is valuable regardless of workflow. The logic is simple (count `- [ ]` vs `- [x]`) and doesn't need special OPSX handling.

### Decision 5: Move change to archive/ with date prefix

Same archive behavior as regular command: move to `openspec/changes/archive/YYYY-MM-DD-<name>/`.

**Rationale**: Consistency with existing archive convention. The `.openspec.yaml` file moves with the change, preserving schema metadata.

## Risks / Trade-offs

**Risk**: Users confused about when to use `/opsx:archive` vs `openspec archive`
â†’ **Mitigation**: Documentation should clarify: use `/opsx:archive` if you've been using the OPSX workflow, use `openspec archive` otherwise. Both produce the same archived result.

**Risk**: Incomplete sync if user declines and has delta specs
â†’ **Mitigation**: The prompt is informational; user has full control. They may want to archive without syncing (e.g., abandoned change). Log a note in output.

**Trade-off**: No programmatic spec application in OPSX archive
â†’ **Accepted**: This is intentional. OPSX philosophy is agent-driven merging. If user wants programmatic application, use `openspec archive` instead.



================================================
FILE: openspec/changes/archive/2026-01-06-opsx-archive-command/proposal.md
================================================
## Why

The experimental workflow (OPSX) provides a schema-driven, artifact-by-artifact approach to creating changes with `/opsx:new`, `/opsx:continue`, `/opsx:ff`, `/opsx:apply`, and `/opsx:sync`. However, there's no corresponding archive command to finalize and archive completed changes. Users must currently fall back to the regular `openspec archive` command, which doesn't integrate with the OPSX philosophy of agent-driven spec syncing and schema-aware artifact tracking.

## What Changes

- Add `/opsx:archive` slash command for archiving changes in the experimental workflow
- Use artifact graph to check completion status (schema-aware) instead of just validating proposal + specs
- Prompt for `/opsx:sync` before archiving instead of programmatically applying specs
- Preserve `.openspec.yaml` schema metadata when moving to archive
- Integrate with existing OPSX commands for a cohesive workflow

## Capabilities

### New Capabilities

- `opsx-archive-skill`: Slash command and skill for archiving completed changes in the experimental workflow. Checks artifact completion via artifact graph, verifies task completion, optionally syncs specs via `/opsx:sync`, and moves the change to `archive/YYYY-MM-DD-<name>/`.

### Modified Capabilities

(none - this is a new skill that doesn't modify existing specs)

## Impact

- New file: `.claude/commands/opsx/archive.md`
- New skill definition (generated via `openspec artifact-experimental-setup`)
- No changes to existing archive command or other OPSX commands
- Completes the OPSX command suite for full lifecycle management



================================================
FILE: openspec/changes/archive/2026-01-06-opsx-archive-command/tasks.md
================================================
## 1. Create Slash Command

- [x] 1.1 Create `.claude/commands/opsx/archive.md` with skill definition
- [x] 1.2 Add YAML frontmatter (name, description, category, tags)
- [x] 1.3 Implement change selection logic (prompt if not provided)
- [x] 1.4 Implement artifact completion check using `openspec status --json`
- [x] 1.5 Implement task completion check (parse tasks.md for `- [ ]`)
- [x] 1.6 Implement spec sync prompt (check for specs/ directory, offer `/opsx:sync`)
- [x] 1.7 Implement archive process (move to archive/YYYY-MM-DD-<name>/)
- [x] 1.8 Add output formatting for success/warning cases

## 2. Regenerate Skills

- [x] 2.1 Run `openspec artifact-experimental-setup` to regenerate skills
- [x] 2.2 Verify skill appears in `.claude/skills/` directory

## 3. Testing

- [x] 3.1 Test `/opsx:archive` with a complete change (all artifacts, all tasks done)
- [x] 3.2 Test `/opsx:archive` with incomplete artifacts (verify warning shown)
- [x] 3.3 Test `/opsx:archive` with incomplete tasks (verify warning shown)
- [x] 3.4 Test `/opsx:archive` with delta specs (verify sync prompt shown)
- [x] 3.5 Test `/opsx:archive` without change name (verify selection prompt)



================================================
FILE: openspec/changes/archive/2026-01-06-opsx-archive-command/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-07



================================================
FILE: openspec/changes/archive/2026-01-06-opsx-archive-command/specs/opsx-archive-skill/spec.md
================================================
## ADDED Requirements

### Requirement: OPSX Archive Skill

The system SHALL provide an `/opsx:archive` skill that archives completed changes in the experimental workflow.

#### Scenario: Archive a change with all artifacts complete

- **WHEN** agent executes `/opsx:archive` with a change name
- **AND** all artifacts in the schema are complete
- **AND** all tasks are complete
- **THEN** the agent moves the change to `openspec/changes/archive/YYYY-MM-DD-<name>/`
- **AND** displays success message with archived location

#### Scenario: Change selection prompt

- **WHEN** agent executes `/opsx:archive` without specifying a change
- **THEN** the agent prompts user to select from available changes
- **AND** shows only active changes (excludes archive/)

### Requirement: Artifact Completion Check

The skill SHALL check artifact completion status using the artifact graph before archiving.

#### Scenario: Incomplete artifacts warning

- **WHEN** agent checks artifact status
- **AND** one or more artifacts have status other than `done`
- **THEN** display warning listing incomplete artifacts
- **AND** prompt user for confirmation to continue
- **AND** proceed if user confirms

#### Scenario: All artifacts complete

- **WHEN** agent checks artifact status
- **AND** all artifacts have status `done`
- **THEN** proceed without warning

### Requirement: Task Completion Check

The skill SHALL check task completion status from tasks.md before archiving.

#### Scenario: Incomplete tasks found

- **WHEN** agent reads tasks.md
- **AND** incomplete tasks are found (marked with `- [ ]`)
- **THEN** display warning showing count of incomplete tasks
- **AND** prompt user for confirmation to continue
- **AND** proceed if user confirms

#### Scenario: All tasks complete

- **WHEN** agent reads tasks.md
- **AND** all tasks are complete (marked with `- [x]`)
- **THEN** proceed without task-related warning

#### Scenario: No tasks file

- **WHEN** tasks.md does not exist
- **THEN** proceed without task-related warning

### Requirement: Spec Sync Prompt

The skill SHALL prompt to sync delta specs before archiving if specs exist.

#### Scenario: Delta specs exist

- **WHEN** agent checks for delta specs
- **AND** `specs/` directory exists in the change with spec files
- **THEN** prompt user: "This change has delta specs. Would you like to sync them to main specs before archiving?"
- **AND** if user confirms, execute `/opsx:sync` logic
- **AND** proceed with archive regardless of sync choice

#### Scenario: No delta specs

- **WHEN** agent checks for delta specs
- **AND** no `specs/` directory or no spec files exist
- **THEN** proceed without sync prompt

### Requirement: Archive Process

The skill SHALL move the change to the archive folder with date prefix.

#### Scenario: Successful archive

- **WHEN** archiving a change
- **THEN** create `archive/` directory if it doesn't exist
- **AND** generate target name as `YYYY-MM-DD-<change-name>` using current date
- **AND** move entire change directory to archive location
- **AND** preserve `.openspec.yaml` file in archived change

#### Scenario: Archive already exists

- **WHEN** target archive directory already exists
- **THEN** fail with error message
- **AND** suggest renaming existing archive or using different date

### Requirement: Skill Output

The skill SHALL provide clear feedback about the archive operation.

#### Scenario: Archive complete with sync

- **WHEN** archive completes after syncing specs
- **THEN** display summary:
  - Specs synced (from `/opsx:sync` output)
  - Change archived to location
  - Schema that was used

#### Scenario: Archive complete without sync

- **WHEN** archive completes without syncing specs
- **THEN** display summary:
  - Note that specs were not synced (if applicable)
  - Change archived to location
  - Schema that was used

#### Scenario: Archive complete with warnings

- **WHEN** archive completes with incomplete artifacts or tasks
- **THEN** include note about what was incomplete
- **AND** suggest reviewing if archive was intentional



================================================
FILE: openspec/changes/archive/2026-01-07-add-nix-flake-support/design.md
================================================
## Context

OpenSpec is a TypeScript CLI tool using pnpm for dependency management. The project requires Node.js â‰¥20.19.0. Nix uses its own build system that needs to understand how to fetch dependencies and build the project reproducibly.

The Nix ecosystem has specific patterns for packaging Node.js/pnpm projects that differ from the traditional npm ecosystem.

## Goals

- Enable OpenSpec to be run directly via `nix run github:Fission-AI/OpenSpec`
- Support all major platforms (Linux x86/ARM, macOS x86/ARM)
- Use existing pnpm-lock.yaml for reproducible builds
- Provide development environment for Nix users

## Non-Goals

- Replace existing npm/pnpm publishing workflow
- Publish to nixpkgs (can be done later as separate effort)
- Support Windows (Nix doesn't run natively on Windows)

## Decisions

### Use stdenv.mkDerivation instead of buildNpmPackage

**Decision**: Package OpenSpec using `stdenv.mkDerivation` with pnpm hooks.

**Rationale**: The zigbee2mqtt package in nixpkgs demonstrates the current best practice for pnpm projects. Using `buildNpmPackage` with pnpm requires complex configuration, while `mkDerivation` with the right hooks is more straightforward and better supported.

**Alternative considered**: Using `buildNpmPackage` with `npmConfigHook = pkgs.pnpmConfigHook` - this is the older pattern and causes issues with dependency fetching.

### Use fetchPnpmDeps with explicit pnpm version

**Decision**: Use `pkgs.fetchPnpmDeps` with `pnpm = pkgs.pnpm_9` and `fetcherVersion = 3`.

**Rationale**:
- pnpm lockfile version 9.0 requires fetcherVersion 3
- Explicit pnpm_9 ensures consistency between fetch and build
- This is the documented way to handle pnpm projects in nixpkgs

### Multi-platform support without flake-utils

**Decision**: Implement multi-platform support using plain Nix with `nixpkgs.lib.genAttrs`.

**Rationale**: Per user request, avoid extra dependencies. The `genAttrs` pattern is simple and well-understood in the Nix community.

### Node.js 20 instead of latest

**Decision**: Pin to nodejs_20 to match package.json engines requirement.

**Rationale**: Ensures consistency with development environment and npm package requirements. Avoids potential compatibility issues with newer Node versions.

## Key Implementation Details

### Dependency Hash Management

The `pnpmDeps.hash` field must be updated whenever dependencies change. The workflow:
1. Set hash to fake value (all zeros)
2. Run `nix build`
3. Nix fails with actual hash
4. Update flake.nix with correct hash

This is standard Nix workflow for fixed-output derivations.

### Build Inputs

Required nativeBuildInputs:
- `nodejs_20` - runtime
- `npmHooks.npmInstallHook` - handles installation phase
- `pnpmConfigHook` - configures pnpm environment
- `pnpm_9` - pnpm executable

The `dontNpmPrune = true` is important to keep all dependencies after build.

## Risks / Trade-offs

**[Risk]** Hash needs updating when dependencies change â†’ **Mitigation**: Document this clearly; error message from Nix provides correct hash

**[Risk]** Nix builds might lag behind npm releases â†’ **Mitigation**: This is fine; Nix users can still use npm if they need bleeding edge

**[Trade-off]** Additional maintenance burden for hash updates â†’ **Benefit**: Better experience for Nix ecosystem users

## Migration Plan

1. Add flake.nix to repository
2. Test builds on multiple platforms (can use GitHub Actions with Nix)
3. Update README with Nix installation instructions
4. Optionally add to CI pipeline to catch hash mismatches early

No breaking changes - this is purely additive.

## Open Questions

- Should we add automatic hash updating to CI? (Could use nix-update-script)
- Should we submit to nixpkgs after validation? (Separate decision)
- Do we want to support older Node versions in flake? (Probably no - stick to package.json requirement)



================================================
FILE: openspec/changes/archive/2026-01-07-add-nix-flake-support/proposal.md
================================================
## Why

OpenSpec users on NixOS or using the Nix package manager cannot easily install or run OpenSpec without going through npm. Adding a Nix flake makes OpenSpec a first-class citizen in the Nix ecosystem, enabling users to run `nix run github:Fission-AI/OpenSpec -- init` or include OpenSpec in their development environments declaratively.

## What Changes

- Add `flake.nix` to repository root with multi-platform support (x86_64-linux, aarch64-linux, x86_64-darwin, aarch64-darwin)
- Package uses pnpm for dependency management (matching existing development workflow)
- Support both direct execution via `nix run` and installation via `nix profile install`
- Provide dev shell for contributors using Nix

## Capabilities

### New Capabilities
- `nix-flake-support`: Nix flake configuration for building and running OpenSpec

### Modified Capabilities
- None

## Impact

- **New files**: `flake.nix` in repository root
- **Documentation**: Should add installation instructions for Nix users
- **CI/CD**: Could add flake checking to CI pipeline (optional)
- **Maintenance**: Requires updating pnpmDeps hash when dependencies change



================================================
FILE: openspec/changes/archive/2026-01-07-add-nix-flake-support/tasks.md
================================================
## 1. Create Flake Structure

- [x] 1.1 Create flake.nix in repository root
- [x] 1.2 Define inputs (nixpkgs only, no flake-utils)
- [x] 1.3 Set up supportedSystems list (4 platforms)
- [x] 1.4 Create forAllSystems helper function

## 2. Configure Package Build

- [x] 2.1 Set up stdenv.mkDerivation with finalAttrs pattern
- [x] 2.2 Configure pnpmDeps with fetchPnpmDeps
- [x] 2.3 Set pnpm = pnpm_9 and fetcherVersion = 3
- [x] 2.4 Add placeholder hash (all zeros)
- [x] 2.5 Configure nativeBuildInputs (nodejs_20, hooks, pnpm_9)
- [x] 2.6 Set dontNpmPrune = true

## 3. Define Build Phase

- [x] 3.1 Add buildPhase with runHook preBuild
- [x] 3.2 Add pnpm run build command
- [x] 3.3 Add runHook postBuild

## 4. Configure Installation

- [x] 4.1 Let npmInstallHook handle installation automatically
- [x] 4.2 Verify binary ends up in $out/bin/openspec

## 5. Add Metadata

- [x] 5.1 Set meta.description
- [x] 5.2 Set meta.homepage
- [x] 5.3 Set meta.license (MIT)
- [x] 5.4 Set meta.mainProgram = "openspec"

## 6. Configure App Entry Point

- [x] 6.1 Add apps output with forAllSystems
- [x] 6.2 Set default app to openspec binary
- [x] 6.3 Test that nix run works

## 7. Add Development Shell

- [x] 7.1 Add devShells output with forAllSystems
- [x] 7.2 Include nodejs_20 and pnpm_9 in buildInputs
- [x] 7.3 Add shellHook with welcome message and instructions

## 8. Get Correct Dependency Hash

- [x] 8.1 Run nix build to trigger hash mismatch
- [x] 8.2 Copy correct hash from error message
- [x] 8.3 Update pnpmDeps.hash in flake.nix
- [x] 8.4 Verify build succeeds

## 9. Testing

- [x] 9.1 Test `nix build` on x86_64-linux
- [x] 9.2 Test `nix run . -- --version` works
- [x] 9.3 Test `nix develop` provides correct environment
- [ ] 9.4 Test on macOS if available
- [ ] 9.5 Test `nix run github:Fission-AI/OpenSpec -- init` after merge to main

## 10. Documentation

- [x] 10.1 Add Nix installation section to README
- [x] 10.2 Include example commands for common Nix workflows in README



================================================
FILE: openspec/changes/archive/2026-01-07-add-nix-flake-support/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-07



================================================
FILE: openspec/changes/archive/2026-01-07-add-nix-flake-support/specs/nix-flake-support/spec.md
================================================
## ADDED Requirements

### Requirement: Multi-platform Nix flake
The system SHALL provide a Nix flake that builds OpenSpec for multiple platforms.

#### Scenario: Build on Linux x86_64
- **WHEN** user runs `nix build` on x86_64-linux system
- **THEN** system builds OpenSpec package successfully
- **AND** package includes the `openspec` binary

#### Scenario: Build on macOS ARM
- **WHEN** user runs `nix build` on aarch64-darwin system
- **THEN** system builds OpenSpec package successfully
- **AND** package includes the `openspec` binary

#### Scenario: Build on Linux ARM
- **WHEN** user runs `nix build` on aarch64-linux system
- **THEN** system builds OpenSpec package successfully

#### Scenario: Build on macOS x86_64
- **WHEN** user runs `nix build` on x86_64-darwin system
- **THEN** system builds OpenSpec package successfully

### Requirement: Direct execution via nix run
The system SHALL allow users to run OpenSpec directly from GitHub without installing.

#### Scenario: Run init command from GitHub
- **WHEN** user runs `nix run github:Fission-AI/OpenSpec -- init`
- **THEN** system downloads and builds OpenSpec
- **AND** executes `openspec init` command

#### Scenario: Run any OpenSpec command
- **WHEN** user runs `nix run github:Fission-AI/OpenSpec -- <command> <args>`
- **THEN** system executes `openspec <command> <args>`

### Requirement: pnpm dependency management
The system SHALL use pnpm for building OpenSpec in the Nix flake.

#### Scenario: Fetch dependencies with pnpm
- **WHEN** Nix builds the package
- **THEN** system uses `fetchPnpmDeps` to download dependencies
- **AND** uses pnpm-lock.yaml for reproducible builds
- **AND** uses fetcherVersion 3 for lockfile version 9.0

#### Scenario: Build with pnpm
- **WHEN** Nix runs the build phase
- **THEN** system executes `pnpm run build`
- **AND** produces dist directory with compiled TypeScript

### Requirement: Node.js version compatibility
The system SHALL use Node.js 20 as specified in package.json engines field.

#### Scenario: Build with correct Node version
- **WHEN** Nix builds OpenSpec
- **THEN** system uses nodejs_20 from nixpkgs
- **AND** build succeeds without version compatibility errors

### Requirement: Development shell
The system SHALL provide a Nix development shell for contributors.

#### Scenario: Enter dev shell
- **WHEN** user runs `nix develop` in OpenSpec repository
- **THEN** system provides shell with nodejs_20 and pnpm_9
- **AND** displays welcome message with versions
- **AND** provides instructions to run `pnpm install`

### Requirement: Proper binary installation
The system SHALL install the openspec binary correctly.

#### Scenario: Binary in PATH
- **WHEN** package is built or installed
- **THEN** `openspec` binary is available in `$out/bin/openspec`
- **AND** binary is executable
- **AND** binary can be invoked without full path when installed

#### Scenario: Binary executes correctly
- **WHEN** user runs the installed `openspec` command
- **THEN** system executes the CLI entry point
- **AND** all subcommands work correctly



================================================
FILE: openspec/changes/archive/2026-01-09-add-flake-update-script/design.md
================================================
## Context

The Nix flake added in the previous change requires manual maintenance when:
1. Package version changes (must update flake.nix version field)
2. Dependencies change (must update pnpmDeps hash)

Currently this requires maintainers to:
- Manually edit flake.nix version
- Set placeholder hash
- Run nix build to get error
- Copy hash from error message
- Update flake.nix again
- Verify build works

This is tedious and error-prone, especially for maintainers unfamiliar with Nix.

## Goals

- Automate version and hash updates for flake.nix
- Make script idempotent and safe to run multiple times
- Provide clear feedback during execution
- Integrate easily into release workflow

## Non-Goals

- Automatically commit changes (maintainer decides when to commit)
- Support non-pnpm package managers
- Handle complex Nix configurations beyond OpenSpec's use case

## Decisions

### Use Bash instead of Node.js script

**Decision**: Implement as bash script rather than Node.js.

**Rationale**:
- Needs to call Nix commands which are bash-native
- Parsing Nix output is simpler in bash with grep/sed
- Maintainers updating flake.nix likely have Nix installed (bash environment)
- Node.js would add unnecessary complexity for shell operations

**Alternative considered**: Node.js script with child_process - adds dependency on extra npm packages for shell operations, less natural for Nix tooling.

### Extract hash from build error output

**Decision**: Trigger intentional build failure with placeholder hash to get correct hash.

**Rationale**: This is the standard Nix workflow for updating fixed-output derivations. No API exists to compute the hash without building.

**Alternative considered**: Pre-compute hash from pnpm-lock.yaml - would require understanding Nix's hash algorithm and pnpm's lockfile structure, fragile and non-standard.

### Use sed for in-place file editing

**Decision**: Use `sed -i` for updating flake.nix in place.

**Rationale**: Simple, available on all Unix-like systems, handles the specific replacement patterns needed.

**Alternative considered**:
- Using Node.js to parse/modify: Overkill for simple string replacement
- Manual `sed` without `-i`: Requires temp files, more complex

### Verify build after hash update

**Decision**: Always run verification build after updating hash.

**Rationale**: Catches errors immediately, gives maintainer confidence the update worked.

**Trade-off**: Takes extra time (~30s) but prevents broken flake.nix commits.

## Key Implementation Details

### Path Resolution

Script calculates paths relative to its own location:
```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
```

This allows running from any working directory.

### Error Handling

Uses `set -euo pipefail` for strict error handling:
- `-e`: Exit on any command failure
- `-u`: Exit on undefined variable access
- `-o pipefail`: Catch failures in pipes

### Hash Extraction Pattern

Uses grep with Perl regex to extract hash:
```bash
grep -oP 'got:\s+\Ksha256-[A-Za-z0-9+/=]+'
```

This reliably extracts the hash regardless of surrounding text.

## Risks / Trade-offs

**[Risk]** Script assumes standard Nix error message format â†’ **Mitigation**: If extraction fails, script exits with error and shows full output

**[Risk]** Build might fail for reasons other than hash mismatch â†’ **Mitigation**: Script checks for hash in output before proceeding

**[Trade-off]** Requires Nix installed to run â†’ **Benefit**: Only maintainers updating flake need to run this, and they have Nix

## Migration Plan

1. Add script to scripts directory
2. Document in scripts/README.md
3. Use in next version bump to verify workflow
4. Update CONTRIBUTING.md if needed to mention script

No breaking changes - purely additive tooling.

## Open Questions

None - straightforward automation script.



================================================
FILE: openspec/changes/archive/2026-01-09-add-flake-update-script/proposal.md
================================================
## Why

Maintaining the Nix flake requires manual updates to version and dependency hash when releasing new versions or updating dependencies. This is error-prone and requires maintainers to understand Nix internals. Automating this process ensures consistency and reduces friction for releases.

## What Changes

- Add `scripts/update-flake.sh` to automatically update flake.nix version and dependency hash
- Add `scripts/README.md` documenting all maintenance scripts
- Script extracts version from package.json and determines correct pnpm dependency hash automatically

## Capabilities

### New Capabilities
- `flake-update-script`: Automation script for maintaining flake.nix

### Modified Capabilities
- None

## Impact

- **New files**: `scripts/update-flake.sh`, `scripts/README.md`
- **Maintainer workflow**: Version bumps now include running `./scripts/update-flake.sh`
- **Dependencies**: Script requires Node.js (already a dependency) and Nix (for maintainers using Nix)



================================================
FILE: openspec/changes/archive/2026-01-09-add-flake-update-script/tasks.md
================================================
## 1. Create Update Script

- [x] 1.1 Create scripts/update-flake.sh file
- [x] 1.2 Add shebang and error handling (set -euo pipefail)
- [x] 1.3 Add path resolution for project root and files
- [x] 1.4 Make script executable (chmod +x)

## 2. Implement Version Update Logic

- [x] 2.1 Extract version from package.json using Node.js
- [x] 2.2 Use sed to update version in flake.nix
- [x] 2.3 Report if version already up-to-date
- [x] 2.4 Display detected version to user

## 3. Implement Hash Update Logic

- [x] 3.1 Set placeholder hash in flake.nix
- [x] 3.2 Run nix build and capture output (allow failure)
- [x] 3.3 Extract correct hash from build error using grep
- [x] 3.4 Handle case where hash extraction fails
- [x] 3.5 Update flake.nix with correct hash
- [x] 3.6 Display detected hash to user

## 4. Add Build Verification

- [x] 4.1 Run nix build after hash update
- [x] 4.2 Check for dirty git tree warning
- [x] 4.3 Report success or failure clearly

## 5. Add User Feedback

- [x] 5.1 Add progress messages for each step
- [x] 5.2 Add success summary with version and hash
- [x] 5.3 Add next steps instructions (test, commit)
- [x] 5.4 Add error messages with context

## 6. Create Documentation

- [x] 6.1 Create scripts/README.md
- [x] 6.2 Document update-flake.sh purpose and usage
- [x] 6.3 Add example workflow
- [x] 6.4 Document other existing scripts

## 7. Testing

- [x] 7.1 Test script runs successfully
- [x] 7.2 Verify version is extracted correctly
- [x] 7.3 Verify hash is updated correctly
- [x] 7.4 Verify build succeeds after update
- [x] 7.5 Test idempotency (running twice works)

## 8. Integration

- [ ] 8.1 Add note to release process documentation
- [ ] 8.2 Use in next actual version bump to validate workflow



================================================
FILE: openspec/changes/archive/2026-01-09-add-flake-update-script/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-09



================================================
FILE: openspec/changes/archive/2026-01-09-add-flake-update-script/specs/flake-update-script/spec.md
================================================
## ADDED Requirements

### Requirement: Automatic Version Update
The script SHALL automatically update the version in flake.nix to match package.json.

#### Scenario: Version extraction from package.json
- **WHEN** script runs
- **THEN** version is read from package.json using Node.js
- **AND** version field in flake.nix is updated to match

#### Scenario: Version already up-to-date
- **WHEN** script runs and flake.nix version already matches package.json
- **THEN** script reports version is up-to-date
- **AND** continues to hash update

### Requirement: Automatic Hash Determination
The script SHALL automatically determine and update the correct pnpm dependency hash.

#### Scenario: Trigger build to get hash
- **WHEN** script needs to determine correct hash
- **THEN** script sets placeholder hash in flake.nix
- **AND** runs nix build which fails with correct hash
- **AND** extracts correct hash from build error output

#### Scenario: Hash extraction from build output
- **WHEN** nix build fails with hash mismatch
- **THEN** script parses "got: sha256-..." from error output
- **AND** updates flake.nix with correct hash

#### Scenario: Hash update failure
- **WHEN** script cannot extract hash from build output
- **THEN** script exits with error
- **AND** displays build output for debugging

### Requirement: Build Verification
The script SHALL verify that flake.nix builds successfully after updates.

#### Scenario: Successful verification
- **WHEN** hash has been updated
- **THEN** script runs nix build to verify
- **AND** reports success if build completes

#### Scenario: Dirty git tree warning
- **WHEN** build succeeds but git tree is dirty
- **THEN** script reports warning about dirty tree
- **AND** still indicates build success

### Requirement: User Feedback
The script SHALL provide clear progress information and next steps.

#### Scenario: Progress reporting
- **WHEN** script runs
- **THEN** each step is reported with descriptive message
- **AND** detected version and hash are displayed

#### Scenario: Success summary
- **WHEN** script completes successfully
- **THEN** summary shows updated version and hash
- **AND** next steps are displayed (test, commit, etc.)

### Requirement: Script Safety
The script SHALL fail fast on errors and use safe defaults.

#### Scenario: Bash error handling
- **WHEN** script encounters an error
- **THEN** script exits immediately (set -e)
- **AND** undefined variables cause exit (set -u)
- **AND** pipe failures are caught (set -o pipefail)

#### Scenario: File path resolution
- **WHEN** script determines file locations
- **THEN** paths are calculated relative to script location
- **AND** script works regardless of working directory

### Requirement: Documentation
The system SHALL provide documentation for the update script.

#### Scenario: Script usage documentation
- **WHEN** maintainer needs to use update script
- **THEN** scripts/README.md explains when and how to use it
- **AND** example workflow is provided

#### Scenario: Script listing
- **WHEN** maintainer views scripts/README.md
- **THEN** all maintenance scripts are documented
- **AND** purpose of each script is clear



================================================
FILE: openspec/changes/archive/2026-01-09-add-posthog-analytics/design.md
================================================
## Context

OpenSpec needs usage analytics to understand adoption and inform product decisions. PostHog provides a privacy-conscious analytics platform suitable for open source projects.

## Goals / Non-Goals

**Goals:**
- Track daily/weekly/monthly active usage
- Understand command usage patterns
- Keep implementation minimal and privacy-respecting
- Enable opt-out with minimal friction

**Non-Goals:**
- Detailed error tracking or diagnostics
- User identification or profiling
- Complex event hierarchies
- Full CLI command for telemetry management (env var sufficient for now)

## Decisions

### Opt-Out Model

**Decision:** Telemetry enabled by default, opt-out via environment variable.

```bash
OPENSPEC_TELEMETRY=0    # Disable telemetry
DO_NOT_TRACK=1          # Industry standard, also respected
```

Auto-disabled when `CI=true` is detected.

**Rationale:**
- Opt-in typically yields ~3% participationâ€”not enough for meaningful data
- Understanding usage patterns requires statistically significant sample sizes
- Environment variable opt-out is simple and immediate
- Respecting `DO_NOT_TRACK` follows industry convention

**Alternatives considered:**
- Opt-in only - Insufficient data for product decisions
- Config file setting - More complex, env var sufficient for MVP
- Full `openspec telemetry` command - Can add later if users request

### Event Design

**Decision:** Single event type with minimal properties.

```typescript
{
  event: 'command_executed',
  properties: {
    command: 'init',      // Command name only
    version: '1.2.3'      // OpenSpec version
  }
}
```

**Rationale:**
- Answers the core questions: how much usage, which commands are popular
- PostHog derives DAU/WAU/MAU from anonymous user counts over time
- No arguments, paths, or contentâ€”clean privacy story
- Easy to explain in disclosure notice

**Not tracked:**
- Command arguments
- File paths or contents
- Error messages or stack traces
- Project names or spec content
- IP addresses (`$ip: null` explicitly set)

### Anonymous ID

**Decision:** Random UUID, lazily generated on first telemetry send, stored in global config.

```typescript
// ~/.config/openspec/config.json
{
  "telemetry": {
    "anonymousId": "f47ac10b-58cc-4372-a567-0e02b2c3d479"
  }
}
```

**Rationale:**
- Random UUID has no relation to the personâ€”can't be reversed
- Stored in config so same user = same ID across sessions (needed for DAU/WAU/MAU)
- Lazy generation means no ID created if user opts out before first command
- User can delete config to reset identity

**Alternatives considered:**
- Machine-derived hash (hostname, MAC) - Feels invasive, fingerprint-like
- Per-session UUID - Breaks user counting metrics entirely

### SDK Configuration

**Decision:** PostHog Node SDK with immediate flush, shutdown on exit.

```typescript
const posthog = new PostHog(API_KEY, {
  flushAt: 1,        // Send immediately, don't batch
  flushInterval: 0   // No timer-based flushing
});

// Before CLI exits
await posthog.shutdown();
```

**Rationale:**
- CLI processes are short-lived; batching would lose events
- `flushAt: 1` ensures each event sends immediately
- `shutdown()` guarantees flush before process exit
- Adds ~100-300ms to exitâ€”negligible for typical CLI workflows

**Error handling:**
- Network failures silently ignored (telemetry shouldn't break CLI)
- `shutdown()` wrapped in try/catch

### Hook Location

**Decision:** Commander.js `preAction` and `postAction` hooks.

```typescript
program
  .hook('preAction', (thisCommand) => {
    maybeShowTelemetryNotice();
    trackCommand(thisCommand.name(), VERSION);
  })
  .hook('postAction', async () => {
    await shutdown();
  });
```

**Rationale:**
- Centralizedâ€”one place for all telemetry logic
- Automaticâ€”new commands get tracked without code changes
- Clean separationâ€”command handlers don't know about telemetry

**Subcommand handling:**
- Track full command path for nested commands (e.g., `change:apply`)

### First-Run Notice

**Decision:** One-liner on first command ever, stored "seen" flag in config.

```
Note: OpenSpec collects anonymous usage stats. Opt out: OPENSPEC_TELEMETRY=0
```

**Rationale:**
- First command (not just `init`) ensures notice is always seen
- Non-blockingâ€”no prompt, just informational
- One-liner is visible but not intrusive
- Storing "seen" in config prevents repeated display

**Config after first run:**
```json
{
  "telemetry": {
    "anonymousId": "...",
    "noticeSeen": true
  }
}
```

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Users prefer opt-in | Clear disclosure, trivial opt-out, transparent about what's collected |
| GDPR concerns | No personal data, no IP, user can delete config |
| Slows CLI exit by ~200ms | Negligible for most workflows; can optimize if needed |
| PostHog outage affects CLI | Fire-and-forget with timeout; failures are silent |

## Open Questions

Noneâ€”design is intentionally minimal. Future enhancements (dedicated command, workflow tracking) can be added based on user feedback.



================================================
FILE: openspec/changes/archive/2026-01-09-add-posthog-analytics/proposal.md
================================================
## Why

OpenSpec currently has no visibility into how the tool is being used. Without analytics, we cannot:
- Understand which commands and features are most valuable to users
- Measure adoption and usage patterns
- Make data-driven decisions about product development

Adding PostHog analytics enables product insights while respecting user privacy through transparent, opt-out telemetry.

## What Changes

- Add PostHog Node.js SDK as a dependency
- Implement telemetry system with environment variable opt-out
- Track command usage (command name and version only)
- Show first-run notice informing users about telemetry
- Store anonymous ID in global config (`~/.config/openspec/config.json`)
- Respect `DO_NOT_TRACK` and `OPENSPEC_TELEMETRY=0` environment variables
- Auto-disable in CI environments

## Capabilities

### New Capabilities

- `telemetry`: Anonymous usage analytics using PostHog. Covers command tracking, opt-out controls, and first-run disclosure notice.

### Modified Capabilities

- `global-config`: Add telemetry state storage (anonymous ID, notice seen flag)

## Impact

- **Dependencies**: Add `posthog-node` package
- **Privacy**: Opt-out via env var, no personal data collected, clear disclosure
- **Configuration**: New global config fields for telemetry state
- **Network**: Async event sending with flush on exit (~100-300ms added)
- **CI/CD**: Telemetry auto-disabled when `CI=true`
- **Documentation**: Update README with telemetry disclosure



================================================
FILE: openspec/changes/archive/2026-01-09-add-posthog-analytics/tasks.md
================================================
## 1. Setup

- [x] 1.1 Add `posthog-node` package as a dependency
- [x] 1.2 Create `src/telemetry/` module directory
- [x] 1.3 Add PostHog API key configuration (environment variable or embedded)

## 2. Global Config

- [x] 2.1 Create or extend global config module for `~/.config/openspec/config.json`
- [x] 2.2 Implement read/write functions that preserve existing config fields
- [x] 2.3 Define telemetry config structure (`anonymousId`, `noticeSeen`)

## 3. Core Telemetry Module

- [x] 3.1 Implement `isTelemetryEnabled()` checking `OPENSPEC_TELEMETRY`, `DO_NOT_TRACK`, and `CI` env vars
- [x] 3.2 Implement `getOrCreateAnonymousId()` with lazy UUID generation
- [x] 3.3 Initialize PostHog client with `flushAt: 1` and `flushInterval: 0`
- [x] 3.4 Implement `trackCommand(commandName, version)` with `$ip: null`
- [x] 3.5 Implement `shutdown()` with try/catch for silent failure handling

## 4. First-Run Notice

- [x] 4.1 Implement `maybeShowTelemetryNotice()` function
- [x] 4.2 Check `noticeSeen` flag before displaying notice
- [x] 4.3 Display notice text: "Note: OpenSpec collects anonymous usage stats. Opt out: OPENSPEC_TELEMETRY=0"
- [x] 4.4 Update `noticeSeen` in config after first display

## 5. CLI Integration

- [x] 5.1 Add Commander.js `preAction` hook to show notice and track command
- [x] 5.2 Add Commander.js `postAction` hook to call shutdown
- [x] 5.3 Handle subcommand path extraction (e.g., `change:apply`)

## 6. Testing

- [x] 6.1 Test opt-out via `OPENSPEC_TELEMETRY=0`
- [x] 6.2 Test opt-out via `DO_NOT_TRACK=1`
- [x] 6.3 Test auto-disable in CI environment
- [x] 6.4 Test first-run notice display and noticeSeen persistence
- [x] 6.5 Test anonymous ID generation and persistence
- [x] 6.6 Test silent failure on network error (mock PostHog)

## 7. Documentation

- [x] 7.1 Add telemetry disclosure section to README
- [x] 7.2 Document opt-out methods (`OPENSPEC_TELEMETRY=0`, `DO_NOT_TRACK=1`)
- [x] 7.3 Document what data is collected and not collected



================================================
FILE: openspec/changes/archive/2026-01-09-add-posthog-analytics/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-10



================================================
FILE: openspec/changes/archive/2026-01-09-add-posthog-analytics/specs/global-config/spec.md
================================================
## MODIFIED Requirements

### Requirement: Global configuration storage
The system SHALL store global configuration in `~/.config/openspec/config.json`, including telemetry state with `anonymousId` and `noticeSeen` fields.

#### Scenario: Initial config creation
- **WHEN** no global config file exists
- **AND** the first telemetry event is about to be sent
- **THEN** the system creates `~/.config/openspec/config.json` with telemetry configuration

#### Scenario: Telemetry config structure
- **WHEN** reading or writing telemetry configuration
- **THEN** the config contains a `telemetry` object with `anonymousId` (string UUID) and `noticeSeen` (boolean) fields

#### Scenario: Config file format
- **WHEN** storing configuration
- **THEN** the system writes valid JSON that can be read and modified by users

#### Scenario: Existing config preservation
- **WHEN** adding telemetry fields to an existing config file
- **THEN** the system preserves all existing configuration fields



================================================
FILE: openspec/changes/archive/2026-01-09-add-posthog-analytics/specs/telemetry/spec.md
================================================
## ADDED Requirements

### Requirement: Command execution tracking
The system SHALL send a `command_executed` event to PostHog when any CLI command executes, including only the command name and OpenSpec version as properties.

#### Scenario: Standard command execution
- **WHEN** a user runs any openspec command
- **THEN** the system sends a `command_executed` event with `command` and `version` properties

#### Scenario: Subcommand execution
- **WHEN** a user runs a nested command like `openspec change apply`
- **THEN** the system sends a `command_executed` event with the full command path (e.g., `change:apply`)

### Requirement: Privacy-preserving event design
The system SHALL NOT include command arguments, file paths, project names, spec content, error messages, or IP addresses in telemetry events.

#### Scenario: Command with arguments
- **WHEN** a user runs `openspec init my-project --force`
- **THEN** the telemetry event contains only `command: "init"` and `version: "<version>"` without arguments

#### Scenario: IP address exclusion
- **WHEN** the system sends a telemetry event
- **THEN** the event explicitly sets `$ip: null` to prevent IP tracking

### Requirement: Environment variable opt-out
The system SHALL disable telemetry when `OPENSPEC_TELEMETRY=0` or `DO_NOT_TRACK=1` environment variables are set.

#### Scenario: OPENSPEC_TELEMETRY opt-out
- **WHEN** `OPENSPEC_TELEMETRY=0` is set in the environment
- **THEN** the system sends no telemetry events

#### Scenario: DO_NOT_TRACK opt-out
- **WHEN** `DO_NOT_TRACK=1` is set in the environment
- **THEN** the system sends no telemetry events

#### Scenario: Environment variable takes precedence
- **WHEN** the user has previously used the CLI (config exists)
- **AND** the user sets `OPENSPEC_TELEMETRY=0`
- **THEN** telemetry is disabled regardless of config state

### Requirement: CI environment auto-disable
The system SHALL automatically disable telemetry when `CI=true` environment variable is detected.

#### Scenario: CI environment detection
- **WHEN** `CI=true` is set in the environment
- **THEN** the system sends no telemetry events

#### Scenario: CI with explicit enable
- **WHEN** `CI=true` is set
- **AND** `OPENSPEC_TELEMETRY=1` is explicitly set
- **THEN** telemetry remains disabled (CI takes precedence for privacy)

### Requirement: First-run telemetry notice
The system SHALL display a one-line telemetry disclosure notice on the first command execution, before any telemetry is sent.

#### Scenario: First command execution
- **WHEN** a user runs their first openspec command
- **AND** telemetry is enabled
- **THEN** the system displays: "Note: OpenSpec collects anonymous usage stats. Opt out: OPENSPEC_TELEMETRY=0"

#### Scenario: Subsequent command execution
- **WHEN** a user has already seen the notice (noticeSeen: true in config)
- **THEN** the system does not display the notice

#### Scenario: Notice before telemetry
- **WHEN** displaying the first-run notice
- **THEN** the notice appears before any telemetry event is sent

### Requirement: Anonymous user identification
The system SHALL generate a random UUID as an anonymous identifier on first telemetry send, stored in global config.

#### Scenario: First telemetry event
- **WHEN** the first telemetry event is sent
- **AND** no anonymousId exists in config
- **THEN** the system generates a random UUID v4 and stores it in config

#### Scenario: Persistent identity
- **WHEN** a user runs multiple commands across sessions
- **THEN** the same anonymousId is used for all events

#### Scenario: Lazy generation with opt-out
- **WHEN** a user opts out before running any command
- **THEN** no anonymousId is ever generated or stored

### Requirement: Immediate event sending
The system SHALL send telemetry events immediately without batching, using `flushAt: 1` and `flushInterval: 0` configuration.

#### Scenario: Event transmission timing
- **WHEN** a command executes
- **THEN** the telemetry event is sent immediately, not queued for batch transmission

### Requirement: Graceful shutdown
The system SHALL call `posthog.shutdown()` before CLI exit to ensure pending events are flushed.

#### Scenario: Normal exit
- **WHEN** a command completes successfully
- **THEN** the system awaits `shutdown()` before exiting

#### Scenario: Error exit
- **WHEN** a command fails with an error
- **THEN** the system still awaits `shutdown()` before exiting

### Requirement: Silent failure handling
The system SHALL silently ignore telemetry failures without affecting CLI functionality.

#### Scenario: Network failure
- **WHEN** the telemetry request fails due to network error
- **THEN** the CLI command completes normally without error message

#### Scenario: PostHog outage
- **WHEN** PostHog service is unavailable
- **THEN** the CLI command completes normally without error message

#### Scenario: Shutdown failure
- **WHEN** `shutdown()` fails or times out
- **THEN** the CLI exits normally without error message



================================================
FILE: openspec/changes/archive/2026-01-09-fix-codebuddy-frontmatter-fields/proposal.md
================================================
## Why

CodeBuddy slash command configurator currently uses inconsistent frontmatter fields compared to other tools. It uses `category` and `tags` fields (like Crush) but should use `argument-hint` field (like Factory, Auggie, and Codex) for better consistency. Additionally, the `proposal` command is missing frontmatter fields entirely. After reviewing CodeBuddy's official documentation, the correct format should use `description` and `argument-hint` fields with square bracket parameter format.

## What Changes

- Replace `category` and `tags` fields with `argument-hint` field in CodeBuddy frontmatter
- Add missing frontmatter fields to the `proposal` command
- Use correct square bracket format for `argument-hint` parameters (e.g., `[change-id]`)
- Ensure consistency with CodeBuddy's official documentation

## Impact

- Affected specs: cli-init, cli-update
- Affected code: `src/core/configurators/slash/codebuddy.ts`
- CodeBuddy users will get proper argument hints in the correct format for slash commands


================================================
FILE: openspec/changes/archive/2026-01-09-fix-codebuddy-frontmatter-fields/tasks.md
================================================
## 1. Implementation

- [x] 1.1 Update CodeBuddy frontmatter to use `argument-hint` instead of `category` and `tags`
- [x] 1.2 Add missing frontmatter fields to the `proposal` command
- [x] 1.3 Ensure all three commands (proposal, apply, archive) have consistent frontmatter structure
- [x] 1.4 Test the changes by running `openspec init` and `openspec update`


================================================
FILE: openspec/changes/archive/2026-01-09-fix-codebuddy-frontmatter-fields/specs/cli-init/spec.md
================================================
## MODIFIED Requirements

### Requirement: Slash Command Configuration

The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Antigravity
- **WHEN** the user selects Antigravity during initialization
- **THEN** create `.agent/workflows/openspec-proposal.md`, `.agent/workflows/openspec-apply.md`, and `.agent/workflows/openspec-archive.md`
- **AND** ensure each file begins with YAML frontmatter that contains only a `description: <stage summary>` field followed by the shared OpenSpec workflow instructions wrapped in managed markers
- **AND** populate the workflow body with the same proposal/apply/archive guidance used for other tools so Antigravity behaves like Windsurf while pointing to the `.agent/workflows/` directory

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for CodeBuddy Code
- **WHEN** the user selects CodeBuddy Code during initialization
- **THEN** create `.codebuddy/commands/openspec/proposal.md`, `.codebuddy/commands/openspec/apply.md`, and `.codebuddy/commands/openspec/archive.md`
- **AND** populate each file from shared templates that include CodeBuddy-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** use square bracket format for `argument-hint` parameters (e.g., `[change-id]`)
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cline
- **WHEN** the user selects Cline during initialization
- **THEN** create `.clinerules/workflows/openspec-proposal.md`, `.clinerules/workflows/openspec-apply.md`, and `.clinerules/workflows/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Crush
- **WHEN** the user selects Crush during initialization
- **THEN** create `.crush/commands/openspec/proposal.md`, `.crush/commands/openspec/apply.md`, and `.crush/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Factory Droid
- **WHEN** the user selects Factory Droid during initialization
- **THEN** create `.factory/commands/openspec-proposal.md`, `.factory/commands/openspec-apply.md`, and `.factory/commands/openspec-archive.md`
- **AND** populate each file from shared templates that include Factory-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** include the `$ARGUMENTS` placeholder in the template body so droid receives any user-supplied input
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes


================================================
FILE: openspec/changes/archive/2026-01-09-fix-codebuddy-frontmatter-fields/specs/cli-update/spec.md
================================================
## MODIFIED Requirements

### Requirement: Slash Command Updates

The update command SHALL refresh existing slash command files for configured tools without creating new ones, and ensure the OpenCode archive command accepts change ID arguments.

#### Scenario: Updating slash commands for Antigravity
- **WHEN** `.agent/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh the OpenSpec-managed portion of each file so the workflow copy matches other tools while preserving the existing single-field `description` frontmatter
- **AND** skip creating any missing workflow files during update, mirroring the behavior for Windsurf and other IDEs

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for CodeBuddy Code
- **WHEN** `.codebuddy/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using the shared CodeBuddy templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** use square bracket format for `argument-hint` parameters (e.g., `[change-id]`)
- **AND** preserve any user customizations outside the OpenSpec managed markers

#### Scenario: Updating slash commands for Cline
- **WHEN** `.clinerules/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Crush
- **WHEN** `.crush/commands/` contains `openspec/proposal.md`, `openspec/apply.md`, and `openspec/archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Factory Droid
- **WHEN** `.factory/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using the shared Factory templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** ensure the template body retains the `$ARGUMENTS` placeholder so user input keeps flowing into droid
- **AND** update only the content inside the OpenSpec managed markers, leaving any unmanaged notes untouched
- **AND** skip creating missing files during update

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** ensure the archive command includes `$ARGUMENTS` placeholder in frontmatter for accepting change ID arguments

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage


================================================
FILE: openspec/changes/archive/2026-01-15-add-nix-ci-validation/design.md
================================================
# Design: Nix CI Validation

## Context

OpenSpec recently added Nix flake support to enable Nix users to install the tool. This includes:
- `flake.nix`: Nix package definition with pnpm dependency fetching
- `scripts/update-flake.sh`: Automation script to update version and hash when releasing

Currently, there is no CI validation ensuring these Nix artifacts remain functional. The existing CI workflow (.github/workflows/ci.yml) validates Node.js builds, tests, and linting across multiple platforms (Linux, macOS, Windows) but does not validate Nix builds.

**Stakeholders**: Nix users, maintainers, contributors who need confidence that Nix support works.

**Constraints**:
- Must work in GitHub Actions Linux runners
- Should minimize CI runtime impact (<5 minutes added)
- Should support local testing with `act` for rapid iteration
- Must integrate with existing required checks

## Goals / Non-Goals

**Goals**:
- Validate `nix build` succeeds on every PR/push
- Validate `scripts/update-flake.sh` executes without errors
- Ensure Nix support doesn't regress silently
- Support local testing with `act`
- Optimize with caching to minimize CI time

**Non-Goals**:
- Testing on macOS (GitHub-hosted macOS runners are slower and more expensive; Nix flake already declares macOS support)
- Building for all declared systems (x86_64-linux, aarch64-linux, x86_64-darwin, aarch64-darwin) - focus on most common platform
- Validating Nix flake quality/style (nixpkgs-fmt, etc.) - can be added later if needed
- Running OpenSpec's full test suite through Nix build - existing CI already does this

## Decisions

### Decision 1: Use DeterminateSystems nix-installer-action

**What**: Use `determinatesystems/nix-installer-action` for installing Nix in CI.

**Why**:
- Official GitHub Action maintained by Determinate Systems (Nix experts)
- Handles GitHub Actions environment quirks automatically
- Includes automatic caching configuration
- More reliable than curl | sh installation script
- Better error messages and diagnostics

**Alternatives considered**:
- Official Nix installer (`curl -L https://nixos.org/nix/install | sh`): Works but requires manual setup of flakes, caching, and CI-specific configuration
- `cachix/install-nix-action`: Popular alternative but determinatesystems is more actively maintained and has better GHA integration

### Decision 2: Use Magic Nix Cache for performance

**What**: Use `determinatesystems/magic-nix-cache-action` for automatic binary caching.

**Why**:
- Zero-configuration caching for Nix store
- Significantly reduces CI time on subsequent runs (from ~5min to ~1-2min)
- Free for public repositories
- Handles cache keys automatically

**Alternatives considered**:
- Manual Nix store caching with GitHub Actions cache: More complex, requires manual cache key management
- Cachix: Excellent tool but requires account setup and token management
- No caching: Acceptable for initial implementation, but poor developer experience

### Decision 3: Separate job for Nix validation

**What**: Create a dedicated `nix-validate` job in .github/workflows/ci.yml that runs in parallel with other jobs.

**Why**:
- Keeps Nix validation isolated from Node.js validation
- Allows parallel execution for faster CI
- Easier to debug when Nix-specific issues occur
- Can be marked as required check independently

**Alternatives considered**:
- Add Nix steps to existing jobs: Creates coupling between Node.js and Nix validation, harder to maintain
- Separate workflow file: Overkill for a single job, harder to manage required checks

### Decision 4: Validate update script by executing it

**What**: Run `scripts/update-flake.sh` as part of CI validation.

**Why**:
- Ensures the script doesn't break due to changes in package.json format, nix build output, or dependencies
- Tests the full workflow users will follow when releasing
- Catches errors early

**Implementation approach**:
- Execute script in a way that doesn't modify git state (or discard changes after)
- Verify script exits with code 0
- Optionally validate that flake.nix contains expected patterns after execution

**Alternatives considered**:
- Mock/dry-run mode: Would require modifying the script significantly
- Skip validation: Risky - script could break and only be discovered at release time
- Only run on release branches: Misses issues early in development

### Decision 5: Run on pull_request and push to main

**What**: Configure Nix validation job to run on:
- `pull_request` events (any PR to main)
- `push` events (direct pushes to main)
- `workflow_dispatch` (manual trigger for testing)

**Why**:
- Catches issues before merge (pull_request)
- Validates main branch stays healthy (push)
- Allows manual testing without creating PRs (workflow_dispatch)

### Decision 6: Support act for local testing

**What**: Ensure workflow is compatible with `act` tool for local CI testing.

**Why**:
- Faster iteration when developing CI changes
- Allows testing without pushing to GitHub
- Reduces commit noise from CI debugging

**Requirements**:
- Use standard GitHub Actions syntax
- Document any act-specific configuration needed
- Test that Nix can be installed in act's Docker containers

**Limitations**:
- act may not perfectly replicate GitHub's runners, but close enough for validation

## Risks / Trade-offs

### Risk: CI runtime increase

**Impact**: Adding Nix validation will increase total CI time by 2-5 minutes per run.

**Mitigation**:
- Run Nix job in parallel with existing jobs (no blocking delay)
- Use magic-nix-cache for subsequent runs (~1-2 min with cache)
- Configure appropriate timeout (10 minutes max)

**Acceptance**: The benefit of preventing Nix regressions outweighs the cost.

### Risk: Nix installer failures in CI

**Impact**: Transient failures in Nix installation could block PRs.

**Mitigation**:
- Use determinatesystems action which has retry logic
- Monitor for flaky failures and adjust if needed
- Document troubleshooting steps

**Acceptance**: Nix installation is generally stable in GHA; this is low risk.

### Risk: Update script modifies git state

**Impact**: Running update-flake.sh modifies flake.nix, which could cause CI to fail if git state is checked.

**Mitigation**:
- Run script in isolation without committing changes
- Add `git checkout -- flake.nix` after validation
- Or accept dirty git state in CI (doesn't affect build validation)

**Acceptance**: Script validation is important enough to handle this carefully.

### Risk: act compatibility issues

**Impact**: Workflow might not work perfectly with act due to Docker environment differences.

**Mitigation**:
- Document known limitations
- Focus on GitHub Actions as primary validation target
- Use act as best-effort local testing

**Acceptance**: act support is nice-to-have, not required.

## Migration Plan

### Phase 1: Add Nix job (new, non-required)
1. Add `nix-validate` job to .github/workflows/ci.yml
2. Configure to run in parallel with existing jobs
3. Do NOT mark as required check initially
4. Monitor for ~1 week to ensure stability

### Phase 2: Make required
1. After validation is stable, add to required checks
2. Update branch protection rules in GitHub settings
3. Document in CONTRIBUTING.md or README

### Rollback Plan
If Nix validation causes issues:
1. Remove job from required checks in GitHub settings (immediate)
2. Comment out or remove job from workflow (permanent fix)
3. Investigate and fix issues
4. Re-enable following same phased approach

## Open Questions

- **Q**: Should we test update-flake.sh on every CI run, or only when package.json or pnpm-lock.yaml changes?
  - **A**: Test on every run for simplicity. The script is fast (<30 seconds) and catching regressions is valuable.

- **Q**: Should we validate on macOS as well?
  - **A**: No for initial implementation. Linux validation is sufficient and macOS runners are slower/more expensive. Can add later if users report macOS-specific issues.

- **Q**: Should we run full OpenSpec tests through the Nix build?
  - **A**: No. The Nix build already runs `pnpm test` as part of its build phase. Existing CI jobs cover testing thoroughly. Nix validation focuses on build success.

- **Q**: What timeout should we use for the Nix validation job?
  - **A**: Start with 10 minutes. With caching, jobs should complete in 1-3 minutes. Without cache (first run), 5-7 minutes is expected.



================================================
FILE: openspec/changes/archive/2026-01-15-add-nix-ci-validation/proposal.md
================================================
# Add Nix CI Validation

## Why

The project recently added Nix flake support (flake.nix) and an automated update script (scripts/update-flake.sh) to enable Nix users to install OpenSpec. However, there is no CI validation ensuring these Nix artifacts continue to work as the project evolves. This creates risk that breaking changes could be merged without detection.

## What Changes

- Add a new GitHub Actions workflow job to validate Nix flake builds successfully
- Add validation that the update-flake.sh script executes without errors
- Test on Linux (where Nix support is most common)
- Ensure CI fails if Nix build or update script breaks
- Enable local testing with `act` for developers

## Impact

- Affected specs: New capability `ci-nix-validation`
- Affected code: `.github/workflows/ci.yml` (add new job)
- Affected infrastructure: GitHub Actions runners with Nix installed
- Benefits: Prevents regressions in Nix support, gives confidence to Nix users
- Trade-offs: Adds ~2-3 minutes to CI runtime



================================================
FILE: openspec/changes/archive/2026-01-15-add-nix-ci-validation/tasks.md
================================================
# Implementation Tasks

## 1. Add Nix Installation to CI

- [x] 1.1 Research Nix installation options for GitHub Actions (nix-installer-action vs manual install)
- [x] 1.2 Add Nix installation step to .github/workflows/ci.yml
- [x] 1.3 Configure Nix with experimental features enabled (flakes, nix-command)
- [x] 1.4 Add Nix store caching to improve CI performance

## 2. Create Nix Build Validation Job

- [x] 2.1 Add new `nix-flake-validate` job to .github/workflows/ci.yml
- [x] 2.2 Implement `nix build` step with proper error handling
- [x] 2.3 Add verification step to confirm binary exists in build output
- [x] 2.4 Add step to test binary execution (`nix run . -- --version`)

## 3. Add Update Script Validation

- [x] 3.1 Add job step to run scripts/update-flake.sh in dry-run or test mode
- [x] 3.2 Verify script executes without errors
- [x] 3.3 Add validation that version is correctly extracted from package.json
- [x] 3.4 Verify flake.nix is updated with correct format (version and hash)

## 4. Configure Job Dependencies and Requirements

- [x] 4.1 Configure Nix validation job to run on pull_request and push events
- [x] 4.2 Add Nix validation to required checks list
- [x] 4.3 Configure job to run in parallel with existing test/lint jobs
- [x] 4.4 Set appropriate timeout (5-10 minutes)

## 5. Test with act Locally

- [x] 5.1 Install act locally if not already available
- [x] 5.2 Test Nix validation job using `act pull_request`
- [x] 5.3 Verify act can run the workflow with Nix installed
- [x] 5.4 Document any act-specific configuration needed in .actrc or README

## 6. Documentation and Finalization

- [x] 6.1 Add documentation about Nix CI validation to README or CONTRIBUTING.md
- [x] 6.2 Document how to test CI locally with act
- [ ] 6.3 Update CI badge or status indicators if needed
- [ ] 6.4 Test end-to-end by creating a test PR

## 7. Archive Change

- [x] 7.1 After merge and verification, create new spec file at openspec/specs/ci-nix-validation/spec.md
- [x] 7.2 Move change directory to openspec/changes/archive/[date]-add-nix-ci-validation/
- [x] 7.3 Run `openspec validate --strict` to confirm archived change passes



================================================
FILE: openspec/changes/archive/2026-01-15-add-nix-ci-validation/specs/ci-nix-validation/spec.md
================================================
# CI Nix Validation Specification

## ADDED Requirements

### Requirement: Nix Flake Build Validation

The CI system SHALL validate that the Nix flake builds successfully on every pull request and push to main.

#### Scenario: Successful flake build

- **WHEN** a pull request or push to main is made
- **THEN** the CI SHALL execute `nix build` and verify it completes with exit code 0
- **AND** the build output SHALL contain the openspec binary

#### Scenario: Flake build failure

- **WHEN** the Nix flake configuration is broken
- **THEN** the CI job SHALL fail with a non-zero exit code
- **AND** the CI SHALL prevent merging of the pull request

#### Scenario: Multi-platform support check

- **WHEN** the flake declares support for multiple systems
- **THEN** the CI SHALL validate the flake builds on at least Linux (x86_64-linux)

### Requirement: Update Script Validation

The CI system SHALL validate that the update-flake.sh script executes successfully and produces valid output.

#### Scenario: Update script execution

- **WHEN** the CI runs the update script validation
- **THEN** the script SHALL execute without errors
- **AND** the script SHALL correctly extract the version from package.json
- **AND** the script SHALL update flake.nix with the correct version

#### Scenario: Update script with mock hash

- **WHEN** validating the update script in CI
- **THEN** the script SHALL be able to detect and extract the correct pnpm dependency hash
- **AND** the flake.nix SHALL be updated with a valid sha256 hash

### Requirement: CI Job Integration

The Nix validation jobs SHALL be integrated into the existing GitHub Actions workflow and required for merge.

#### Scenario: PR merge requirements

- **WHEN** a pull request is created
- **THEN** the Nix validation job SHALL be included in required checks
- **AND** the PR SHALL NOT be mergeable until Nix validation passes

#### Scenario: Job execution triggers

- **WHEN** code is pushed to a pull request OR pushed to main OR manually triggered
- **THEN** the Nix validation job SHALL execute automatically

### Requirement: Local Testing Support

The CI workflow SHALL be testable locally using the `act` tool to enable rapid iteration.

#### Scenario: Local CI execution with act

- **WHEN** a developer runs `act` with the Nix validation workflow
- **THEN** the workflow SHALL execute in the local Docker environment
- **AND** the developer SHALL receive feedback on Nix build status without pushing to GitHub

#### Scenario: Act configuration compatibility

- **WHEN** the workflow is designed
- **THEN** it SHALL use standard GitHub Actions syntax compatible with `act`
- **AND** any Nix-specific setup SHALL work in the act Docker environment

### Requirement: Nix Installation in CI

The CI environment SHALL have Nix properly installed and configured before running validation.

#### Scenario: Nix installation step

- **WHEN** the Nix validation job starts
- **THEN** Nix SHALL be installed using the official Nix installer or determinatesystems/nix-installer-action
- **AND** the Nix installation SHALL be cached for subsequent runs to improve performance

#### Scenario: Nix configuration for CI

- **WHEN** Nix is installed in CI
- **THEN** it SHALL be configured to work in the GitHub Actions environment
- **AND** experimental features (flakes, nix-command) SHALL be enabled

### Requirement: CI Performance Optimization

The Nix validation SHALL be optimized to minimize CI runtime impact.

#### Scenario: Acceptable runtime

- **WHEN** the Nix validation job runs
- **THEN** it SHALL complete in under 5 minutes on a clean run
- **AND** with caching, it SHALL complete in under 3 minutes on subsequent runs

#### Scenario: Parallel execution

- **WHEN** multiple CI jobs are running
- **THEN** the Nix validation job SHALL run in parallel with other validation jobs (tests, lint)
- **AND** SHALL NOT block other independent checks



================================================
FILE: openspec/changes/merge-init-experimental/design.md
================================================
## Context

Currently `openspec init` and `openspec experimental` are separate commands with distinct purposes:

- **init**: Creates `openspec/` directory, generates `AGENTS.md`/`project.md`, configures tool config files (`CLAUDE.md`, etc.), generates old slash commands (`/openspec:proposal`, etc.)
- **experimental**: Generates skills (9 per tool), generates opsx slash commands (`/opsx:new`, etc.), creates `config.yaml`

The skill-based workflow (experimental) is the direction we're going, so we're making it the default by merging into `init`.

## Goals / Non-Goals

**Goals:**
- Single `openspec init` command that sets up the complete skill-based workflow
- Clean migration path for existing users with legacy artifacts
- Remove all code related to config files and old slash commands
- Keep the polished UX from experimental (animated welcome, searchable multi-select)

**Non-Goals:**
- Supporting both workflows simultaneously
- Providing options to use the old workflow
- Backward compatibility for `/openspec:*` commands (breaking change)

## Decisions

### Decision 1: Merge into init, not into experimental

**Choice**: Rewrite `init` to do what `experimental` does, then delete `experimental`.

**Rationale**: `init` is the canonical setup command. Users expect `init` to set up their project. `experimental` was always meant to be temporary.

**Alternatives considered**:
- Keep `experimental` as the main command â†’ confusing name for default behavior
- Create new command â†’ unnecessary, `init` already exists

### Decision 2: Legacy cleanup with Y/N prompt

**Choice**: Detect legacy artifacts, show what was found, prompt `"Legacy files detected. Upgrade and clean up? [Y/n]"`, then remove if confirmed.

**Rationale**: Users should know what's being removed. A single Y/N is simple and decisive. No need for multiple options.

**Alternatives considered**:
- Multiple options (keep/remove/cancel) â†’ overcomplicated
- Silent removal â†’ users might be surprised
- Just warn without removing â†’ leaves cruft

### Decision 3: Surgical removal of legacy content

**Choice**: For files with mixed content (OpenSpec markers + user content), only remove the OpenSpec marker block. For files that are 100% OpenSpec content, delete the entire file.

**Rationale**: Respects user customizations. CLAUDE.md might have other instructions beyond OpenSpec.

**Edge cases**:
- **Config files with mixed content**: Remove only `<!-- OPENSPEC:START -->` to `<!-- OPENSPEC:END -->` block
- **Config files that are 100% OpenSpec**: Delete file entirely (check if content outside markers is empty/whitespace)
- **Old slash command directories** (`.claude/commands/openspec/`): Delete entire directory (ours)
- **`openspec/AGENTS.md`**: Delete (ours)
- **Root `AGENTS.md`**: Only remove OpenSpec marker block, preserve rest

### Decision 6: Preserve project.md with migration hint

**Choice**: Do NOT auto-delete `openspec/project.md`. Preserve it and show a message directing users to manually migrate content to `config.yaml`'s `context:` field.

**Rationale**:
- `project.md` may contain valuable user-written project documentation
- The new workflow uses `config.yaml.context` for the same purpose (auto-injected into artifacts)
- Auto-deleting would lose user content; auto-migrating is complex (needs LLM to compress)
- Users can migrate manually or use `/opsx:explore` to get AI assistance

**Migration path**:
1. During legacy cleanup, detect `openspec/project.md` but do not delete
2. Show in output: "openspec/project.md still exists - migrate content to config.yaml's context: field, then delete"
3. User migrates manually or asks Claude in explore mode: "help me migrate project.md to config.yaml"
4. User deletes project.md when ready

**Why not auto-migrate?**
- `project.md` is verbose (sections, headers, placeholders)
- `config.yaml.context` should be concise and dense
- LLM compression would be ideal but adds complexity and non-determinism to init
- Manual migration lets users decide what's actually important

### Decision 4: Hidden alias for experimental

**Choice**: Keep `openspec experimental` as a hidden command that delegates to `init`.

**Rationale**: Users who learned `experimental` can still use it during transition. Hidden means it won't show in help.

### Decision 5: Reuse existing infrastructure

**Choice**: Reuse skill templates, command adapters, welcome screen, and multi-select from experimental.

**Rationale**: Already built and working. Just needs to be called from init instead of experimental.

## Risks / Trade-offs

| Risk | Mitigation |
|------|------------|
| Users with custom `/openspec:*` commands lose them | Document in release notes; old commands are in git history |
| Mixed-content detection might be imperfect | Conservative approach: if unsure, preserve the file and warn |
| Users confused by missing config files | Clear messaging in init output about what changed |
| `openspec update` might break | Review and update `update` command to work with new structure |

## Architecture

### What init creates (after merge)

```
openspec/
  â”œâ”€â”€ config.yaml           # Schema settings (from experimental)
  â”œâ”€â”€ specs/                # Empty, for user's specs
  â””â”€â”€ changes/              # Empty, for user's changes
      â””â”€â”€ archive/

.<tool>/skills/             # 9 skills per selected tool
  â”œâ”€â”€ openspec-explore/SKILL.md
  â”œâ”€â”€ openspec-new-change/SKILL.md
  â”œâ”€â”€ openspec-continue-change/SKILL.md
  â”œâ”€â”€ openspec-apply-change/SKILL.md
  â”œâ”€â”€ openspec-ff-change/SKILL.md
  â”œâ”€â”€ openspec-verify-change/SKILL.md
  â”œâ”€â”€ openspec-sync-specs/SKILL.md
  â”œâ”€â”€ openspec-archive-change/SKILL.md
  â””â”€â”€ openspec-bulk-archive-change/SKILL.md

.<tool>/commands/opsx/      # 9 slash commands per selected tool
  â”œâ”€â”€ explore.md
  â”œâ”€â”€ new.md
  â”œâ”€â”€ continue.md
  â”œâ”€â”€ apply.md
  â”œâ”€â”€ ff.md
  â”œâ”€â”€ verify.md
  â”œâ”€â”€ sync.md
  â”œâ”€â”€ archive.md
  â””â”€â”€ bulk-archive.md
```

### What init no longer creates

- `CLAUDE.md`, `.cursorrules`, `.windsurfrules`, etc. (config files)
- `openspec/AGENTS.md`
- `openspec/project.md`
- Root `AGENTS.md` stub
- `.claude/commands/openspec/` (old slash commands)

### Legacy detection targets

| Artifact Type | Detection Method | Removal Method |
|--------------|------------------|----------------|
| Config files (CLAUDE.md, etc.) | File exists AND contains OpenSpec markers | Remove marker block; delete file if empty after |
| Old slash command dirs | Directory exists at `.<tool>/commands/openspec/` | Delete entire directory |
| openspec/AGENTS.md | File exists at `openspec/AGENTS.md` | Delete file |
| openspec/project.md | File exists at `openspec/project.md` | **Preserve** - show migration hint only |
| Root AGENTS.md | File exists at `AGENTS.md` AND contains OpenSpec markers | Remove marker block; delete file if empty after |

### Code to remove

- `src/core/configurators/` - entire directory (ToolRegistry, all config generators)
- `src/core/configurators/slash/` - entire directory (SlashCommandRegistry, old command generators)
- `src/core/templates/slash-command-templates.ts` - old `/openspec:*` content
- `src/core/templates/claude-template.ts`
- `src/core/templates/cline-template.ts`
- `src/core/templates/costrict-template.ts`
- `src/core/templates/agents-template.ts`
- `src/core/templates/agents-root-stub.ts`
- `src/core/templates/project-template.ts`
- `src/commands/experimental/` - entire directory (merged into init)
- Related test files

### Code to migrate into init

- Animated welcome screen (`src/ui/welcome-screen.ts`) - keep, call from init
- Searchable multi-select (`src/prompts/searchable-multi-select.ts`) - keep, call from init
- Skill templates (`src/core/templates/skill-templates.ts`) - keep
- Command generation (`src/core/command-generation/`) - keep
- Tool states detection (from `experimental/setup.ts`) - move to init

## Open Questions

1. **What happens to `openspec update`?** - RESOLVED

   **Current behavior**: Updates `openspec/AGENTS.md`, config files (`CLAUDE.md`, etc.) via `ToolRegistry`, and old slash commands (`/openspec:*`) via `SlashCommandRegistry`.

   **New behavior**: Rewrite to refresh skills and opsx commands instead:
   - Detect which tools have skills installed (check for `.claude/skills/openspec-*/`, etc.)
   - Refresh all 9 skill files per installed tool using `skill-templates.ts`
   - Refresh all 9 opsx command files per installed tool using `command-generation/` adapters
   - Remove imports of `ToolRegistry`, `SlashCommandRegistry`, `agentsTemplate`
   - Update output messaging to reflect skills/commands instead of config files

   **Key principle**: Same as current update - only refresh existing tools, don't add new ones.

2. **Should we keep `openspec schemas` and other experimental subcommands?** - RESOLVED

   **Decision**: Yes, keep them. Remove "[Experimental]" label from all subcommands (status, instructions, schemas, etc.). See task 4.3.



================================================
FILE: openspec/changes/merge-init-experimental/proposal.md
================================================
## Why

The current setup has two separate commands (`openspec init` and `openspec experimental`) that configure different parts of the OpenSpec workflow. This creates confusion about which command to run, results in partial setups, and maintains two parallel systems (config files + old slash commands vs skills + opsx commands). Making the skill-based workflow the default simplifies onboarding and establishes a single, consistent way to use OpenSpec.

## What Changes

- **BREAKING**: `openspec init` now generates skills and `/opsx:*` commands instead of config files and `/openspec:*` commands
- **BREAKING**: Config files (`CLAUDE.md`, `.cursorrules`, etc.) are no longer generated
- **BREAKING**: Old slash commands (`/openspec:proposal`, `/openspec:apply`, `/openspec:archive`) are no longer generated
- **BREAKING**: `openspec/AGENTS.md` and `openspec/project.md` are no longer generated
- Merge `experimental` command functionality into `init`
- Add legacy detection and auto-cleanup with Y/N confirmation
- Keep `openspec experimental` as hidden alias for backward compatibility
- Use the animated welcome screen from experimental for the unified init

## Capabilities

### New Capabilities

- `legacy-cleanup`: Detect and remove legacy OpenSpec artifacts (config files, old slash commands, AGENTS.md) during init

### Modified Capabilities

- `cli-init`: Complete rewrite - generates skills and opsx commands instead of config files and old slash commands; removes AGENTS.md/project.md generation; adds legacy cleanup; uses experimental's animated welcome screen

## Impact

- **Code removal**: `ToolRegistry`, `SlashCommandRegistry`, config file generators, old slash command templates, AGENTS.md/project.md templates
- **Code migration**: Move skill generation and command adapter logic from `experimental/setup.ts` into `init.ts`
- **Commands affected**: `init` (rewritten), `experimental` (becomes hidden alias), `update` (may need adjustment)
- **User migration**: Existing users running `init` will be prompted to clean up legacy files
- **Breaking for**: Users relying on config files for passive triggering, users using `/openspec:*` commands



================================================
FILE: openspec/changes/merge-init-experimental/tasks.md
================================================
## 1. Legacy Detection & Cleanup Module

- [ ] 1.1 Create `src/core/legacy-cleanup.ts` with detection functions for all legacy artifact types
- [ ] 1.2 Implement `detectLegacyConfigFiles()` - check for config files with OpenSpec markers
- [ ] 1.3 Implement `detectLegacySlashCommands()` - check for old `/openspec:*` command directories
- [ ] 1.4 Implement `detectLegacyStructureFiles()` - check for AGENTS.md (project.md detected separately for messaging)
- [ ] 1.5 Implement `removeMarkerBlock()` - surgically remove OpenSpec marker blocks from files
- [ ] 1.6 Implement `cleanupLegacyArtifacts()` - orchestrate removal with proper edge case handling (preserves project.md)
- [ ] 1.7 Implement migration hint output for project.md - show message directing users to migrate to config.yaml
- [ ] 1.8 Add unit tests for legacy detection and cleanup functions

## 2. Rewrite Init Command

- [ ] 2.1 Replace `src/core/init.ts` with new implementation using experimental's approach
- [ ] 2.2 Import and use animated welcome screen from `src/ui/welcome-screen.ts`
- [ ] 2.3 Import and use searchable multi-select from `src/prompts/searchable-multi-select.ts`
- [ ] 2.4 Integrate legacy detection at start of init flow
- [ ] 2.5 Add Y/N prompt for legacy cleanup confirmation
- [ ] 2.6 Generate skills using existing `skill-templates.ts`
- [ ] 2.7 Generate slash commands using existing `command-generation/` adapters
- [ ] 2.8 Create `openspec/config.yaml` with default schema
- [ ] 2.9 Update success output to match new workflow (skills, /opsx:* commands)
- [ ] 2.10 Add `--force` flag to skip legacy cleanup prompt in non-interactive mode

## 3. Remove Legacy Code

- [ ] 3.1 Delete `src/core/configurators/` directory (ToolRegistry, all config generators)
- [ ] 3.2 Delete `src/core/templates/slash-command-templates.ts`
- [ ] 3.3 Delete `src/core/templates/claude-template.ts`
- [ ] 3.4 Delete `src/core/templates/cline-template.ts`
- [ ] 3.5 Delete `src/core/templates/costrict-template.ts`
- [ ] 3.6 Delete `src/core/templates/agents-template.ts`
- [ ] 3.7 Delete `src/core/templates/agents-root-stub.ts`
- [ ] 3.8 Delete `src/core/templates/project-template.ts`
- [ ] 3.9 Delete `src/commands/experimental/` directory
- [ ] 3.10 Update `src/core/templates/index.ts` to remove deleted exports
- [ ] 3.11 Delete related test files for removed modules

## 4. Update CLI Registration

- [ ] 4.1 Update `src/cli/index.ts` to remove `registerArtifactWorkflowCommands()` call
- [ ] 4.2 Keep experimental subcommands (status, instructions, schemas, etc.) but register directly
- [ ] 4.3 Remove "[Experimental]" labels from kept subcommands
- [ ] 4.4 Add hidden `experimental` command as alias to `init`

## 5. Update Related Commands

- [ ] 5.1 Update `openspec update` command to refresh skills/commands instead of config files
- [ ] 5.2 Remove config file refresh logic from update
- [ ] 5.3 Add skill refresh logic to update

## 6. Testing & Verification

- [ ] 6.1 Add integration tests for new init flow (fresh install)
- [ ] 6.2 Add integration tests for legacy detection and cleanup
- [ ] 6.3 Add integration tests for extend mode (re-running init)
- [ ] 6.4 Test non-interactive mode with `--tools` flag
- [ ] 6.5 Test `--force` flag for CI environments
- [ ] 6.6 Verify cross-platform path handling (use path.join throughout)
- [ ] 6.7 Run full test suite and fix any broken tests

## 7. Documentation & Cleanup

- [ ] 7.1 Update README with new init behavior
- [ ] 7.2 Document breaking changes for release notes
- [ ] 7.3 Remove any orphaned imports/references to deleted modules
- [ ] 7.4 Run linter and fix any issues



================================================
FILE: openspec/changes/merge-init-experimental/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-23



================================================
FILE: openspec/changes/merge-init-experimental/specs/cli-init/spec.md
================================================
## MODIFIED Requirements

### Requirement: Directory Creation

The command SHALL create the OpenSpec directory structure with config file.

#### Scenario: Creating OpenSpec structure

- **WHEN** `openspec init` is executed
- **THEN** create the following directory structure:
```
openspec/
â”œâ”€â”€ config.yaml
â”œâ”€â”€ specs/
â””â”€â”€ changes/
    â””â”€â”€ archive/
```

### Requirement: AI Tool Configuration

The command SHALL configure AI coding assistants with skills and slash commands using a searchable multi-select experience.

#### Scenario: Prompting for AI tool selection

- **WHEN** run interactively
- **THEN** display animated welcome screen with OpenSpec logo
- **AND** present a searchable multi-select that shows all available tools
- **AND** mark already configured tools with "(configured âœ“)" indicator
- **AND** pre-select configured tools for easy refresh
- **AND** sort configured tools to appear first in the list
- **AND** allow filtering by typing to search

#### Scenario: Selecting tools to configure

- **WHEN** user selects tools and confirms
- **THEN** generate skills in `.<tool>/skills/` directory for each selected tool
- **AND** generate slash commands in `.<tool>/commands/opsx/` directory for each selected tool
- **AND** create `openspec/config.yaml` with default schema setting

### Requirement: Skill Generation

The command SHALL generate Agent Skills for selected AI tools.

#### Scenario: Generating skills for a tool

- **WHEN** a tool is selected during initialization
- **THEN** create 9 skill directories under `.<tool>/skills/`:
  - `openspec-explore/SKILL.md`
  - `openspec-new-change/SKILL.md`
  - `openspec-continue-change/SKILL.md`
  - `openspec-apply-change/SKILL.md`
  - `openspec-ff-change/SKILL.md`
  - `openspec-verify-change/SKILL.md`
  - `openspec-sync-specs/SKILL.md`
  - `openspec-archive-change/SKILL.md`
  - `openspec-bulk-archive-change/SKILL.md`
- **AND** each SKILL.md SHALL contain YAML frontmatter with name and description
- **AND** each SKILL.md SHALL contain the skill instructions

### Requirement: Slash Command Generation

The command SHALL generate opsx slash commands for selected AI tools.

#### Scenario: Generating slash commands for a tool

- **WHEN** a tool is selected during initialization
- **THEN** create 9 slash command files using the tool's command adapter:
  - `/opsx:explore`
  - `/opsx:new`
  - `/opsx:continue`
  - `/opsx:apply`
  - `/opsx:ff`
  - `/opsx:verify`
  - `/opsx:sync`
  - `/opsx:archive`
  - `/opsx:bulk-archive`
- **AND** use tool-specific path conventions (e.g., `.claude/commands/opsx/` for Claude)
- **AND** include tool-specific frontmatter format

### Requirement: Success Output

The command SHALL provide clear, actionable next steps upon successful initialization.

#### Scenario: Displaying success message

- **WHEN** initialization completes successfully
- **THEN** display categorized summary:
  - "Created: <tools>" for newly configured tools
  - "Refreshed: <tools>" for already-configured tools that were updated
  - Count of skills and commands generated
- **AND** display getting started section with:
  - `/opsx:new` - Start a new change
  - `/opsx:continue` - Create the next artifact
  - `/opsx:apply` - Implement tasks
- **AND** display links to documentation and feedback

#### Scenario: Displaying restart instruction

- **WHEN** initialization completes successfully and tools were created or refreshed
- **THEN** display instruction to restart IDE for slash commands to take effect

### Requirement: Config File Generation

The command SHALL create an OpenSpec config file with schema settings.

#### Scenario: Creating config.yaml

- **WHEN** initialization completes
- **AND** config.yaml does not exist
- **THEN** create `openspec/config.yaml` with default schema setting
- **AND** display config location in output

#### Scenario: Preserving existing config.yaml

- **WHEN** initialization runs in extend mode
- **AND** `openspec/config.yaml` already exists
- **THEN** preserve the existing config file
- **AND** display "(exists)" indicator in output

### Requirement: Non-Interactive Mode

The command SHALL support non-interactive operation through command-line options.

#### Scenario: Select all tools non-interactively

- **WHEN** run with `--tools all`
- **THEN** automatically select every available AI tool without prompting
- **AND** proceed with skill and command generation

#### Scenario: Select specific tools non-interactively

- **WHEN** run with `--tools claude,cursor`
- **THEN** parse the comma-separated tool IDs
- **AND** generate skills and commands for specified tools only

#### Scenario: Skip tool configuration non-interactively

- **WHEN** run with `--tools none`
- **THEN** create only the openspec directory structure and config.yaml
- **AND** skip skill and command generation

### Requirement: Experimental Command Alias

The command SHALL maintain backward compatibility with the experimental command.

#### Scenario: Running openspec experimental

- **WHEN** user runs `openspec experimental`
- **THEN** delegate to `openspec init`
- **AND** the command SHALL be hidden from help output

## REMOVED Requirements

### Requirement: File Generation

**Reason**: AGENTS.md and project.md are no longer generated. Skills contain all necessary instructions.

**Migration**: Skills in `.<tool>/skills/` provide all OpenSpec workflow instructions. No manual file needed.

### Requirement: AI Tool Configuration Details

**Reason**: Config files (CLAUDE.md, .cursorrules, etc.) are replaced by skills.

**Migration**: Use skills in `.<tool>/skills/` instead of config files. Skills provide richer, tool-specific instructions.

### Requirement: Slash Command Configuration

**Reason**: Old `/openspec:*` slash commands are replaced by `/opsx:*` commands with richer functionality.

**Migration**: Use `/opsx:new`, `/opsx:continue`, `/opsx:apply` instead of `/openspec:proposal`, `/openspec:apply`, `/openspec:archive`.

### Requirement: Root instruction stub

**Reason**: Root AGENTS.md stub is no longer needed. Skills provide tool-specific instructions.

**Migration**: Skills are loaded automatically by supporting tools. No root stub needed.



================================================
FILE: openspec/changes/merge-init-experimental/specs/legacy-cleanup/spec.md
================================================
## ADDED Requirements

### Requirement: Legacy artifact detection

The system SHALL detect legacy OpenSpec artifacts from previous init versions.

#### Scenario: Detecting legacy config files

- **WHEN** running `openspec init` on an existing project
- **THEN** the system SHALL check for config files with OpenSpec markers:
  - `CLAUDE.md`
  - `.cursorrules`
  - `.windsurfrules`
  - `.clinerules`
  - `.kilocode_rules`
  - `.github/copilot-instructions.md`
  - `.amazonq/instructions.md`
  - `CODEBUDDY.md`
  - `IFLOW.md`
  - And all other tool config files from the legacy ToolRegistry

#### Scenario: Detecting legacy slash command directories

- **WHEN** running `openspec init` on an existing project
- **THEN** the system SHALL check for old slash command directories:
  - `.claude/commands/openspec/`
  - `.cursor/commands/openspec/` (note: old format used `openspec-*.md` in commands root)
  - `.windsurf/workflows/openspec-*.md`
  - And equivalent directories for all tools in the legacy SlashCommandRegistry

#### Scenario: Detecting legacy OpenSpec structure files

- **WHEN** running `openspec init` on an existing project
- **THEN** the system SHALL check for:
  - `openspec/AGENTS.md`
  - `openspec/project.md` (for migration messaging only, not deleted)
  - Root `AGENTS.md` with OpenSpec markers

### Requirement: Legacy cleanup confirmation

The system SHALL prompt for confirmation before removing legacy artifacts.

#### Scenario: Prompting for cleanup when legacy detected

- **WHEN** legacy artifacts are detected
- **THEN** the system SHALL display what was found
- **AND** prompt: "Legacy files detected. Upgrade and clean up? [Y/n]"
- **AND** default to Yes if user presses Enter

#### Scenario: User confirms cleanup

- **WHEN** user responds Y or presses Enter
- **THEN** the system SHALL remove legacy artifacts
- **AND** proceed with skill-based setup

#### Scenario: User declines cleanup

- **WHEN** user responds N
- **THEN** the system SHALL abort initialization
- **AND** display message suggesting manual cleanup or using `--force` flag

#### Scenario: Non-interactive mode

- **WHEN** running with `--no-interactive` or in CI environment
- **AND** legacy artifacts are detected
- **THEN** the system SHALL abort with exit code 1
- **AND** display detected legacy artifacts
- **AND** suggest running interactively or using `--force` flag

### Requirement: Surgical removal of config file content

The system SHALL preserve user content when removing OpenSpec markers from config files.

#### Scenario: Config file with only OpenSpec content

- **WHEN** a config file contains only OpenSpec marker block (whitespace outside is acceptable)
- **THEN** the system SHALL delete the entire file

#### Scenario: Config file with mixed content

- **WHEN** a config file contains content outside OpenSpec markers
- **THEN** the system SHALL remove only the `<!-- OPENSPEC:START -->` to `<!-- OPENSPEC:END -->` block
- **AND** preserve all content before and after the markers
- **AND** clean up any resulting double blank lines

#### Scenario: Root AGENTS.md with mixed content

- **WHEN** root `AGENTS.md` contains OpenSpec markers AND other content
- **THEN** the system SHALL remove only the OpenSpec marker block
- **AND** preserve the rest of the file

### Requirement: Legacy directory removal

The system SHALL remove legacy slash command directories entirely.

#### Scenario: Removing old slash command directory

- **WHEN** a legacy slash command directory exists (e.g., `.claude/commands/openspec/`)
- **THEN** the system SHALL delete the entire directory and its contents
- **AND** NOT delete the parent directory (e.g., `.claude/commands/` remains)

#### Scenario: Removing legacy AGENTS.md

- **WHEN** `openspec/AGENTS.md` exists
- **THEN** the system SHALL delete the file
- **AND** NOT delete the `openspec/` directory itself

### Requirement: project.md migration hint

The system SHALL preserve project.md and display a migration hint instead of deleting it.

#### Scenario: project.md exists during upgrade

- **WHEN** `openspec/project.md` exists during legacy cleanup
- **THEN** the system SHALL NOT delete the file
- **AND** the system SHALL display a migration hint in the output:
  ```
  Manual migration needed:
    â†’ openspec/project.md still exists
      Move useful content to config.yaml's "context:" field, then delete
  ```

#### Scenario: project.md migration rationale

- **GIVEN** project.md may contain user-written project documentation
- **AND** config.yaml's context field serves the same purpose (auto-injected into artifacts)
- **WHEN** displaying the migration hint
- **THEN** users can migrate manually or use `/opsx:explore` to get AI assistance

### Requirement: Cleanup reporting

The system SHALL report what was cleaned up.

#### Scenario: Displaying cleanup summary

- **WHEN** legacy cleanup completes
- **THEN** the system SHALL display a summary section:
  ```
  Cleaned up legacy files:
    âœ“ Removed CLAUDE.md (replaced by skills)
    âœ“ Removed .claude/commands/openspec/ (replaced by /opsx:*)
    âœ“ Removed openspec/AGENTS.md (no longer needed)
  ```
- **AND IF** `openspec/project.md` exists
- **THEN** the system SHALL display a separate migration section:
  ```
  Manual migration needed:
    â†’ openspec/project.md still exists
      Move useful content to config.yaml's "context:" field, then delete
  ```

#### Scenario: No legacy detected

- **WHEN** no legacy artifacts are found
- **THEN** the system SHALL NOT display the cleanup section
- **AND** proceed directly with skill setup



================================================
FILE: openspec/changes/multi-provider-skill-generation/design.md
================================================
## Context

The `artifact-experimental-setup` command generates skill files and opsx slash commands for AI coding assistants. Currently it hardcodes paths to `.claude/skills` and `.claude/commands/opsx`.

The existing `AI_TOOLS` array in `config.ts` lists 22 AI tools but lacks path information. There's also an existing `SlashCommandConfigurator` system for the old workflow commands, but it's tightly coupled to the old 3 commands (proposal, apply, archive) and can't be easily extended for the 9 opsx commands.

Each AI tool has:
- Different skill directory conventions (`.claude/skills/`, `.cursor/skills/`, etc.)
- Different command file paths (`.claude/commands/opsx/`, `.cursor/commands/`, etc.)
- Different frontmatter formats (YAML keys, structure varies by tool)

## Goals / Non-Goals

**Goals:**
- Support skill generation for any AI tool following the Agent Skills spec
- Support command generation with tool-specific formatting via adapters
- Require explicit tool selection (no defaults)
- Create a generic, extensible command generation system

**Non-Goals:**
- Global path installation (deferred to future work)
- Multi-tool generation in single command (future enhancement)
- Unifying with existing SlashCommandConfigurator (separate systems for now)

## Decisions

### 1. Add `skillsDir` to `AIToolOption` interface

**Decision**: Add single `skillsDir` field to existing interface. No `commandsDir` or `globalSkillsDir`.

```typescript
interface AIToolOption {
  name: string;
  value: string;
  available: boolean;
  successLabel?: string;
  skillsDir?: string;  // e.g., '.claude' - /skills suffix per Agent Skills spec
}
```

**Rationale**:
- Skills follow Agent Skills spec: `<toolDir>/skills/` - suffix is standard
- Commands need per-tool formatting, handled by adapters (not a simple path)
- Global paths deferred - can extend interface later

### 2. Strategy/Adapter pattern for command generation

**Decision**: Create generic command generation with tool-specific adapters.

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CommandContent                              â”‚
â”‚  (tool-agnostic: id, name, description, category, tags, body)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   generateCommand(content, adapter)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Claude  â”‚   â”‚  Cursor  â”‚   â”‚ Windsurf â”‚
        â”‚ Adapter  â”‚   â”‚ Adapter  â”‚   â”‚ Adapter  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interfaces:**

```typescript
// Tool-agnostic command data
interface CommandContent {
  id: string;           // e.g., 'explore', 'new', 'apply'
  name: string;         // e.g., 'OpenSpec Explore'
  description: string;  // e.g., 'Enter explore mode...'
  category: string;     // e.g., 'OpenSpec'
  tags: string[];       // e.g., ['openspec', 'explore']
  body: string;         // The command instructions
}

// Per-tool formatting strategy
interface ToolCommandAdapter {
  toolId: string;
  getFilePath(commandId: string): string;
  formatFile(content: CommandContent): string;
}
```

**Rationale**:
- Separates "what to generate" from "how to format it"
- Each tool's frontmatter quirks encapsulated in its adapter
- Easy to add new tools by implementing adapter interface
- Body content shared across all tools

**Alternative considered**: Extend existing SlashCommandConfigurator
- Rejected: Tightly coupled to old 3 commands, significant refactor needed

### 3. Adapter registry pattern

**Decision**: Create `CommandAdapterRegistry` similar to existing `SlashCommandRegistry`.

```typescript
class CommandAdapterRegistry {
  private static adapters: Map<string, ToolCommandAdapter> = new Map();

  static get(toolId: string): ToolCommandAdapter | undefined;
  static getAll(): ToolCommandAdapter[];
}
```

**Rationale**:
- Consistent with existing codebase patterns
- Easy lookup by tool ID
- Centralized registration

### 4. Required tool flag

**Decision**: Require `--tool` flag - error if omitted.

**Rationale**:
- Explicit tool selection avoids assumptions
- Consistent with project convention of not providing defaults
- Users must consciously choose their target tool

## Risks / Trade-offs

**[Risk] Adapter maintenance burden** â†’ Each new tool needs an adapter. Mitigated by simple interface - most adapters are ~20 lines.

**[Risk] Frontmatter format drift** â†’ Tools may change their formats. Mitigated by encapsulating format in adapter - single place to update.

**[Trade-off] Two command systems** â†’ Old SlashCommandConfigurator and new CommandAdapterRegistry coexist. Acceptable for now - can unify later if needed.

**[Trade-off] skillsDir optional** â†’ Tools without skillsDir configured will error. Acceptable - we add paths as tools are tested.

## Implementation Approach

1. Add `skillsDir` to `AIToolOption` and populate for known tools
2. Create `CommandContent` and `ToolCommandAdapter` interfaces
3. Implement adapters for Claude, Cursor, Windsurf (start with 3)
4. Create `CommandAdapterRegistry`
5. Create `generateCommand()` function
6. Update `artifact-experimental-setup` to use new system
7. Add `--tool` flag with validation



================================================
FILE: openspec/changes/multi-provider-skill-generation/proposal.md
================================================
## Why

The `artifact-experimental-setup` command currently hardcodes skill output paths to `.claude/skills` and `.claude/commands/opsx`. This prevents users of other AI coding tools (Cursor, Windsurf, Codex, etc.) from using OpenSpec's skill generation. We need to support the diverse ecosystem of AI coding assistants, each with their own conventions for skill/instruction file locations and command frontmatter formats.

## What Changes

- Add `skillsDir` path configuration to the existing `AIToolOption` interface in `config.ts`
- Add required `--tool <tool-id>` flag to the `artifact-experimental-setup` command
- Create a generic command generation system using Strategy/Adapter pattern:
  - `CommandContent`: tool-agnostic command data (id, name, description, body)
  - `ToolCommandAdapter`: per-tool formatting (file paths, frontmatter format)
  - `CommandGenerator`: orchestrates generation using content + adapter
- Require explicit tool selection (no default) for clarity

## Capabilities

### New Capabilities

- `ai-tool-paths`: Configuration mapping AI tool IDs to their project-local skill directory paths
- `command-generation`: Generic command generation system with tool adapters for formatting differences

### Modified Capabilities

- `cli-artifact-workflow`: Adding `--tool` flag to setup command for provider selection

## Impact

- **Files Modified**:
  - `src/core/config.ts` - Extend `AIToolOption` interface with `skillsDir` field
  - `src/commands/artifact-workflow.ts` - Add `--tool` flag, use provider paths and adapters
- **New Files**:
  - `src/core/command-generation/types.ts` - CommandContent, ToolCommandAdapter interfaces
  - `src/core/command-generation/generator.ts` - Generic command generator
  - `src/core/command-generation/adapters/*.ts` - Per-tool adapters
- **Backward Compatibility**: Existing workflows unaffected - this is a new command setup feature
- **User-Facing**: Required `--tool` flag on `artifact-experimental-setup` command for explicit tool selection



================================================
FILE: openspec/changes/multi-provider-skill-generation/tasks.md
================================================
## 1. Extend AIToolOption Interface

- [x] 1.1 Add `skillsDir?: string` field to `AIToolOption` interface in `src/core/config.ts`

## 2. Add skillsDir to AI_TOOLS

- [x] 2.1 Add `skillsDir: '.claude'` to Claude Code tool entry
- [x] 2.2 Add `skillsDir: '.cursor'` to Cursor tool entry
- [x] 2.3 Add `skillsDir: '.windsurf'` to Windsurf tool entry
- [x] 2.4 Add skillsDir for other tools with known Agent Skills spec support (codex, opencode, roocode, kilocode, gemini, factory, github-copilot)

## 3. Create Command Generation Types

- [x] 3.1 Create `src/core/command-generation/types.ts` with `CommandContent` interface
- [x] 3.2 Add `ToolCommandAdapter` interface to types.ts
- [x] 3.3 Export types from module index

## 4. Implement Tool Command Adapters

- [x] 4.1 Create `src/core/command-generation/adapters/claude.ts` with Claude frontmatter format
- [x] 4.2 Create `src/core/command-generation/adapters/cursor.ts` with Cursor frontmatter format
- [x] 4.3 Create `src/core/command-generation/adapters/windsurf.ts` with Windsurf frontmatter format
- [x] 4.4 Create base adapter or utility for shared YAML formatting logic (if applicable)

## 5. Create Command Adapter Registry

- [x] 5.1 Create `src/core/command-generation/registry.ts` with `CommandAdapterRegistry` class
- [x] 5.2 Register Claude, Cursor, Windsurf adapters in static initializer
- [x] 5.3 Add `get(toolId)` and `getAll()` methods

## 6. Create Command Generator

- [x] 6.1 Create `src/core/command-generation/generator.ts` with `generateCommand()` function
- [x] 6.2 Add `generateCommands()` function for batch generation
- [x] 6.3 Create module index `src/core/command-generation/index.ts` exporting public API

## 7. Update artifact-experimental-setup Command

- [x] 7.1 Add `--tool <tool-id>` option (required) to command in `src/commands/artifact-workflow.ts`
- [x] 7.2 Add validation: `--tool` flag is required (error if missing with list of valid tools)
- [x] 7.3 Add validation: tool exists in AI_TOOLS
- [x] 7.4 Add validation: tool has skillsDir configured
- [x] 7.5 Replace hardcoded `.claude` skill paths with `tool.skillsDir`
- [x] 7.6 Replace hardcoded command generation with `CommandAdapterRegistry.get()` + `generateCommands()`
- [x] 7.7 Handle missing adapter gracefully (skip commands with message)
- [x] 7.8 Update output messages to show target tool name and paths

## 8. Testing

- [x] 8.1 Add unit tests for `CommandContent` and `ToolCommandAdapter` contracts
- [x] 8.2 Add unit tests for Claude adapter (path + frontmatter format)
- [x] 8.3 Add unit tests for Cursor adapter (path + frontmatter format)
- [x] 8.4 Add unit tests for `CommandAdapterRegistry.get()` and missing adapter case
- [x] 8.5 Add integration test for `--tool` flag validation
- [x] 8.6 Verify cross-platform path handling uses `path.join()` throughout



================================================
FILE: openspec/changes/multi-provider-skill-generation/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-22



================================================
FILE: openspec/changes/multi-provider-skill-generation/specs/ai-tool-paths/spec.md
================================================
# ai-tool-paths Specification

## Purpose

Define the path configuration for AI coding tool skill directories, enabling skill generation to target different tools following the Agent Skills spec.

## Requirements

## ADDED Requirements

### Requirement: AIToolOption skillsDir field

The `AIToolOption` interface SHALL include an optional `skillsDir` field for skill generation path configuration.

#### Scenario: Interface includes skillsDir field

- **WHEN** a tool entry is defined in `AI_TOOLS` that supports skill generation
- **THEN** it SHALL include a `skillsDir` field specifying the project-local base directory (e.g., `.claude`)

#### Scenario: Skills path follows Agent Skills spec

- **WHEN** generating skills for a tool with `skillsDir: '.claude'`
- **THEN** skills SHALL be written to `<projectRoot>/<skillsDir>/skills/`
- **AND** the `/skills` suffix is appended per Agent Skills specification

### Requirement: Path configuration for supported tools

The `AI_TOOLS` array SHALL include `skillsDir` for tools that support the Agent Skills specification.

#### Scenario: Claude Code paths defined

- **WHEN** looking up the `claude` tool
- **THEN** `skillsDir` SHALL be `.claude`

#### Scenario: Cursor paths defined

- **WHEN** looking up the `cursor` tool
- **THEN** `skillsDir` SHALL be `.cursor`

#### Scenario: Windsurf paths defined

- **WHEN** looking up the `windsurf` tool
- **THEN** `skillsDir` SHALL be `.windsurf`

#### Scenario: Tools without skillsDir

- **WHEN** a tool has no `skillsDir` defined
- **THEN** skill generation SHALL error with message indicating the tool is not supported

### Requirement: Cross-platform path handling

The system SHALL handle paths correctly across operating systems.

#### Scenario: Path construction on Windows

- **WHEN** constructing skill paths on Windows
- **THEN** the system SHALL use `path.join()` for all path construction
- **AND** SHALL NOT hardcode forward slashes

#### Scenario: Path construction on Unix

- **WHEN** constructing skill paths on macOS or Linux
- **THEN** the system SHALL use `path.join()` for consistency



================================================
FILE: openspec/changes/multi-provider-skill-generation/specs/cli-artifact-workflow/spec.md
================================================
# cli-artifact-workflow Delta Specification

## Purpose

Add `--tool` flag to the `artifact-experimental-setup` command for multi-provider support.

## ADDED Requirements

### Requirement: Tool selection flag

The `artifact-experimental-setup` command SHALL accept a `--tool <tool-id>` flag to specify the target AI tool.

#### Scenario: Specify tool via flag

- **WHEN** user runs `openspec artifact-experimental-setup --tool cursor`
- **THEN** skill files are generated in `.cursor/skills/`
- **AND** command files are generated using Cursor's frontmatter format

#### Scenario: Missing tool flag

- **WHEN** user runs `openspec artifact-experimental-setup` without `--tool`
- **THEN** the system displays an error requiring the `--tool` flag
- **AND** lists valid tool IDs in the error message

#### Scenario: Unknown tool ID

- **WHEN** user runs `openspec artifact-experimental-setup --tool unknown-tool`
- **AND** the tool ID is not in `AI_TOOLS`
- **THEN** the system displays an error listing valid tool IDs

#### Scenario: Tool without skillsDir

- **WHEN** user specifies a tool that has no `skillsDir` configured
- **THEN** the system displays an error indicating skill generation is not supported for that tool

#### Scenario: Tool without command adapter

- **WHEN** user specifies a tool that has `skillsDir` but no command adapter registered
- **THEN** skill files are generated successfully
- **AND** command generation is skipped with informational message

### Requirement: Output messaging

The setup command SHALL display clear output about what was generated.

#### Scenario: Show target tool in output

- **WHEN** setup command runs successfully
- **THEN** output includes the target tool name (e.g., "Setting up for Cursor...")

#### Scenario: Show generated paths

- **WHEN** setup command completes
- **THEN** output lists all generated skill file paths
- **AND** lists all generated command file paths (if applicable)

#### Scenario: Show skipped commands message

- **WHEN** command generation is skipped due to missing adapter
- **THEN** output includes message: "Command generation skipped - no adapter for <tool>"



================================================
FILE: openspec/changes/multi-provider-skill-generation/specs/command-generation/spec.md
================================================
# command-generation Specification

## Purpose

Define a generic command generation system that supports multiple AI tools through a Strategy/Adapter pattern, separating command content from tool-specific formatting.

## ADDED Requirements

### Requirement: CommandContent interface

The system SHALL define a tool-agnostic `CommandContent` interface for command data.

#### Scenario: CommandContent structure

- **WHEN** defining a command to generate
- **THEN** `CommandContent` SHALL include:
  - `id`: string identifier (e.g., 'explore', 'apply')
  - `name`: human-readable name (e.g., 'OpenSpec Explore')
  - `description`: brief description of command purpose
  - `category`: grouping category (e.g., 'OpenSpec')
  - `tags`: array of tag strings
  - `body`: the command instruction content

### Requirement: ToolCommandAdapter interface

The system SHALL define a `ToolCommandAdapter` interface for per-tool formatting.

#### Scenario: Adapter interface structure

- **WHEN** implementing a tool adapter
- **THEN** `ToolCommandAdapter` SHALL require:
  - `toolId`: string identifier matching `AIToolOption.value`
  - `getFilePath(commandId: string)`: returns relative file path for command
  - `formatFile(content: CommandContent)`: returns complete file content with frontmatter

#### Scenario: Claude adapter formatting

- **WHEN** formatting a command for Claude Code
- **THEN** the adapter SHALL output YAML frontmatter with `name`, `description`, `category`, `tags` fields
- **AND** file path SHALL follow pattern `.claude/commands/opsx/<id>.md`

#### Scenario: Cursor adapter formatting

- **WHEN** formatting a command for Cursor
- **THEN** the adapter SHALL output YAML frontmatter with `name` as `/opsx-<id>`, `id`, `category`, `description` fields
- **AND** file path SHALL follow pattern `.cursor/commands/opsx-<id>.md`

#### Scenario: Windsurf adapter formatting

- **WHEN** formatting a command for Windsurf
- **THEN** the adapter SHALL output YAML frontmatter with `name`, `description`, `category`, `tags` fields
- **AND** file path SHALL follow pattern `.windsurf/commands/opsx/<id>.md`

### Requirement: Command generator function

The system SHALL provide a `generateCommand` function that combines content with adapter.

#### Scenario: Generate command file

- **WHEN** calling `generateCommand(content, adapter)`
- **THEN** it SHALL return an object with:
  - `path`: the file path from `adapter.getFilePath(content.id)`
  - `fileContent`: the formatted content from `adapter.formatFile(content)`

#### Scenario: Generate multiple commands

- **WHEN** generating all opsx commands for a tool
- **THEN** the system SHALL iterate over command contents and generate each using the tool's adapter

### Requirement: CommandAdapterRegistry

The system SHALL provide a registry for looking up tool adapters.

#### Scenario: Get adapter by tool ID

- **WHEN** calling `CommandAdapterRegistry.get('cursor')`
- **THEN** it SHALL return the Cursor adapter or undefined if not registered

#### Scenario: Get all adapters

- **WHEN** calling `CommandAdapterRegistry.getAll()`
- **THEN** it SHALL return array of all registered adapters

#### Scenario: Adapter not found

- **WHEN** looking up an adapter for unregistered tool
- **THEN** `CommandAdapterRegistry.get()` SHALL return undefined
- **AND** caller SHALL handle missing adapter appropriately

### Requirement: Shared command body content

The body content of commands SHALL be shared across all tools.

#### Scenario: Same instructions across tools

- **WHEN** generating the 'explore' command for Claude and Cursor
- **THEN** both SHALL use the same `body` content
- **AND** only the frontmatter and file path SHALL differ



================================================
FILE: openspec/changes/project-config/design.md
================================================
# Design: Project Config

## Context

OpenSpec currently has a fixed schema resolution order:
1. `--schema` CLI flag
2. `.openspec.yaml` in change directory
3. Hardcoded default: `"spec-driven"`

This forces users who want project-level customization to fork entire schemas, even for simple additions like injecting tech stack context or adding artifact-specific rules.

The proposal introduces `openspec/config.yaml` as a lightweight customization layer that sits between preset schemas and full forking. It allows teams to:
- Set a default schema
- Inject project context into all artifacts
- Add per-artifact rules

**Constraints:**
- Must not break existing changes that lack config
- Must maintain clean separation between "configure" (this) and "fork" (project-local-schemas)
- Config is project-level only (no global/user-level config)

**Key stakeholders:**
- OpenSpec users who need light customization without forking
- Teams sharing workflow conventions via committed config

## Goals / Non-Goals

**Goals:**
- Load and parse `openspec/config.yaml` using Zod schema
- Use config's `schema` field as default in schema resolution
- Inject `context` into all artifact instructions
- Inject `rules` into matching artifact instructions only
- Gracefully handle missing or invalid config (fallback to defaults)

**Non-Goals:**
- Structural changes to schemas (`skip`, `add`, inheritance) - those belong in fork path
- File references for context (`context: ./file.md`) - start with strings
- Global user-level config (XDG dirs, etc.)
- Config management commands (`openspec config init`) - manual creation for now
- Migration from old setups (no existing config to migrate from)

## Decisions

### 1. Config File Format: YAML vs JSON

**Decision:** Use YAML (`.yaml` extension, support `.yml` alias)

**Rationale:**
- YAML supports multi-line strings naturally (`context: |`)
- More readable for documentation-heavy content
- Consistent with `.openspec.yaml` used in changes
- Easy to parse with existing `yaml` library

**Alternatives considered:**
- JSON: More strict, but poor multi-line string UX
- TOML: Less familiar to most users

### 2. Config Location: Project Root vs openspec/ Directory

**Decision:** `./openspec/config.yaml` (inside openspec directory)

**Rationale:**
- Co-located with `openspec/schemas/` (project-local-schemas)
- Keeps project root clean
- Natural namespace for OpenSpec configuration
- Mirrors structure used by other tools (e.g., `.github/`)

**Alternatives considered:**
- `./openspec.config.yaml` in root: Pollutes root, less clear ownership
- XDG config directories: Out of scope, no global config yet

### 3. Context Injection: XML Tags vs Markdown Sections

**Decision:** Use XML-style tags `<context>` and `<rules>`

**Rationale:**
- Clear delimiters that don't conflict with Markdown
- Agents can easily parse structure
- Matches existing patterns in the codebase for special sections

**Example:**
```xml
<context>
Tech stack: TypeScript, React
</context>

<rules>
- Include rollback plan
</rules>

<template>
## Summary
...
</template>
```

**Alternatives considered:**
- Markdown headers: Conflicts with template content
- Comments: Less visible to agents

### 4. Schema Resolution: Insert Position

**Decision:** Config's `schema` field goes between change metadata and hardcoded default

**New resolution order:**
1. `--schema` CLI flag (explicit override)
2. `.openspec.yaml` in change directory (change-specific binding)
3. **`openspec/config.yaml` schema field** (NEW - project default)
4. `"spec-driven"` (hardcoded fallback)

**Rationale:**
- Preserves CLI and change-level overrides (most specific wins)
- Makes config act as a "project default"
- Backwards compatible (no existing configs to conflict with)

### 5. Rules Validation: Strict vs Permissive

**Decision:** Warn on unknown artifact IDs, don't error

**Rationale:**
- Future-proof: If schema adds new artifacts, old configs don't break
- Dev experience: Typos show warnings, but don't halt workflow
- User can fix incrementally

**Example:**
```yaml
rules:
  proposal: [...]
  testplan: [...]  # Schema doesn't have this artifact â†’ WARN, not ERROR
```

### 6. Error Handling: Config Parse Failures

**Decision:** Log warning and fall back to defaults (don't halt commands)

**Rationale:**
- Syntax errors in config shouldn't break all of OpenSpec
- User can fix config incrementally
- Commands remain usable during config development

**Warning message:**
```
âš ï¸  Failed to parse openspec/config.yaml: [error details]
    Falling back to default schema (spec-driven)
```

## Implementation Plan

### Phase 1: Core Types and Loading

**File: `src/core/project-config.ts` (NEW)**

```typescript
import { z } from 'zod';
import { readFileSync, existsSync } from 'fs';
import { parse as parseYaml } from 'yaml';
import { findProjectRoot } from '../utils/path-utils';

/**
 * Zod schema for project configuration.
 *
 * Purpose:
 * 1. Documentation - clearly defines the config file structure
 * 2. Type safety - TypeScript infers ProjectConfig type from schema
 * 3. Runtime validation - uses safeParse() for resilient field-by-field validation
 *
 * Why Zod over manual validation:
 * - Helps understand OpenSpec's data interfaces at a glance
 * - Single source of truth for type and validation
 * - Consistent with other OpenSpec schemas
 */
export const ProjectConfigSchema = z.object({
  schema: z.string().min(1).describe('The workflow schema to use (e.g., "spec-driven", "tdd")'),
  context: z.string().optional().describe('Project context injected into all artifact instructions'),
  rules: z.record(
    z.string(),
    z.array(z.string())
  ).optional().describe('Per-artifact rules, keyed by artifact ID'),
});

export type ProjectConfig = z.infer<typeof ProjectConfigSchema>;

const MAX_CONTEXT_SIZE = 50 * 1024; // 50KB hard limit

/**
 * Read and parse openspec/config.yaml from project root.
 * Uses resilient parsing - validates each field independently using Zod safeParse.
 * Returns null if file doesn't exist.
 * Returns partial config if some fields are invalid (with warnings).
 */
export function readProjectConfig(): ProjectConfig | null {
  const projectRoot = findProjectRoot();

  // Try both .yaml and .yml, prefer .yaml
  let configPath = path.join(projectRoot, 'openspec', 'config.yaml');
  if (!existsSync(configPath)) {
    configPath = path.join(projectRoot, 'openspec', 'config.yml');
    if (!existsSync(configPath)) {
      return null; // No config is OK
    }
  }

  try {
    const content = readFileSync(configPath, 'utf-8');
    const raw = parseYaml(content);

    if (!raw || typeof raw !== 'object') {
      console.warn(`âš ï¸  openspec/config.yaml is not a valid YAML object`);
      return null;
    }

    const config: Partial<ProjectConfig> = {};

    // Parse schema field using Zod
    const schemaField = z.string().min(1);
    const schemaResult = schemaField.safeParse(raw.schema);
    if (schemaResult.success) {
      config.schema = schemaResult.data;
    } else if (raw.schema !== undefined) {
      console.warn(`âš ï¸  Invalid 'schema' field in config (must be non-empty string)`);
    }

    // Parse context field with size limit
    if (raw.context !== undefined) {
      const contextField = z.string();
      const contextResult = contextField.safeParse(raw.context);

      if (contextResult.success) {
        const contextSize = Buffer.byteLength(contextResult.data, 'utf-8');
        if (contextSize > MAX_CONTEXT_SIZE) {
          console.warn(
            `âš ï¸  Context too large (${(contextSize / 1024).toFixed(1)}KB, limit: ${MAX_CONTEXT_SIZE / 1024}KB)`
          );
          console.warn(`   Ignoring context field`);
        } else {
          config.context = contextResult.data;
        }
      } else {
        console.warn(`âš ï¸  Invalid 'context' field in config (must be string)`);
      }
    }

    // Parse rules field using Zod
    if (raw.rules !== undefined) {
      const rulesField = z.record(z.string(), z.array(z.string()));

      // First check if it's an object structure
      if (typeof raw.rules === 'object' && !Array.isArray(raw.rules)) {
        const parsedRules: Record<string, string[]> = {};
        let hasValidRules = false;

        for (const [artifactId, rules] of Object.entries(raw.rules)) {
          const rulesArrayResult = z.array(z.string()).safeParse(rules);

          if (rulesArrayResult.success) {
            // Filter out empty strings
            const validRules = rulesArrayResult.data.filter(r => r.length > 0);
            if (validRules.length > 0) {
              parsedRules[artifactId] = validRules;
              hasValidRules = true;
            }
            if (validRules.length < rulesArrayResult.data.length) {
              console.warn(
                `âš ï¸  Some rules for '${artifactId}' are empty strings, ignoring them`
              );
            }
          } else {
            console.warn(
              `âš ï¸  Rules for '${artifactId}' must be an array of strings, ignoring this artifact's rules`
            );
          }
        }

        if (hasValidRules) {
          config.rules = parsedRules;
        }
      } else {
        console.warn(`âš ï¸  Invalid 'rules' field in config (must be object)`);
      }
    }

    // Return partial config even if some fields failed
    return Object.keys(config).length > 0 ? (config as ProjectConfig) : null;

  } catch (error) {
    console.warn(`âš ï¸  Failed to parse openspec/config.yaml:`, error);
    return null;
  }
}

/**
 * Validate artifact IDs in rules against a schema's artifacts.
 * Called during instruction loading (when schema is known).
 * Returns warnings for unknown artifact IDs.
 */
export function validateConfigRules(
  rules: Record<string, string[]>,
  validArtifactIds: Set<string>,
  schemaName: string
): string[] {
  const warnings: string[] = [];

  for (const artifactId of Object.keys(rules)) {
    if (!validArtifactIds.has(artifactId)) {
      const validIds = Array.from(validArtifactIds).sort().join(', ');
      warnings.push(
        `Unknown artifact ID in rules: "${artifactId}". ` +
        `Valid IDs for schema "${schemaName}": ${validIds}`
      );
    }
  }

  return warnings;
}

/**
 * Suggest valid schema names when user provides invalid schema.
 * Uses fuzzy matching to find similar names.
 */
export function suggestSchemas(
  invalidSchemaName: string,
  availableSchemas: { name: string; isBuiltIn: boolean }[]
): string {
  // Simple fuzzy match: Levenshtein distance
  function levenshtein(a: string, b: string): number {
    const matrix: number[][] = [];
    for (let i = 0; i <= b.length; i++) {
      matrix[i] = [i];
    }
    for (let j = 0; j <= a.length; j++) {
      matrix[0][j] = j;
    }
    for (let i = 1; i <= b.length; i++) {
      for (let j = 1; j <= a.length; j++) {
        if (b.charAt(i - 1) === a.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          );
        }
      }
    }
    return matrix[b.length][a.length];
  }

  // Find closest matches (distance <= 3)
  const suggestions = availableSchemas
    .map(s => ({ ...s, distance: levenshtein(invalidSchemaName, s.name) }))
    .filter(s => s.distance <= 3)
    .sort((a, b) => a.distance - b.distance)
    .slice(0, 3);

  const builtIn = availableSchemas.filter(s => s.isBuiltIn).map(s => s.name);
  const projectLocal = availableSchemas.filter(s => !s.isBuiltIn).map(s => s.name);

  let message = `âŒ Schema '${invalidSchemaName}' not found in openspec/config.yaml\n\n`;

  if (suggestions.length > 0) {
    message += `Did you mean one of these?\n`;
    suggestions.forEach(s => {
      const type = s.isBuiltIn ? 'built-in' : 'project-local';
      message += `  - ${s.name} (${type})\n`;
    });
    message += '\n';
  }

  message += `Available schemas:\n`;
  if (builtIn.length > 0) {
    message += `  Built-in: ${builtIn.join(', ')}\n`;
  }
  if (projectLocal.length > 0) {
    message += `  Project-local: ${projectLocal.join(', ')}\n`;
  } else {
    message += `  Project-local: (none found)\n`;
  }

  message += `\nFix: Edit openspec/config.yaml and change 'schema: ${invalidSchemaName}' to a valid schema name`;

  return message;
}
```

### Phase 2: Schema Resolution

**File: `src/utils/change-metadata.ts`**

Update `resolveSchemaForChange()` to check config:

```typescript
export function resolveSchemaForChange(
  changeName: string,
  cliSchema?: string
): string {
  // 1. CLI flag wins
  if (cliSchema) {
    return cliSchema;
  }

  // 2. Change metadata (.openspec.yaml)
  const metadata = readChangeMetadata(changeName);
  if (metadata?.schema) {
    return metadata.schema;
  }

  // 3. Project config (NEW)
  const projectConfig = readProjectConfig();
  if (projectConfig?.schema) {
    return projectConfig.schema;
  }

  // 4. Hardcoded default
  return 'spec-driven';
}
```

**File: `src/utils/change-utils.ts`**

Update `createNewChange()` to use config schema:

```typescript
export function createNewChange(
  changeName: string,
  schema?: string
): void {
  // Use schema from config if not specified
  const resolvedSchema = schema ?? readProjectConfig()?.schema ?? 'spec-driven';

  // ... rest of change creation logic
}
```

### Phase 3: Instruction Injection and Validation

**File: `src/core/artifact-graph/instruction-loader.ts`**

Update `loadInstructions()` to inject context, rules, and validate artifact IDs:

```typescript
// Session-level cache for validation warnings (avoid repeating same warnings)
const shownWarnings = new Set<string>();

export function loadInstructions(
  changeName: string,
  artifactId: string
): InstructionOutput {
  const projectConfig = readProjectConfig();

  // Load base instructions from schema
  const baseInstructions = loadSchemaInstructions(changeName, artifactId);
  const schema = getSchemaForChange(changeName); // Assumes we have schema loaded

  // Validate rules artifact IDs (only once per session)
  if (projectConfig?.rules) {
    const validArtifactIds = new Set(schema.artifacts.map(a => a.id));
    const warnings = validateConfigRules(
      projectConfig.rules,
      validArtifactIds,
      schema.name
    );

    // Show each unique warning only once per session
    for (const warning of warnings) {
      if (!shownWarnings.has(warning)) {
        console.warn(`âš ï¸  ${warning}`);
        shownWarnings.add(warning);
      }
    }
  }

  // Build enriched instruction with XML sections
  let enrichedInstruction = '';

  // Add context (all artifacts)
  if (projectConfig?.context) {
    enrichedInstruction += `<context>\n${projectConfig.context}\n</context>\n\n`;
  }

  // Add rules (only for matching artifact)
  const rulesForArtifact = projectConfig?.rules?.[artifactId];
  if (rulesForArtifact && rulesForArtifact.length > 0) {
    enrichedInstruction += `<rules>\n`;
    for (const rule of rulesForArtifact) {
      enrichedInstruction += `- ${rule}\n`;
    }
    enrichedInstruction += `</rules>\n\n`;
  }

  // Add original template
  enrichedInstruction += `<template>\n${baseInstructions.template}\n</template>`;

  return {
    ...baseInstructions,
    instruction: enrichedInstruction,
  };
}
```

**Note on validation timing:** Rules are validated lazily during instruction loading (not at config load time) because:
1. Schema isn't known at config load time (circular dependency)
2. Warnings shown when user actually uses the feature (better UX)
3. Validation warnings cached per session to avoid spam

### Phase 4: Performance and Caching

**Why config is read multiple times:**

```typescript
// Example: "openspec instructions proposal --change my-feature"

// 1. Schema resolution (to know which schema to use)
resolveSchemaForChange('my-feature')
  â†’ readProjectConfig()  // Read #1

// 2. Instruction loading (to inject context and rules)
loadInstructions('my-feature', 'proposal')
  â†’ readProjectConfig()  // Read #2

// Result: Config read twice per command
// More complex commands may read 3-5 times
```

**Performance Strategy:**

V1 approach: No caching, read config fresh each time
- Simpler implementation
- No cache invalidation complexity
- Acceptable if config reads are fast enough

**Benchmark targets:**
- Typical config (1KB context, 5 artifact rules): **< 10ms** per read (imperceptible even 5x)
- Large config (50KB context limit): **< 50ms** per read (acceptable for rare case)

**If benchmarks fail:** Add simple caching:

```typescript
// Simple in-memory cache with no invalidation
let cachedConfig: { mtime: number; config: ProjectConfig | null } | null = null;

export function readProjectConfig(): ProjectConfig | null {
  const projectRoot = findProjectRoot();
  const configPath = path.join(projectRoot, 'openspec', 'config.yaml');

  if (!existsSync(configPath)) {
    return null;
  }

  const stats = statSync(configPath);
  const mtime = stats.mtimeMs;

  // Return cached config if file hasn't changed
  if (cachedConfig && cachedConfig.mtime === mtime) {
    return cachedConfig.config;
  }

  // Read and parse config
  const config = parseConfigFile(configPath); // Extracted logic

  // Cache result
  cachedConfig = { mtime, config };
  return config;
}
```

**Performance testing task:** Add to Phase 6 (Testing)
- Measure typical config read time (1KB context)
- Measure large config read time (50KB context limit)
- Measure repeated reads within single command
- Document results, add caching only if needed

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                              â”‚
â”‚  User runs: openspec instructions proposal --change foo     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  resolveSchemaForChange("foo")                               â”‚
â”‚                                                              â”‚
â”‚  1. Check CLI flag âœ—                                         â”‚
â”‚  2. Check .openspec.yaml âœ—                                   â”‚
â”‚  3. Check openspec/config.yaml âœ“ â†’ "spec-driven"             â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  loadInstructions("foo", "proposal")                         â”‚
â”‚                                                              â”‚
â”‚  1. Load spec-driven/artifacts/proposal.yaml                 â”‚
â”‚  2. Read openspec/config.yaml                                â”‚
â”‚  3. Build enriched instruction:                              â”‚
â”‚     - <context>...</context>                                 â”‚
â”‚     - <rules>...</rules>  (if rules.proposal exists)         â”‚
â”‚     - <template>...</template>                               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return InstructionOutput with enriched content              â”‚
â”‚                                                              â”‚
â”‚  Agent sees project context + rules + schema template        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Risks / Trade-offs

**[Risk]** Config typos silently ignored (e.g., wrong artifact ID in rules)
â†’ **Mitigation:** Validate and warn on unknown artifact IDs during config load. Don't error to allow forward compatibility.

**[Risk]** Context grows too large, pollutes all artifact instructions
â†’ **Mitigation:** Document recommended size (< 500 chars). If this becomes an issue, add per-artifact context override later.

**[Risk]** YAML parsing errors break OpenSpec commands
â†’ **Mitigation:** Catch parse errors, log warning, fall back to defaults. Commands remain functional.

**[Risk]** Config cached incorrectly across commands
â†’ **Mitigation:** Read config fresh on each `readProjectConfig()` call. No caching layer for v1 (simplicity over perf).

**[Trade-off]** Context is injected into ALL artifacts
â†’ **Benefit:** Consistent project knowledge across workflow
â†’ **Cost:** Can't scope context to specific artifacts (yet)
â†’ **Future:** Add `context: { global: "...", proposal: "..." }` if needed

**[Trade-off]** Rules use artifact IDs, not human names
â†’ **Benefit:** Stable identifiers (IDs don't change)
â†’ **Cost:** User needs to know artifact IDs from schema
â†’ **Mitigation:** Document common artifact IDs, show in `openspec status` output

## Migration Plan

**No migration needed** - this is a new feature with no existing state.

**Rollout steps:**
1. Deploy with config loading behind feature flag (optional, for safety)
2. Test with internal project (this repo)
3. Document in README with examples
4. Remove feature flag if used

**Rollback strategy:**
- Config is additive only (doesn't break existing changes)
- If bugs found, config parsing can be disabled with env var
- Users can delete config file to restore old behavior

## Open Questions

**Q: Should context support file references (`context: ./CONTEXT.md`)?**
**A (deferred):** Start with string-only. Add file reference later if users request it. Keeps v1 simple.

**Q: Should we support `.yml` alias in addition to `.yaml`?**
**A:** Yes, check both extensions. Prefer `.yaml` in docs, but accept `.yml` for users who prefer it.

**Q: What if config's schema field references a non-existent schema?**
**A:** Schema resolution will fail downstream. Show error when trying to load schema, suggest valid schema names.

**Q: Should rules be validated against the resolved schema's artifact IDs?**
**A:** Yes, validate and warn, but don't halt. This allows forward compatibility if schema evolves.



================================================
FILE: openspec/changes/project-config/proposal.md
================================================
# Project Config

## Summary

Add `openspec/config.yaml` support for project-level configuration. This enables teams to customize OpenSpec behavior without forking schemas, by providing context and rules that are injected into artifact generation.

## Motivation

Currently, customizing OpenSpec requires forking entire schemas:
- Must copy all files even to add one rule
- Lose updates when openspec upgrades
- High friction for simple customizations

Most users don't need different workflow structure. They need to:
- Provide project context (tech stack, conventions, constraints)
- Add rules for specific artifacts (requirements, formatting preferences)

## Design Decisions

### Two-Path Model

OpenSpec customization follows two distinct paths:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   CONFIGURE (this change)         FORK (project-local-schemas)  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚   Use a preset schema             Define your own schema        â”‚
â”‚   + add context                   from scratch                  â”‚
â”‚   + add rules                                                   â”‚
â”‚                                                                 â”‚
â”‚   openspec/config.yaml            openspec/schemas/my-flow/     â”‚
â”‚                                                                 â”‚
â”‚   âœ“ Simple                        âœ“ Full control                â”‚
â”‚   âœ“ Get updates                   âœ— You maintain everything     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Config Schema

```yaml
# openspec/config.yaml

# Required: which workflow schema to use
schema: spec-driven

# Optional: project context injected into all artifact prompts
context: |
  Tech stack: TypeScript, React, Node.js, PostgreSQL
  API style: RESTful, documented in docs/api-conventions.md
  Testing: Jest + React Testing Library
  We value backwards compatibility for all public APIs

# Optional: per-artifact rules (additive)
rules:
  proposal:
    - Include rollback plan
    - Identify affected teams and notify in #platform-changes
  specs:
    - Use Given/When/Then format
    - Reference existing patterns before inventing new ones
  tasks:
    - Each task should be completable in < 2 hours
    - Include acceptance criteria
```

### What's NOT in Config

The following were explicitly excluded to keep the model simple:

| Feature | Decision | Rationale |
|---------|----------|-----------|
| `skip: [artifact]` | Not supported | Structural changes belong in fork path |
| `add: [{...}]` | Not supported | Structural changes belong in fork path |
| `extends: base` | Not supported | No inheritance, fork is full copy |
| `context: ./file.md` | Not supported (yet) | Start with string, add file reference later if needed |

### Field Definitions

#### `schema` (required)

Which workflow schema to use. Can be:
- Built-in name: `spec-driven`, `tdd`
- Project-local schema name: `my-workflow` (requires project-local-schemas change)

This becomes the default schema for:
- New changes created without `--schema` flag
- Commands run on changes without `.openspec.yaml` metadata

#### `context` (optional)

A string containing project context. Injected into ALL artifact prompts.

Use cases:
- Tech stack description
- Link to conventions/style guides
- Team constraints or preferences
- Domain-specific context

#### `rules` (optional)

Per-artifact rules, keyed by artifact ID. Additive to schema's built-in guidance.

```yaml
rules:
  <artifact-id>:
    - Rule 1
    - Rule 2
```

Rules are injected into the specific artifact's prompt, not all prompts.

### Injection Format

When generating instructions for an artifact:

```xml
<context>
Tech stack: TypeScript, React, Node.js, PostgreSQL
API style: RESTful, documented in docs/api-conventions.md
...
</context>

<rules>
- Include rollback plan
- Identify affected teams and notify in #platform-changes
</rules>

<template>
[Schema's built-in template content]
</template>
```

Context appears for all artifacts. Rules only appear for the matching artifact.

### Config Creation Strategy

**Why integrate with `artifact-experimental-setup`?**

This feature targets **experimental workflow users**. The decision to create config during experimental setup (rather than providing standalone commands) is intentional:

**Rationale:**
1. **Single entry point** - Users setting up experimental features are already in "configuration mode"
2. **Contextual timing** - Natural to configure project defaults when setting up workflow
3. **Avoids premature API surface** - No standalone `openspec config init` until feature graduates
4. **Experimental scope** - Keeps config as experimental feature, not stable API
5. **Progressive disclosure** - Users can skip and create manually later if needed

**Evolution path:**

```
Today (Experimental):
  openspec artifact-experimental-setup
    â†’ prompts for config creation
    â†’ creates .claude/skills/
    â†’ creates openspec/config.yaml

Future (When graduating):
  openspec init
    â†’ prompts for config creation
    â†’ creates openspec/ directory
    â†’ creates openspec/config.yaml

  + standalone commands:
    openspec config init
    openspec config validate
    openspec config set <key> <value>
```

**Why optional?**

Config is **additive**, not required:
- OpenSpec works without config (uses defaults)
- Users can skip during setup and add manually later
- Teams can start simple and add config when they feel friction
- No config file in git = no problem, everyone gets defaults

**Design principle:** The system never *requires* config, but makes it easy to create when users want customization.

## Scope

### In Scope

**Core Config System:**
- Define `ProjectConfig` type with Zod schema
- Add `readProjectConfig()` function with graceful error handling
- Update instruction generation to inject context (all artifacts)
- Update instruction generation to inject rules (per-artifact)
- Update schema resolution to use config's `schema` field as default
- Update `openspec new change` to use config's schema as default

**Config Creation (Experimental Setup):**
- Extend `artifact-experimental-setup` command to optionally create config
- Interactive prompts for schema selection (with description of each schema)
- Interactive prompts for project context (optional multi-line input)
- Interactive prompts for per-artifact rules (optional)
- Validate config immediately after creation
- Show clear "skip" option for users who want to create config manually later
- Display created config location and usage examples

### Out of Scope

- `skip` / `add` for structural changes (use fork path for structural changes)
- File reference for context (`context: ./CONTEXT.md`) - start with string, add later if needed
- Global user-level config (XDG directories, etc.)
- Integration with standard `openspec init` (will add when experimental graduates)
- Standalone `openspec config init` command (may add in future change)
- `openspec config validate` command (may add in future change)
- Config editing/updating commands (users edit YAML directly)

## User Experience

### Setting Up Config (Experimental Workflow)

When users set up the experimental workflow, they're prompted to optionally create config:

```bash
$ openspec artifact-experimental-setup

Setting up experimental artifact workflow...

âœ“ Created .claude/skills/openspec-explore/SKILL.md
âœ“ Created .claude/skills/openspec-new-change/SKILL.md
âœ“ Created .claude/skills/openspec-continue-change/SKILL.md
âœ“ Created .claude/skills/openspec-apply-change/SKILL.md
âœ“ Created .claude/skills/openspec-ff-change/SKILL.md
âœ“ Created .claude/skills/openspec-sync-specs/SKILL.md
âœ“ Created .claude/skills/openspec-archive-change/SKILL.md

âœ“ Created .claude/commands/opsx/explore.md
âœ“ Created .claude/commands/opsx/new.md
âœ“ Created .claude/commands/opsx/continue.md
âœ“ Created .claude/commands/opsx/apply.md
âœ“ Created .claude/commands/opsx/ff.md
âœ“ Created .claude/commands/opsx/sync.md
âœ“ Created .claude/commands/opsx/archive.md

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ Project Configuration (Optional)

Configure project defaults for OpenSpec workflows.

? Create openspec/config.yaml? (Y/n) Y

? Default schema for new changes?
  â¯ spec-driven (proposal â†’ specs â†’ design â†’ tasks)
    tdd (spec â†’ tests â†’ implementation â†’ docs)

? Add project context? (optional)
  Context is shown to AI when creating artifacts.
  Examples: tech stack, conventions, style guides, domain knowledge

  Press Enter to skip, or type/paste context:
  â”‚ Tech stack: TypeScript, React, Node.js, PostgreSQL
  â”‚ API style: RESTful, documented in docs/api-conventions.md
  â”‚ Testing: Jest + React Testing Library
  â”‚ We value backwards compatibility for all public APIs
  â”‚
  [Press Enter when done]

? Add per-artifact rules? (optional) (Y/n) Y

  Which artifacts should have custom rules?
  [Space to select, Enter when done]
  â—¯ proposal
  â—‰ specs
  â—¯ design
  â—¯ tasks

? Rules for specs artifact:
  Enter rules one per line, press Enter on empty line to finish:
  â”‚ Use Given/When/Then format for scenarios
  â”‚ Reference existing patterns before inventing new ones
  â”‚
  [Empty line to finish]

âœ“ Created openspec/config.yaml

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ‰ Setup Complete!

ğŸ“– Config created at: openspec/config.yaml
   â€¢ Default schema: spec-driven
   â€¢ Project context: Added (4 lines)
   â€¢ Rules: 1 artifact configured

Usage:
  â€¢ New changes automatically use 'spec-driven' schema
  â€¢ Context injected into all artifact instructions
  â€¢ Rules applied to matching artifacts

To share with team:
  git add openspec/config.yaml .claude/
  git commit -m "Setup OpenSpec experimental workflow with project config"

[Rest of experimental setup output...]
```

**Key UX decisions:**

1. **Prompted during setup** - Natural place since users are already configuring experimental features
2. **Optional at every step** - Clear skip options, no forced configuration
3. **Guided prompts** - Schema descriptions, example context, artifact selection
4. **Immediate validation** - Config is validated after creation, errors shown immediately
5. **Clear output** - Shows exactly what was created and how it affects workflow

### Setting Up Config (Manual Creation)

Users can also create config manually (or skip during setup and add later):

```bash
# Create config file manually
cat > openspec/config.yaml << 'EOF'
schema: spec-driven

context: |
  Tech stack: TypeScript, React, Node.js
  We follow REST conventions documented in docs/api.md
  All changes require backwards compatibility consideration

rules:
  proposal:
    - Must include rollback plan
    - Must identify affected teams
  specs:
    - Use Given/When/Then format
EOF
```

### Effect on Workflow

Once config is created, it affects the experimental workflow in three ways:

**1. Default Schema Selection**

```bash
# Before config: must specify schema
/opsx:new my-feature --schema spec-driven

# After config (with schema: spec-driven): schema is automatic
/opsx:new my-feature
# Automatically uses spec-driven from config

# Override still works
/opsx:new my-feature --schema tdd
# Uses tdd, ignoring config
```

**2. Context Injection (All Artifacts)**

```bash
# Get instructions for any artifact
openspec instructions proposal --change my-feature

# Output now includes project context:
<context>
Tech stack: TypeScript, React, Node.js, PostgreSQL
API style: RESTful, documented in docs/api-conventions.md
Testing: Jest + React Testing Library
We value backwards compatibility for all public APIs
</context>

<template>
[Schema's proposal template]
</template>
```

Context appears in instructions for **all artifacts** (proposal, specs, design, tasks).

**3. Rules Injection (Per-Artifact)**

```bash
# Get instructions for artifact with rules configured
openspec instructions specs --change my-feature

# Output includes artifact-specific rules:
<context>
[Project context]
</context>

<rules>
- Use Given/When/Then format for scenarios
- Reference existing patterns before inventing new ones
</rules>

<template>
[Schema's specs template]
</template>
```

Rules only appear for the **specific artifact** they're configured for.

**Artifacts without rules** (e.g., design, tasks) don't get a `<rules>` section:

```bash
openspec instructions design --change my-feature
# Output: <context> then <template> only (no rules)
```

### Team Sharing

```bash
# Commit config
git add openspec/config.yaml
git commit -m "Add project config with context and rules"

# Everyone gets the same context and rules automatically
```

## Implementation Notes

### Files to Modify/Create

| File | Changes |
|------|---------|
| `src/core/project-config.ts` | **NEW FILE:** Types, parsing, reading, validation helpers |
| `src/core/artifact-graph/instruction-loader.ts` | Inject context (all artifacts) and rules (per-artifact) |
| `src/utils/change-utils.ts` | Use config schema as default in `createChange()` |
| `src/utils/change-metadata.ts` | Update `resolveSchemaForChange()` to check config |
| `src/commands/artifact-workflow.ts` | Extend `artifactExperimentalSetupCommand()` to prompt for config creation |
| `src/core/config-prompts.ts` | **NEW FILE:** Interactive prompts for config creation (reusable) |

### Config Location

Always at `./openspec/config.yaml` relative to project root. No XDG/global config for simplicity.

### Resolution Order Update

Schema selection order becomes:

```
1. --schema CLI flag                    # Explicit override
2. .openspec.yaml in change directory   # Change-specific binding
3. openspec/config.yaml schema field    # Project default (NEW)
4. "spec-driven"                        # Hardcoded fallback
```

### Validation

- `schema` must be a valid schema name (exists in resolution)
- `context` must be string
- `rules` must be object with string keys (artifact IDs) and array values
- Unknown artifact IDs in `rules` should warn, not error (allows forward compat)

### Experimental Setup Integration

**Changes to `artifactExperimentalSetupCommand()` in `src/commands/artifact-workflow.ts`:**

After creating skills and commands, the setup command will:

1. **Display section header:**
   ```
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ğŸ“‹ Project Configuration (Optional)
   Configure project defaults for OpenSpec workflows.
   ```

2. **Prompt: Create config?**
   - Yes/No prompt with default "Yes"
   - If No â†’ skip entire config section, show usage instructions
   - If Yes â†’ continue to detailed prompts

3. **Prompt: Schema selection**
   - Use `listSchemasWithInfo()` to get available schemas
   - Display each with description and artifact flow
   - Default to first schema (likely "spec-driven")

4. **Prompt: Project context**
   - Multi-line input (or editor if available)
   - Show examples: "tech stack, conventions, style guides"
   - Allow empty (skip)

5. **Prompt: Per-artifact rules**
   - Yes/No prompt, default "No" (rules are less common)
   - If Yes:
     - Show checklist of artifacts from selected schema
     - For each selected artifact, prompt for rules (line-by-line input)
     - Allow empty line to finish each artifact's rules

6. **Create and validate config:**
   - Build `ProjectConfig` object from inputs
   - Validate with Zod schema
   - Write to `openspec/config.yaml` using YAML serializer
   - If validation fails, show error and ask to retry or skip

7. **Display success summary:**
   - Path to created config
   - Summary: schema used, context added (line count), rules count
   - Usage examples showing how config affects workflow
   - Suggestion to commit config to git

**Error handling:**
- Invalid schema selection â†’ show available schemas with fuzzy match suggestions, retry
- Context too large (>50KB) â†’ reject with error, ask to reduce size
- Rules reference invalid artifact â†’ warn but continue (forward compat)
- File write fails â†’ show error, suggest manual creation
- Config already exists â†’ show message, skip config section, continue with setup
- User cancellation (Ctrl+C) â†’ log "Config creation cancelled", continue with rest of setup (skills/commands already created)

**If config already exists:**

When `openspec/config.yaml` already exists:

```bash
$ openspec artifact-experimental-setup

[Skills and commands created...]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ Project Configuration

â„¹ï¸  openspec/config.yaml already exists. Skipping config creation.

   To update config, edit openspec/config.yaml manually or:
   1. Delete openspec/config.yaml
   2. Run openspec artifact-experimental-setup again

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[Rest of setup output...]
```

This prevents accidentally overwriting user's config.

**Implementation approach:**

Create separate `src/core/config-prompts.ts` module:

```typescript
export interface ConfigPromptResult {
  createConfig: boolean;
  schema?: string;
  context?: string;
  rules?: Record<string, string[]>;
}

export async function promptForConfig(): Promise<ConfigPromptResult> {
  // Prompt logic using inquirer or similar
  // Returns structured result for config creation
  // Throws ExitPromptError on Ctrl+C (handled by caller)
}
```

**Ctrl+C handling in setup command:**

```typescript
try {
  const configResult = await promptForConfig();
  if (configResult.createConfig) {
    writeConfigFile(configResult);
    console.log('âœ“ Created openspec/config.yaml');
  }
} catch (error) {
  if (error.name === 'ExitPromptError') {
    console.log('\nâ„¹ï¸  Config creation cancelled');
    console.log('   Skills and commands already created');
    console.log('   Run setup again to create config later');
    // Continue with rest of setup (not a fatal error)
  } else {
    throw error; // Re-throw unexpected errors
  }
}
```

This keeps prompts reusable and testable separately from the setup command.

### Dependencies

**Interactive Prompting Library:**

The experimental setup command will need an interactive prompting library for the config creation flow. Options:

1. **@inquirer/prompts** (recommended)
   - Modern, tree-shakeable, TypeScript-first
   - Individual imports: `@inquirer/input`, `@inquirer/confirm`, `@inquirer/checkbox`, `@inquirer/editor`
   - Already used in OpenSpec (if not, lightweight addition)

2. **inquirer** (classic)
   - More established, larger ecosystem
   - Heavier bundle size
   - Single package with all prompt types

**Prompts needed:**
- `confirm` - "Create config?" "Add rules?"
- `select` - Schema selection with descriptions
- `editor` or multi-line `input` - Project context
- `checkbox` - Artifact selection for rules
- `input` (repeated) - Rule entry (line-by-line)

**Alternative (no dependency):**

Use Node's built-in `readline` for basic prompts:
- More code to write
- Less polished UX (no arrow key navigation, checkbox selection)
- Zero dependency cost

**Recommendation:** Use `@inquirer/prompts` for best UX. Config setup is a one-time operation where UX matters.

### YAML Serialization

Config creation needs YAML serialization:

- **yaml** package (already a dependency)
- Use `yaml.stringify()` to write config
- Preserve multi-line strings with `|` literal style
- Format: 2-space indent, no quotes unless needed

Example:
```typescript
import { stringify } from 'yaml';

const config = {
  schema: 'spec-driven',
  context: 'Multi-line\ncontext\nhere',
  rules: { proposal: ['Rule 1', 'Rule 2'] }
};

const yamlContent = stringify(config, {
  indent: 2,
  defaultStringType: 'QUOTE_DOUBLE',
  defaultKeyType: 'PLAIN',
});
// context will use | literal style automatically for multi-line
```

## Testing Considerations

**Core Config Functionality:**
- Create config with all fields (schema, context, rules), verify parsing
- Create minimal config (schema only), verify parsing
- Verify context appears in instruction output for all artifacts
- Verify rules appear only for matching artifact (not all artifacts)
- Verify schema from config is used for new changes
- Verify CLI `--schema` flag overrides config
- Verify change's `.openspec.yaml` overrides config
- Verify graceful handling of missing config (fallback to defaults)
- Verify graceful handling of invalid YAML syntax (warning, fallback)
- Verify graceful handling of invalid schema (warning, show valid schemas)
- Verify unknown artifact IDs in rules emit warnings but don't halt

**Schema Resolution Precedence:**
- Test all four levels of schema resolution:
  1. CLI flag `--schema` (highest priority)
  2. Change metadata `.openspec.yaml`
  3. Project config `openspec/config.yaml`
  4. Hardcoded default "spec-driven" (lowest priority)
- Verify each level correctly overrides lower levels

**Context and Rules Injection:**
- Verify context injection uses `<context>` XML-style tags
- Verify rules injection uses `<rules>` XML-style tags with bullets
- Verify injection order: `<context>` â†’ `<rules>` â†’ `<template>`
- Verify multi-line context is preserved
- Verify special characters in context/rules are not escaped
- Verify empty context/rules don't create tags

**Experimental Setup Integration:**
- Test `artifact-experimental-setup` with user skipping config creation
- Test `artifact-experimental-setup` with minimal config (schema only)
- Test `artifact-experimental-setup` with full config (schema + context + rules)
- Test schema selection from available schemas
- Test multi-line context input
- Test per-artifact rules prompts
- Test artifact selection (checkboxes)
- Test validation errors during config creation
- Test file write errors (permissions, etc.)
- Verify created config can be parsed by `readProjectConfig()`
- Verify success summary shows correct information

**Edge Cases:**
- Config file exists but is empty â†’ treat as invalid, warn
- Config has `.yml` extension instead of `.yaml` â†’ accept both
- Both `.yaml` and `.yml` exist â†’ prefer `.yaml`
- Context contains YAML-significant characters â†’ properly escape in output
- Rules array contains empty strings â†’ filter out or warn
- Schema references non-existent schema â†’ error with suggestions
- Config in subdirectory (not project root) â†’ not found, use defaults

**Backward Compatibility:**
- Existing projects without config continue to work
- Existing changes with `.openspec.yaml` metadata aren't affected by config
- Adding config to existing project doesn't break in-progress changes

**Integration Tests:**
- Create config â†’ create change â†’ verify schema used
- Create config â†’ get instructions â†’ verify context injected
- Create config â†’ get instructions â†’ verify rules injected
- Update config â†’ verify changes reflected immediately (no caching)
- Run `artifact-experimental-setup` â†’ create config â†’ create change â†’ verify flow

## Related Changes

- **project-local-schemas**: Enables `schema: my-workflow` to reference project-local schemas

## Appendix: Full Config Schema

```typescript
import { z } from 'zod';

// Zod schema serves as both runtime validation and documentation
// Type is inferred from schema for type safety
export const ProjectConfigSchema = z.object({
  // Required: which schema to use (e.g., "spec-driven", "tdd", or project-local schema name)
  schema: z.string().min(1).describe('The workflow schema to use (e.g., "spec-driven", "tdd")'),

  // Optional: project context (injected into all artifact instructions)
  // Max size: 50KB (enforced during parsing)
  context: z.string().optional().describe('Project context injected into all artifact instructions'),

  // Optional: per-artifact rules (additive to schema's built-in guidance)
  rules: z.record(
    z.string(),           // artifact ID
    z.array(z.string())   // list of rules
  ).optional().describe('Per-artifact rules, keyed by artifact ID'),
});

export type ProjectConfig = z.infer<typeof ProjectConfigSchema>;

// Note: Parsing uses safeParse() on individual fields for resilient error handling
// Invalid fields are warned about but don't prevent other fields from being loaded
```

## Appendix: Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   User provides:                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ openspec/config.yaml                                    â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚ schema: spec-driven                                     â”‚   â”‚
â”‚   â”‚ context: "We use React, TypeScript..."                  â”‚   â”‚
â”‚   â”‚ rules:                                                  â”‚   â”‚
â”‚   â”‚   proposal: [...]                                       â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ OpenSpec merges:                                        â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚   Schema (spec-driven)                                  â”‚   â”‚
â”‚   â”‚   + User's context                                      â”‚   â”‚
â”‚   â”‚   + User's rules                                        â”‚   â”‚
â”‚   â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”‚   â”‚
â”‚   â”‚   = Enriched instructions                               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Agent sees (for proposal artifact):                     â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚ <context>                                               â”‚   â”‚
â”‚   â”‚ We use React, TypeScript...                             â”‚   â”‚
â”‚   â”‚ </context>                                              â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚ <rules>                                                 â”‚   â”‚
â”‚   â”‚ - Include rollback plan                                 â”‚   â”‚
â”‚   â”‚ - Identify affected teams                               â”‚   â”‚
â”‚   â”‚ </rules>                                                â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚ <template>                                              â”‚   â”‚
â”‚   â”‚ [Built-in proposal template]                            â”‚   â”‚
â”‚   â”‚ </template>                                             â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```



================================================
FILE: openspec/changes/project-config/tasks.md
================================================
## 1. Core Config System

- [x] 1.1 Create `src/core/project-config.ts` with ProjectConfigSchema using Zod (for docs and type inference)
- [x] 1.2 Implement `readProjectConfig()` with resilient field-by-field parsing using Zod's `safeParse()`
- [x] 1.3 Add support for both .yaml and .yml extensions (prefer .yaml)
- [x] 1.4 Add 50KB hard limit for context field with size check and warning
- [x] 1.5 Implement `validateConfigRules()` to validate artifact IDs against schema (called during instruction loading)
- [x] 1.6 Implement `suggestSchemas()` with Levenshtein distance fuzzy matching for helpful error messages
- [x] 1.7 Add unit tests for resilient parsing (partial configs, field-level errors with Zod safeParse)
- [x] 1.8 Add unit tests for context size limit enforcement
- [x] 1.9 Add unit tests for .yml/.yaml precedence
- [x] 1.10 Add unit tests for fuzzy schema matching with typos

## 2. Schema Resolution Integration

- [x] 2.1 Update `resolveSchemaForChange()` in `src/utils/change-metadata.ts` to check project config (3rd in precedence)
- [x] 2.2 Update `createNewChange()` in `src/utils/change-utils.ts` to use config schema as default
- [x] 2.3 Add integration tests for schema resolution precedence (CLI â†’ change metadata â†’ config â†’ default)
- [x] 2.4 Add test for project-local schema names in config
- [x] 2.5 Add test for non-existent schema error handling with suggestions

## 3. Context and Rules Injection

- [x] 3.1 Update `loadInstructions()` in `src/core/artifact-graph/instruction-loader.ts` to inject context for all artifacts
- [x] 3.2 Add rules injection logic for matching artifacts only with XML tags and bullet formatting
- [x] 3.3 Add validation call during instruction loading to check artifact IDs in rules
- [x] 3.4 Implement session-level warning cache to avoid repeating same validation warnings
- [x] 3.5 Implement proper ordering: `<context>` â†’ `<rules>` â†’ `<template>`
- [x] 3.6 Preserve multi-line strings and special characters without escaping
- [x] 3.7 Add unit tests for context injection (present, absent, multi-line, special chars)
- [x] 3.8 Add unit tests for rules injection (matching artifact, non-matching, empty array, multiple artifacts)
- [x] 3.9 Add unit tests for validation timing (warnings during instruction load, not config load)
- [x] 3.10 Add unit tests for warning deduplication (same warning shown once per session)
- [x] 3.11 Add integration test verifying full instruction output with context + rules + template

## 4. Interactive Config Creation

- [x] 4.1 Add @inquirer/prompts dependency to package.json
- [x] 4.2 Create `src/core/config-prompts.ts` with ConfigPromptResult interface
- [x] 4.3 Implement `promptForConfig()` function with schema selection prompt
- [x] 4.4 Add multi-line context input prompt with examples and skip option
- [x] 4.5 Add per-artifact rules prompts with checkbox selection and line-by-line input
- [x] 4.6 Implement YAML serialization with proper multi-line string formatting
- [x] 4.7 Add validation and retry logic for prompt errors

## 5. Experimental Setup Integration

- [x] 5.1 Update `artifactExperimentalSetupCommand()` in `src/commands/artifact-workflow.ts` to check for existing config
- [x] 5.2 Add config creation section after skills/commands creation with header and description
- [x] 5.3 Integrate `promptForConfig()` calls with proper flow control
- [x] 5.4 Add Ctrl+C (ExitPromptError) handling - log cancellation message, continue with setup (non-fatal)
- [x] 5.5 Write created config to `openspec/config.yaml` using YAML stringify
- [x] 5.6 Display success summary showing path, schema, context lines, rules count
- [x] 5.7 Show usage examples and git commit suggestion
- [x] 5.8 Handle existing config case with skip message and manual update instructions
- [x] 5.9 Add error handling for file write failures with fallback suggestions
- [x] 5.10 Add test for cancellation behavior (skills/commands preserved, config not created)

## 6. Testing and Documentation

- [x] 6.1 Add end-to-end test: run experimental setup â†’ create config â†’ create change â†’ verify schema used
- [x] 6.2 Add end-to-end test: create config â†’ get instructions â†’ verify context and rules injected
- [x] 6.3 Test backwards compatibility: existing changes work without config
- [x] 6.4 Test config changes are reflected immediately (no stale cache)
- [x] 6.5 Add performance benchmark: measure config read time with typical config (1KB context)
- [x] 6.6 Add performance benchmark: measure config read time with large config (50KB context)
- [x] 6.7 Add performance benchmark: measure repeated reads within single command
- [x] 6.8 Document benchmark results and decide if caching is needed (target: <10ms typical, <50ms acceptable)
- [x] 6.9 If benchmarks fail: implement mtime-based caching with cache invalidation
- [x] 6.10 Update README or docs with config feature examples and schema
- [x] 6.11 Document common artifact IDs for different schemas
- [x] 6.12 Add troubleshooting section for config validation errors



================================================
FILE: openspec/changes/project-config/.openspec.yaml
================================================
schema: spec-driven
created: "2025-01-13"



================================================
FILE: openspec/changes/project-config/specs/config-loading/spec.md
================================================
# Spec: Config Loading

## ADDED Requirements

### Requirement: Load project config from openspec/config.yaml

The system SHALL read and parse the project configuration file located at `openspec/config.yaml` relative to the project root.

#### Scenario: Valid config file exists
- **WHEN** `openspec/config.yaml` exists with valid YAML content
- **THEN** system parses the file and returns a ProjectConfig object

#### Scenario: Config file does not exist
- **WHEN** `openspec/config.yaml` does not exist
- **THEN** system returns null without error

#### Scenario: Config file has invalid YAML syntax
- **WHEN** `openspec/config.yaml` contains malformed YAML
- **THEN** system logs a warning message and returns null

#### Scenario: Config file has valid YAML but invalid schema
- **WHEN** `openspec/config.yaml` contains valid YAML that fails Zod schema validation
- **THEN** system logs a warning message with validation details and returns null

### Requirement: Support .yml file extension alias

The system SHALL accept both `.yaml` and `.yml` file extensions for the config file.

#### Scenario: Config file uses .yml extension
- **WHEN** `openspec/config.yml` exists and `openspec/config.yaml` does not exist
- **THEN** system reads from `openspec/config.yml`

#### Scenario: Both .yaml and .yml exist
- **WHEN** both `openspec/config.yaml` and `openspec/config.yml` exist
- **THEN** system prefers `openspec/config.yaml`

### Requirement: Use resilient field-by-field parsing

The system SHALL parse each config field independently, collecting valid fields and warning about invalid ones without rejecting the entire config.

#### Scenario: Schema field is valid
- **WHEN** config contains `schema: "spec-driven"`
- **THEN** schema field is included in returned config

#### Scenario: Schema field is missing
- **WHEN** config lacks the `schema` field
- **THEN** no warning is logged (field is optional at parse level)

#### Scenario: Schema field is empty string
- **WHEN** config contains `schema: ""`
- **THEN** warning is logged and schema field is not included in returned config

#### Scenario: Schema field is invalid type
- **WHEN** config contains `schema: 123` (number instead of string)
- **THEN** warning is logged and schema field is not included in returned config

#### Scenario: Context field is valid
- **WHEN** config contains `context: "Tech stack: TypeScript"`
- **THEN** context field is included in returned config

#### Scenario: Context field is invalid type
- **WHEN** config contains `context: 123` (number instead of string)
- **THEN** warning is logged and context field is not included in returned config

#### Scenario: Rules field has valid structure
- **WHEN** config contains `rules: { proposal: ["Rule 1"], specs: ["Rule 2"] }`
- **THEN** rules field is included in returned config with valid rules

#### Scenario: Rules field has non-array value for artifact
- **WHEN** config contains `rules: { proposal: "not an array", specs: ["Valid"] }`
- **THEN** warning is logged for proposal, but specs rules are still included in returned config

#### Scenario: Rules array contains non-string elements
- **WHEN** config contains `rules: { proposal: ["Valid rule", 123, ""] }`
- **THEN** only "Valid rule" is included, warning logged about invalid elements

#### Scenario: Mix of valid and invalid fields
- **WHEN** config contains valid schema, invalid context type, valid rules
- **THEN** config is returned with schema and rules fields, warning logged about context

### Requirement: Enforce context size limit

The system SHALL reject context fields exceeding 50KB and log a warning.

#### Scenario: Context within size limit
- **WHEN** config contains context of 1KB
- **THEN** context is included in returned config

#### Scenario: Context at size limit
- **WHEN** config contains context of exactly 50KB
- **THEN** context is included in returned config

#### Scenario: Context exceeds size limit
- **WHEN** config contains context of 51KB
- **THEN** warning is logged with size and limit, context field is not included in returned config

### Requirement: Defer artifact ID validation to instruction loading

The system SHALL NOT validate artifact IDs in rules during config load time. Validation happens during instruction loading when schema is known.

#### Scenario: Config with rules is loaded
- **WHEN** config contains `rules: { unknownartifact: [...] }`
- **THEN** config is loaded successfully without validation errors

#### Scenario: Validation happens at instruction load time
- **WHEN** instructions are loaded for any artifact and config has unknown artifact IDs in rules
- **THEN** warnings are emitted about unknown artifact IDs (see rules-injection spec for details)

### Requirement: Gracefully handle config errors without halting

The system SHALL continue operation with default values when config loading or parsing fails.

#### Scenario: Config parse failure during command execution
- **WHEN** config file has syntax errors and user runs `openspec new change`
- **THEN** command executes using default schema "spec-driven"

#### Scenario: Warning is visible to user
- **WHEN** config loading fails
- **THEN** system outputs warning message to stderr with details about the failure



================================================
FILE: openspec/changes/project-config/specs/context-injection/spec.md
================================================
# Spec: Context Injection

## ADDED Requirements

### Requirement: Inject context into all artifact instructions

The system SHALL inject the context field from project config into instructions for all artifacts, wrapped in XML-style `<context>` tags.

#### Scenario: Config has context field
- **WHEN** config contains `context: "Tech stack: TypeScript, React"`
- **THEN** instruction output includes `<context>\nTech stack: TypeScript, React\n</context>`

#### Scenario: Config has no context field
- **WHEN** config omits the context field or context is undefined
- **THEN** instruction output does not include `<context>` tags

#### Scenario: Context is multi-line string
- **WHEN** config contains context with multiple lines
- **THEN** instruction output preserves line breaks within `<context>` tags

#### Scenario: Context applied to all artifacts
- **WHEN** instructions are loaded for any artifact (proposal, specs, design, tasks)
- **THEN** context section appears in all instruction outputs

### Requirement: Format context with XML-style tags

The system SHALL wrap context content in `<context>` opening and `</context>` closing tags with content on separate lines.

#### Scenario: Context tag structure
- **WHEN** context is injected into instructions
- **THEN** format is exactly `<context>\n{content}\n</context>\n\n`

#### Scenario: Context appears before template
- **WHEN** instructions are generated with context
- **THEN** `<context>` section appears before the `<template>` section

### Requirement: Preserve context content exactly as provided

The system SHALL inject context content without modification, escaping, or interpretation.

#### Scenario: Context contains special characters
- **WHEN** context includes characters like `<`, `>`, `&`, quotes
- **THEN** characters are preserved exactly as written in the config

#### Scenario: Context contains URLs
- **WHEN** context includes URLs like "docs at https://example.com"
- **THEN** URLs are preserved exactly in the injected content

#### Scenario: Context contains markdown
- **WHEN** context includes markdown formatting like `**bold**` or `[links](url)`
- **THEN** markdown is preserved without rendering or escaping



================================================
FILE: openspec/changes/project-config/specs/rules-injection/spec.md
================================================
# Spec: Rules Injection

## ADDED Requirements

### Requirement: Inject rules only for matching artifact

The system SHALL inject rules from config into instructions only when the artifact ID matches a key in the rules object.

#### Scenario: Rules exist for the artifact
- **WHEN** loading instructions for "proposal" and config has `rules: { proposal: ["Rule 1", "Rule 2"] }`
- **THEN** instruction output includes rules section with both rules

#### Scenario: No rules for the artifact
- **WHEN** loading instructions for "design" and config has `rules: { proposal: [...] }`
- **THEN** instruction output does not include `<rules>` tags

#### Scenario: Rules object is undefined
- **WHEN** config omits the rules field or rules is undefined
- **THEN** instruction output does not include `<rules>` tags for any artifact

#### Scenario: Rules array is empty for artifact
- **WHEN** config has `rules: { proposal: [] }`
- **THEN** instruction output does not include `<rules>` tags

### Requirement: Format rules with XML-style tags and bullet list

The system SHALL wrap rules in `<rules>` tags with each rule as a bulleted list item.

#### Scenario: Single rule for artifact
- **WHEN** config has `rules: { proposal: ["Include rollback plan"] }`
- **THEN** instruction output includes `<rules>\n- Include rollback plan\n</rules>\n\n`

#### Scenario: Multiple rules for artifact
- **WHEN** config has `rules: { proposal: ["Rule 1", "Rule 2", "Rule 3"] }`
- **THEN** instruction output includes each rule as separate bullet point

#### Scenario: Rules appear after context and before template
- **WHEN** instructions are generated with both context and rules
- **THEN** order is `<context>` then `<rules>` then `<template>`

### Requirement: Preserve rule text exactly as provided

The system SHALL inject rule text without modification, escaping, or interpretation.

#### Scenario: Rule contains markdown
- **WHEN** rule includes markdown like "Use **Given/When/Then** format"
- **THEN** markdown is preserved in the injected content

#### Scenario: Rule contains special characters
- **WHEN** rule includes characters like `<`, `>`, quotes
- **THEN** characters are preserved exactly as written

#### Scenario: Rule is multi-line string
- **WHEN** rule text contains line breaks
- **THEN** line breaks are preserved within the bullet point

### Requirement: Support multiple artifacts with different rules

The system SHALL allow different rule sets for different artifacts in the same config.

#### Scenario: Multiple artifacts have rules
- **WHEN** config has `rules: { proposal: ["P1"], specs: ["S1", "S2"], tasks: ["T1"] }`
- **THEN** proposal instructions show only ["P1"], specs show only ["S1", "S2"], tasks show only ["T1"]

#### Scenario: Some artifacts have rules, others do not
- **WHEN** config has rules for proposal and specs only
- **THEN** design and tasks instructions have no `<rules>` section

### Requirement: Rules are additive to schema guidance

The system SHALL add config rules to the schema's built-in artifact instruction, not replace it.

#### Scenario: Artifact has schema instruction and config rules
- **WHEN** artifact has built-in instruction from schema and config provides rules
- **THEN** final instruction contains both schema guidance and config rules

#### Scenario: Rules provide additional constraints
- **WHEN** schema says "create proposal" and config rules say "include rollback plan"
- **THEN** agent sees both the schema template and the additional rule

### Requirement: Validate artifact IDs during instruction loading

The system SHALL validate artifact IDs in rules against the schema when instructions are loaded and emit warnings for unknown IDs.

#### Scenario: All artifact IDs are valid
- **WHEN** instructions loaded and config has `rules: { proposal: [...], specs: [...] }` for schema with those artifacts
- **THEN** no validation warnings are emitted

#### Scenario: Unknown artifact ID in rules
- **WHEN** instructions loaded and config has `rules: { unknownartifact: [...] }`
- **THEN** warning emitted: "Unknown artifact ID in rules: 'unknownartifact'. Valid IDs for schema 'spec-driven': design, proposal, specs, tasks"

#### Scenario: Multiple unknown artifact IDs
- **WHEN** instructions loaded and config has multiple unknown artifact IDs
- **THEN** separate warning emitted for each unknown artifact ID

#### Scenario: Validation warnings shown once per session
- **WHEN** instructions loaded multiple times in same CLI session
- **THEN** each unique validation warning is shown only once (cached)



================================================
FILE: openspec/changes/project-config/specs/schema-resolution/spec.md
================================================
# Spec: Schema Resolution with Config

## ADDED Requirements

### Requirement: Use config schema as default for new changes

The system SHALL use the schema field from `openspec/config.yaml` as the default when creating new changes without explicit `--schema` flag.

#### Scenario: Create change without --schema flag and config exists
- **WHEN** user runs `openspec new change foo` and config contains `schema: "tdd"`
- **THEN** system creates change with schema "tdd"

#### Scenario: Create change without --schema flag and no config
- **WHEN** user runs `openspec new change foo` and no config file exists
- **THEN** system creates change with default schema "spec-driven"

#### Scenario: Create change with explicit --schema flag
- **WHEN** user runs `openspec new change foo --schema custom` and config contains `schema: "tdd"`
- **THEN** system creates change with schema "custom" (CLI flag overrides config)

### Requirement: Resolve schema with updated precedence order

The system SHALL resolve the schema for a change using the following precedence order: CLI flag, change metadata, project config, hardcoded default.

#### Scenario: CLI flag is provided
- **WHEN** user runs command with `--schema custom`
- **THEN** system uses "custom" regardless of change metadata or config

#### Scenario: Change metadata specifies schema
- **WHEN** change has `.openspec.yaml` with `schema: bound` and config has `schema: tdd`
- **THEN** system uses "bound" from change metadata

#### Scenario: Only project config specifies schema
- **WHEN** no CLI flag or change metadata, but config has `schema: tdd`
- **THEN** system uses "tdd" from project config

#### Scenario: No schema specified anywhere
- **WHEN** no CLI flag, change metadata, or project config
- **THEN** system uses hardcoded default "spec-driven"

### Requirement: Support project-local schema names in config

The system SHALL allow the config schema field to reference project-local schemas defined in `openspec/schemas/`.

#### Scenario: Config references project-local schema
- **WHEN** config contains `schema: "my-workflow"` and `openspec/schemas/my-workflow/` exists
- **THEN** system resolves to the project-local schema

#### Scenario: Config references non-existent schema
- **WHEN** config contains `schema: "nonexistent"` and that schema does not exist
- **THEN** system shows error when attempting to load the schema with fuzzy match suggestions and list of all valid schemas

### Requirement: Provide helpful error message for invalid schema

The system SHALL display schema error with fuzzy match suggestions, list of available schemas, and fix instructions.

#### Scenario: Schema name with typo (close match)
- **WHEN** config contains `schema: "spce-driven"` (typo)
- **THEN** error message includes "Did you mean: spec-driven (built-in)" as suggestion

#### Scenario: Schema name with no close matches
- **WHEN** config contains `schema: "completely-wrong"`
- **THEN** error message shows list of all available built-in and project-local schemas

#### Scenario: Error message includes fix instructions
- **WHEN** config references invalid schema
- **THEN** error message includes "Fix: Edit openspec/config.yaml and change 'schema: X' to a valid schema name"

#### Scenario: Error distinguishes built-in vs project-local schemas
- **WHEN** error lists available schemas
- **THEN** output clearly labels each as "built-in" or "project-local"

### Requirement: Maintain backwards compatibility for existing changes

The system SHALL continue to work with existing changes that do not have project config.

#### Scenario: Existing change without config
- **WHEN** change was created before config feature and no config file exists
- **THEN** system resolves schema using existing logic (change metadata or hardcoded default)

#### Scenario: Existing change with config added later
- **WHEN** config file is added to project with existing changes
- **THEN** existing changes continue to use their bound schema from `.openspec.yaml`



================================================
FILE: openspec/changes/project-local-schemas/design.md
================================================
## Context

OpenSpec currently resolves schemas from two locations:
1. User override: `~/.local/share/openspec/schemas/<name>/`
2. Package built-in: `<npm-package>/schemas/<name>/`

This change adds a third, highest-priority level: project-local schemas at `./openspec/schemas/<name>/`.

The resolver functions in `src/core/artifact-graph/resolver.ts` currently don't take a `projectRoot` parameter because user and package paths are absolute. To support project-local schemas, we need to pass project root context into the resolver.

## Goals / Non-Goals

**Goals:**
- Enable version-controlled custom workflow schemas
- Allow teams to share schemas via git without per-machine setup
- Maintain backward compatibility with existing resolver API
- Integrate with `config.yaml`'s `schema` field (from project-config change)

**Non-Goals:**
- Schema inheritance or `extends` keyword
- Template-level overrides (partial forks)
- Schema management CLI commands (`openspec schema copy/which/diff/reset`)
- Validation that project-local schema names don't conflict with built-ins (shadowing is intentional)

## Decisions

### Decision 1: Add optional `projectRoot` parameter to resolver functions

**Choice:** Add optional `projectRoot?: string` parameter to resolver functions rather than using `process.cwd()` internally.

**Alternatives considered:**
- Use `process.cwd()` internally: Simpler API but implicit, harder to test, doesn't match existing codebase patterns
- Create separate project-aware functions: No breaking changes but awkward API, callers must compose

**Rationale:** The codebase already follows a pattern where CLI commands get project root via `process.cwd()` and pass it down to functions that need it. Adding an optional parameter maintains backward compatibility while enabling explicit, testable behavior.

**Affected functions:**
```typescript
getSchemaDir(name: string, projectRoot?: string): string | null
listSchemas(projectRoot?: string): string[]
listSchemasWithInfo(projectRoot?: string): SchemaInfo[]
resolveSchema(name: string, projectRoot?: string): SchemaYaml
```

### Decision 2: Resolution order is project â†’ user â†’ package

**Choice:** Project-local schemas have highest priority, then user overrides, then package built-ins.

**Rationale:**
- Project-local should win because it represents team intent (version controlled, shared)
- User overrides still useful for personal experimentation without affecting team
- Package built-ins are the fallback defaults

```
1. ./openspec/schemas/<name>/              # Project-local (highest)
2. ~/.local/share/openspec/schemas/<name>/ # User override
3. <npm-package>/schemas/<name>/           # Package built-in (lowest)
```

### Decision 3: Add `getProjectSchemasDir()` helper function

**Choice:** Create a dedicated function to get the project schemas directory path.

```typescript
function getProjectSchemasDir(projectRoot: string): string {
  return path.join(projectRoot, 'openspec', 'schemas');
}
```

**Rationale:** Matches existing pattern with `getPackageSchemasDir()` and `getUserSchemasDir()`. Keeps path logic centralized.

### Decision 4: Extend `SchemaInfo.source` to include `'project'`

**Choice:** Update the source type from `'package' | 'user'` to `'project' | 'user' | 'package'`.

**Rationale:** Consumers need to distinguish project-local schemas for display purposes (e.g., `schemasCommand` output).

### Decision 5: No special handling for schema name conflicts

**Choice:** If a project-local schema has the same name as a built-in (e.g., `spec-driven`), the project-local version wins. No warning, no error.

**Rationale:** This is intentional shadowing. Teams may want to customize a built-in schema while keeping the same name for familiarity.

## Risks / Trade-offs

### Risk: Confusion when project schema shadows built-in
A team could create `openspec/schemas/spec-driven/` that shadows the built-in, causing confusion when someone expects default behavior.

**Mitigation:** The `openspec schemas` command shows the source of each schema. Users can see `spec-driven (project)` vs `spec-driven (package)`.

### Risk: Missing projectRoot parameter
If callers forget to pass `projectRoot`, project-local schemas won't be found.

**Mitigation:**
- Make the change incrementally, updating call sites that need project-local support
- Existing behavior (user + package only) is preserved when `projectRoot` is undefined

### Trade-off: Optional parameter vs required
Making `projectRoot` optional maintains backward compatibility but means some code paths may silently skip project-local resolution.

**Accepted:** Backward compatibility is more important. The main entry points (CLI commands) will always pass `projectRoot`.

## Implementation Approach

1. **Update `resolver.ts`:**
   - Add `getProjectSchemasDir(projectRoot: string)` function
   - Update `getSchemaDir()` to check project-local first when `projectRoot` provided
   - Update `listSchemas()` to include project schemas when `projectRoot` provided
   - Update `listSchemasWithInfo()` to return `source: 'project'` for project schemas
   - Update `SchemaInfo` type to include `'project'` in source union

2. **Update `artifact-workflow.ts`:**
   - Update `schemasCommand` to pass `projectRoot` and display source labels

3. **Update call sites:**
   - Any existing code that needs project-local resolution should pass `projectRoot`
   - `config.yaml` schema resolution already has access to `projectRoot`



================================================
FILE: openspec/changes/project-local-schemas/proposal.md
================================================
# Project-Local Schemas

## Summary

Add project-local schema resolution (`./openspec/schemas/`) as the highest priority in the schema lookup chain. This enables teams to version control custom workflow schemas with their repository.

## Motivation

Currently, schema resolution is 2-level:
1. User override: `~/.local/share/openspec/schemas/<name>/`
2. Package built-in: `<npm-package>/schemas/<name>/`

This creates friction for teams:
- Custom schemas must be set up per-machine via XDG paths
- Cannot share schemas via version control
- No single source of truth for team workflows

## Design Decisions

### 3-Level Resolution Order

```
1. ./openspec/schemas/<name>/                    # Project-local (NEW)
2. ~/.local/share/openspec/schemas/<name>/       # User global (XDG)
3. <npm-package>/schemas/<name>/                 # Package built-in
```

Project-local takes highest priority, enabling:
- Version-controlled custom workflows
- Automatic team sharing via git
- No per-machine setup required

### Fork Model (Not Inheritance)

Custom schemas are complete definitions, not extensions. There is no `extends` keyword.

**Rationale:** Simplicity. Inheritance adds complexity (conflict resolution, partial overrides, debugging "where did this come from?"). Users who need custom workflows can define them fully. This keeps the mental model simple:
- Use a preset â†’ Configure path (see project-config change)
- Need different structure â†’ Fork path (define your own)

### Directory Structure

```
openspec/
â”œâ”€â”€ schemas/                      # Project-local schemas
â”‚   â””â”€â”€ my-workflow/
â”‚       â”œâ”€â”€ schema.yaml           # Full schema definition
â”‚       â””â”€â”€ templates/
â”‚           â”œâ”€â”€ artifact1.md
â”‚           â”œâ”€â”€ artifact2.md
â”‚           â””â”€â”€ ...
â””â”€â”€ changes/
```

### Schema Naming

Project-local schemas are referenced by their directory name:
- `openspec/schemas/my-workflow/` â†’ referenced as `my-workflow`
- Works with `--schema my-workflow` flag
- Works with `schema: my-workflow` in config.yaml (see project-config change)

## Scope

### In Scope

- Add `getProjectSchemasDir()` function to resolver
- Update `getSchemaDir()` to check project-local first
- Update `listSchemas()` to include project schemas
- Update `listSchemasWithInfo()` to include `source: 'project'`
- Update `schemasCommand` output to show project schemas

### Out of Scope

- Schema management CLI (`openspec schema copy/which/diff/reset`) - future enhancement
- Schema inheritance/extends - explicitly not supported
- Template-level overrides (partial fork) - explicitly not supported

## User Experience

### Creating a Custom Schema

```bash
# Create schema directory
mkdir -p openspec/schemas/my-workflow/templates

# Define schema
cat > openspec/schemas/my-workflow/schema.yaml << 'EOF'
name: my-workflow
version: 1
description: Our team's planning workflow

artifacts:
  - id: research
    generates: research.md
    template: research.md
    description: Background research
    requires: []

  - id: proposal
    generates: proposal.md
    template: proposal.md
    description: Change proposal
    requires: [research]

  - id: tasks
    generates: tasks.md
    template: tasks.md
    description: Implementation tasks
    requires: [proposal]
EOF

# Create templates
echo "# Research\n\n..." > openspec/schemas/my-workflow/templates/research.md
# ... etc
```

### Using the Custom Schema

```bash
# Via CLI flag
openspec new change add-feature --schema my-workflow
openspec status --change add-feature --schema my-workflow

# Via config.yaml (requires project-config change)
# schema: my-workflow
```

### Team Sharing

```bash
# Commit to repo
git add openspec/schemas/
git commit -m "Add custom workflow schema"
git push

# Team members get it automatically
git pull
openspec status --change add-feature --schema my-workflow  # Just works
```

## Implementation Notes

### Files to Modify

| File | Changes |
|------|---------|
| `src/core/artifact-graph/resolver.ts` | Add `getProjectSchemasDir()`, update resolution order |
| `src/commands/artifact-workflow.ts` | Update `schemasCommand` to show source |

### Project Root Detection

Use existing `findProjectRoot()` pattern or current working directory. The project-local schemas directory is always `./openspec/schemas/` relative to project root.

### Source Indication

`listSchemasWithInfo()` returns `source: 'project' | 'user' | 'package'`. Update type definition and implementation.

## Testing Considerations

- Create temp project with local schema, verify resolution priority
- Verify local schema overrides user override with same name
- Verify `listSchemas()` includes project schemas
- Verify `schemasCommand` shows correct source labels

## Related Changes

- **project-config**: Adds `config.yaml` with `schema` field that can reference project-local schemas



================================================
FILE: openspec/changes/project-local-schemas/tasks.md
================================================
## 1. Update Resolver Types and Helpers

- [x] 1.1 Update `SchemaInfo.source` type to include `'project'` in `src/core/artifact-graph/resolver.ts`
- [x] 1.2 Add `getProjectSchemasDir(projectRoot: string): string` function

## 2. Update Schema Resolution Functions

- [x] 2.1 Update `getSchemaDir(name, projectRoot?)` to check project-local first when projectRoot provided
- [x] 2.2 Update `resolveSchema(name, projectRoot?)` to pass projectRoot to getSchemaDir
- [x] 2.3 Update `listSchemas(projectRoot?)` to include project-local schemas
- [x] 2.4 Update `listSchemasWithInfo(projectRoot?)` to include project schemas with `source: 'project'`

## 3. Update CLI Commands

- [x] 3.1 Update `schemasCommand` to pass projectRoot and display source labels in output

## 4. Update Call Sites

- [x] 4.1 Review and update call sites that need project-local schema support to pass projectRoot

## 5. Testing

- [x] 5.1 Add unit tests for `getProjectSchemasDir()`
- [x] 5.2 Add unit tests for project-local schema resolution priority
- [x] 5.3 Add unit tests for backward compatibility (no projectRoot = user + package only)
- [x] 5.4 Add unit tests for `listSchemas()` including project schemas
- [x] 5.5 Add unit tests for `listSchemasWithInfo()` with `source: 'project'`
- [x] 5.6 Add integration test with temp project containing local schema



================================================
FILE: openspec/changes/project-local-schemas/.openspec.yaml
================================================
schema: spec-driven
created: "2025-01-13"



================================================
FILE: openspec/changes/project-local-schemas/specs/schema-resolution/spec.md
================================================
## ADDED Requirements

### Requirement: Project-local schema resolution

The system SHALL resolve schemas from the project-local directory (`./openspec/schemas/<name>/`) with highest priority when a `projectRoot` is provided.

#### Scenario: Project-local schema takes precedence over user override
- **WHEN** a schema named "my-workflow" exists at `./openspec/schemas/my-workflow/schema.yaml`
- **AND** a schema named "my-workflow" exists at `~/.local/share/openspec/schemas/my-workflow/schema.yaml`
- **AND** `getSchemaDir("my-workflow", projectRoot)` is called
- **THEN** the system SHALL return the project-local path

#### Scenario: Project-local schema takes precedence over package built-in
- **WHEN** a schema named "spec-driven" exists at `./openspec/schemas/spec-driven/schema.yaml`
- **AND** "spec-driven" is a package built-in schema
- **AND** `getSchemaDir("spec-driven", projectRoot)` is called
- **THEN** the system SHALL return the project-local path

#### Scenario: Falls back to user override when no project-local schema
- **WHEN** no schema named "my-workflow" exists at `./openspec/schemas/my-workflow/`
- **AND** a schema named "my-workflow" exists at `~/.local/share/openspec/schemas/my-workflow/schema.yaml`
- **AND** `getSchemaDir("my-workflow", projectRoot)` is called
- **THEN** the system SHALL return the user override path

#### Scenario: Falls back to package built-in when no project-local or user schema
- **WHEN** no schema named "spec-driven" exists at `./openspec/schemas/spec-driven/`
- **AND** no schema named "spec-driven" exists at `~/.local/share/openspec/schemas/spec-driven/`
- **AND** "spec-driven" is a package built-in schema
- **AND** `getSchemaDir("spec-driven", projectRoot)` is called
- **THEN** the system SHALL return the package built-in path

#### Scenario: Backward compatibility when projectRoot not provided
- **WHEN** `getSchemaDir("my-workflow")` is called without a `projectRoot` parameter
- **THEN** the system SHALL only check user override and package built-in locations
- **AND** the system SHALL NOT check project-local location

### Requirement: Project schemas directory helper

The system SHALL provide a `getProjectSchemasDir(projectRoot)` function that returns the project-local schemas directory path.

#### Scenario: Returns correct path
- **WHEN** `getProjectSchemasDir("/path/to/project")` is called
- **THEN** the system SHALL return `/path/to/project/openspec/schemas`

### Requirement: List schemas includes project-local

The system SHALL include project-local schemas when listing available schemas if `projectRoot` is provided.

#### Scenario: Project-local schemas appear in list
- **WHEN** a schema named "team-flow" exists at `./openspec/schemas/team-flow/schema.yaml`
- **AND** `listSchemas(projectRoot)` is called
- **THEN** the returned list SHALL include "team-flow"

#### Scenario: Project-local schema shadows same-named user schema in list
- **WHEN** a schema named "custom" exists at both project-local and user override locations
- **AND** `listSchemas(projectRoot)` is called
- **THEN** the returned list SHALL include "custom" exactly once

#### Scenario: Backward compatibility for listSchemas
- **WHEN** `listSchemas()` is called without a `projectRoot` parameter
- **THEN** the system SHALL only include user override and package built-in schemas

### Requirement: Schema info includes project source

The system SHALL indicate `source: 'project'` for project-local schemas in `listSchemasWithInfo()` results.

#### Scenario: Project-local schema shows project source
- **WHEN** a schema named "team-flow" exists at `./openspec/schemas/team-flow/schema.yaml`
- **AND** `listSchemasWithInfo(projectRoot)` is called
- **THEN** the schema info for "team-flow" SHALL have `source: 'project'`

#### Scenario: User override schema shows user source
- **WHEN** a schema named "my-custom" exists only at `~/.local/share/openspec/schemas/my-custom/`
- **AND** `listSchemasWithInfo(projectRoot)` is called
- **THEN** the schema info for "my-custom" SHALL have `source: 'user'`

#### Scenario: Package built-in schema shows package source
- **WHEN** "spec-driven" exists only as a package built-in
- **AND** `listSchemasWithInfo(projectRoot)` is called
- **THEN** the schema info for "spec-driven" SHALL have `source: 'package'`

### Requirement: Schemas command shows source

The `openspec schemas` command SHALL display the source of each schema.

#### Scenario: Display format includes source
- **WHEN** user runs `openspec schemas`
- **THEN** the output SHALL show each schema with its source label (project, user, or package)



================================================
FILE: openspec/changes/schema-alias-support/proposal.md
================================================
## Why

We want to rename `spec-driven` to `openspec-default` to better reflect that it's the standard/default workflow. However, renaming directly would break existing projects that have `schema: spec-driven` in their `openspec/config.yaml`. Adding alias support allows both names to work interchangeably, enabling a smooth transition with no breaking changes.

## What Changes

- Add schema alias resolution in the schema resolver
- `openspec-default` and `spec-driven` will both resolve to the same schema
- The physical directory remains `schemas/spec-driven/` (or could be renamed to `schemas/openspec-default/` with `spec-driven` as the alias)
- All CLI commands and config files accept either name
- No changes required to existing user configs

## Capabilities

### New Capabilities

- `schema-aliases`: Support for schema name aliases so multiple names can resolve to the same schema directory

### Modified Capabilities

<!-- No existing spec-level behavior is changing - this is purely additive -->

## Impact

- `src/core/artifact-graph/resolver.ts` - Add alias resolution logic
- `schemas/` directory - Potentially rename `spec-driven` to `openspec-default`
- Documentation - Update to prefer `openspec-default` while noting `spec-driven` still works
- Default schema constants - Update `DEFAULT_SCHEMA` to `openspec-default`



================================================
FILE: openspec/changes/schema-alias-support/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-20



================================================
FILE: openspec/changes/schema-management-cli/design.md
================================================
## Context

OpenSpec uses workflow schemas to define artifact sequences for change proposals. Currently, schemas are resolved from three locations (project â†’ user â†’ package), but managing custom schemas requires manual file creation with no tooling support. The resolver infrastructure exists (`src/core/artifact-graph/resolver.ts`) but there's no CLI exposure for schema management operations.

Users who want to customize workflows must:
1. Manually create directory structures under `openspec/schemas/<name>/`
2. Copy and modify `schema.yaml` files without validation
3. Debug resolution issues by inspecting the filesystem directly

This creates friction for schema customization and leads to runtime errors when schemas are malformed.

## Goals / Non-Goals

**Goals:**
- Provide CLI commands for common schema management operations
- Enable interactive schema creation with guided prompts
- Allow forking existing schemas as customization starting points
- Surface schema validation errors before runtime
- Help debug schema resolution order when shadowing occurs

**Non-Goals:**
- Schema editing (users edit YAML directly or via `$EDITOR`)
- Schema publishing or sharing mechanisms
- Schema versioning or migration tooling
- Validation of template file contents (only checks existence)
- Schema inheritance or composition beyond simple forking

## Decisions

### 1. Command Structure: `openspec schema <subcommand>`

Add a new command group following the existing pattern used by `openspec config` and `openspec completion`.

**Rationale:** Grouping related commands under a noun (schema) matches the established CLI patterns and provides a natural namespace for future schema operations.

**Alternatives considered:**
- Flat commands (`openspec schema-init`, `openspec schema-fork`): Rejected because it pollutes the top-level namespace and doesn't scale well.
- Extending existing commands (`openspec init --schema`): Rejected because schema management is distinct from project initialization.

### 2. Implementation Location

New file `src/commands/schema.ts` with a `registerSchemaCommand(program: Command)` function that registers the `schema` command group and all subcommands.

**Rationale:** Follows the pattern established by `config.ts` and matches how other command groups are organized.

### 3. Schema Validation Approach

Validation checks:
1. `schema.yaml` exists and is valid YAML
2. Parses successfully against the Zod schema in `types.ts`
3. All referenced template files exist in the schema directory
4. Artifact dependency graph has no cycles (use existing topological sort)

**Rationale:** Reuse existing validation infrastructure (`parseSchema` from `schema.ts`) and extend with template existence checks. This catches the most common errors without duplicating validation logic.

**Alternatives considered:**
- Deep template validation (check frontmatter, syntax): Rejected as over-engineering. Template contents are free-form markdown.

### 4. Interactive Prompts for `schema init`

Use `@inquirer/prompts` (already a dependency) for:
- Schema name input with kebab-case validation
- Schema description input
- Multi-select for artifact selection with descriptions
- Optional: set as project default

**Rationale:** Matches the UX established by `openspec init` and `openspec config reset`. Provides a guided experience while keeping the wizard lightweight.

### 5. Fork Source Resolution

`schema fork <source>` resolves the source schema using the existing `getSchemaDir()` function, respecting the full resolution order (project â†’ user â†’ package). This allows forking from any accessible schema.

The destination is always project-local: `openspec/schemas/<name>/`

**Rationale:** Forking to project scope makes sense because:
- Custom schemas are project-specific decisions
- User-global schemas can be added manually if needed
- Keeps the command simple with a clear default

### 6. Output Format Consistency

All commands support `--json` flag for machine-readable output:
- `schema init`: Outputs `{ "created": true, "path": "...", "schema": "..." }`
- `schema fork`: Outputs `{ "forked": true, "source": "...", "destination": "..." }`
- `schema validate`: Outputs validation report matching existing validate command format
- `schema which`: Outputs `{ "name": "...", "source": "project|user|package", "path": "..." }`

Text output uses ora spinners for progress and clear success/error messaging.

**Rationale:** Consistent with existing OpenSpec commands and enables scripting/automation.

### 7. Schema `which` Command Design

Shows resolution details for a schema name:
- Which location it resolves from (project/user/package)
- Full path to the schema directory
- Whether it shadows other schemas at lower priority levels

**Rationale:** Essential for debugging "why isn't my schema being used?" scenarios when multiple schemas with the same name exist.

## Risks / Trade-offs

**[Template scaffolding may become stale]** â†’ The `schema init` command will scaffold a default set of artifacts (proposal, specs, design, tasks). If the built-in schema patterns evolve, these templates may not reflect best practices.
- *Mitigation*: Document that `init` creates a minimal starting point. Users can `fork` built-in schemas for the latest patterns.

**[Interactive prompts in CI environments]** â†’ `schema init` with prompts may hang in non-interactive environments.
- *Mitigation*: Support `--name`, `--description`, and `--artifacts` flags for non-interactive use. Detect TTY and show helpful error if prompts would hang.

**[Validation doesn't catch all errors]** â†’ Schema validation checks structure but can't verify semantic correctness (e.g., a template that doesn't match its artifact purpose).
- *Mitigation*: This is acceptable. Full semantic validation would require understanding template intent, which is out of scope.

**[Fork overwrites without warning]** â†’ If target schema already exists, `fork` could overwrite it.
- *Mitigation*: Check for existing schema and require `--force` flag or interactive confirmation before overwriting.



================================================
FILE: openspec/changes/schema-management-cli/proposal.md
================================================
## Why

Creating and managing project-local schemas currently requires manual directory creation, copying files, and hoping the structure is correct. Users only discover structural errors at runtime when commands fail. This friction discourages schema customization and makes it harder to tailor OpenSpec workflows to specific project needs.

Key pain points:
- **Manual scaffolding**: Users must manually create `openspec/schemas/<name>/` with correct structure
- **No validation feedback**: Schema errors aren't caught until a command tries to use the schema
- **Starting from scratch is hard**: No easy way to base a custom schema on an existing one
- **Debugging resolution**: When a schema doesn't resolve as expected, there's no way to see the resolution path

## What Changes

Add a new `openspec schema` command group with subcommands for creating, forking, validating, and inspecting schemas.

### Commands

1. **`openspec schema init <name>`** - Interactive wizard to scaffold a new project schema
   - Prompts for schema description
   - Prompts for artifacts to include (with explanations)
   - Creates valid directory structure with `schema.yaml` and template files
   - Optionally sets as project default in `openspec/config.yaml`

2. **`openspec schema fork <source> [name]`** - Copy an existing schema as a starting point
   - Copies from user override or package built-in
   - Allows renaming (defaults to `<source>-custom`)
   - Preserves all templates and configuration

3. **`openspec schema validate [name]`** - Validate schema structure and templates
   - Checks `schema.yaml` is valid
   - Verifies all referenced templates exist
   - Reports missing or malformed files
   - Run without name to validate all project schemas

4. **`openspec schema which <name>`** - Show schema resolution path
   - Displays which location the schema resolves from (project/user/package)
   - Shows full path to schema directory
   - Useful for debugging shadowing issues

## Capabilities

### New Capabilities
- `schema-init-command`: Interactive wizard for creating new project schemas with guided prompts
- `schema-fork-command`: Copy existing schemas to project for customization
- `schema-validate-command`: Validate schema structure and report errors before runtime
- `schema-which-command`: Debug schema resolution by showing which location is used

### Modified Capabilities
<!-- None - these are additive commands -->

## Impact

- **Code**: New command implementations in `src/commands/` using existing resolver infrastructure
- **CLI**: New `schema` command group with 4 subcommands
- **Dependencies**: May use `enquirer` or similar for interactive prompts in `schema init`
- **Documentation**: Need to update CLI reference and schema customization guide



================================================
FILE: openspec/changes/schema-management-cli/tasks.md
================================================
## 1. Setup and Command Structure

- [x] 1.1 Create `src/commands/schema.ts` with `registerSchemaCommand(program: Command)` function
- [x] 1.2 Register schema command in `src/cli/index.ts` (import and call `registerSchemaCommand`)
- [x] 1.3 Add schema command group with description: "Manage workflow schemas"

## 2. Schema Which Command

- [x] 2.1 Add `schema which <name>` subcommand with `--json` and `--all` options
- [x] 2.2 Implement resolution lookup using `getSchemaDir()` with project root
- [x] 2.3 Implement shadow detection by checking all three locations (project, user, package)
- [x] 2.4 Add text output: show source, path, and shadowing info
- [x] 2.5 Add JSON output: `{ name, source, path, shadows: [] }`
- [x] 2.6 Add `--all` mode to list all schemas with their resolution sources

## 3. Schema Validate Command

- [x] 3.1 Add `schema validate [name]` subcommand with `--json` and `--verbose` options
- [x] 3.2 Implement single-schema validation using existing `parseSchema()` from `schema.ts`
- [x] 3.3 Add template existence check for each artifact's template file
- [x] 3.4 Add dependency graph cycle detection (reuse topological sort logic)
- [x] 3.5 Add validate-all mode when no name provided (scan `openspec/schemas/`)
- [x] 3.6 Add text output with pass/fail indicators and error messages
- [x] 3.7 Add JSON output matching existing `openspec validate` format: `{ valid, issues: [] }`
- [x] 3.8 Add verbose mode showing each validation step

## 4. Schema Fork Command

- [x] 4.1 Add `schema fork <source> [name]` subcommand with `--json` and `--force` options
- [x] 4.2 Implement source resolution using `getSchemaDir()` with project root
- [x] 4.3 Implement default destination naming: `<source>-custom`
- [x] 4.4 Implement directory copy with recursive file copy
- [x] 4.5 Update `name` field in copied `schema.yaml`
- [x] 4.6 Add overwrite protection: check destination exists, require `--force` or confirmation
- [x] 4.7 Add text output with source/destination paths
- [x] 4.8 Add JSON output: `{ forked, source, destination, sourceLocation }`

## 5. Schema Init Command

- [x] 5.1 Add `schema init <name>` subcommand with `--json`, `--description`, `--artifacts`, `--default`, `--no-default`, `--force` options
- [x] 5.2 Implement schema name validation (kebab-case, no spaces)
- [x] 5.3 Implement interactive prompts for description using `@inquirer/prompts`
- [x] 5.4 Implement interactive artifact selection with descriptions (multi-select)
- [x] 5.5 Create schema directory and `schema.yaml` with selected configuration
- [x] 5.6 Create default template files for selected artifacts
- [x] 5.7 Add `--default` flag to update `openspec/config.yaml` with new schema as default
- [x] 5.8 Add overwrite protection: check if schema exists, require `--force`
- [x] 5.9 Add text output with created path and next steps
- [x] 5.10 Add JSON output: `{ created, path, schema }`
- [x] 5.11 Add non-interactive mode with `--description` and `--artifacts` flags

## 6. Testing

- [x] 6.1 Add unit tests for `schema which` command in `test/commands/schema.test.ts`
- [x] 6.2 Add unit tests for `schema validate` command
- [x] 6.3 Add unit tests for `schema fork` command
- [x] 6.4 Add unit tests for `schema init` command
- [x] 6.5 Test interactive mode mocking with `@inquirer/prompts`
- [x] 6.6 Test JSON output format for all commands
- [x] 6.7 Test error cases: invalid name, not found, already exists, cycle detection

## 7. Documentation and Polish

- [x] 7.1 Add CLI help text for all schema subcommands
- [x] 7.2 Update shell completion to include schema commands
- [x] 7.3 Run linting and fix any issues (`npm run lint`)
- [x] 7.4 Run full test suite (`npm test`)



================================================
FILE: openspec/changes/schema-management-cli/.openspec.yaml
================================================
schema: spec-driven
created: 2026-01-20



================================================
FILE: openspec/changes/schema-management-cli/specs/schema-fork-command/spec.md
================================================
## ADDED Requirements

### Requirement: Schema fork copies existing schema
The CLI SHALL provide an `openspec schema fork <source> [name]` command that copies an existing schema to the project's `openspec/schemas/` directory.

#### Scenario: Fork with explicit name
- **WHEN** user runs `openspec schema fork spec-driven my-custom`
- **THEN** system locates `spec-driven` schema using resolution order (project â†’ user â†’ package)
- **AND** copies all files to `openspec/schemas/my-custom/`
- **AND** updates `name` field in `schema.yaml` to `my-custom`
- **AND** displays success message with source and destination paths

#### Scenario: Fork with default name
- **WHEN** user runs `openspec schema fork spec-driven` without specifying a name
- **THEN** system copies to `openspec/schemas/spec-driven-custom/`
- **AND** updates `name` field in `schema.yaml` to `spec-driven-custom`

#### Scenario: Source schema not found
- **WHEN** user runs `openspec schema fork nonexistent`
- **THEN** system displays error that schema was not found
- **AND** lists available schemas
- **AND** exits with non-zero code

### Requirement: Schema fork prevents accidental overwrites
The CLI SHALL require confirmation or `--force` flag when the destination schema already exists.

#### Scenario: Destination exists without force
- **WHEN** user runs `openspec schema fork spec-driven my-custom` and `openspec/schemas/my-custom/` exists
- **THEN** system displays error that destination already exists
- **AND** suggests using `--force` to overwrite
- **AND** exits with non-zero code

#### Scenario: Destination exists with force flag
- **WHEN** user runs `openspec schema fork spec-driven my-custom --force` and destination exists
- **THEN** system removes existing destination directory
- **AND** copies source schema to destination
- **AND** displays success message

#### Scenario: Interactive confirmation for overwrite
- **WHEN** user runs `openspec schema fork spec-driven my-custom` in interactive mode and destination exists
- **THEN** system prompts for confirmation to overwrite
- **AND** proceeds based on user response

### Requirement: Schema fork preserves all schema files
The CLI SHALL copy the complete schema directory including templates, configuration, and any additional files.

#### Scenario: Copy includes template files
- **WHEN** user forks a schema with template files (e.g., `proposal.md`, `design.md`)
- **THEN** all template files are copied to the destination
- **AND** template file contents are unchanged

#### Scenario: Copy includes nested directories
- **WHEN** user forks a schema with nested directories (e.g., `templates/specs/`)
- **THEN** nested directory structure is preserved
- **AND** all nested files are copied

### Requirement: Schema fork outputs JSON format
The CLI SHALL support `--json` flag for machine-readable output.

#### Scenario: JSON output on success
- **WHEN** user runs `openspec schema fork spec-driven my-custom --json`
- **THEN** system outputs JSON with `forked: true`, `source`, `destination`, and `sourcePath` fields

#### Scenario: JSON output shows source location
- **WHEN** user runs `openspec schema fork spec-driven --json`
- **THEN** JSON output includes `sourceLocation` field indicating "project", "user", or "package"



================================================
FILE: openspec/changes/schema-management-cli/specs/schema-init-command/spec.md
================================================
## ADDED Requirements

### Requirement: Schema init command creates project-local schema
The CLI SHALL provide an `openspec schema init <name>` command that creates a new schema directory under `openspec/schemas/<name>/` with a valid `schema.yaml` file and default template files.

#### Scenario: Create schema with valid name
- **WHEN** user runs `openspec schema init my-workflow`
- **THEN** system creates directory `openspec/schemas/my-workflow/`
- **AND** creates `schema.yaml` with name, version, description, and artifacts array
- **AND** creates template files referenced by artifacts
- **AND** displays success message with created path

#### Scenario: Reject invalid schema name
- **WHEN** user runs `openspec schema init "My Workflow"` (contains space)
- **THEN** system displays error about invalid schema name
- **AND** suggests using kebab-case format
- **AND** exits with non-zero code

#### Scenario: Schema name already exists
- **WHEN** user runs `openspec schema init existing-schema` and `openspec/schemas/existing-schema/` already exists
- **THEN** system displays error that schema already exists
- **AND** suggests using `--force` to overwrite or `schema fork` to copy
- **AND** exits with non-zero code

### Requirement: Schema init supports interactive mode
The CLI SHALL prompt for schema configuration when run in an interactive terminal without explicit flags.

#### Scenario: Interactive prompts for description
- **WHEN** user runs `openspec schema init my-workflow` in an interactive terminal
- **THEN** system prompts for schema description
- **AND** uses provided description in generated `schema.yaml`

#### Scenario: Interactive prompts for artifact selection
- **WHEN** user runs `openspec schema init my-workflow` in an interactive terminal
- **THEN** system displays multi-select prompt with common artifacts (proposal, specs, design, tasks)
- **AND** each option includes a brief description
- **AND** uses selected artifacts in generated `schema.yaml`

#### Scenario: Non-interactive mode with flags
- **WHEN** user runs `openspec schema init my-workflow --description "My workflow" --artifacts proposal,tasks`
- **THEN** system creates schema without prompting
- **AND** uses flag values for configuration

### Requirement: Schema init supports setting project default
The CLI SHALL offer to set the newly created schema as the project default.

#### Scenario: Set as default interactively
- **WHEN** user runs `openspec schema init my-workflow` in interactive mode
- **AND** user confirms setting as default
- **THEN** system updates `openspec/config.yaml` with `defaultSchema: my-workflow`

#### Scenario: Set as default via flag
- **WHEN** user runs `openspec schema init my-workflow --default`
- **THEN** system creates schema and updates `openspec/config.yaml` with `defaultSchema: my-workflow`

#### Scenario: Skip setting default
- **WHEN** user runs `openspec schema init my-workflow --no-default`
- **THEN** system creates schema without modifying `openspec/config.yaml`

### Requirement: Schema init outputs JSON format
The CLI SHALL support `--json` flag for machine-readable output.

#### Scenario: JSON output on success
- **WHEN** user runs `openspec schema init my-workflow --json --description "Test" --artifacts proposal`
- **THEN** system outputs JSON with `created: true`, `path`, and `schema` fields
- **AND** does not display interactive prompts or spinners

#### Scenario: JSON output on error
- **WHEN** user runs `openspec schema init "invalid name" --json`
- **THEN** system outputs JSON with `error` field describing the issue
- **AND** exits with non-zero code



================================================
FILE: openspec/changes/schema-management-cli/specs/schema-validate-command/spec.md
================================================
## ADDED Requirements

### Requirement: Schema validate checks schema structure
The CLI SHALL provide an `openspec schema validate [name]` command that validates schema configuration and reports errors.

#### Scenario: Validate specific schema
- **WHEN** user runs `openspec schema validate my-workflow`
- **THEN** system locates schema using resolution order
- **AND** validates `schema.yaml` against the schema Zod type
- **AND** displays validation result (valid or list of errors)

#### Scenario: Validate all project schemas
- **WHEN** user runs `openspec schema validate` without a name
- **THEN** system validates all schemas in `openspec/schemas/`
- **AND** displays results for each schema
- **AND** exits with non-zero code if any schema is invalid

#### Scenario: Schema not found
- **WHEN** user runs `openspec schema validate nonexistent`
- **THEN** system displays error that schema was not found
- **AND** exits with non-zero code

### Requirement: Schema validate checks YAML syntax
The CLI SHALL report YAML parsing errors with line numbers when possible.

#### Scenario: Invalid YAML syntax
- **WHEN** user runs `openspec schema validate my-workflow` and `schema.yaml` has syntax errors
- **THEN** system displays YAML parse error with line number
- **AND** exits with non-zero code

#### Scenario: Valid YAML but missing required fields
- **WHEN** `schema.yaml` is valid YAML but missing `name` field
- **THEN** system displays Zod validation error for missing required field
- **AND** identifies the specific missing field

### Requirement: Schema validate checks template existence
The CLI SHALL verify that all template files referenced by artifacts exist.

#### Scenario: Missing template file
- **WHEN** artifact references `template: proposal.md` but file doesn't exist in schema directory
- **THEN** system reports error: "Template file 'proposal.md' not found for artifact 'proposal'"
- **AND** exits with non-zero code

#### Scenario: All templates exist
- **WHEN** all artifact templates exist
- **THEN** system reports that templates are valid
- **AND** template existence is included in validation summary

### Requirement: Schema validate checks dependency graph
The CLI SHALL verify that artifact dependencies form a valid directed acyclic graph.

#### Scenario: Valid dependency graph
- **WHEN** artifact dependencies form a valid DAG (e.g., tasks â†’ specs â†’ proposal)
- **THEN** system reports dependency graph is valid

#### Scenario: Circular dependency detected
- **WHEN** artifact A requires B and artifact B requires A
- **THEN** system reports circular dependency error
- **AND** identifies the artifacts involved in the cycle
- **AND** exits with non-zero code

#### Scenario: Unknown dependency reference
- **WHEN** artifact requires `nonexistent-artifact`
- **THEN** system reports error: "Artifact 'x' requires unknown artifact 'nonexistent-artifact'"
- **AND** exits with non-zero code

### Requirement: Schema validate outputs JSON format
The CLI SHALL support `--json` flag for machine-readable validation results.

#### Scenario: JSON output for valid schema
- **WHEN** user runs `openspec schema validate my-workflow --json` and schema is valid
- **THEN** system outputs JSON with `valid: true`, `name`, and `path` fields

#### Scenario: JSON output for invalid schema
- **WHEN** user runs `openspec schema validate my-workflow --json` and schema has errors
- **THEN** system outputs JSON with `valid: false` and `issues` array
- **AND** each issue includes `level`, `path`, and `message` fields
- **AND** format matches existing `openspec validate` output structure

### Requirement: Schema validate supports verbose mode
The CLI SHALL support `--verbose` flag for detailed validation information.

#### Scenario: Verbose output shows all checks
- **WHEN** user runs `openspec schema validate my-workflow --verbose`
- **THEN** system displays each validation check as it runs
- **AND** shows pass/fail status for: YAML parsing, Zod validation, template existence, dependency graph



================================================
FILE: openspec/changes/schema-management-cli/specs/schema-which-command/spec.md
================================================
## ADDED Requirements

### Requirement: Schema which shows resolution result
The CLI SHALL provide an `openspec schema which <name>` command that displays where a schema resolves from.

#### Scenario: Schema resolves from project
- **WHEN** user runs `openspec schema which my-workflow` and schema exists in `openspec/schemas/my-workflow/`
- **THEN** system displays source as "project"
- **AND** displays full path to schema directory

#### Scenario: Schema resolves from user directory
- **WHEN** user runs `openspec schema which my-workflow` and schema exists only in user data directory
- **THEN** system displays source as "user"
- **AND** displays full path including XDG data directory

#### Scenario: Schema resolves from package
- **WHEN** user runs `openspec schema which spec-driven` and no override exists
- **THEN** system displays source as "package"
- **AND** displays full path to package's schemas directory

#### Scenario: Schema not found
- **WHEN** user runs `openspec schema which nonexistent`
- **THEN** system displays error that schema was not found
- **AND** lists available schemas
- **AND** exits with non-zero code

### Requirement: Schema which shows shadowing information
The CLI SHALL indicate when a schema shadows another schema at a lower priority level.

#### Scenario: Project schema shadows package
- **WHEN** user runs `openspec schema which spec-driven` and both project and package have `spec-driven`
- **THEN** system displays that project schema is active
- **AND** indicates it shadows the package version
- **AND** shows path to shadowed package schema

#### Scenario: No shadowing
- **WHEN** schema exists only in one location
- **THEN** system does not display shadowing information

#### Scenario: Multiple shadows
- **WHEN** project schema shadows both user and package schemas
- **THEN** system lists all shadowed locations in priority order

### Requirement: Schema which outputs JSON format
The CLI SHALL support `--json` flag for machine-readable output.

#### Scenario: JSON output basic
- **WHEN** user runs `openspec schema which spec-driven --json`
- **THEN** system outputs JSON with `name`, `source`, and `path` fields

#### Scenario: JSON output with shadows
- **WHEN** user runs `openspec schema which spec-driven --json` and schema has shadows
- **THEN** JSON includes `shadows` array with `source` and `path` for each shadowed schema

### Requirement: Schema which supports list mode
The CLI SHALL support listing all schemas with their resolution sources.

#### Scenario: List all schemas
- **WHEN** user runs `openspec schema which --all`
- **THEN** system displays all available schemas grouped by source
- **AND** indicates which schemas shadow others

#### Scenario: List in JSON format
- **WHEN** user runs `openspec schema which --all --json`
- **THEN** system outputs JSON array with resolution info for each schema



================================================
FILE: openspec/specs/artifact-graph/spec.md
================================================
# artifact-graph Specification

## Purpose
TBD - created by archiving change add-artifact-graph-core. Update Purpose after archive.
## Requirements
### Requirement: Schema Loading
The system SHALL load artifact graph definitions from YAML schema files within schema directories.

#### Scenario: Valid schema loaded
- **WHEN** a schema directory contains a valid `schema.yaml` file
- **THEN** the system returns an ArtifactGraph with all artifacts and dependencies

#### Scenario: Invalid schema rejected
- **WHEN** a schema YAML file is missing required fields
- **THEN** the system throws an error with a descriptive message

#### Scenario: Cyclic dependencies detected
- **WHEN** a schema contains cyclic artifact dependencies
- **THEN** the system throws an error listing the artifact IDs in the cycle

#### Scenario: Invalid dependency reference
- **WHEN** an artifact's `requires` array references a non-existent artifact ID
- **THEN** the system throws an error identifying the invalid reference

#### Scenario: Duplicate artifact IDs rejected
- **WHEN** a schema contains multiple artifacts with the same ID
- **THEN** the system throws an error identifying the duplicate

#### Scenario: Schema directory not found
- **WHEN** resolving a schema name that has no corresponding directory
- **THEN** the system throws an error listing available schemas

### Requirement: Build Order Calculation
The system SHALL compute a valid topological build order for artifacts.

#### Scenario: Linear dependency chain
- **WHEN** artifacts form a linear chain (A â†’ B â†’ C)
- **THEN** getBuildOrder() returns [A, B, C]

#### Scenario: Diamond dependency
- **WHEN** artifacts form a diamond (A â†’ B, A â†’ C, B â†’ D, C â†’ D)
- **THEN** getBuildOrder() returns A before B and C, and D last

#### Scenario: Independent artifacts
- **WHEN** artifacts have no dependencies
- **THEN** getBuildOrder() returns them in a stable order

### Requirement: State Detection
The system SHALL detect artifact completion state by scanning the filesystem.

#### Scenario: Simple file exists
- **WHEN** an artifact generates "proposal.md" and the file exists
- **THEN** the artifact is marked as completed

#### Scenario: Simple file missing
- **WHEN** an artifact generates "proposal.md" and the file does not exist
- **THEN** the artifact is not marked as completed

#### Scenario: Glob pattern with files
- **WHEN** an artifact generates "specs/*.md" and the specs/ directory contains .md files
- **THEN** the artifact is marked as completed

#### Scenario: Glob pattern empty
- **WHEN** an artifact generates "specs/*.md" and the specs/ directory is empty or missing
- **THEN** the artifact is not marked as completed

#### Scenario: Missing change directory
- **WHEN** the change directory does not exist
- **THEN** all artifacts are marked as not completed (empty state)

### Requirement: Ready Artifact Query
The system SHALL identify which artifacts are ready to be created based on dependency completion.

#### Scenario: Root artifacts ready initially
- **WHEN** no artifacts are completed
- **THEN** getNextArtifacts() returns artifacts with no dependencies

#### Scenario: Dependent artifact becomes ready
- **WHEN** an artifact's dependencies are all completed
- **THEN** getNextArtifacts() includes that artifact

#### Scenario: Blocked artifacts excluded
- **WHEN** an artifact has uncompleted dependencies
- **THEN** getNextArtifacts() does not include that artifact

### Requirement: Completion Check
The system SHALL determine when all artifacts in a graph are complete.

#### Scenario: All complete
- **WHEN** all artifacts in the graph are in the completed set
- **THEN** isComplete() returns true

#### Scenario: Partially complete
- **WHEN** some artifacts in the graph are not completed
- **THEN** isComplete() returns false

### Requirement: Blocked Query
The system SHALL identify which artifacts are blocked and return all their unmet dependencies.

#### Scenario: Artifact blocked by single dependency
- **WHEN** artifact B requires artifact A and A is not complete
- **THEN** getBlocked() returns `{ B: ['A'] }`

#### Scenario: Artifact blocked by multiple dependencies
- **WHEN** artifact C requires A and B, and only A is complete
- **THEN** getBlocked() returns `{ C: ['B'] }`

#### Scenario: Artifact blocked by all dependencies
- **WHEN** artifact C requires A and B, and neither is complete
- **THEN** getBlocked() returns `{ C: ['A', 'B'] }`

### Requirement: Schema Directory Structure
The system SHALL support self-contained schema directories with co-located templates.

#### Scenario: Schema with templates
- **WHEN** a schema directory contains `schema.yaml` and `templates/` subdirectory
- **THEN** artifacts can reference templates relative to the schema's templates directory

#### Scenario: User schema override
- **WHEN** a schema directory exists at `${XDG_DATA_HOME}/openspec/schemas/<name>/`
- **THEN** the system uses that directory instead of the built-in

#### Scenario: Built-in schema fallback
- **WHEN** no user override exists for a schema
- **THEN** the system uses the package built-in schema directory

#### Scenario: List available schemas
- **WHEN** listing schemas
- **THEN** the system returns schema names from both user and package directories




================================================
FILE: openspec/specs/change-creation/spec.md
================================================
# change-creation Specification

## Purpose
Provide programmatic utilities for creating and validating OpenSpec change directories.
## Requirements
### Requirement: Change Creation
The system SHALL provide a function to create new change directories programmatically.

#### Scenario: Create change
- **WHEN** `createChange(projectRoot, 'add-auth')` is called
- **THEN** the system creates `openspec/changes/add-auth/` directory

#### Scenario: Duplicate change rejected
- **WHEN** `createChange(projectRoot, 'add-auth')` is called and `openspec/changes/add-auth/` already exists
- **THEN** the system throws an error indicating the change already exists

#### Scenario: Creates parent directories if needed
- **WHEN** `createChange(projectRoot, 'add-auth')` is called and `openspec/changes/` does not exist
- **THEN** the system creates the full path including parent directories

#### Scenario: Invalid change name rejected
- **WHEN** `createChange(projectRoot, 'Add Auth')` is called with an invalid name
- **THEN** the system throws a validation error

### Requirement: Change Name Validation
The system SHALL validate change names follow kebab-case conventions.

#### Scenario: Valid kebab-case name accepted
- **WHEN** a change name like `add-user-auth` is validated
- **THEN** validation returns `{ valid: true }`

#### Scenario: Numeric suffixes accepted
- **WHEN** a change name like `add-feature-2` is validated
- **THEN** validation returns `{ valid: true }`

#### Scenario: Single word accepted
- **WHEN** a change name like `refactor` is validated
- **THEN** validation returns `{ valid: true }`

#### Scenario: Uppercase characters rejected
- **WHEN** a change name like `Add-Auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Spaces rejected
- **WHEN** a change name like `add auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Underscores rejected
- **WHEN** a change name like `add_auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Special characters rejected
- **WHEN** a change name like `add-auth!` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Leading hyphen rejected
- **WHEN** a change name like `-add-auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Trailing hyphen rejected
- **WHEN** a change name like `add-auth-` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`

#### Scenario: Consecutive hyphens rejected
- **WHEN** a change name like `add--auth` is validated
- **THEN** validation returns `{ valid: false, error: "..." }`




================================================
FILE: openspec/specs/ci-nix-validation/spec.md
================================================
# ci-nix-validation Specification

## Purpose

Validates Nix flake builds and maintenance scripts in CI to ensure Nix users can reliably install and use OpenSpec. Prevents regressions in Nix support by testing builds and the update-flake.sh script on every pull request and push to main.
## Requirements
### Requirement: Nix Flake Build Validation

The CI system SHALL validate that the Nix flake builds successfully on every pull request and push to main.

#### Scenario: Successful flake build

- **WHEN** a pull request or push to main is made
- **THEN** the CI SHALL execute `nix build` and verify it completes with exit code 0
- **AND** the build output SHALL contain the openspec binary

#### Scenario: Flake build failure

- **WHEN** the Nix flake configuration is broken
- **THEN** the CI job SHALL fail with a non-zero exit code
- **AND** the CI SHALL prevent merging of the pull request

#### Scenario: Multi-platform support check

- **WHEN** the flake declares support for multiple systems
- **THEN** the CI SHALL validate the flake builds on at least Linux (x86_64-linux)

### Requirement: Update Script Validation

The CI system SHALL validate that the update-flake.sh script executes successfully and produces valid output.

#### Scenario: Update script execution

- **WHEN** the CI runs the update script validation
- **THEN** the script SHALL execute without errors
- **AND** the script SHALL correctly extract the version from package.json
- **AND** the script SHALL update flake.nix with the correct version

#### Scenario: Update script with mock hash

- **WHEN** validating the update script in CI
- **THEN** the script SHALL be able to detect and extract the correct pnpm dependency hash
- **AND** the flake.nix SHALL be updated with a valid sha256 hash

### Requirement: CI Job Integration

The Nix validation jobs SHALL be integrated into the existing GitHub Actions workflow and required for merge.

#### Scenario: PR merge requirements

- **WHEN** a pull request is created
- **THEN** the Nix validation job SHALL be included in required checks
- **AND** the PR SHALL NOT be mergeable until Nix validation passes

#### Scenario: Job execution triggers

- **WHEN** code is pushed to a pull request OR pushed to main OR manually triggered
- **THEN** the Nix validation job SHALL execute automatically

### Requirement: Local Testing Support

The CI workflow SHALL be testable locally using the `act` tool to enable rapid iteration.

#### Scenario: Local CI execution with act

- **WHEN** a developer runs `act` with the Nix validation workflow
- **THEN** the workflow SHALL execute in the local Docker environment
- **AND** the developer SHALL receive feedback on Nix build status without pushing to GitHub

#### Scenario: Act configuration compatibility

- **WHEN** the workflow is designed
- **THEN** it SHALL use standard GitHub Actions syntax compatible with `act`
- **AND** any Nix-specific setup SHALL work in the act Docker environment

### Requirement: Nix Installation in CI

The CI environment SHALL have Nix properly installed and configured before running validation.

#### Scenario: Nix installation step

- **WHEN** the Nix validation job starts
- **THEN** Nix SHALL be installed using the official Nix installer or determinatesystems/nix-installer-action
- **AND** the Nix installation SHALL be cached for subsequent runs to improve performance

#### Scenario: Nix configuration for CI

- **WHEN** Nix is installed in CI
- **THEN** it SHALL be configured to work in the GitHub Actions environment
- **AND** experimental features (flakes, nix-command) SHALL be enabled

### Requirement: CI Performance Optimization

The Nix validation SHALL be optimized to minimize CI runtime impact.

#### Scenario: Acceptable runtime

- **WHEN** the Nix validation job runs
- **THEN** it SHALL complete in under 5 minutes on a clean run
- **AND** with caching, it SHALL complete in under 3 minutes on subsequent runs

#### Scenario: Parallel execution

- **WHEN** multiple CI jobs are running
- **THEN** the Nix validation job SHALL run in parallel with other validation jobs (tests, lint)
- **AND** SHALL NOT block other independent checks




================================================
FILE: openspec/specs/cli-archive/spec.md
================================================
# CLI Archive Command Specification

## Purpose
The archive command moves completed changes from the active changes directory to the archive folder with date-based naming, following OpenSpec conventions.

## Command Syntax
```bash
openspec archive [change-name] [--yes|-y]
```

Options:
- `--yes`, `-y`: Skip confirmation prompts (for automation)
## Requirements
### Requirement: Change Selection

The command SHALL support both interactive and direct change selection methods.

#### Scenario: Interactive selection

- **WHEN** no change-name is provided
- **THEN** display interactive list of available changes (excluding archive/)
- **AND** allow user to select one

#### Scenario: Direct selection

- **WHEN** change-name is provided
- **THEN** use that change directly
- **AND** validate it exists

### Requirement: Task Completion Check

The command SHALL verify task completion status before archiving to prevent premature archival.

#### Scenario: Incomplete tasks found

- **WHEN** incomplete tasks are found (marked with `- [ ]`)
- **THEN** display all incomplete tasks to the user
- **AND** prompt for confirmation to continue
- **AND** default to "No" for safety

#### Scenario: All tasks complete

- **WHEN** all tasks are complete OR no tasks.md exists
- **THEN** proceed with archiving without prompting

### Requirement: Archive Process

The archive operation SHALL follow a structured process to safely move changes to the archive.

#### Scenario: Performing archive

- **WHEN** archiving a change
- **THEN** execute these steps:
  1. Create archive/ directory if it doesn't exist
  2. Generate target name as `YYYY-MM-DD-[change-name]` using current date
  3. Check if target directory already exists
  4. Update main specs from the change's future state specs (see Spec Update Process below)
  5. Move the entire change directory to the archive location

#### Scenario: Archive already exists

- **WHEN** target archive already exists
- **THEN** fail with error message
- **AND** do not overwrite existing archive

#### Scenario: Successful archive

- **WHEN** move succeeds
- **THEN** display success message with archived name and list of updated specs

### Requirement: Spec Update Process

Before moving the change to archive, the command SHALL apply delta changes to main specs to reflect the deployed reality.

#### Scenario: Applying delta changes

- **WHEN** archiving a change with delta-based specs
- **THEN** parse and apply delta changes as defined in openspec-conventions
- **AND** validate all operations before applying

#### Scenario: Validating delta changes

- **WHEN** processing delta changes
- **THEN** perform validations as specified in openspec-conventions
- **AND** if validation fails, show specific errors and abort

#### Scenario: Conflict detection

- **WHEN** applying deltas would create duplicate requirement headers
- **THEN** abort with error message showing the conflict
- **AND** suggest manual resolution

### Requirement: Confirmation Behavior

The spec update confirmation SHALL provide clear visibility into changes before they are applied.

#### Scenario: Displaying confirmation

- **WHEN** prompting for confirmation
- **THEN** display a clear summary showing:
  - Which specs will be created (new capabilities)
  - Which specs will be updated (existing capabilities)
  - The source path for each spec
- **AND** format the confirmation prompt as:
  ```
  The following specs will be updated:
  
  NEW specs to be created:
    - cli-archive (from changes/add-archive-command/specs/cli-archive/spec.md)
  
  EXISTING specs to be updated:
    - cli-init (from changes/update-init-command/specs/cli-init/spec.md)
  
  Update 2 specs and archive 'add-archive-command'? [y/N]:
  ```
#### Scenario: Handling confirmation response

- **WHEN** waiting for user confirmation
- **THEN** default to "No" for safety (require explicit "y" or "yes")
- **AND** skip confirmation when `--yes` or `-y` flag is provided

#### Scenario: User declines confirmation

- **WHEN** user declines the confirmation
- **THEN** abort the entire archive operation
- **AND** display message: "Archive cancelled. No changes were made."
- **AND** exit with non-zero status code

### Requirement: Error Conditions

The command SHALL handle various error conditions gracefully.

#### Scenario: Handling errors

- **WHEN** errors occur
- **THEN** handle the following conditions:
  - Missing openspec/changes/ directory
  - Change not found
  - Archive target already exists
  - File system permissions issues

### Requirement: Skip Specs Option

The archive command SHALL support a `--skip-specs` flag that skips all spec update operations and proceeds directly to archiving.

#### Scenario: Skipping spec updates with flag

- **WHEN** executing `openspec archive <change> --skip-specs`
- **THEN** skip spec discovery and update confirmation
- **AND** proceed directly to moving the change to archive
- **AND** display a message indicating specs were skipped

### Requirement: Non-blocking confirmation

The archive operation SHALL proceed when the user declines spec updates instead of cancelling the entire operation.

#### Scenario: User declines spec update confirmation

- **WHEN** the user declines spec update confirmation
- **THEN** skip spec updates
- **AND** continue with the archive operation
- **AND** display a success message indicating specs were not updated

### Requirement: Display Output

The command SHALL provide clear feedback about delta operations.

#### Scenario: Showing delta application

- **WHEN** applying delta changes
- **THEN** display for each spec:
  - Number of requirements added
  - Number of requirements modified
  - Number of requirements removed
  - Number of requirements renamed
- **AND** use standard output symbols (+ ~ - â†’) as defined in openspec-conventions:
  ```
  Applying changes to specs/user-auth/spec.md:
    + 2 added
    ~ 3 modified
    - 1 removed
    â†’ 1 renamed
  ```

### Requirement: Archive Validation

The archive command SHALL validate changes before applying them to ensure data integrity.

#### Scenario: Pre-archive validation

- **WHEN** executing `openspec archive change-name`
- **THEN** validate the change structure first
- **AND** only proceed if validation passes
- **AND** show validation errors if it fails

#### Scenario: Force archive without validation

- **WHEN** executing `openspec archive change-name --no-validate`
- **THEN** skip validation (unsafe mode)
- **AND** show warning about skipping validation

## Why These Decisions

**Interactive selection**: Reduces typing and helps users see available changes
**Task checking**: Prevents accidental archiving of incomplete work
**Date prefixing**: Maintains chronological order and prevents naming conflicts
**No overwrite**: Preserves historical archives and prevents data loss
**Spec updates before archiving**: Specs in the main directory represent current reality; when a change is deployed and archived, its future state specs become the new reality and must replace the main specs
**Confirmation for spec updates**: Provides visibility into what will change, prevents accidental overwrites, and ensures users understand the impact before specs are modified
**--yes flag for automation**: Allows CI/CD pipelines to archive without interactive prompts while maintaining safety by default for manual use


================================================
FILE: openspec/specs/cli-artifact-workflow/spec.md
================================================
# cli-artifact-workflow Specification

## Purpose
TBD - created by archiving change add-artifact-workflow-cli. Update Purpose after archive.
## Requirements
### Requirement: Status Command

The system SHALL display artifact completion status for a change, including scaffolded (empty) changes.

> **Fixes bug**: Previously required `proposal.md` to exist via `getActiveChangeIds()`.

#### Scenario: Show status with all states

- **WHEN** user runs `openspec status --change <id>`
- **THEN** the system displays each artifact with status indicator:
  - `[x]` for completed artifacts
  - `[ ]` for ready artifacts
  - `[-]` for blocked artifacts (with missing dependencies listed)

#### Scenario: Status shows completion summary

- **WHEN** user runs `openspec status --change <id>`
- **THEN** output includes completion percentage and count (e.g., "2/4 artifacts complete")

#### Scenario: Status JSON output

- **WHEN** user runs `openspec status --change <id> --json`
- **THEN** the system outputs JSON with changeName, schemaName, isComplete, and artifacts array

#### Scenario: Status JSON includes apply requirements

- **WHEN** user runs `openspec status --change <id> --json`
- **THEN** the system outputs JSON with:
  - `changeName`, `schemaName`, `isComplete`, `artifacts` array
  - `applyRequires`: array of artifact IDs needed for apply phase

#### Scenario: Status on scaffolded change

- **WHEN** user runs `openspec status --change <id>` on a change with no artifacts
- **THEN** system displays all artifacts with their status
- **AND** root artifacts (no dependencies) show as ready `[ ]`
- **AND** dependent artifacts show as blocked `[-]`

#### Scenario: Missing change parameter

- **WHEN** user runs `openspec status` without `--change`
- **THEN** the system displays an error with list of available changes
- **AND** includes scaffolded changes (directories without proposal.md)

#### Scenario: Unknown change

- **WHEN** user runs `openspec status --change unknown-id`
- **AND** directory `openspec/changes/unknown-id/` does not exist
- **THEN** the system displays an error listing all available change directories

### Requirement: Instructions Command

The system SHALL output enriched instructions for creating an artifact, including for scaffolded changes.

#### Scenario: Show enriched instructions

- **WHEN** user runs `openspec instructions <artifact> --change <id>`
- **THEN** the system outputs:
  - Artifact metadata (ID, output path, description)
  - Template content
  - Dependency status (done/missing)
  - Unlocked artifacts (what becomes available after completion)

#### Scenario: Instructions JSON output

- **WHEN** user runs `openspec instructions <artifact> --change <id> --json`
- **THEN** the system outputs JSON matching ArtifactInstructions interface

#### Scenario: Unknown artifact

- **WHEN** user runs `openspec instructions unknown-artifact --change <id>`
- **THEN** the system displays an error listing valid artifact IDs for the schema

#### Scenario: Artifact with unmet dependencies

- **WHEN** user requests instructions for a blocked artifact
- **THEN** the system displays instructions with a warning about missing dependencies

#### Scenario: Instructions on scaffolded change

- **WHEN** user runs `openspec instructions proposal --change <id>` on a scaffolded change
- **THEN** system outputs template and metadata for creating the proposal
- **AND** does not require any artifacts to already exist

### Requirement: Templates Command
The system SHALL show resolved template paths for all artifacts in a schema.

#### Scenario: List template paths with default schema
- **WHEN** user runs `openspec templates`
- **THEN** the system displays each artifact with its resolved template path using the default schema

#### Scenario: List template paths with custom schema
- **WHEN** user runs `openspec templates --schema tdd`
- **THEN** the system displays template paths for the specified schema

#### Scenario: Templates JSON output
- **WHEN** user runs `openspec templates --json`
- **THEN** the system outputs JSON mapping artifact IDs to template paths

#### Scenario: Template resolution source
- **WHEN** displaying template paths
- **THEN** the system indicates whether each template is from user override or package built-in

### Requirement: New Change Command
The system SHALL create new change directories with validation.

#### Scenario: Create valid change
- **WHEN** user runs `openspec new change add-feature`
- **THEN** the system creates `openspec/changes/add-feature/` directory

#### Scenario: Invalid change name
- **WHEN** user runs `openspec new change "Add Feature"` with invalid name
- **THEN** the system displays validation error with guidance

#### Scenario: Duplicate change name
- **WHEN** user runs `openspec new change existing-change` for an existing change
- **THEN** the system displays an error indicating the change already exists

#### Scenario: Create with description
- **WHEN** user runs `openspec new change add-feature --description "Add new feature"`
- **THEN** the system creates the change directory with description in README.md

### Requirement: Schema Selection
The system SHALL support custom schema selection for workflow commands.

#### Scenario: Default schema
- **WHEN** user runs workflow commands without `--schema`
- **THEN** the system uses the "spec-driven" schema

#### Scenario: Custom schema
- **WHEN** user runs `openspec status --change <id> --schema tdd`
- **THEN** the system uses the specified schema for artifact graph

#### Scenario: Unknown schema
- **WHEN** user specifies an unknown schema
- **THEN** the system displays an error listing available schemas

### Requirement: Output Formatting
The system SHALL provide consistent output formatting.

#### Scenario: Color output
- **WHEN** terminal supports colors
- **THEN** status indicators use colors: green (done), yellow (ready), red (blocked)

#### Scenario: No color output
- **WHEN** `--no-color` flag is used or NO_COLOR environment variable is set
- **THEN** output uses text-only indicators without ANSI colors

#### Scenario: Progress indication
- **WHEN** loading change state takes time
- **THEN** the system displays a spinner during loading

### Requirement: Experimental Isolation
The system SHALL implement artifact workflow commands in isolation for easy removal.

#### Scenario: Single file implementation
- **WHEN** artifact workflow feature is implemented
- **THEN** all commands are in `src/commands/artifact-workflow.ts`

#### Scenario: Help text marking
- **WHEN** user runs `--help` on any artifact workflow command
- **THEN** help text indicates the command is experimental

### Requirement: Schema Apply Block

The system SHALL support an `apply` block in schema definitions that controls when and how implementation begins.

#### Scenario: Schema with apply block

- **WHEN** a schema defines an `apply` block
- **THEN** the system uses `apply.requires` to determine which artifacts must exist before apply
- **AND** uses `apply.tracks` to identify the file for progress tracking (or null if none)
- **AND** uses `apply.instruction` for guidance shown to the agent

#### Scenario: Schema without apply block

- **WHEN** a schema has no `apply` block
- **THEN** the system requires all artifacts to exist before apply is available
- **AND** uses default instruction: "All artifacts complete. Proceed with implementation."

### Requirement: Apply Instructions Command

The system SHALL generate schema-aware apply instructions via `openspec instructions apply`.

#### Scenario: Generate apply instructions

- **WHEN** user runs `openspec instructions apply --change <id>`
- **AND** all required artifacts (per schema's `apply.requires`) exist
- **THEN** the system outputs:
  - Context files from all existing artifacts
  - Schema-specific instruction text
  - Progress tracking file path (if `apply.tracks` is set)

#### Scenario: Apply blocked by missing artifacts

- **WHEN** user runs `openspec instructions apply --change <id>`
- **AND** required artifacts are missing
- **THEN** the system indicates apply is blocked
- **AND** lists which artifacts must be created first

#### Scenario: Apply instructions JSON output

- **WHEN** user runs `openspec instructions apply --change <id> --json`
- **THEN** the system outputs JSON with:
  - `contextFiles`: array of paths to existing artifacts
  - `instruction`: the apply instruction text
  - `tracks`: path to progress file or null
  - `applyRequires`: list of required artifact IDs

## REMOVED Requirements

### Requirement: Next Command

**Reason**: Redundant with Status Command - `openspec status` already shows which artifacts are ready (status: "ready") vs blocked vs done.

**Migration**: Use `openspec status --change <id> --json` and filter artifacts with `status: "ready"` to find artifacts that can be created next.




================================================
FILE: openspec/specs/cli-change/spec.md
================================================
# cli-change Specification

## Purpose
TBD - created by archiving change add-change-commands. Update Purpose after archive.
## Requirements
### Requirement: Change Command

The system SHALL provide a `change` command with subcommands for displaying, listing, and validating change proposals.

#### Scenario: Show change as JSON

- **WHEN** executing `openspec change show update-error --json`
- **THEN** parse the markdown change file
- **AND** extract change structure and deltas
- **AND** output valid JSON to stdout

#### Scenario: List all changes

- **WHEN** executing `openspec change list`
- **THEN** scan the openspec/changes directory
- **AND** return list of all pending changes
- **AND** support JSON output with `--json` flag

#### Scenario: Show only requirement changes

- **WHEN** executing `openspec change show update-error --requirements-only`
- **THEN** display only the requirement changes (ADDED/MODIFIED/REMOVED/RENAMED)
- **AND** exclude why and what changes sections

#### Scenario: Validate change structure

- **WHEN** executing `openspec change validate update-error`
- **THEN** parse the change file
- **AND** validate against Zod schema
- **AND** ensure deltas are well-formed

### Requirement: Legacy Compatibility

The system SHALL maintain backward compatibility with the existing `list` command while showing deprecation notices.

#### Scenario: Legacy list command

- **WHEN** executing `openspec list`
- **THEN** display current list of changes (existing behavior)
- **AND** show deprecation notice: "Note: 'openspec list' is deprecated. Use 'openspec change list' instead."

#### Scenario: Legacy list with --all flag

- **WHEN** executing `openspec list --all`
- **THEN** display all changes (existing behavior)
- **AND** show same deprecation notice

### Requirement: Interactive show selection

The change show command SHALL support interactive selection when no change name is provided.

#### Scenario: Interactive change selection for show

- **WHEN** executing `openspec change show` without arguments
- **THEN** display an interactive list of available changes
- **AND** allow the user to select a change to show
- **AND** display the selected change content
- **AND** maintain all existing show options (--json, --deltas-only)

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec change show` without a change name
- **THEN** do not prompt interactively
- **AND** print the existing hint including available change IDs
- **AND** set `process.exitCode = 1`

### Requirement: Interactive validation selection

The change validate command SHALL support interactive selection when no change name is provided.

#### Scenario: Interactive change selection for validation

- **WHEN** executing `openspec change validate` without arguments
- **THEN** display an interactive list of available changes
- **AND** allow the user to select a change to validate
- **AND** validate the selected change

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec change validate` without a change name
- **THEN** do not prompt interactively
- **AND** print the existing hint including available change IDs
- **AND** set `process.exitCode = 1`




================================================
FILE: openspec/specs/cli-completion/spec.md
================================================
# cli-completion Specification

## Purpose
Provide shell completion scripts for the OpenSpec CLI, enabling tab-completion for commands, flags, and dynamic values (change IDs, spec IDs) across multiple shells. Supports Zsh, Bash, Fish, and PowerShell.
## Requirements
### Requirement: Native Shell Behavior Integration

The completion system SHALL respect and integrate with each supported shell's native completion patterns and user interaction model.

#### Scenario: Zsh native completion

- **WHEN** generating Zsh completion scripts
- **THEN** use Zsh completion system with `_arguments`, `_describe`, and `compadd`
- **AND** completions SHALL trigger on single TAB (standard Zsh behavior)
- **AND** display as an interactive menu that users navigate with TAB/arrow keys
- **AND** support Oh My Zsh's enhanced menu styling automatically

#### Scenario: Bash native completion

- **WHEN** generating Bash completion scripts
- **THEN** use Bash completion with `complete` builtin and `COMPREPLY` array
- **AND** completions SHALL trigger on double TAB (standard Bash behavior)
- **AND** display as space-separated list or column format
- **AND** support both bash-completion v1 and v2 patterns

#### Scenario: Fish native completion

- **WHEN** generating Fish completion scripts
- **THEN** use Fish's `complete` command with conditions
- **AND** completions SHALL trigger on single TAB with auto-suggestion preview
- **AND** display with Fish's native coloring and description alignment
- **AND** leverage Fish's built-in caching automatically

#### Scenario: PowerShell native completion

- **WHEN** generating PowerShell completion scripts
- **THEN** use `Register-ArgumentCompleter` with scriptblock
- **AND** completions SHALL trigger on TAB with cycling behavior
- **AND** display with PowerShell's native completion UI
- **AND** support both Windows PowerShell 5.1 and PowerShell Core 7+

#### Scenario: No custom UX patterns

- **WHEN** implementing completion for any shell
- **THEN** do NOT attempt to customize completion trigger behavior
- **AND** do NOT override shell-specific navigation patterns
- **AND** ensure completions feel native to experienced users of that shell

### Requirement: Command Structure

The completion command SHALL follow a subcommand pattern for generating and managing completion scripts.

#### Scenario: Available subcommands

- **WHEN** user executes `openspec completion --help`
- **THEN** display available subcommands:
  - `generate [shell]` - Generate completion script for a shell (outputs to stdout)
  - `install [shell]` - Install completion for Zsh (auto-detects or requires explicit shell)
  - `uninstall [shell]` - Remove completion for Zsh (auto-detects or requires explicit shell)

### Requirement: Shell Detection

The completion system SHALL automatically detect the user's current shell environment.

#### Scenario: Detecting Zsh from environment

- **WHEN** no shell is explicitly specified
- **THEN** read the `$SHELL` environment variable
- **AND** extract the shell name from the path (e.g., `/bin/zsh` â†’ `zsh`)
- **AND** validate the shell is one of: `zsh`, `bash`, `fish`, `powershell`
- **AND** throw an error if the shell is not supported

#### Scenario: Detecting Bash from environment

- **WHEN** `$SHELL` contains `bash` in the path
- **THEN** detect shell as `bash`
- **AND** proceed with bash-specific completion logic

#### Scenario: Detecting Fish from environment

- **WHEN** `$SHELL` contains `fish` in the path
- **THEN** detect shell as `fish`
- **AND** proceed with fish-specific completion logic

#### Scenario: Detecting PowerShell from environment

- **WHEN** `$PSModulePath` environment variable is present
- **THEN** detect shell as `powershell`
- **AND** proceed with PowerShell-specific completion logic

#### Scenario: Unsupported shell detection

- **WHEN** shell path indicates an unsupported shell
- **THEN** throw error: "Shell '<name>' is not supported. Supported shells: zsh, bash, fish, powershell"

### Requirement: Completion Generation

The completion command SHALL generate completion scripts for all supported shells on demand.

#### Scenario: Generating Zsh completion

- **WHEN** user executes `openspec completion generate zsh`
- **THEN** output a complete Zsh completion script to stdout
- **AND** include completions for all commands: init, list, show, validate, archive, view, update, change, spec, completion
- **AND** include all command-specific flags and options
- **AND** use Zsh's `_arguments` and `_describe` built-in functions
- **AND** support dynamic completion for change and spec IDs

#### Scenario: Generating Bash completion

- **WHEN** user executes `openspec completion generate bash`
- **THEN** output a complete Bash completion script to stdout
- **AND** include completions for all commands and subcommands
- **AND** use `complete -F` with custom completion function
- **AND** populate `COMPREPLY` with appropriate suggestions
- **AND** support dynamic completion for change and spec IDs via `openspec __complete`

#### Scenario: Generating Fish completion

- **WHEN** user executes `openspec completion generate fish`
- **THEN** output a complete Fish completion script to stdout
- **AND** use `complete -c openspec` with conditions
- **AND** include command-specific completions with `--condition` predicates
- **AND** support dynamic completion for change and spec IDs via `openspec __complete`
- **AND** include descriptions for each completion option

#### Scenario: Generating PowerShell completion

- **WHEN** user executes `openspec completion generate powershell`
- **THEN** output a complete PowerShell completion script to stdout
- **AND** use `Register-ArgumentCompleter -CommandName openspec`
- **AND** implement scriptblock that handles command context
- **AND** support dynamic completion for change and spec IDs via `openspec __complete`
- **AND** return `[System.Management.Automation.CompletionResult]` objects

### Requirement: Dynamic Completions

The completion system SHALL provide context-aware dynamic completions for project-specific values.

#### Scenario: Completing change IDs

- **WHEN** completing arguments for commands that accept change names (show, validate, archive)
- **THEN** discover active changes from `openspec/changes/` directory
- **AND** exclude archived changes in `openspec/changes/archive/`
- **AND** return change IDs as completion suggestions
- **AND** only provide suggestions when inside an OpenSpec-enabled project

#### Scenario: Completing spec IDs

- **WHEN** completing arguments for commands that accept spec names (show, validate)
- **THEN** discover specs from `openspec/specs/` directory
- **AND** return spec IDs as completion suggestions
- **AND** only provide suggestions when inside an OpenSpec-enabled project

#### Scenario: Completion caching

- **WHEN** dynamic completions are requested
- **THEN** cache discovered change and spec IDs for 2 seconds
- **AND** reuse cached values for subsequent requests within cache window
- **AND** automatically refresh cache after expiration

#### Scenario: Project detection

- **WHEN** user requests completions outside an OpenSpec project
- **THEN** skip dynamic change/spec ID completions
- **AND** only suggest static commands and flags

### Requirement: Installation Automation

The completion command SHALL automatically install completion scripts into shell configuration files for all supported shells.

#### Scenario: Installing for Oh My Zsh

- **WHEN** user executes `openspec completion install zsh`
- **THEN** detect if Oh My Zsh is installed by checking for `$ZSH` environment variable or `~/.oh-my-zsh/` directory
- **AND** create custom completions directory at `~/.oh-my-zsh/custom/completions/` if it doesn't exist
- **AND** write completion script to `~/.oh-my-zsh/custom/completions/_openspec`
- **AND** ensure `~/.oh-my-zsh/custom/completions` is in `$fpath` by updating `~/.zshrc` if needed
- **AND** display success message with instruction to run `exec zsh` or restart terminal

#### Scenario: Installing for standard Zsh

- **WHEN** user executes `openspec completion install zsh` and Oh My Zsh is not detected
- **THEN** create completions directory at `~/.zsh/completions/` if it doesn't exist
- **AND** write completion script to `~/.zsh/completions/_openspec`
- **AND** add `fpath=(~/.zsh/completions $fpath)` to `~/.zshrc` if not already present
- **AND** add `autoload -Uz compinit && compinit` to `~/.zshrc` if not already present
- **AND** display success message with instruction to run `exec zsh` or restart terminal

#### Scenario: Installing for Bash with bash-completion

- **WHEN** user executes `openspec completion install bash`
- **THEN** detect if bash-completion is installed by checking for `/usr/share/bash-completion` or `/etc/bash_completion.d`
- **AND** if bash-completion is available, write to `/etc/bash_completion.d/openspec` (with sudo) or `~/.local/share/bash-completion/completions/openspec`
- **AND** if bash-completion is not available, write to `~/.bash_completion.d/openspec` and source it from `~/.bashrc`
- **AND** add sourcing line to `~/.bashrc` using marker-based updates if needed
- **AND** display success message with instruction to run `exec bash` or restart terminal

#### Scenario: Installing for Fish

- **WHEN** user executes `openspec completion install fish`
- **THEN** create Fish completions directory at `~/.config/fish/completions/` if it doesn't exist
- **AND** write completion script to `~/.config/fish/completions/openspec.fish`
- **AND** Fish automatically loads completions from this directory (no config file modification needed)
- **AND** display success message indicating completions are immediately available

#### Scenario: Installing for PowerShell

- **WHEN** user executes `openspec completion install powershell`
- **THEN** detect PowerShell profile location via `$PROFILE` environment variable or default paths
- **AND** create profile directory if it doesn't exist
- **AND** add completion script import to profile using marker-based updates
- **AND** write completion script to PowerShell modules directory or alongside profile
- **AND** display success message with instruction to restart PowerShell or run `. $PROFILE`

#### Scenario: Auto-detecting shell for installation

- **WHEN** user executes `openspec completion install` without specifying a shell
- **THEN** detect current shell using shell detection logic
- **AND** install completion for the detected shell (zsh, bash, fish, or powershell)
- **AND** display which shell was detected

#### Scenario: Already installed

- **WHEN** completion is already installed for the target shell
- **THEN** display message indicating completion is already installed
- **AND** offer to reinstall/update by overwriting existing files
- **AND** exit with code 0

### Requirement: Uninstallation

The completion command SHALL remove installed completion scripts and configuration for all supported shells.

#### Scenario: Uninstalling Zsh completion

- **WHEN** user executes `openspec completion uninstall zsh`
- **THEN** prompt for confirmation before proceeding (unless `--yes` flag provided)
- **AND** if user declines, cancel uninstall and display "Uninstall cancelled."
- **AND** if user confirms, remove `~/.oh-my-zsh/custom/completions/_openspec` if Oh My Zsh is detected
- **AND** remove `~/.zsh/completions/_openspec` if standard Zsh setup is detected
- **AND** remove fpath modifications from `~/.zshrc` using marker-based removal
- **AND** display success message

#### Scenario: Uninstalling Bash completion

- **WHEN** user executes `openspec completion uninstall bash`
- **THEN** prompt for confirmation (unless `--yes` flag provided)
- **AND** if user confirms, remove completion file from bash-completion directory or `~/.bash_completion.d/`
- **AND** remove sourcing lines from `~/.bashrc` using marker-based removal
- **AND** display success message

#### Scenario: Uninstalling Fish completion

- **WHEN** user executes `openspec completion uninstall fish`
- **THEN** prompt for confirmation (unless `--yes` flag provided)
- **AND** if user confirms, remove `~/.config/fish/completions/openspec.fish`
- **AND** display success message (no config file modification needed)

#### Scenario: Uninstalling PowerShell completion

- **WHEN** user executes `openspec completion uninstall powershell`
- **THEN** prompt for confirmation (unless `--yes` flag provided)
- **AND** if user confirms, remove completion import from PowerShell profile using marker-based removal
- **AND** remove completion script file
- **AND** display success message

#### Scenario: Auto-detecting shell for uninstallation

- **WHEN** user executes `openspec completion uninstall` without specifying a shell
- **THEN** detect current shell and uninstall completion for that shell

#### Scenario: Not installed

- **WHEN** attempting to uninstall completion that isn't installed
- **THEN** display error message indicating completion is not installed
- **AND** exit with code 1

### Requirement: Architecture Patterns

The completion implementation SHALL follow clean architecture principles with TypeScript best practices, supporting multiple shells through a plugin-based pattern.

#### Scenario: Shell-specific generators

- **WHEN** implementing completion generators
- **THEN** create generator classes for each shell: `ZshGenerator`, `BashGenerator`, `FishGenerator`, `PowerShellGenerator`
- **AND** implement a common `CompletionGenerator` interface with method:
  - `generate(commands: CommandDefinition[]): string` - Returns complete shell script
- **AND** each generator handles shell-specific syntax, escaping, and patterns
- **AND** all generators consume the same `CommandDefinition[]` from the command registry

#### Scenario: Shell-specific installers

- **WHEN** implementing completion installers
- **THEN** create installer classes for each shell: `ZshInstaller`, `BashInstaller`, `FishInstaller`, `PowerShellInstaller`
- **AND** implement a common `CompletionInstaller` interface with methods:
  - `install(script: string): Promise<InstallationResult>` - Installs completion script
  - `uninstall(): Promise<{ success: boolean; message: string }>` - Removes completion
- **AND** each installer handles shell-specific paths, config files, and installation patterns

#### Scenario: Factory pattern for shell selection

- **WHEN** selecting shell-specific implementation
- **THEN** use `CompletionFactory` class with static methods:
  - `createGenerator(shell: SupportedShell): CompletionGenerator`
  - `createInstaller(shell: SupportedShell): CompletionInstaller`
- **AND** factory uses switch statements with TypeScript exhaustiveness checking
- **AND** adding new shell requires updating `SupportedShell` type and factory cases

#### Scenario: Dynamic completion providers

- **WHEN** implementing dynamic completions
- **THEN** create a `CompletionProvider` class that encapsulates project discovery logic
- **AND** implement methods:
  - `getChangeIds(): Promise<string[]>` - Discovers active change IDs
  - `getSpecIds(): Promise<string[]>` - Discovers spec IDs
  - `isOpenSpecProject(): boolean` - Checks if current directory is OpenSpec-enabled
- **AND** implement caching with 2-second TTL using class properties

#### Scenario: Command registry

- **WHEN** defining completable commands
- **THEN** create a centralized `CommandDefinition` type with properties:
  - `name: string` - Command name
  - `description: string` - Help text
  - `flags: FlagDefinition[]` - Available flags
  - `acceptsPositional: boolean` - Whether command takes positional arguments
  - `positionalType: string` - Type of positional (change-id, spec-id, path, shell)
  - `subcommands?: CommandDefinition[]` - Nested subcommands
- **AND** export a `COMMAND_REGISTRY` constant with all command definitions
- **AND** all generators consume this registry to ensure consistency across shells

#### Scenario: Type-safe shell detection

- **WHEN** implementing shell detection
- **THEN** define a `SupportedShell` type as literal type: `'zsh' | 'bash' | 'fish' | 'powershell'`
- **AND** implement `detectShell()` function in `src/utils/shell-detection.ts`
- **AND** return detected shell or throw error with supported shells list

### Requirement: Error Handling

The completion command SHALL provide clear error messages for common failure scenarios.

#### Scenario: Unsupported shell

- **WHEN** user requests completion for unsupported shell (e.g., ksh, csh, tcsh)
- **THEN** display error message: "Shell '<name>' is not supported yet. Currently supported: zsh, bash, fish, powershell"
- **AND** exit with code 1

#### Scenario: Permission errors during installation

- **WHEN** installation fails due to file permission issues
- **THEN** display clear error message indicating permission problem
- **AND** suggest using appropriate permissions or alternative installation method
- **AND** exit with code 1

#### Scenario: Missing shell configuration directory

- **WHEN** expected shell configuration directory doesn't exist
- **THEN** create the directory automatically (with user notification)
- **AND** proceed with installation

#### Scenario: Shell not detected

- **WHEN** `openspec completion install` cannot detect current shell
- **THEN** display error: "Could not auto-detect shell. Please specify shell explicitly."
- **AND** display usage hint: "Usage: openspec completion <operation> [shell]"
- **AND** exit with code 1

### Requirement: Output Format

The completion command SHALL provide machine-parseable and human-readable output.

#### Scenario: Script generation output

- **WHEN** generating completion script to stdout
- **THEN** output only the completion script content (no extra messages)
- **AND** allow redirection to files: `openspec completion generate zsh > /path/to/_openspec`

#### Scenario: Installation success output

- **WHEN** installation completes successfully
- **THEN** display formatted success message with:
  - Checkmark indicator
  - Installation location
  - Next steps (shell reload instructions)
- **AND** use colors when terminal supports it (unless `--no-color` is set)

#### Scenario: Verbose installation output

- **WHEN** user provides `--verbose` flag during installation
- **THEN** display detailed steps:
  - Shell detection result
  - Target file paths
  - Configuration modifications
  - File creation confirmations

### Requirement: Testing Support

The completion implementation SHALL be testable with unit and integration tests for all supported shells.

#### Scenario: Mock shell environment

- **WHEN** writing tests for shell detection
- **THEN** allow overriding `$SHELL` and `$PSModulePath` environment variables
- **AND** use dependency injection for file system operations
- **AND** test detection for all four shells independently

#### Scenario: Generator output verification

- **WHEN** testing completion generators
- **THEN** create test suite for each shell generator (zsh, bash, fish, powershell)
- **AND** verify generated scripts contain expected patterns for that shell
- **AND** test that command registry is properly consumed
- **AND** ensure dynamic completion placeholders are present
- **AND** verify shell-specific syntax and escaping

#### Scenario: Installer simulation

- **WHEN** testing installation logic
- **THEN** create test suite for each shell installer
- **AND** use temporary test directories instead of actual home directories
- **AND** verify file creation without modifying real shell configurations
- **AND** test path resolution logic independently
- **AND** mock file system operations to avoid side effects

#### Scenario: Cross-shell consistency

- **WHEN** testing completion behavior
- **THEN** verify all shells support the same commands and flags
- **AND** verify dynamic completions work consistently across shells
- **AND** ensure error messages are consistent across shells




================================================
FILE: openspec/specs/cli-config/spec.md
================================================
# cli-config Specification

## Purpose
Provide a user-friendly CLI interface for viewing and modifying global OpenSpec configuration settings without manually editing JSON files.
## Requirements
### Requirement: Command Structure

The config command SHALL provide subcommands for all configuration operations.

#### Scenario: Available subcommands

- **WHEN** user executes `openspec config --help`
- **THEN** display available subcommands:
  - `path` - Show config file location
  - `list` - Show all current settings
  - `get <key>` - Get a specific value
  - `set <key> <value>` - Set a value
  - `unset <key>` - Remove a key (revert to default)
  - `reset` - Reset configuration to defaults
  - `edit` - Open config in editor

### Requirement: Config Path

The config command SHALL display the config file location.

#### Scenario: Show config path

- **WHEN** user executes `openspec config path`
- **THEN** print the absolute path to the config file
- **AND** exit with code 0

### Requirement: Config List

The config command SHALL display all current configuration values.

#### Scenario: List config in human-readable format

- **WHEN** user executes `openspec config list`
- **THEN** display all config values in YAML-like format
- **AND** show nested objects with indentation

#### Scenario: List config as JSON

- **WHEN** user executes `openspec config list --json`
- **THEN** output the complete config as valid JSON
- **AND** output only JSON (no additional text)

### Requirement: Config Get

The config command SHALL retrieve specific configuration values.

#### Scenario: Get top-level key

- **WHEN** user executes `openspec config get <key>` with a valid top-level key
- **THEN** print the raw value only (no labels or formatting)
- **AND** exit with code 0

#### Scenario: Get nested key with dot notation

- **WHEN** user executes `openspec config get featureFlags.someFlag`
- **THEN** traverse the nested structure using dot notation
- **AND** print the value at that path

#### Scenario: Get non-existent key

- **WHEN** user executes `openspec config get <key>` with a key that does not exist
- **THEN** print nothing (empty output)
- **AND** exit with code 1

#### Scenario: Get object value

- **WHEN** user executes `openspec config get <key>` where the value is an object
- **THEN** print the object as JSON

### Requirement: Config Set

The config command SHALL set configuration values with automatic type coercion.

#### Scenario: Set string value

- **WHEN** user executes `openspec config set <key> <value>`
- **AND** value does not match boolean or number patterns
- **THEN** store value as a string
- **AND** display confirmation message

#### Scenario: Set boolean value

- **WHEN** user executes `openspec config set <key> true` or `openspec config set <key> false`
- **THEN** store value as boolean (not string)
- **AND** display confirmation message

#### Scenario: Set numeric value

- **WHEN** user executes `openspec config set <key> <value>`
- **AND** value is a valid number (integer or float)
- **THEN** store value as number (not string)

#### Scenario: Force string with --string flag

- **WHEN** user executes `openspec config set <key> <value> --string`
- **THEN** store value as string regardless of content
- **AND** this allows storing literal "true" or "123" as strings

#### Scenario: Set nested key

- **WHEN** user executes `openspec config set featureFlags.newFlag true`
- **THEN** create intermediate objects if they don't exist
- **AND** set the value at the nested path

### Requirement: Config Unset

The config command SHALL remove configuration overrides.

#### Scenario: Unset existing key

- **WHEN** user executes `openspec config unset <key>`
- **AND** the key exists in the config
- **THEN** remove the key from the config file
- **AND** the value reverts to its default
- **AND** display confirmation message

#### Scenario: Unset non-existent key

- **WHEN** user executes `openspec config unset <key>`
- **AND** the key does not exist in the config
- **THEN** display message indicating key was not set
- **AND** exit with code 0

### Requirement: Config Reset

The config command SHALL reset configuration to defaults.

#### Scenario: Reset all with confirmation

- **WHEN** user executes `openspec config reset --all`
- **THEN** prompt for confirmation before proceeding
- **AND** if confirmed, delete the config file or reset to defaults
- **AND** display confirmation message

#### Scenario: Reset all with -y flag

- **WHEN** user executes `openspec config reset --all -y`
- **THEN** reset without prompting for confirmation

#### Scenario: Reset without --all flag

- **WHEN** user executes `openspec config reset` without `--all`
- **THEN** display error indicating `--all` is required
- **AND** exit with code 1

### Requirement: Config Edit

The config command SHALL open the config file in the user's editor.

#### Scenario: Open editor successfully

- **WHEN** user executes `openspec config edit`
- **AND** `$EDITOR` or `$VISUAL` environment variable is set
- **THEN** open the config file in that editor
- **AND** create the config file with defaults if it doesn't exist
- **AND** wait for the editor to close before returning

#### Scenario: No editor configured

- **WHEN** user executes `openspec config edit`
- **AND** neither `$EDITOR` nor `$VISUAL` is set
- **THEN** display error message suggesting to set `$EDITOR`
- **AND** exit with code 1

### Requirement: Key Naming Convention

The config command SHALL use camelCase keys matching the JSON structure.

#### Scenario: Keys match JSON structure

- **WHEN** accessing configuration keys via CLI
- **THEN** use camelCase matching the actual JSON property names
- **AND** support dot notation for nested access (e.g., `featureFlags.someFlag`)

### Requirement: Schema Validation

The config command SHALL validate configuration writes against the config schema using zod, while rejecting unknown keys for `config set` unless explicitly overridden.

#### Scenario: Unknown key rejected by default

- **WHEN** user executes `openspec config set someFutureKey 123`
- **THEN** display a descriptive error message indicating the key is invalid
- **AND** do not modify the config file
- **AND** exit with code 1

#### Scenario: Unknown key accepted with override

- **WHEN** user executes `openspec config set someFutureKey 123 --allow-unknown`
- **THEN** the value is saved successfully
- **AND** exit with code 0

#### Scenario: Invalid feature flag value rejected

- **WHEN** user executes `openspec config set featureFlags.someFlag notABoolean`
- **THEN** display a descriptive error message
- **AND** do not modify the config file
- **AND** exit with code 1

### Requirement: Reserved Scope Flag

The config command SHALL reserve the `--scope` flag for future extensibility.

#### Scenario: Scope flag defaults to global

- **WHEN** user executes any config command without `--scope`
- **THEN** operate on global configuration (default behavior)

#### Scenario: Project scope not yet implemented

- **WHEN** user executes `openspec config --scope project <subcommand>`
- **THEN** display error message: "Project-local config is not yet implemented"
- **AND** exit with code 1



================================================
FILE: openspec/specs/cli-init/spec.md
================================================
# CLI Init Specification

## Purpose

The `openspec init` command SHALL create a complete OpenSpec directory structure in any project, enabling immediate adoption of OpenSpec conventions with support for multiple AI coding assistants.
## Requirements
### Requirement: Progress Indicators

The command SHALL display progress indicators during initialization to provide clear feedback about each step.

#### Scenario: Displaying initialization progress

- **WHEN** executing initialization steps
- **THEN** validate environment silently in background (no output unless error)
- **AND** display progress with ora spinners:
  - Show spinner: "â ‹ Creating OpenSpec structure..."
  - Then success: "âœ” OpenSpec structure created"
  - Show spinner: "â ‹ Configuring AI tools..."
  - Then success: "âœ” AI tools configured"

### Requirement: Directory Creation
The command SHALL create the complete OpenSpec directory structure with all required directories and files.

#### Scenario: Creating OpenSpec structure
- **WHEN** `openspec init` is executed
- **THEN** create the following directory structure:
```
openspec/
â”œâ”€â”€ project.md
â”œâ”€â”€ AGENTS.md
â”œâ”€â”€ specs/
â””â”€â”€ changes/
    â””â”€â”€ archive/
```

### Requirement: File Generation
The command SHALL generate required template files with appropriate content for immediate use.

#### Scenario: Generating template files
- **WHEN** initializing OpenSpec
- **THEN** generate `openspec/AGENTS.md` containing complete OpenSpec instructions for AI assistants
- **AND** generate `project.md` with project context template

### Requirement: AI Tool Configuration
The command SHALL configure AI coding assistants with OpenSpec instructions using a grouped selection experience so teams can enable native integrations while always provisioning guidance for other assistants.

#### Scenario: Prompting for AI tool selection
- **WHEN** run interactively
- **THEN** present a multi-select wizard that separates options into two headings:
  - **Natively supported providers** shows each available first-party integration (Claude Code, Cursor, OpenCode, â€¦) with checkboxes
  - **Other tools** explains that the root-level `AGENTS.md` stub is always generated for AGENTS-compatible assistants and cannot be deselected
- **AND** mark already configured native tools with "(already configured)" to signal that choosing them will refresh managed content
- **AND** keep disabled or unavailable providers labelled as "coming soon" so users know they cannot opt in yet
- **AND** allow confirming the selection even when no native provider is chosen because the root stub remains enabled by default
- **AND** change the base prompt copy in extend mode to "Which natively supported AI tools would you like to add or refresh?"

### Requirement: AI Tool Configuration Details

The command SHALL properly configure selected AI tools with OpenSpec-specific instructions using a marker system.

#### Scenario: Configuring Claude Code

- **WHEN** Claude Code is selected
- **THEN** create or update `CLAUDE.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Configuring CodeBuddy Code

- **WHEN** CodeBuddy Code is selected
- **THEN** create or update `CODEBUDDY.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Configuring Cline

- **WHEN** Cline is selected
- **THEN** create or update `CLINE.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Configuring iFlow CLI

- **WHEN** iFlow CLI is selected
- **THEN** create or update `IFLOW.md` in the project root directory (not inside openspec/)
- **AND** populate the managed block with a short stub that points teammates to `@/openspec/AGENTS.md`

#### Scenario: Creating new CLAUDE.md

- **WHEN** CLAUDE.md does not exist
- **THEN** create new file with stub instructions wrapped in markers so the full workflow stays in `openspec/AGENTS.md`:
```markdown
<!-- OPENSPEC:START -->
# OpenSpec Instructions

This project uses OpenSpec to manage AI assistant workflows.

- Full guidance lives in '@/openspec/AGENTS.md'.
- Keep this managed block so 'openspec update' can refresh the instructions.
<!-- OPENSPEC:END -->
```

### Requirement: Interactive Mode
The command SHALL provide an interactive menu for AI tool selection with clear navigation instructions.
#### Scenario: Displaying interactive menu
- **WHEN** run in fresh or extend mode
- **THEN** present a looping select menu that lets users toggle tools with Space and review selections with Enter
- **AND** when Enter is pressed on a highlighted selectable tool that is not already selected, automatically add it to the selection before moving to review so the highlighted tool is configured
- **AND** label already configured tools with "(already configured)" while keeping disabled options marked "coming soon"
- **AND** change the prompt copy in extend mode to "Which AI tools would you like to add or refresh?"
- **AND** display inline instructions clarifying that Space toggles tools and Enter selects the highlighted tool before reviewing selections

### Requirement: Safety Checks
The command SHALL perform safety checks to prevent overwriting existing structures and ensure proper permissions.

#### Scenario: Detecting existing initialization
- **WHEN** the `openspec/` directory already exists
- **THEN** inform the user that OpenSpec is already initialized, skip recreating the base structure, and enter an extend mode
- **AND** continue to the AI tool selection step so additional tools can be configured
- **AND** display the existing-initialization error message only when the user declines to add any AI tools

### Requirement: Success Output

The command SHALL provide clear, actionable next steps upon successful initialization.

#### Scenario: Displaying success message
- **WHEN** initialization completes successfully
- **THEN** include prompt: "Please explain the OpenSpec workflow from openspec/AGENTS.md and how I should work with you on this project"

#### Scenario: Displaying restart instruction
- **WHEN** initialization completes successfully and tools were created or refreshed
- **THEN** display a prominent restart instruction before the "Next steps" section
- **AND** inform users that slash commands are loaded at startup
- **AND** instruct users to restart their coding assistant to ensure /openspec commands appear

### Requirement: Exit Codes

The command SHALL use consistent exit codes to indicate different failure modes.

#### Scenario: Returning exit codes

- **WHEN** the command completes
- **THEN** return appropriate exit code:
  - 0: Success
  - 1: General error (including when OpenSpec directory already exists)
  - 2: Insufficient permissions (reserved for future use)
  - 3: User cancelled operation (reserved for future use)

### Requirement: Additional AI Tool Initialization
`openspec init` SHALL allow users to add configuration files for new AI coding assistants after the initial setup.

#### Scenario: Configuring an extra tool after initial setup
- **GIVEN** an `openspec/` directory already exists and at least one AI tool file is present
- **WHEN** the user runs `openspec init` and selects a different supported AI tool
- **THEN** generate that tool's configuration files with OpenSpec markers the same way as during first-time initialization
- **AND** leave existing tool configuration files unchanged except for managed sections that need refreshing
- **AND** exit with code 0 and display a success summary highlighting the newly added tool files

### Requirement: Success Output Enhancements
`openspec init` SHALL summarize tool actions when initialization or extend mode completes.

#### Scenario: Showing tool summary
- **WHEN** the command completes successfully
- **THEN** display a categorized summary of tools that were created, refreshed, or skipped (including already-configured skips)
- **AND** personalize the "Next steps" header using the names of the selected tools, defaulting to a generic label when none remain

### Requirement: Exit Code Adjustments
`openspec init` SHALL treat extend mode without new native tool selections as a successful refresh.

#### Scenario: Allowing empty extend runs
- **WHEN** OpenSpec is already initialized and the user selects no additional natively supported tools
- **THEN** complete successfully while refreshing the root `AGENTS.md` stub
- **AND** exit with code 0

### Requirement: Slash Command Configuration
The init command SHALL generate slash command files for supported editors using shared templates.

#### Scenario: Generating slash commands for Antigravity
- **WHEN** the user selects Antigravity during initialization
- **THEN** create `.agent/workflows/openspec-proposal.md`, `.agent/workflows/openspec-apply.md`, and `.agent/workflows/openspec-archive.md`
- **AND** ensure each file begins with YAML frontmatter that contains only a `description: <stage summary>` field followed by the shared OpenSpec workflow instructions wrapped in managed markers
- **AND** populate the workflow body with the same proposal/apply/archive guidance used for other tools so Antigravity behaves like Windsurf while pointing to the `.agent/workflows/` directory

#### Scenario: Generating slash commands for Claude Code
- **WHEN** the user selects Claude Code during initialization
- **THEN** create `.claude/commands/openspec/proposal.md`, `.claude/commands/openspec/apply.md`, and `.claude/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for CodeBuddy Code
- **WHEN** the user selects CodeBuddy Code during initialization
- **THEN** create `.codebuddy/commands/openspec/proposal.md`, `.codebuddy/commands/openspec/apply.md`, and `.codebuddy/commands/openspec/archive.md`
- **AND** populate each file from shared templates that include CodeBuddy-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** use square bracket format for `argument-hint` parameters (e.g., `[change-id]`)
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cline
- **WHEN** the user selects Cline during initialization
- **THEN** create `.clinerules/workflows/openspec-proposal.md`, `.clinerules/workflows/openspec-apply.md`, and `.clinerules/workflows/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Crush
- **WHEN** the user selects Crush during initialization
- **THEN** create `.crush/commands/openspec/proposal.md`, `.crush/commands/openspec/apply.md`, and `.crush/commands/openspec/archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Cursor
- **WHEN** the user selects Cursor during initialization
- **THEN** create `.cursor/commands/openspec-proposal.md`, `.cursor/commands/openspec-apply.md`, and `.cursor/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Continue
- **WHEN** the user selects Continue during initialization
- **THEN** create `.continue/prompts/openspec-proposal.prompt`, `.continue/prompts/openspec-apply.prompt`, and `.continue/prompts/openspec-archive.prompt`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Factory Droid
- **WHEN** the user selects Factory Droid during initialization
- **THEN** create `.factory/commands/openspec-proposal.md`, `.factory/commands/openspec-apply.md`, and `.factory/commands/openspec-archive.md`
- **AND** populate each file from shared templates that include Factory-compatible YAML frontmatter for the `description` and `argument-hint` fields
- **AND** include the `$ARGUMENTS` placeholder in the template body so droid receives any user-supplied input
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands

#### Scenario: Generating slash commands for OpenCode
- **WHEN** the user selects OpenCode during initialization
- **THEN** create `.opencode/commands/openspec-proposal.md`, `.opencode/commands/openspec-apply.md`, and `.opencode/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Windsurf
- **WHEN** the user selects Windsurf during initialization
- **THEN** create `.windsurf/workflows/openspec-proposal.md`, `.windsurf/workflows/openspec-apply.md`, and `.windsurf/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Kilo Code
- **WHEN** the user selects Kilo Code during initialization
- **THEN** create `.kilocode/workflows/openspec-proposal.md`, `.kilocode/workflows/openspec-apply.md`, and `.kilocode/workflows/openspec-archive.md`
- **AND** populate each file from shared templates (wrapped in OpenSpec markers) so workflow text matches other tools
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Codex
- **WHEN** the user selects Codex during initialization
- **THEN** create global prompt files at `~/.codex/prompts/openspec-proposal.md`, `~/.codex/prompts/openspec-apply.md`, and `~/.codex/prompts/openspec-archive.md` (or under `$CODEX_HOME/prompts` if set)
- **AND** populate each file from shared templates that map the first numbered placeholder (`$1`) to the primary user input (e.g., change identifier or question text)
- **AND** wrap the generated content in OpenSpec markers so `openspec update` can refresh the prompts without touching surrounding custom notes

#### Scenario: Generating slash commands for GitHub Copilot
- **WHEN** the user selects GitHub Copilot during initialization
- **THEN** create `.github/prompts/openspec-proposal.prompt.md`, `.github/prompts/openspec-apply.prompt.md`, and `.github/prompts/openspec-archive.prompt.md`
- **AND** populate each file with YAML frontmatter containing a `description` field that summarizes the workflow stage
- **AND** include `$ARGUMENTS` placeholder to capture user input
- **AND** wrap the shared template body with OpenSpec markers so `openspec update` can refresh the content
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for Gemini CLI
- **WHEN** the user selects Gemini CLI during initialization
- **THEN** create `.gemini/commands/openspec/proposal.toml`, `.gemini/commands/openspec/apply.toml`, and `.gemini/commands/openspec/archive.toml`
- **AND** populate each file as TOML that sets a stage-specific `description = "<summary>"` and a multi-line `prompt = """` block with the shared OpenSpec template
- **AND** wrap the OpenSpec managed markers (`<!-- OPENSPEC:START -->` / `<!-- OPENSPEC:END -->`) inside the `prompt` value so `openspec update` can safely refresh the body between markers without touching the TOML framing
- **AND** ensure the slash-command copy matches the existing proposal/apply/archive templates used by other tools

#### Scenario: Generating slash commands for iFlow CLI
- **WHEN** the user selects iFlow CLI during initialization
- **THEN** create `.iflow/commands/openspec-proposal.md`, `.iflow/commands/openspec-apply.md`, and `.iflow/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include YAML frontmatter with `name`, `id`, `category`, and `description` fields for each command
- **AND** wrap the generated content in OpenSpec managed markers so `openspec update` can safely refresh the commands
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

#### Scenario: Generating slash commands for RooCode
- **WHEN** the user selects RooCode during initialization
- **THEN** create `.roo/commands/openspec-proposal.md`, `.roo/commands/openspec-apply.md`, and `.roo/commands/openspec-archive.md`
- **AND** populate each file from shared templates so command text matches other tools
- **AND** include simple Markdown headings (e.g., `# OpenSpec: Proposal`) without YAML frontmatter
- **AND** wrap the generated content in OpenSpec managed markers where applicable so `openspec update` can safely refresh the commands
- **AND** each template includes instructions for the relevant OpenSpec workflow stage

### Requirement: Non-Interactive Mode
The command SHALL support non-interactive operation through command-line options for automation and CI/CD use cases.

#### Scenario: Select all tools non-interactively
- **WHEN** run with `--tools all`
- **THEN** automatically select every available AI tool without prompting
- **AND** proceed with initialization using the selected tools

#### Scenario: Select specific tools non-interactively
- **WHEN** run with `--tools claude,cursor`
- **THEN** parse the comma-separated tool IDs and validate against available tools
- **AND** proceed with initialization using only the specified valid tools

#### Scenario: Skip tool configuration non-interactively
- **WHEN** run with `--tools none`
- **THEN** skip AI tool configuration entirely
- **AND** only create the OpenSpec directory structure and template files

#### Scenario: Invalid tool specification
- **WHEN** run with `--tools` containing any IDs not present in the AI tool registry
- **THEN** exit with code 1 and display available values (`all`, `none`, or the supported tool IDs)

#### Scenario: Help text lists available tool IDs
- **WHEN** displaying CLI help for `openspec init`
- **THEN** show the `--tools` option description with the valid values derived from the AI tool registry

### Requirement: Root instruction stub
`openspec init` SHALL always scaffold the root-level `AGENTS.md` hand-off so every teammate finds the primary OpenSpec instructions.

#### Scenario: Creating root `AGENTS.md`
- **GIVEN** the project may or may not already contain an `AGENTS.md` file
- **WHEN** initialization completes in fresh or extend mode
- **THEN** create or refresh `AGENTS.md` at the repository root using the managed marker block from `TemplateManager.getAgentsStandardTemplate()`
- **AND** preserve any existing content outside the managed markers while replacing the stub text inside them
- **AND** create the stub regardless of which native AI tools are selected

## Why

Manual creation of OpenSpec structure is error-prone and creates adoption friction. A standardized init command ensures:
- Consistent structure across all projects
- Proper AI instruction files are always included
- Quick onboarding for new projects
- Clear conventions from the start



================================================
FILE: openspec/specs/cli-list/spec.md
================================================
# List Command Specification

## Purpose

The `openspec list` command SHALL provide developers with a quick overview of all active changes in the project, showing their names and task completion status.
## Requirements
### Requirement: Command Execution
The command SHALL scan and analyze either active changes or specs based on the selected mode.

#### Scenario: Scanning for changes (default)
- **WHEN** `openspec list` is executed without flags
- **THEN** scan the `openspec/changes/` directory for change directories
- **AND** exclude the `archive/` subdirectory from results
- **AND** parse each change's `tasks.md` file to count task completion

#### Scenario: Scanning for specs
- **WHEN** `openspec list --specs` is executed
- **THEN** scan the `openspec/specs/` directory for capabilities
- **AND** read each capability's `spec.md`
- **AND** parse requirements to compute requirement counts

### Requirement: Task Counting

The command SHALL accurately count task completion status using standard markdown checkbox patterns.

#### Scenario: Counting tasks in tasks.md

- **WHEN** parsing a `tasks.md` file
- **THEN** count tasks matching these patterns:
  - Completed: Lines containing `- [x]`
  - Incomplete: Lines containing `- [ ]`
- **AND** calculate total tasks as the sum of completed and incomplete

### Requirement: Output Format
The command SHALL display items in a clear, readable table format with mode-appropriate progress or counts.

#### Scenario: Displaying change list (default)
- **WHEN** displaying the list of changes
- **THEN** show a table with columns:
  - Change name (directory name)
  - Task progress (e.g., "3/5 tasks" or "âœ“ Complete")

#### Scenario: Displaying spec list
- **WHEN** displaying the list of specs
- **THEN** show a table with columns:
  - Spec id (directory name)
  - Requirement count (e.g., "requirements 12")

### Requirement: Flags
The command SHALL accept flags to select the noun being listed.

#### Scenario: Selecting specs
- **WHEN** `--specs` is provided
- **THEN** list specs instead of changes

#### Scenario: Selecting changes
- **WHEN** `--changes` is provided
- **THEN** list changes explicitly (same as default behavior)

### Requirement: Empty State
The command SHALL provide clear feedback when no items are present for the selected mode.

#### Scenario: Handling empty state (changes)
- **WHEN** no active changes exist (only archive/ or empty changes/)
- **THEN** display: "No active changes found."

#### Scenario: Handling empty state (specs)
- **WHEN** no specs directory exists or contains no capabilities
- **THEN** display: "No specs found."

### Requirement: Error Handling

The command SHALL gracefully handle missing files and directories with appropriate messages.

#### Scenario: Missing tasks.md file

- **WHEN** a change directory has no `tasks.md` file
- **THEN** display the change with "No tasks" status

#### Scenario: Missing changes directory

- **WHEN** `openspec/changes/` directory doesn't exist
- **THEN** display error: "No OpenSpec changes directory found. Run 'openspec init' first."
- **AND** exit with code 1

### Requirement: Sorting

The command SHALL maintain consistent ordering of changes for predictable output.

#### Scenario: Ordering changes

- **WHEN** displaying multiple changes
- **THEN** sort them in alphabetical order by change name

## Why

Developers need a quick way to:
- See what changes are in progress
- Identify which changes are ready to archive
- Understand the overall project evolution status
- Get a bird's-eye view without opening multiple files

This command provides that visibility with minimal effort, following OpenSpec's philosophy of simplicity and clarity.


================================================
FILE: openspec/specs/cli-show/spec.md
================================================
# cli-show Specification

## Purpose
TBD - created by archiving change add-interactive-show-command. Update Purpose after archive.
## Requirements
### Requirement: Top-level show command

The CLI SHALL provide a top-level `show` command for displaying changes and specs with intelligent selection.

#### Scenario: Interactive show selection

- **WHEN** executing `openspec show` without arguments
- **THEN** prompt user to select type (change or spec)
- **AND** display list of available items for selected type
- **AND** show the selected item's content

#### Scenario: Non-interactive environments do not prompt

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec show` without arguments
- **THEN** do not prompt
- **AND** print a helpful hint with examples for `openspec show <item>` or `openspec change/spec show`
- **AND** exit with code 1

#### Scenario: Direct item display

- **WHEN** executing `openspec show <item-name>`
- **THEN** automatically detect if item is a change or spec
- **AND** display the item's content
- **AND** use appropriate formatting based on item type

#### Scenario: Type detection and ambiguity handling

- **WHEN** executing `openspec show <item-name>`
- **THEN** if `<item-name>` uniquely matches a change or a spec, show that item
- **AND** if it matches both, print an ambiguity error and suggest `--type change|spec` or using `openspec change show`/`openspec spec show`
- **AND** if it matches neither, print not-found with nearest-match suggestions

#### Scenario: Explicit type override

- **WHEN** executing `openspec show --type change <item>`
- **THEN** treat `<item>` as a change ID and show it (skipping auto-detection)

- **WHEN** executing `openspec show --type spec <item>`
- **THEN** treat `<item>` as a spec ID and show it (skipping auto-detection)

### Requirement: Output format options

The show command SHALL support various output formats consistent with existing commands.

#### Scenario: JSON output

- **WHEN** executing `openspec show <item> --json`
- **THEN** output the item in JSON format
- **AND** include parsed metadata and structure
- **AND** maintain format consistency with existing change/spec show commands

#### Scenario: Flag scoping and delegation

- **WHEN** showing a change or a spec via the top-level command
- **THEN** accept common flags such as `--json`
- **AND** pass through type-specific flags to the corresponding implementation
  - Change-only flags: `--deltas-only` (alias `--requirements-only` deprecated)
  - Spec-only flags: `--requirements`, `--no-scenarios`, `-r/--requirement`
- **AND** ignore irrelevant flags for the detected type with a warning

### Requirement: Interactivity controls

- The CLI SHALL respect `--no-interactive` to disable prompts.
- The CLI SHALL respect `OPEN_SPEC_INTERACTIVE=0` to disable prompts globally.
- Interactive prompts SHALL only be shown when stdin is a TTY and interactivity is not disabled.

#### Scenario: Change-specific options

- **WHEN** showing a change with `openspec show <change-name> --deltas-only`
- **THEN** display only the deltas in JSON format
- **AND** maintain compatibility with existing change show options

#### Scenario: Spec-specific options  

- **WHEN** showing a spec with `openspec show <spec-id> --requirements`
- **THEN** display only requirements in JSON format
- **AND** support other spec options (--no-scenarios, -r)
- **AND** maintain compatibility with existing spec show options




================================================
FILE: openspec/specs/cli-spec/spec.md
================================================
# cli-spec Specification

## Purpose
TBD - created by archiving change add-interactive-show-command. Update Purpose after archive.
## Requirements
### Requirement: Interactive spec show

The spec show command SHALL support interactive selection when no spec-id is provided.

#### Scenario: Interactive spec selection for show

- **WHEN** executing `openspec spec show` without arguments
- **THEN** display an interactive list of available specs
- **AND** allow the user to select a spec to show
- **AND** display the selected spec content
- **AND** maintain all existing show options (--json, --requirements, --no-scenarios, -r)

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec spec show` without a spec-id
- **THEN** do not prompt interactively
- **AND** print the existing error message for missing spec-id
- **AND** set non-zero exit code

### Requirement: Spec Command

The system SHALL provide a `spec` command with subcommands for displaying, listing, and validating specifications.

#### Scenario: Show spec as JSON

- **WHEN** executing `openspec spec show init --json`
- **THEN** parse the markdown spec file
- **AND** extract headings and content hierarchically
- **AND** output valid JSON to stdout

#### Scenario: List all specs

- **WHEN** executing `openspec spec list`
- **THEN** scan the openspec/specs directory
- **AND** return list of all available capabilities
- **AND** support JSON output with `--json` flag

#### Scenario: Filter spec content

- **WHEN** executing `openspec spec show init --requirements`
- **THEN** display only requirement names and SHALL statements
- **AND** exclude scenario content

#### Scenario: Validate spec structure

- **WHEN** executing `openspec spec validate init`
- **THEN** parse the spec file
- **AND** validate against Zod schema
- **AND** report any structural issues

### Requirement: JSON Schema Definition

The system SHALL define Zod schemas that accurately represent the spec structure for runtime validation.

#### Scenario: Schema validation

- **WHEN** parsing a spec into JSON
- **THEN** validate the structure using Zod schemas
- **AND** ensure all required fields are present
- **AND** provide clear error messages for validation failures

### Requirement: Interactive spec validation

The spec validate command SHALL support interactive selection when no spec-id is provided.

#### Scenario: Interactive spec selection for validation

- **WHEN** executing `openspec spec validate` without arguments
- **THEN** display an interactive list of available specs
- **AND** allow the user to select a spec to validate
- **AND** validate the selected spec
- **AND** maintain all existing validation options (--strict, --json)

#### Scenario: Non-interactive fallback keeps current behavior

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec spec validate` without a spec-id
- **THEN** do not prompt interactively
- **AND** print the existing error message for missing spec-id
- **AND** set non-zero exit code




================================================
FILE: openspec/specs/cli-update/spec.md
================================================
# Update Command Specification

## Purpose

As a developer using OpenSpec, I want to update the OpenSpec instructions in my project when new versions are released, so that I can benefit from improvements to AI agent instructions.
## Requirements
### Requirement: Update Behavior
The update command SHALL update OpenSpec instruction files to the latest templates in a team-friendly manner.

#### Scenario: Running update command
- **WHEN** a user runs `openspec update`
- **THEN** replace `openspec/AGENTS.md` with the latest template
- **AND** if a root-level stub (`AGENTS.md`/`CLAUDE.md`) exists, refresh it so it points to `@/openspec/AGENTS.md`

### Requirement: Prerequisites

The command SHALL require an existing OpenSpec structure before allowing updates.

#### Scenario: Checking prerequisites

- **GIVEN** the command requires an existing `openspec` directory (created by `openspec init`)
- **WHEN** the `openspec` directory does not exist
- **THEN** display error: "No OpenSpec directory found. Run 'openspec init' first."
- **AND** exit with code 1

### Requirement: File Handling
The update command SHALL handle file updates in a predictable and safe manner.

#### Scenario: Updating files
- **WHEN** updating files
- **THEN** completely replace `openspec/AGENTS.md` with the latest template
- **AND** if a root-level stub exists, update the managed block content so it keeps directing teammates to `@/openspec/AGENTS.md`

### Requirement: Tool-Agnostic Updates
The update command SHALL refresh OpenSpec-managed files in a predictable manner while respecting each team's chosen tooling.

#### Scenario: Updating files
- **WHEN** updating files
- **THEN** completely replace `openspec/AGENTS.md` with the latest template
- **AND** create or refresh the root-level `AGENTS.md` stub using the managed marker block, even if the file was previously absent
- **AND** update only the OpenSpec-managed sections inside existing AI tool files, leaving user-authored content untouched
- **AND** avoid creating new native-tool configuration files (slash commands, CLAUDE.md, etc.) unless they already exist

### Requirement: Core Files Always Updated
The update command SHALL always update the core OpenSpec files and display an ASCII-safe success message.

#### Scenario: Successful update
- **WHEN** the update completes successfully
- **THEN** replace `openspec/AGENTS.md` with the latest template
- **AND** if a root-level stub exists, refresh it so it still directs contributors to `@/openspec/AGENTS.md`

### Requirement: Slash Command Updates

The update command SHALL refresh existing slash command files for configured tools without creating new ones, and ensure the OpenCode archive command accepts change ID arguments.

#### Scenario: Updating slash commands for Antigravity
- **WHEN** `.agent/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh the OpenSpec-managed portion of each file so the workflow copy matches other tools while preserving the existing single-field `description` frontmatter
- **AND** skip creating any missing workflow files during update, mirroring the behavior for Windsurf and other IDEs

#### Scenario: Updating slash commands for Claude Code
- **WHEN** `.claude/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for CodeBuddy Code
- **WHEN** `.codebuddy/commands/openspec/` contains `proposal.md`, `apply.md`, and `archive.md`
- **THEN** refresh each file using the shared CodeBuddy templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** use square bracket format for `argument-hint` parameters (e.g., `[change-id]`)
- **AND** preserve any user customizations outside the OpenSpec managed markers

#### Scenario: Updating slash commands for Cline
- **WHEN** `.clinerules/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Cline-specific Markdown heading frontmatter
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Continue
- **WHEN** `.continue/prompts/` contains `openspec-proposal.prompt`, `openspec-apply.prompt`, and `openspec-archive.prompt`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Crush
- **WHEN** `.crush/commands/` contains `openspec/proposal.md`, `openspec/apply.md`, and `openspec/archive.md`
- **THEN** refresh each file using shared templates
- **AND** include Crush-specific frontmatter with OpenSpec category and tags
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Cursor
- **WHEN** `.cursor/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Factory Droid
- **WHEN** `.factory/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using the shared Factory templates that include YAML frontmatter for the `description` and `argument-hint` fields
- **AND** ensure the template body retains the `$ARGUMENTS` placeholder so user input keeps flowing into droid
- **AND** update only the content inside the OpenSpec managed markers, leaving any unmanaged notes untouched
- **AND** skip creating missing files during update

#### Scenario: Updating slash commands for OpenCode
- **WHEN** `.opencode/command/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** ensure the archive command includes `$ARGUMENTS` placeholder in frontmatter for accepting change ID arguments

#### Scenario: Updating slash commands for Windsurf
- **WHEN** `.windsurf/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Kilo Code
- **WHEN** `.kilocode/workflows/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates wrapped in OpenSpec markers
- **AND** ensure templates include instructions for the relevant workflow stage
- **AND** skip creating missing files (the update command only refreshes what already exists)

#### Scenario: Updating slash commands for Codex
- **GIVEN** the global Codex prompt directory contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **WHEN** a user runs `openspec update`
- **THEN** refresh each file using the shared slash-command templates (including placeholder guidance)
- **AND** preserve any unmanaged content outside the OpenSpec marker block
- **AND** skip creation when a Codex prompt file is missing

#### Scenario: Updating slash commands for GitHub Copilot
- **WHEN** `.github/prompts/` contains `openspec-proposal.prompt.md`, `openspec-apply.prompt.md`, and `openspec-archive.prompt.md`
- **THEN** refresh each file using shared templates while preserving the YAML frontmatter
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Updating slash commands for Gemini CLI
- **WHEN** `.gemini/commands/openspec/` contains `proposal.toml`, `apply.toml`, and `archive.toml`
- **THEN** refresh the body of each file using the shared proposal/apply/archive templates
- **AND** replace only the content between `<!-- OPENSPEC:START -->` and `<!-- OPENSPEC:END -->` markers inside the `prompt = """` block so the TOML framing (`description`, `prompt`) stays intact
- **AND** skip creating any missing `.toml` files during update; only pre-existing Gemini commands are refreshed

#### Scenario: Updating slash commands for iFlow CLI
- **WHEN** `.iflow/commands/` contains `openspec-proposal.md`, `openspec-apply.md`, and `openspec-archive.md`
- **THEN** refresh each file using shared templates
- **AND** preserve the YAML frontmatter with `name`, `id`, `category`, and `description` fields
- **AND** update only the OpenSpec-managed block between markers
- **AND** ensure templates include instructions for the relevant workflow stage

#### Scenario: Missing slash command file
- **WHEN** a tool lacks a slash command file
- **THEN** do not create a new file during update

### Requirement: Archive Command Argument Support
The archive slash command template SHALL support optional change ID arguments for tools that support `$ARGUMENTS` placeholder.

#### Scenario: Archive command with change ID argument
- **WHEN** a user invokes `/openspec:archive <change-id>` with a change ID
- **THEN** the template SHALL instruct the AI to validate the provided change ID against `openspec list`
- **AND** use the provided change ID for archiving if valid
- **AND** fail fast if the provided change ID doesn't match an archivable change

#### Scenario: Archive command without argument (backward compatibility)
- **WHEN** a user invokes `/openspec:archive` without providing a change ID
- **THEN** the template SHALL instruct the AI to identify the change ID from context or by running `openspec list`
- **AND** proceed with the existing behavior (maintaining backward compatibility)

#### Scenario: OpenCode archive template generation
- **WHEN** generating the OpenCode archive slash command file
- **THEN** include the `$ARGUMENTS` placeholder in the frontmatter
- **AND** wrap it in a clear structure like `<ChangeId>\n  $ARGUMENTS\n</ChangeId>` to indicate the expected argument
- **AND** include validation steps in the template body to check if the change ID is valid

## Edge Cases

### Requirement: Error Handling

The command SHALL handle edge cases gracefully.

#### Scenario: File permission errors

- **WHEN** file write fails
- **THEN** let the error bubble up naturally with file path

#### Scenario: Missing AI tool files

- **WHEN** an AI tool configuration file doesn't exist
- **THEN** skip updating that file
- **AND** do not create it

#### Scenario: Custom directory names

- **WHEN** considering custom directory names
- **THEN** not supported in this change
- **AND** the default directory name `openspec` SHALL be used

## Success Criteria

Users SHALL be able to:
- Update OpenSpec instructions with a single command
- Get the latest AI agent instructions
- See clear confirmation of the update

The update process SHALL be:
- Simple and fast (no version checking)
- Predictable (same result every time)
- Self-contained (no network required)



================================================
FILE: openspec/specs/cli-validate/spec.md
================================================
# cli-validate Specification

## Purpose
TBD - created by archiving change improve-validate-error-messages. Update Purpose after archive.
## Requirements
### Requirement: Validation SHALL provide actionable remediation steps
Validation output SHALL include specific guidance to fix each error, including expected structure, example headers, and suggested commands to verify fixes.

#### Scenario: No deltas found in change
- **WHEN** validating a change with zero parsed deltas
- **THEN** show error "No deltas found" with guidance:
  - Explain that change specs must include `## ADDED Requirements`, `## MODIFIED Requirements`, `## REMOVED Requirements`, or `## RENAMED Requirements`
  - Remind authors that files must live under `openspec/changes/{id}/specs/<capability>/spec.md`
  - Include an explicit note: "Spec delta files cannot start with titles before the operation headers"
  - Suggest running `openspec change show {id} --json --deltas-only` for debugging

#### Scenario: Missing required sections
- **WHEN** a required section is missing
- **THEN** include expected header names and a minimal skeleton:
  - For Spec: `## Purpose`, `## Requirements`
  - For Change: `## Why`, `## What Changes`
  - Provide an example snippet of the missing section with placeholder prose ready to copy
  - Mention the quick-reference section in `openspec/AGENTS.md` as the authoritative template

#### Scenario: Missing requirement descriptive text
- **WHEN** a requirement header lacks descriptive text before scenarios
- **THEN** emit an error explaining that `### Requirement:` lines must be followed by narrative text before any `#### Scenario:` headers
  - Show compliant example: "### Requirement: Foo" followed by "The system SHALL ..."
  - Suggest adding 1-2 sentences describing the normative behavior prior to listing scenarios
  - Reference the pre-validation checklist in `openspec/AGENTS.md`

### Requirement: Validator SHALL detect likely misformatted scenarios and warn with a fix
The validator SHALL recognize bulleted lines that look like scenarios (e.g., lines beginning with WHEN/THEN/AND) and emit a targeted warning with a conversion example to `#### Scenario:`.

#### Scenario: Bulleted WHEN/THEN under a Requirement
- **WHEN** bullets that start with WHEN/THEN/AND are found under a requirement without any `#### Scenario:` headers
- **THEN** emit warning: "Scenarios must use '#### Scenario:' headers", and show a conversion template:
```
#### Scenario: Short name
- **WHEN** ...
- **THEN** ...
- **AND** ...
```

### Requirement: All issues SHALL include file paths and structured locations
Error, warning, and info messages SHALL include:
- Source file path (`openspec/changes/{id}/proposal.md`, `.../specs/{cap}/spec.md`)
- Structured path (e.g., `deltas[0].requirements[0].scenarios`)

#### Scenario: Zod validation error
- **WHEN** a schema validation fails
- **THEN** the message SHALL include `file`, `path`, and a remediation hint if applicable

### Requirement: Invalid results SHALL include a Next steps footer in human-readable output
The CLI SHALL append a Next steps footer when the item is invalid and not using `--json`, including:
- Summary line with counts
- Top-3 guidance bullets (contextual to the most frequent or blocking errors)
- A suggestion to re-run with `--json` and/or the debug command

#### Scenario: Change invalid summary
- **WHEN** a change validation fails
- **THEN** print "Next steps" with 2-3 targeted bullets and suggest `openspec change show <id> --json --deltas-only`

### Requirement: Top-level validate command

The CLI SHALL provide a top-level `validate` command for validating changes and specs with flexible selection options.

#### Scenario: Interactive validation selection

- **WHEN** executing `openspec validate` without arguments
- **THEN** prompt user to select what to validate (all, changes, specs, or specific item)
- **AND** perform validation based on selection
- **AND** display results with appropriate formatting

#### Scenario: Non-interactive environments do not prompt

- **GIVEN** stdin is not a TTY or `--no-interactive` is provided or environment variable `OPEN_SPEC_INTERACTIVE=0`
- **WHEN** executing `openspec validate` without arguments
- **THEN** do not prompt interactively
- **AND** print a helpful hint listing available commands/flags and exit with code 1

#### Scenario: Direct item validation

- **WHEN** executing `openspec validate <item-name>`
- **THEN** automatically detect if item is a change or spec
- **AND** validate the specified item
- **AND** display validation results

### Requirement: Bulk and filtered validation

The validate command SHALL support flags for bulk validation (--all) and filtered validation by type (--changes, --specs).

#### Scenario: Validate everything

- **WHEN** executing `openspec validate --all`
- **THEN** validate all changes in openspec/changes/ (excluding archive)
- **AND** validate all specs in openspec/specs/
- **AND** display a summary showing passed/failed items
- **AND** exit with code 1 if any validation fails

#### Scenario: Scope of bulk validation

- **WHEN** validating with `--all` or `--changes`
- **THEN** include all change proposals under `openspec/changes/`
- **AND** exclude the `openspec/changes/archive/` directory

- **WHEN** validating with `--specs`
- **THEN** include all specs that have a `spec.md` under `openspec/specs/<id>/spec.md`

#### Scenario: Validate all changes

- **WHEN** executing `openspec validate --changes`
- **THEN** validate all changes in openspec/changes/ (excluding archive)
- **AND** display results for each change
- **AND** show summary statistics

#### Scenario: Validate all specs

- **WHEN** executing `openspec validate --specs`
- **THEN** validate all specs in openspec/specs/
- **AND** display results for each spec
- **AND** show summary statistics

### Requirement: Validation options and progress indication

The validate command SHALL support standard validation options (--strict, --json) and display progress during bulk operations.

#### Scenario: Strict validation

- **WHEN** executing `openspec validate --all --strict`
- **THEN** apply strict validation to all items
- **AND** treat warnings as errors
- **AND** fail if any item has warnings or errors

#### Scenario: JSON output

- **WHEN** executing `openspec validate --all --json`
- **THEN** output validation results as JSON
- **AND** include detailed issues for each item
- **AND** include summary statistics

#### Scenario: JSON output schema for bulk validation

- **WHEN** executing `openspec validate --all --json` (or `--changes` / `--specs`)
- **THEN** output a JSON object with the following shape:
  - `items`: Array of objects with fields `{ id: string, type: "change"|"spec", valid: boolean, issues: Issue[], durationMs: number }`
  - `summary`: Object `{ totals: { items: number, passed: number, failed: number }, byType: { change?: { items: number, passed: number, failed: number }, spec?: { items: number, passed: number, failed: number } } }`
  - `version`: String identifier for the schema (e.g., `"1.0"`)
- **AND** exit with code 1 if any `items[].valid === false`

Where `Issue` follows the existing per-item validation report shape `{ level: "ERROR"|"WARNING"|"INFO", path: string, message: string }`.

#### Scenario: Show validation progress

- **WHEN** validating multiple items (--all, --changes, or --specs)
- **THEN** show progress indicator or status updates
- **AND** indicate which item is currently being validated
- **AND** display running count of passed/failed items

#### Scenario: Concurrency limits for performance

- **WHEN** validating multiple items
- **THEN** run validations with a bounded concurrency (e.g., 4â€“8 in parallel)
- **AND** ensure progress indicators remain responsive

### Requirement: Item type detection and ambiguity handling

The validate command SHALL handle ambiguous names and explicit type overrides to ensure clear, deterministic behavior.

#### Scenario: Direct item validation with automatic type detection

- **WHEN** executing `openspec validate <item-name>`
- **THEN** if `<item-name>` uniquely matches a change or a spec, validate that item

#### Scenario: Ambiguity between change and spec names

- **GIVEN** `<item-name>` exists both as a change and as a spec
- **WHEN** executing `openspec validate <item-name>`
- **THEN** print an ambiguity error explaining both matches
- **AND** suggest passing `--type change` or `--type spec`, or using `openspec change validate` / `openspec spec validate`
- **AND** exit with code 1 without performing validation

#### Scenario: Unknown item name

- **WHEN** the `<item-name>` matches neither a change nor a spec
- **THEN** print a not-found error
- **AND** show nearest-match suggestions when available
- **AND** exit with code 1

#### Scenario: Explicit type override

- **WHEN** executing `openspec validate --type change <item>`
- **THEN** treat `<item>` as a change ID and validate it (skipping auto-detection)

- **WHEN** executing `openspec validate --type spec <item>`
- **THEN** treat `<item>` as a spec ID and validate it (skipping auto-detection)

### Requirement: Interactivity controls

- The CLI SHALL respect `--no-interactive` to disable prompts.
- The CLI SHALL respect `OPEN_SPEC_INTERACTIVE=0` to disable prompts globally.
- Interactive prompts SHALL only be shown when stdin is a TTY and interactivity is not disabled.

#### Scenario: Disabling prompts via flags or environment

- **WHEN** `openspec validate` is executed with `--no-interactive` or with environment `OPEN_SPEC_INTERACTIVE=0`
- **THEN** the CLI SHALL not display interactive prompts
- **AND** SHALL print non-interactive hints or chosen outputs as appropriate

### Requirement: Parser SHALL handle cross-platform line endings
The markdown parser SHALL correctly identify sections regardless of line ending format (LF, CRLF, CR).

#### Scenario: Required sections parsed with CRLF line endings
- **GIVEN** a change proposal markdown saved with CRLF line endings
- **AND** the document contains `## Why` and `## What Changes`
- **WHEN** running `openspec validate <change-id>`
- **THEN** validation SHALL recognize the sections and NOT raise parsing errors




================================================
FILE: openspec/specs/cli-view/spec.md
================================================
# cli-view Specification

## Purpose

The `openspec view` command provides a comprehensive dashboard view of the OpenSpec project state, displaying specifications, changes, and progress metrics in a unified, visually appealing format to help developers quickly understand project status.
## Requirements
### Requirement: Dashboard Display

The system SHALL provide a `view` command that displays a dashboard overview of specs and changes.

#### Scenario: Basic dashboard display

- **WHEN** user runs `openspec view`
- **THEN** system displays a formatted dashboard with sections for summary, active changes, completed changes, and specifications

#### Scenario: No OpenSpec directory

- **WHEN** user runs `openspec view` in a directory without OpenSpec
- **THEN** system displays error message "âœ— No openspec directory found"

### Requirement: Summary Section

The dashboard SHALL display a summary section with key project metrics, including draft change count.

#### Scenario: Complete summary display

- **WHEN** dashboard is rendered with specs and changes
- **THEN** system shows total number of specifications and requirements
- **AND** shows number of draft changes
- **AND** shows number of active changes in progress
- **AND** shows number of completed changes
- **AND** shows overall task progress percentage

#### Scenario: Empty project summary

- **WHEN** no specs or changes exist
- **THEN** summary shows zero counts for all metrics

### Requirement: Active Changes Display
The dashboard SHALL show active changes with visual progress indicators.

#### Scenario: Active changes ordered by completion percentage
- **WHEN** multiple active changes are displayed with progress information
- **THEN** list them sorted by completion percentage ascending so 0% items appear first
- **AND** treat missing progress values as 0% for ordering
- **AND** break ties by change identifier in ascending alphabetical order to keep output deterministic

### Requirement: Completed Changes Display

The dashboard SHALL list completed changes in a separate section, only showing changes with ALL tasks completed.

> **Fixes bug**: Previously, changes with `total === 0` were incorrectly shown as completed.

#### Scenario: Completed changes listing

- **WHEN** there are changes with `tasks.total > 0` AND `tasks.completed === tasks.total`
- **THEN** system shows them with checkmark indicators in a dedicated section

#### Scenario: Mixed completion states

- **WHEN** some changes are complete and others active
- **THEN** system separates them into appropriate sections

#### Scenario: Empty changes not completed

- **WHEN** a change has no tasks.md or zero tasks defined
- **THEN** system does NOT show it in "Completed Changes" section
- **AND** shows it in "Draft Changes" section instead

### Requirement: Specifications Display

The dashboard SHALL display specifications sorted by requirement count.

#### Scenario: Specs listing with counts

- **WHEN** specifications exist in the project
- **THEN** system shows specs sorted by requirement count (descending) with count labels

#### Scenario: Specs with parsing errors

- **WHEN** a spec file cannot be parsed
- **THEN** system includes it with 0 requirement count

### Requirement: Visual Formatting

The dashboard SHALL use consistent visual formatting with colors and symbols.

#### Scenario: Color coding

- **WHEN** dashboard elements are displayed
- **THEN** system uses cyan for specification items
- **AND** yellow for active changes
- **AND** green for completed items
- **AND** dim gray for supplementary text

#### Scenario: Progress bar rendering

- **WHEN** displaying progress bars
- **THEN** system uses filled blocks (â–ˆ) for completed portions and light blocks (â–‘) for remaining

### Requirement: Error Handling

The view command SHALL handle errors gracefully.

#### Scenario: File system errors

- **WHEN** file system operations fail
- **THEN** system continues with available data and omits inaccessible items

#### Scenario: Invalid data structures

- **WHEN** specs or changes have invalid format
- **THEN** system skips invalid items and continues rendering

### Requirement: Draft Changes Display

The dashboard SHALL display changes without tasks in a separate "Draft" section.

#### Scenario: Draft changes listing

- **WHEN** there are changes with no tasks.md or zero tasks defined
- **THEN** system shows them in a "Draft Changes" section
- **AND** uses a distinct indicator (e.g., `â—‹`) to show draft status

#### Scenario: Draft section ordering

- **WHEN** multiple draft changes exist
- **THEN** system sorts them alphabetically by name




================================================
FILE: openspec/specs/docs-agent-instructions/spec.md
================================================
# docs-agent-instructions Specification

## Purpose
TBD - created by archiving change improve-agent-instruction-usability. Update Purpose after archive.
## Requirements
### Requirement: Quick Reference Placement
The AI instructions SHALL begin with a quick-reference section that surfaces required file structures, templates, and formatting rules before any narrative guidance.

#### Scenario: Loading templates at the top
- **WHEN** `openspec/AGENTS.md` is regenerated or updated
- **THEN** the first substantive section after the title SHALL provide copy-ready headings for `proposal.md`, `tasks.md`, spec deltas, and scenario formatting
- **AND** link each template to the corresponding workflow step for deeper reading

### Requirement: Embedded Templates and Examples
`openspec/AGENTS.md` SHALL include complete copy/paste templates and inline examples exactly where agents make corresponding edits.

#### Scenario: Providing file templates
- **WHEN** authors reach the workflow guidance for drafting proposals and deltas
- **THEN** provide fenced Markdown templates that match the required structure (`## Why`, `## ADDED Requirements`, `#### Scenario:` etc.)
- **AND** accompany each template with a brief example showing correct header usage and scenario bullets

### Requirement: Pre-validation Checklist
`openspec/AGENTS.md` SHALL offer a concise pre-validation checklist that highlights common formatting mistakes before running `openspec validate`.

#### Scenario: Highlighting common validation failures
- **WHEN** a reader reaches the validation guidance
- **THEN** present a checklist reminding them to verify requirement headers, scenario formatting, and delta sections
- **AND** include reminders about at least `#### Scenario:` usage and descriptive requirement text before scenarios

### Requirement: Progressive Disclosure of Workflow Guidance
The documentation SHALL separate beginner essentials from advanced topics so newcomers can focus on core steps without losing access to advanced workflows.

#### Scenario: Organizing beginner and advanced sections
- **WHEN** reorganizing `openspec/AGENTS.md`
- **THEN** keep an introductory section limited to the minimum steps (scaffold, draft, validate, request review)
- **AND** move advanced topics (multi-capability changes, archiving details, tooling deep dives) into clearly labeled later sections
- **AND** provide anchor links from the quick-reference to those advanced sections




================================================
FILE: openspec/specs/global-config/spec.md
================================================
# global-config Specification

## Purpose

This spec defines how OpenSpec resolves, reads, and writes user-level global configuration. It governs the `src/core/global-config.ts` module, which provides the foundation for storing user preferences, feature flags, and settings that persist across projects. The spec ensures cross-platform compatibility by following XDG Base Directory Specification with platform-specific fallbacks, and guarantees forward/backward compatibility through schema evolution rules.
## Requirements
### Requirement: Global configuration storage
The system SHALL store global configuration in `~/.config/openspec/config.json`, including telemetry state with `anonymousId` and `noticeSeen` fields.

#### Scenario: Initial config creation
- **WHEN** no global config file exists
- **AND** the first telemetry event is about to be sent
- **THEN** the system creates `~/.config/openspec/config.json` with telemetry configuration

#### Scenario: Telemetry config structure
- **WHEN** reading or writing telemetry configuration
- **THEN** the config contains a `telemetry` object with `anonymousId` (string UUID) and `noticeSeen` (boolean) fields

#### Scenario: Config file format
- **WHEN** storing configuration
- **THEN** the system writes valid JSON that can be read and modified by users

#### Scenario: Existing config preservation
- **WHEN** adding telemetry fields to an existing config file
- **THEN** the system preserves all existing configuration fields

### Requirement: Global Config Directory Path

The system SHALL resolve the global configuration directory path following XDG Base Directory Specification with platform-specific fallbacks.

#### Scenario: Unix/macOS with XDG_CONFIG_HOME set
- **WHEN** `$XDG_CONFIG_HOME` environment variable is set to `/custom/config`
- **THEN** `getGlobalConfigDir()` returns `/custom/config/openspec`

#### Scenario: Unix/macOS without XDG_CONFIG_HOME
- **WHEN** `$XDG_CONFIG_HOME` environment variable is not set
- **AND** the platform is Unix or macOS
- **THEN** `getGlobalConfigDir()` returns `~/.config/openspec` (expanded to absolute path)

#### Scenario: Windows platform
- **WHEN** the platform is Windows
- **AND** `%APPDATA%` is set to `C:\Users\User\AppData\Roaming`
- **THEN** `getGlobalConfigDir()` returns `C:\Users\User\AppData\Roaming\openspec`

### Requirement: Global Config Loading

The system SHALL load global configuration from the config directory with sensible defaults when the config file does not exist or cannot be parsed.

#### Scenario: Config file exists and is valid
- **WHEN** `config.json` exists in the global config directory
- **AND** the file contains valid JSON matching the config schema
- **THEN** `getGlobalConfig()` returns the parsed configuration

#### Scenario: Config file does not exist
- **WHEN** `config.json` does not exist in the global config directory
- **THEN** `getGlobalConfig()` returns the default configuration
- **AND** no directory or file is created

#### Scenario: Config file is invalid JSON
- **WHEN** `config.json` exists but contains invalid JSON
- **THEN** `getGlobalConfig()` returns the default configuration
- **AND** a warning is logged to stderr

### Requirement: Global Config Saving

The system SHALL save global configuration to the config directory, creating the directory if it does not exist.

#### Scenario: Save config to new directory
- **WHEN** `saveGlobalConfig(config)` is called
- **AND** the global config directory does not exist
- **THEN** the directory is created
- **AND** `config.json` is written with the provided configuration

#### Scenario: Save config to existing directory
- **WHEN** `saveGlobalConfig(config)` is called
- **AND** the global config directory already exists
- **THEN** `config.json` is written (overwriting if exists)

### Requirement: Default Configuration

The system SHALL provide a default configuration that is used when no config file exists.

#### Scenario: Default config structure
- **WHEN** no config file exists
- **THEN** the default configuration includes an empty `featureFlags` object

### Requirement: Config Schema Evolution

The system SHALL merge loaded configuration with default values to ensure new config fields are available even when loading older config files.

#### Scenario: Config file missing new fields
- **WHEN** `config.json` exists with `{ "featureFlags": {} }`
- **AND** the current schema includes a new field `defaultAiTool`
- **THEN** `getGlobalConfig()` returns `{ featureFlags: {}, defaultAiTool: <default> }`
- **AND** the loaded values take precedence over defaults for fields that exist in both

#### Scenario: Config file has extra unknown fields
- **WHEN** `config.json` contains fields not in the current schema
- **THEN** the unknown fields are preserved in the returned configuration
- **AND** no error or warning is raised




================================================
FILE: openspec/specs/instruction-loader/spec.md
================================================
# instruction-loader Specification

## Purpose
The instruction-loader loads instruction templates from schema directories, validates and enriches them with metadata and parameters (such as change context and dependency status), and exposes them for use by downstream services including template retrieval, parameter substitution, and enrichment.

## Requirements
### Requirement: Template Loading
The system SHALL load templates from schema directories.

#### Scenario: Load template from schema directory
- **WHEN** `loadTemplate(schemaName, templatePath)` is called
- **THEN** the system loads the template from `schemas/<schemaName>/templates/<templatePath>`

#### Scenario: Template file not found
- **WHEN** a template file does not exist in the schema's templates directory
- **THEN** the system throws an error with the template path

### Requirement: Change Context Loading
The system SHALL load change context combining graph and completion state.

#### Scenario: Load context for existing change
- **WHEN** `loadChangeContext(projectRoot, changeName)` is called for an existing change
- **THEN** the system returns a context with graph, completed set, schema name, and change info

#### Scenario: Load context with custom schema
- **WHEN** `loadChangeContext(projectRoot, changeName, schemaName)` is called
- **THEN** the system uses the specified schema instead of default

#### Scenario: Load context for non-existent change directory
- **WHEN** `loadChangeContext` is called for a non-existent change directory
- **THEN** the system returns context with empty completed set

### Requirement: Template Enrichment
The system SHALL enrich templates with change-specific context.

#### Scenario: Include artifact metadata
- **WHEN** instructions are generated for an artifact
- **THEN** the output includes change name, artifact ID, schema name, and output path

#### Scenario: Include dependency status
- **WHEN** an artifact has dependencies
- **THEN** the output shows each dependency with completion status (done/missing)

#### Scenario: Include unlocked artifacts
- **WHEN** instructions are generated
- **THEN** the output includes which artifacts become available after this one

#### Scenario: Root artifact indicator
- **WHEN** an artifact has no dependencies
- **THEN** the dependency section indicates this is a root artifact

### Requirement: Status Formatting
The system SHALL format change status as readable output.

#### Scenario: All artifacts completed
- **WHEN** all artifacts are completed
- **THEN** status shows all artifacts as "done"

#### Scenario: Mixed completion status
- **WHEN** some artifacts are completed
- **THEN** status shows completed as "done", ready as "ready", blocked as "blocked"

#### Scenario: Blocked artifact details
- **WHEN** an artifact is blocked
- **THEN** status shows which dependencies are missing

#### Scenario: Include output paths
- **WHEN** status is formatted
- **THEN** each artifact shows its output path pattern




================================================
FILE: openspec/specs/openspec-conventions/spec.md
================================================
# OpenSpec Conventions Specification

## Purpose

OpenSpec conventions SHALL define how system capabilities are documented, how changes are proposed and tracked, and how specifications evolve over time. This meta-specification serves as the source of truth for OpenSpec's own conventions.
## Requirements
### Requirement: Structured conventions for specs and changes

OpenSpec conventions SHALL mandate a structured spec format with clear requirement and scenario sections so tooling can parse consistently.

#### Scenario: Following the structured spec format

- **WHEN** writing or updating OpenSpec specifications
- **THEN** authors SHALL use `### Requirement: ...` followed by at least one `#### Scenario: ...` section

### Requirement: Project Structure
An OpenSpec project SHALL maintain a consistent directory structure for specifications and changes.

#### Scenario: Initializing project structure
- **WHEN** an OpenSpec project is initialized
- **THEN** it SHALL have this structure:
```
openspec/
â”œâ”€â”€ project.md              # Project-specific context
â”œâ”€â”€ AGENTS.md               # AI assistant instructions
â”œâ”€â”€ specs/                  # Current deployed capabilities
â”‚   â””â”€â”€ [capability]/       # Single, focused capability
â”‚       â”œâ”€â”€ spec.md         # WHAT and WHY
â”‚       â””â”€â”€ design.md       # HOW (optional, for established patterns)
â””â”€â”€ changes/                # Proposed changes
    â”œâ”€â”€ [change-name]/      # Descriptive change identifier
    â”‚   â”œâ”€â”€ proposal.md     # Why, what, and impact
    â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
    â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional)
    â”‚   â””â”€â”€ specs/          # Complete future state
    â”‚       â””â”€â”€ [capability]/
    â”‚           â””â”€â”€ spec.md # Clean markdown (no diff syntax)
    â””â”€â”€ archive/            # Completed changes
        â””â”€â”€ YYYY-MM-DD-[name]/
```

### Requirement: Structured Format for Behavioral Specs

Behavioral specifications SHALL use a structured format with consistent section headers and keywords to ensure visual consistency and parseability.

#### Scenario: Writing requirement sections

- **WHEN** documenting a requirement in a behavioral specification
- **THEN** use a level-3 heading with format `### Requirement: [Name]`
- **AND** immediately follow with a SHALL statement describing core behavior
- **AND** keep requirement names descriptive and under 50 characters

#### Scenario: Documenting scenarios

- **WHEN** documenting specific behaviors or use cases
- **THEN** use level-4 headings with format `#### Scenario: [Description]`
- **AND** use bullet points with bold keywords for steps:
  - **GIVEN** for initial state (optional)
  - **WHEN** for conditions or triggers
  - **THEN** for expected outcomes
  - **AND** for additional outcomes or conditions

#### Scenario: Adding implementation details

- **WHEN** a step requires additional detail
- **THEN** use sub-bullets under the main step
- **AND** maintain consistent indentation
  - Sub-bullets provide examples or specifics
  - Keep sub-bullets concise

### Requirement: Header-Based Requirement Identification

Requirement headers SHALL serve as unique identifiers for programmatic matching between current specs and proposed changes.

#### Scenario: Matching requirements programmatically

- **WHEN** processing delta changes
- **THEN** use the `### Requirement: [Name]` header as the unique identifier
- **AND** match using normalized headers: `normalize(header) = trim(header)`
- **AND** compare headers with case-sensitive equality after normalization

#### Scenario: Handling requirement renames

- **WHEN** renaming a requirement
- **THEN** use a special `## RENAMED Requirements` section
- **AND** specify both old and new names explicitly:
  ```markdown
  ## RENAMED Requirements
  - FROM: `### Requirement: Old Name`
  - TO: `### Requirement: New Name`
  ```
- **AND** if content also changes, include under MODIFIED using the NEW header

#### Scenario: Validating header uniqueness

- **WHEN** creating or modifying requirements
- **THEN** ensure no duplicate headers exist within a spec
- **AND** validation tools SHALL flag duplicate headers as errors

### Requirement: Change Storage Convention

Change proposals SHALL store only the additions, modifications, and removals to specifications, not complete future states.

#### Scenario: Creating change proposals with additions

- **WHEN** creating a change proposal that adds new requirements
- **THEN** include only the new requirements under `## ADDED Requirements`
- **AND** each requirement SHALL include its complete content
- **AND** use the standard structured format for requirements and scenarios

#### Scenario: Creating change proposals with modifications  

- **WHEN** creating a change proposal that modifies existing requirements
- **THEN** include the modified requirements under `## MODIFIED Requirements`
- **AND** use the same header text as in the current spec (normalized)
- **AND** include the complete modified requirement (not a diff)
- **AND** optionally annotate what changed with inline comments like `â† (was X)`

#### Scenario: Creating change proposals with removals

- **WHEN** creating a change proposal that removes requirements
- **THEN** list them under `## REMOVED Requirements`
- **AND** use the normalized header text for identification
- **AND** include reason for removal
- **AND** document any migration path if applicable

The `changes/[name]/specs/` directory SHALL contain:
- Delta files showing only what changes
- Sections for ADDED, MODIFIED, REMOVED, and RENAMED requirements
- Normalized header matching for requirement identification
- Complete requirements using the structured format
- Clear indication of change type for each requirement

#### Scenario: Using standard output symbols

- **WHEN** displaying delta operations in CLI output
- **THEN** use these standard symbols:
  - `+` for ADDED (green)
  - `~` for MODIFIED (yellow)
  - `-` for REMOVED (red)
  - `â†’` for RENAMED (cyan)

### Requirement: Archive Process Enhancement

The archive process SHALL programmatically apply delta changes to current specifications using header-based matching.

#### Scenario: Archiving changes with deltas

- **WHEN** archiving a completed change
- **THEN** the archive command SHALL:
  1. Parse RENAMED sections first and apply renames
  2. Parse REMOVED sections and remove by normalized header match
  3. Parse MODIFIED sections and replace by normalized header match (using new names if renamed)
  4. Parse ADDED sections and append new requirements
- **AND** validate that all MODIFIED/REMOVED headers exist in current spec
- **AND** validate that ADDED headers don't already exist
- **AND** generate the updated spec in the main specs/ directory

#### Scenario: Handling conflicts during archive

- **WHEN** delta changes conflict with current spec state
- **THEN** the archive command SHALL report specific conflicts
- **AND** require manual resolution before proceeding
- **AND** provide clear guidance on resolving conflicts

### Requirement: Proposal Format

Proposals SHALL explicitly document all changes with clear from/to comparisons.

#### Scenario: Documenting changes

- **WHEN** documenting what changes
- **THEN** the proposal SHALL explicitly describe each change:

```markdown
**[Section or Behavior Name]**
- From: [current state/requirement]
- To: [future state/requirement]
- Reason: [why this change is needed]
- Impact: [breaking/non-breaking, who's affected]
```

This explicit format compensates for not having inline diffs and ensures reviewers understand exactly what will change.

### Requirement: Change Review

The system SHALL support multiple methods for reviewing proposed changes.

#### Scenario: Reviewing changes

- **WHEN** reviewing proposed changes
- **THEN** reviewers can compare using:
- GitHub PR diff view when changes are committed
- Command line: `diff -u specs/[capability]/spec.md changes/[name]/specs/[capability]/spec.md`
- Any visual diff tool comparing current vs future state

### Requirement: Structured Format Adoption

Behavioral specifications SHALL adopt the structured format with `### Requirement:` and `#### Scenario:` headers as the default.

#### Scenario: Use structured headings for behavior

- **WHEN** documenting behavioral requirements
- **THEN** use `### Requirement:` for requirements
- **AND** use `#### Scenario:` for scenarios with bold WHEN/THEN/AND keywords

### Requirement: Verbâ€“Noun CLI Command Structure
OpenSpec CLI design SHALL use verbs as top-level commands with nouns provided as arguments or flags for scoping.

#### Scenario: Verb-first command discovery
- **WHEN** a user runs a command like `openspec list`
- **THEN** the verb communicates the action clearly
- **AND** nouns refine scope via flags or arguments (e.g., `--changes`, `--specs`)

#### Scenario: Backward compatibility for noun commands
- **WHEN** users run noun-prefixed commands such as `openspec spec ...` or `openspec change ...`
- **THEN** the CLI SHALL continue to support them for at least one release
- **AND** display a deprecation warning that points to verb-first alternatives

#### Scenario: Disambiguation guidance
- **WHEN** item names are ambiguous between changes and specs
- **THEN** `openspec show` and `openspec validate` SHALL accept `--type spec|change`
- **AND** the help text SHALL document this clearly

## Core Principles

The system SHALL follow these principles:
- Specs reflect what IS currently built and deployed
- Changes contain proposals for what SHOULD be changed
- AI drives the documentation process
- Specs are living documentation kept in sync with deployed code

## Directory Structure

### Requirement: Project Structure

An OpenSpec project SHALL maintain a consistent directory structure for specifications and changes.

#### Scenario: Initializing project structure

- **WHEN** an OpenSpec project is initialized
- **THEN** it SHALL have this structure:
```
openspec/
â”œâ”€â”€ project.md              # Project-specific context
â”œâ”€â”€ AGENTS.md               # AI assistant instructions
â”œâ”€â”€ specs/                  # Current deployed capabilities
â”‚   â””â”€â”€ [capability]/       # Single, focused capability
â”‚       â”œâ”€â”€ spec.md         # WHAT and WHY
â”‚       â””â”€â”€ design.md       # HOW (optional, for established patterns)
â””â”€â”€ changes/                # Proposed changes
    â”œâ”€â”€ [change-name]/      # Descriptive change identifier
    â”‚   â”œâ”€â”€ proposal.md     # Why, what, and impact
    â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
    â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional)
    â”‚   â””â”€â”€ specs/          # Complete future state
    â”‚       â””â”€â”€ [capability]/
    â”‚           â””â”€â”€ spec.md # Clean markdown (no diff syntax)
    â””â”€â”€ archive/            # Completed changes
        â””â”€â”€ YYYY-MM-DD-[name]/
```

## Specification Format

### Requirement: Structured Format for Behavioral Specs

Behavioral specifications SHALL use a structured format with consistent section headers and keywords to ensure visual consistency and parseability.

#### Scenario: Writing requirement sections

- **WHEN** documenting a requirement in a behavioral specification
- **THEN** use a level-3 heading with format `### Requirement: [Name]`
- **AND** immediately follow with a SHALL statement describing core behavior
- **AND** keep requirement names descriptive and under 50 characters

#### Scenario: Documenting scenarios

- **WHEN** documenting specific behaviors or use cases
- **THEN** use level-4 headings with format `#### Scenario: [Description]`
- **AND** use bullet points with bold keywords for steps:
  - **GIVEN** for initial state (optional)
  - **WHEN** for conditions or triggers
  - **THEN** for expected outcomes
  - **AND** for additional outcomes or conditions

#### Scenario: Adding implementation details

- **WHEN** a step requires additional detail
- **THEN** use sub-bullets under the main step
- **AND** maintain consistent indentation
  - Sub-bullets provide examples or specifics
  - Keep sub-bullets concise

## Change Storage Convention

### Requirement: Header-Based Requirement Identification

Requirement headers SHALL serve as unique identifiers for programmatic matching between current specs and proposed changes.

#### Scenario: Matching requirements programmatically

- **WHEN** processing delta changes
- **THEN** use the `### Requirement: [Name]` header as the unique identifier
- **AND** match using normalized headers: `normalize(header) = trim(header)`
- **AND** compare headers with case-sensitive equality after normalization

#### Scenario: Handling requirement renames

- **WHEN** renaming a requirement
- **THEN** use a special `## RENAMED Requirements` section
- **AND** specify both old and new names explicitly:
  ```markdown
  ## RENAMED Requirements
  - FROM: `### Requirement: Old Name`
  - TO: `### Requirement: New Name`
  ```
- **AND** if content also changes, include under MODIFIED using the NEW header

#### Scenario: Validating header uniqueness

- **WHEN** creating or modifying requirements
- **THEN** ensure no duplicate headers exist within a spec
- **AND** validation tools SHALL flag duplicate headers as errors

### Requirement: Change Storage Convention

Change proposals SHALL store only the additions, modifications, and removals to specifications, not complete future states.

#### Scenario: Creating change proposals with additions

- **WHEN** creating a change proposal that adds new requirements
- **THEN** include only the new requirements under `## ADDED Requirements`
- **AND** each requirement SHALL include its complete content
- **AND** use the standard structured format for requirements and scenarios

#### Scenario: Creating change proposals with modifications  

- **WHEN** creating a change proposal that modifies existing requirements
- **THEN** include the modified requirements under `## MODIFIED Requirements`
- **AND** use the same header text as in the current spec (normalized)
- **AND** include the complete modified requirement (not a diff)
- **AND** optionally annotate what changed with inline comments like `â† (was X)`

#### Scenario: Creating change proposals with removals

- **WHEN** creating a change proposal that removes requirements
- **THEN** list them under `## REMOVED Requirements`
- **AND** use the normalized header text for identification
- **AND** include reason for removal
- **AND** document any migration path if applicable

The `changes/[name]/specs/` directory SHALL contain:
- Delta files showing only what changes
- Sections for ADDED, MODIFIED, REMOVED, and RENAMED requirements
- Normalized header matching for requirement identification
- Complete requirements using the structured format
- Clear indication of change type for each requirement

#### Scenario: Using standard output symbols

- **WHEN** displaying delta operations in CLI output
- **THEN** use these standard symbols:
  - `+` for ADDED (green)
  - `~` for MODIFIED (yellow)
  - `-` for REMOVED (red)
  - `â†’` for RENAMED (cyan)

### Requirement: Archive Process Enhancement

The archive process SHALL programmatically apply delta changes to current specifications using header-based matching.

#### Scenario: Archiving changes with deltas

- **WHEN** archiving a completed change
- **THEN** the archive command SHALL:
  1. Parse RENAMED sections first and apply renames
  2. Parse REMOVED sections and remove by normalized header match
  3. Parse MODIFIED sections and replace by normalized header match (using new names if renamed)
  4. Parse ADDED sections and append new requirements
- **AND** validate that all MODIFIED/REMOVED headers exist in current spec
- **AND** validate that ADDED headers don't already exist
- **AND** generate the updated spec in the main specs/ directory

#### Scenario: Handling conflicts during archive

- **WHEN** delta changes conflict with current spec state
- **THEN** the archive command SHALL report specific conflicts
- **AND** require manual resolution before proceeding
- **AND** provide clear guidance on resolving conflicts

### Requirement: Proposal Format

Proposals SHALL explicitly document all changes with clear from/to comparisons.

#### Scenario: Documenting changes

- **WHEN** documenting what changes
- **THEN** the proposal SHALL explicitly describe each change:

```markdown
**[Section or Behavior Name]**
- From: [current state/requirement]
- To: [future state/requirement]
- Reason: [why this change is needed]
- Impact: [breaking/non-breaking, who's affected]
```

This explicit format compensates for not having inline diffs and ensures reviewers understand exactly what will change.

## Change Lifecycle

The change process SHALL follow these states:

1. **Propose**: AI creates change with future state specs and explicit proposal
2. **Review**: Humans review proposal and future state
3. **Approve**: Change is approved for implementation
4. **Implement**: Follow tasks.md checklist (can span multiple PRs)
5. **Deploy**: Changes are deployed to production
6. **Update**: Specs in `specs/` are updated to match deployed reality
7. **Archive**: Change is moved to `archive/YYYY-MM-DD-[name]/`

## Viewing Changes

### Requirement: Change Review

The system SHALL support multiple methods for reviewing proposed changes.

#### Scenario: Reviewing changes

- **WHEN** reviewing proposed changes
- **THEN** reviewers can compare using:
- GitHub PR diff view when changes are committed
- Command line: `diff -u specs/[capability]/spec.md changes/[name]/specs/[capability]/spec.md`
- Any visual diff tool comparing current vs future state

The system relies on tools to generate diffs rather than storing them.

## Capability Naming

Capabilities SHALL use:
- Verb-noun patterns (e.g., `user-auth`, `payment-capture`)
- Hyphenated lowercase names
- Singular focus (one responsibility per capability)
- No nesting (flat structure under `specs/`)

## When Changes Require Proposals

A proposal SHALL be created for:
- New features or capabilities
- Breaking changes to existing behavior
- Architecture or pattern changes
- Performance optimizations that change behavior
- Security updates affecting access patterns

A proposal is NOT required for:
- Bug fixes restoring intended behavior
- Typos or formatting fixes
- Non-breaking dependency updates
- Adding tests for existing behavior
- Documentation clarifications

## Why This Approach

Clean future state storage provides:
- **Readability**: No diff syntax pollution
- **AI-compatibility**: Standard markdown that AI tools understand
- **Simplicity**: No special parsing or processing needed
- **Tool-agnostic**: Any diff tool can show changes
- **Clear intent**: Explicit proposals document reasoning

The structured format adds:
- **Visual Consistency**: Requirement and Scenario prefixes make sections instantly recognizable
- **Parseability**: Consistent structure enables tooling and automation
- **Gradual Adoption**: Existing specs can migrate incrementally


================================================
FILE: openspec/specs/opsx-archive-skill/spec.md
================================================
# OPSX Archive Skill Spec

### Requirement: OPSX Archive Skill

The system SHALL provide an `/opsx:archive` skill that archives completed changes in the experimental workflow.

#### Scenario: Archive a change with all artifacts complete

- **WHEN** agent executes `/opsx:archive` with a change name
- **AND** all artifacts in the schema are complete
- **AND** all tasks are complete
- **THEN** the agent moves the change to `openspec/changes/archive/YYYY-MM-DD-<name>/`
- **AND** displays success message with archived location

#### Scenario: Change selection prompt

- **WHEN** agent executes `/opsx:archive` without specifying a change
- **THEN** the agent prompts user to select from available changes
- **AND** shows only active changes (excludes archive/)

### Requirement: Artifact Completion Check

The skill SHALL check artifact completion status using the artifact graph before archiving.

#### Scenario: Incomplete artifacts warning

- **WHEN** agent checks artifact status
- **AND** one or more artifacts have status other than `done`
- **THEN** display warning listing incomplete artifacts
- **AND** prompt user for confirmation to continue
- **AND** proceed if user confirms

#### Scenario: All artifacts complete

- **WHEN** agent checks artifact status
- **AND** all artifacts have status `done`
- **THEN** proceed without warning

### Requirement: Task Completion Check

The skill SHALL check task completion status from tasks.md before archiving.

#### Scenario: Incomplete tasks found

- **WHEN** agent reads tasks.md
- **AND** incomplete tasks are found (marked with `- [ ]`)
- **THEN** display warning showing count of incomplete tasks
- **AND** prompt user for confirmation to continue
- **AND** proceed if user confirms

#### Scenario: All tasks complete

- **WHEN** agent reads tasks.md
- **AND** all tasks are complete (marked with `- [x]`)
- **THEN** proceed without task-related warning

#### Scenario: No tasks file

- **WHEN** tasks.md does not exist
- **THEN** proceed without task-related warning

### Requirement: Spec Sync Prompt

The skill SHALL prompt to sync delta specs before archiving if specs exist.

#### Scenario: Delta specs exist

- **WHEN** agent checks for delta specs
- **AND** `specs/` directory exists in the change with spec files
- **THEN** prompt user: "This change has delta specs. Would you like to sync them to main specs before archiving?"
- **AND** if user confirms, execute `/opsx:sync` logic
- **AND** proceed with archive regardless of sync choice

#### Scenario: No delta specs

- **WHEN** agent checks for delta specs
- **AND** no `specs/` directory or no spec files exist
- **THEN** proceed without sync prompt

### Requirement: Archive Process

The skill SHALL move the change to the archive folder with date prefix.

#### Scenario: Successful archive

- **WHEN** archiving a change
- **THEN** create `archive/` directory if it doesn't exist
- **AND** generate target name as `YYYY-MM-DD-<change-name>` using current date
- **AND** move entire change directory to archive location
- **AND** preserve `.openspec.yaml` file in archived change

#### Scenario: Archive already exists

- **WHEN** target archive directory already exists
- **THEN** fail with error message
- **AND** suggest renaming existing archive or using different date

### Requirement: Skill Output

The skill SHALL provide clear feedback about the archive operation.

#### Scenario: Archive complete with sync

- **WHEN** archive completes after syncing specs
- **THEN** display summary:
  - Specs synced (from `/opsx:sync` output)
  - Change archived to location
  - Schema that was used

#### Scenario: Archive complete without sync

- **WHEN** archive completes without syncing specs
- **THEN** display summary:
  - Note that specs were not synced (if applicable)
  - Change archived to location
  - Schema that was used

#### Scenario: Archive complete with warnings

- **WHEN** archive completes with incomplete artifacts or tasks
- **THEN** include note about what was incomplete
- **AND** suggest reviewing if archive was intentional



================================================
FILE: openspec/specs/specs-sync-skill/spec.md
================================================
# specs-sync-skill Specification

## Purpose
Defines the agent skill for syncing delta specs from changes to main specs.

## Requirements

### Requirement: Specs Sync Skill
The system SHALL provide an `/opsx:sync` skill that syncs delta specs from a change to the main specs.

#### Scenario: Sync delta specs to main specs
- **WHEN** agent executes `/opsx:sync` with a change name
- **THEN** the agent reads delta specs from `openspec/changes/<name>/specs/`
- **AND** reads corresponding main specs from `openspec/specs/`
- **AND** reconciles main specs to match what the deltas describe

#### Scenario: Idempotent operation
- **WHEN** agent executes `/opsx:sync` multiple times on the same change
- **THEN** the result is the same as running it once
- **AND** no duplicate requirements are created

#### Scenario: Change selection prompt
- **WHEN** agent executes `/opsx:sync` without specifying a change
- **THEN** the agent prompts user to select from available changes
- **AND** shows changes that have delta specs

### Requirement: Delta Reconciliation Logic
The agent SHALL reconcile main specs with delta specs using the delta operation headers.

#### Scenario: ADDED requirements
- **WHEN** delta contains `## ADDED Requirements` with a requirement
- **AND** the requirement does not exist in main spec
- **THEN** add the requirement to main spec

#### Scenario: ADDED requirement already exists
- **WHEN** delta contains `## ADDED Requirements` with a requirement
- **AND** a requirement with the same name already exists in main spec
- **THEN** update the existing requirement to match the delta version

#### Scenario: MODIFIED requirements
- **WHEN** delta contains `## MODIFIED Requirements` with a requirement
- **AND** the requirement exists in main spec
- **THEN** replace the requirement in main spec with the delta version

#### Scenario: REMOVED requirements
- **WHEN** delta contains `## REMOVED Requirements` with a requirement name
- **AND** the requirement exists in main spec
- **THEN** remove the requirement from main spec

#### Scenario: RENAMED requirements
- **WHEN** delta contains `## RENAMED Requirements` with FROM:/TO: format
- **AND** the FROM requirement exists in main spec
- **THEN** rename the requirement to the TO name

#### Scenario: New capability spec
- **WHEN** delta spec exists for a capability not in main specs
- **THEN** create new main spec file at `openspec/specs/<capability>/spec.md`

### Requirement: Skill Output
The skill SHALL provide clear feedback on what was applied.

#### Scenario: Show applied changes
- **WHEN** reconciliation completes successfully
- **THEN** display summary of changes per capability:
  - Number of requirements added
  - Number of requirements modified
  - Number of requirements removed
  - Number of requirements renamed

#### Scenario: No changes needed
- **WHEN** main specs already match delta specs
- **THEN** display "Specs already in sync - no changes needed"



================================================
FILE: openspec/specs/telemetry/spec.md
================================================
# telemetry Specification

## Purpose

This spec defines how OpenSpec collects anonymous usage telemetry to help improve the tool. It governs the `src/telemetry/` module, which handles PostHog integration, privacy-preserving event design, user opt-out mechanisms, and first-run notice display. The spec ensures telemetry is minimal, transparent, and respects user privacy.

## Requirements

### Requirement: Command execution tracking
The system SHALL send a `command_executed` event to PostHog when any CLI command executes, including only the command name and OpenSpec version as properties.

#### Scenario: Standard command execution
- **WHEN** a user runs any openspec command
- **THEN** the system sends a `command_executed` event with `command` and `version` properties

#### Scenario: Subcommand execution
- **WHEN** a user runs a nested command like `openspec change apply`
- **THEN** the system sends a `command_executed` event with the full command path (e.g., `change:apply`)

### Requirement: Privacy-preserving event design
The system SHALL NOT include command arguments, file paths, project names, spec content, error messages, or IP addresses in telemetry events.

#### Scenario: Command with arguments
- **WHEN** a user runs `openspec init my-project --force`
- **THEN** the telemetry event contains only `command: "init"` and `version: "<version>"` without arguments

#### Scenario: IP address exclusion
- **WHEN** the system sends a telemetry event
- **THEN** the event explicitly sets `$ip: null` to prevent IP tracking

### Requirement: Environment variable opt-out
The system SHALL disable telemetry when `OPENSPEC_TELEMETRY=0` or `DO_NOT_TRACK=1` environment variables are set.

#### Scenario: OPENSPEC_TELEMETRY opt-out
- **WHEN** `OPENSPEC_TELEMETRY=0` is set in the environment
- **THEN** the system sends no telemetry events

#### Scenario: DO_NOT_TRACK opt-out
- **WHEN** `DO_NOT_TRACK=1` is set in the environment
- **THEN** the system sends no telemetry events

#### Scenario: Environment variable takes precedence
- **WHEN** the user has previously used the CLI (config exists)
- **AND** the user sets `OPENSPEC_TELEMETRY=0`
- **THEN** telemetry is disabled regardless of config state

### Requirement: CI environment auto-disable
The system SHALL automatically disable telemetry when `CI=true` environment variable is detected.

#### Scenario: CI environment detection
- **WHEN** `CI=true` is set in the environment
- **THEN** the system sends no telemetry events

#### Scenario: CI with explicit enable
- **WHEN** `CI=true` is set
- **AND** `OPENSPEC_TELEMETRY=1` is explicitly set
- **THEN** telemetry remains disabled (CI takes precedence for privacy)

### Requirement: First-run telemetry notice
The system SHALL display a one-line telemetry disclosure notice on the first command execution, before any telemetry is sent.

#### Scenario: First command execution
- **WHEN** a user runs their first openspec command
- **AND** telemetry is enabled
- **THEN** the system displays: "Note: OpenSpec collects anonymous usage stats. Opt out: OPENSPEC_TELEMETRY=0"

#### Scenario: Subsequent command execution
- **WHEN** a user has already seen the notice (noticeSeen: true in config)
- **THEN** the system does not display the notice

#### Scenario: Notice before telemetry
- **WHEN** displaying the first-run notice
- **THEN** the notice appears before any telemetry event is sent

### Requirement: Anonymous user identification
The system SHALL generate a random UUID as an anonymous identifier on first telemetry send, stored in global config.

#### Scenario: First telemetry event
- **WHEN** the first telemetry event is sent
- **AND** no anonymousId exists in config
- **THEN** the system generates a random UUID v4 and stores it in config

#### Scenario: Persistent identity
- **WHEN** a user runs multiple commands across sessions
- **THEN** the same anonymousId is used for all events

#### Scenario: Lazy generation with opt-out
- **WHEN** a user opts out before running any command
- **THEN** no anonymousId is ever generated or stored

### Requirement: Immediate event sending
The system SHALL send telemetry events immediately without batching, using `flushAt: 1` and `flushInterval: 0` configuration.

#### Scenario: Event transmission timing
- **WHEN** a command executes
- **THEN** the telemetry event is sent immediately, not queued for batch transmission

### Requirement: Graceful shutdown
The system SHALL call `posthog.shutdown()` before CLI exit to ensure pending events are flushed.

#### Scenario: Normal exit
- **WHEN** a command completes successfully
- **THEN** the system awaits `shutdown()` before exiting

#### Scenario: Error exit
- **WHEN** a command fails with an error
- **THEN** the system still awaits `shutdown()` before exiting

### Requirement: Silent failure handling
The system SHALL silently ignore telemetry failures without affecting CLI functionality.

#### Scenario: Network failure
- **WHEN** the telemetry request fails due to network error
- **THEN** the CLI command completes normally without error message

#### Scenario: PostHog outage
- **WHEN** PostHog service is unavailable
- **THEN** the CLI command completes normally without error message

#### Scenario: Shutdown failure
- **WHEN** `shutdown()` fails or times out
- **THEN** the CLI exits normally without error message



================================================
FILE: schemas/spec-driven/schema.yaml
================================================
name: spec-driven
version: 1
description: Default OpenSpec workflow - proposal â†’ specs â†’ design â†’ tasks
artifacts:
  - id: proposal
    generates: proposal.md
    description: Initial proposal document outlining the change
    template: proposal.md
    instruction: |
      Create the proposal document that establishes WHY this change is needed.

      Sections:
      - **Why**: 1-2 sentences on the problem or opportunity. What problem does this solve? Why now?
      - **What Changes**: Bullet list of changes. Be specific about new capabilities, modifications, or removals. Mark breaking changes with **BREAKING**.
      - **Capabilities**: Identify which specs will be created or modified:
        - **New Capabilities**: List capabilities being introduced. Each becomes a new `specs/<name>/spec.md`. Use kebab-case names (e.g., `user-auth`, `data-export`).
        - **Modified Capabilities**: List existing capabilities whose REQUIREMENTS are changing. Only include if spec-level behavior changes (not just implementation details). Each needs a delta spec file. Check `openspec/specs/` for existing spec names. Leave empty if no requirement changes.
      - **Impact**: Affected code, APIs, dependencies, or systems.

      IMPORTANT: The Capabilities section is critical. It creates the contract between
      proposal and specs phases. Research existing specs before filling this in.
      Each capability listed here will need a corresponding spec file.

      Keep it concise (1-2 pages). Focus on the "why" not the "how" -
      implementation details belong in design.md.

      This is the foundation - specs, design, and tasks all build on this.
    requires: []

  - id: specs
    generates: "specs/**/*.md"
    description: Detailed specifications for the change
    template: spec.md
    instruction: |
      Create specification files that define WHAT the system should do.

      Create one spec file per capability/feature area in specs/<name>/spec.md.

      Delta operations (use ## headers):
      - **ADDED Requirements**: New capabilities
      - **MODIFIED Requirements**: Changed behavior - MUST include full updated content
      - **REMOVED Requirements**: Deprecated features - MUST include **Reason** and **Migration**
      - **RENAMED Requirements**: Name changes only - use FROM:/TO: format

      Format requirements:
      - Each requirement: `### Requirement: <name>` followed by description
      - Use SHALL/MUST for normative requirements (avoid should/may)
      - Each scenario: `#### Scenario: <name>` with WHEN/THEN format
      - **CRITICAL**: Scenarios MUST use exactly 4 hashtags (`####`). Using 3 hashtags or bullets will fail silently.
      - Every requirement MUST have at least one scenario.

      MODIFIED requirements workflow:
      1. Locate the existing requirement in openspec/specs/<capability>/spec.md
      2. Copy the ENTIRE requirement block (from `### Requirement:` through all scenarios)
      3. Paste under `## MODIFIED Requirements` and edit to reflect new behavior
      4. Ensure header text matches exactly (whitespace-insensitive)

      Common pitfall: Using MODIFIED with partial content loses detail at archive time.
      If adding new concerns without changing existing behavior, use ADDED instead.

      Example:
      ```
      ## ADDED Requirements

      ### Requirement: User can export data
      The system SHALL allow users to export their data in CSV format.

      #### Scenario: Successful export
      - **WHEN** user clicks "Export" button
      - **THEN** system downloads a CSV file with all user data

      ## REMOVED Requirements

      ### Requirement: Legacy export
      **Reason**: Replaced by new export system
      **Migration**: Use new export endpoint at /api/v2/export
      ```

      Specs should be testable - each scenario is a potential test case.
    requires:
      - proposal

  - id: design
    generates: design.md
    description: Technical design document with implementation details
    template: design.md
    instruction: |
      Create the design document that explains HOW to implement the change.

      When to include design.md (create only if any apply):
      - Cross-cutting change (multiple services/modules) or new architectural pattern
      - New external dependency or significant data model changes
      - Security, performance, or migration complexity
      - Ambiguity that benefits from technical decisions before coding

      Sections:
      - **Context**: Background, current state, constraints, stakeholders
      - **Goals / Non-Goals**: What this design achieves and explicitly excludes
      - **Decisions**: Key technical choices with rationale (why X over Y?). Include alternatives considered for each decision.
      - **Risks / Trade-offs**: Known limitations, things that could go wrong. Format: [Risk] â†’ Mitigation
      - **Migration Plan**: Steps to deploy, rollback strategy (if applicable)
      - **Open Questions**: Outstanding decisions or unknowns to resolve

      Focus on architecture and approach, not line-by-line implementation.
      Reference the proposal for motivation and specs for requirements.

      Good design docs explain the "why" behind technical decisions.
    requires:
      - proposal

  - id: tasks
    generates: tasks.md
    description: Implementation tasks derived from specs and design
    template: tasks.md
    instruction: |
      Create the task list that breaks down the implementation work.

      Guidelines:
      - Group related tasks under ## numbered headings
      - Each task is a checkbox: - [ ] X.Y Task description
      - Tasks should be small enough to complete in one session
      - Order tasks by dependency (what must be done first?)

      Example:
      ```
      ## 1. Setup

      - [ ] 1.1 Create new module structure
      - [ ] 1.2 Add dependencies to package.json

      ## 2. Core Implementation

      - [ ] 2.1 Implement data export function
      - [ ] 2.2 Add CSV formatting utilities
      ```

      Reference specs for what needs to be built, design for how to build it.
      Each task should be verifiable - you know when it's done.
    requires:
      - specs
      - design

apply:
  requires: [tasks]
  tracks: tasks.md
  instruction: |
    Read context files, work through pending tasks, mark complete as you go.
    Pause if you hit blockers or need clarification.



================================================
FILE: schemas/spec-driven/templates/design.md
================================================
## Context

<!-- Background and current state -->

## Goals / Non-Goals

**Goals:**
<!-- What this design aims to achieve -->

**Non-Goals:**
<!-- What is explicitly out of scope -->

## Decisions

<!-- Key design decisions and rationale -->

## Risks / Trade-offs

<!-- Known risks and trade-offs -->



================================================
FILE: schemas/spec-driven/templates/proposal.md
================================================
## Why

<!-- Explain the motivation for this change. What problem does this solve? Why now? -->

## What Changes

<!-- Describe what will change. Be specific about new capabilities, modifications, or removals. -->

## Capabilities

### New Capabilities
<!-- Capabilities being introduced. Replace <name> with kebab-case identifier (e.g., user-auth, data-export, api-rate-limiting). Each creates specs/<name>/spec.md -->
- `<name>`: <brief description of what this capability covers>

### Modified Capabilities
<!-- Existing capabilities whose REQUIREMENTS are changing (not just implementation).
     Only list here if spec-level behavior changes. Each needs a delta spec file.
     Use existing spec names from openspec/specs/. Leave empty if no requirement changes. -->
- `<existing-name>`: <what requirement is changing>

## Impact

<!-- Affected code, APIs, dependencies, systems -->



================================================
FILE: schemas/spec-driven/templates/spec.md
================================================
## ADDED Requirements

### Requirement: <!-- requirement name -->
<!-- requirement text -->

#### Scenario: <!-- scenario name -->
- **WHEN** <!-- condition -->
- **THEN** <!-- expected outcome -->



================================================
FILE: schemas/spec-driven/templates/tasks.md
================================================
## 1. <!-- Task Group Name -->

- [ ] 1.1 <!-- Task description -->
- [ ] 1.2 <!-- Task description -->

## 2. <!-- Task Group Name -->

- [ ] 2.1 <!-- Task description -->
- [ ] 2.2 <!-- Task description -->



================================================
FILE: schemas/tdd/schema.yaml
================================================
name: tdd
version: 1
description: Test-driven development workflow - tests â†’ implementation â†’ docs
artifacts:
  - id: spec
    generates: spec.md
    description: Feature specification defining requirements
    template: spec.md
    instruction: |
      Create the feature specification that defines WHAT to build.

      Sections:
      - **Feature**: Name and high-level description of the feature's purpose and user value
      - **Requirements**: List of specific requirements. Use SHALL/MUST for normative language.
      - **Acceptance Criteria**: Testable criteria in WHEN/THEN format

      Format requirements:
      - Each requirement should be specific and testable
      - Use `#### Scenario: <name>` with WHEN/THEN format for acceptance criteria
      - Define edge cases and error scenarios explicitly
      - Every requirement MUST have at least one scenario

      Example:
      ```
      ## Feature: User Authentication

      Users can securely log into the application.

      ## Requirements

      ### Requirement: Password validation
      The system SHALL validate passwords meet minimum security requirements.

      #### Scenario: Valid password accepted
      - **WHEN** password has 8+ chars, uppercase, lowercase, and number
      - **THEN** password is accepted

      #### Scenario: Weak password rejected
      - **WHEN** password is less than 8 characters
      - **THEN** system displays "Password too short" error
      ```

      This spec drives test creation - each scenario becomes a test case.
    requires: []

  - id: tests
    generates: "tests/*.test.ts"
    description: Test files written before implementation
    template: test.md
    instruction: |
      Write tests BEFORE implementation (TDD red phase).

      File naming:
      - Create test files as `tests/<feature>.test.ts`
      - One test file per feature/capability
      - Use descriptive names matching the spec

      Test structure:
      - Use Given/When/Then format matching spec scenarios
      - Group related tests with `describe()` blocks
      - Each scenario from spec becomes at least one `it()` test

      Coverage requirements:
      - Cover each requirement from the spec
      - Include happy path (success cases)
      - Include edge cases (boundary conditions)
      - Include error scenarios (invalid input, failures)
      - Tests should fail initially (no implementation yet)

      Example:
      ```typescript
      describe('Password validation', () => {
        it('accepts valid password with all requirements', () => {
          // GIVEN a password meeting all requirements
          const password = 'SecurePass1';
          // WHEN validating
          const result = validatePassword(password);
          // THEN it should be accepted
          expect(result.valid).toBe(true);
        });

        it('rejects password shorter than 8 characters', () => {
          // GIVEN a short password
          const password = 'Short1';
          // WHEN validating
          const result = validatePassword(password);
          // THEN it should be rejected with message
          expect(result.valid).toBe(false);
          expect(result.error).toBe('Password too short');
        });
      });
      ```

      Follow the spec requirements exactly - tests verify the spec.
    requires:
      - spec

  - id: implementation
    generates: "src/*.ts"
    description: Implementation code to pass the tests
    template: implementation.md
    instruction: |
      Implement the feature to make tests pass (TDD green phase).

      TDD workflow:
      1. Run tests - confirm they fail (red)
      2. Write minimal code to pass ONE test
      3. Run tests - confirm that test passes (green)
      4. Refactor if needed while keeping tests green
      5. Repeat for next failing test

      Implementation guidelines:
      - Write minimal code to pass each test - no more, no less
      - Run tests frequently to verify progress
      - Keep functions small and focused
      - Use clear, descriptive names

      Code organization:
      - Create source files in `src/<feature>.ts`
      - Export public API clearly
      - Keep implementation details private
      - Add JSDoc comments for public functions

      Example structure:
      ```typescript
      /**
       * Validates a password meets security requirements.
       * @param password - The password to validate
       * @returns Validation result with valid flag and optional error
       */
      export function validatePassword(password: string): ValidationResult {
        if (password.length < 8) {
          return { valid: false, error: 'Password too short' };
        }
        // ... additional checks
        return { valid: true };
      }
      ```

      Don't over-engineer - implement only what tests require.
    requires:
      - tests

  - id: docs
    generates: "docs/*.md"
    description: Documentation for the implemented feature
    template: docs.md
    instruction: |
      Document the implemented feature.

      Sections:
      - **Overview**: What the feature does and why it exists (1-2 paragraphs)
      - **Getting Started**: Quick start guide to use the feature immediately
      - **Examples**: Code examples showing common use cases
      - **Reference**: Detailed API documentation, configuration options

      Guidelines:
      - Write for the user, not the developer
      - Start with the most common use case
      - Include copy-pasteable code examples
      - Document all configuration options with defaults
      - Note any limitations, edge cases, or gotchas
      - Link to related features or specs

      Example structure:
      ```markdown
      ## Overview

      Password validation ensures user passwords meet security requirements
      before account creation or password changes.

      ## Getting Started

      Import and use the validation function:

      ```typescript
      import { validatePassword } from './password';

      const result = validatePassword('MySecurePass1');
      if (!result.valid) {
        console.error(result.error);
      }
      ```

      ## Examples

      ### Basic validation
      ...

      ### Custom error handling
      ...

      ## Reference

      ### validatePassword(password)

      | Parameter | Type | Description |
      |-----------|------|-------------|
      | password | string | The password to validate |

      **Returns**: `{ valid: boolean, error?: string }`
      ```

      Reference the spec for requirements, implementation for details.
    requires:
      - implementation

apply:
  requires: [tests]
  tracks: null
  instruction: |
    Run tests to see failures. Implement minimal code to pass each test.
    Refactor while keeping tests green.



================================================
FILE: schemas/tdd/templates/docs.md
================================================
## Overview

<!-- Feature overview -->

## Getting Started

<!-- Quick start guide -->

## Examples

<!-- Code examples -->

## Reference

<!-- API reference or additional details -->



================================================
FILE: schemas/tdd/templates/implementation.md
================================================
## Implementation Notes

<!-- Technical implementation details -->

## API

<!-- Public API documentation -->

## Usage

<!-- Usage examples -->



================================================
FILE: schemas/tdd/templates/spec.md
================================================
## Feature: <!-- feature name -->

<!-- Feature description -->

## Requirements

<!-- List of requirements -->

## Acceptance Criteria

<!-- List of acceptance criteria -->



================================================
FILE: schemas/tdd/templates/test.md
================================================
## Test Plan

<!-- Describe the testing strategy -->

## Test Cases

### <!-- Test case name -->

- **Given:** <!-- preconditions -->
- **When:** <!-- action -->
- **Then:** <!-- expected result -->



================================================
FILE: scripts/README.md
================================================
# OpenSpec Scripts

Utility scripts for OpenSpec maintenance and development.

## update-flake.sh

Updates `flake.nix` version and dependency hash automatically.

**When to use**: After updating dependencies or releasing a new version.

**Usage**:
```bash
./scripts/update-flake.sh
```

**What it does**:
1. Extracts version from `package.json`
2. Updates version in `flake.nix`
3. Automatically determines the correct pnpm dependency hash
4. Updates the hash in `flake.nix`
5. Verifies the build succeeds

**Example workflow**:
```bash
# After version bump and dependency updates
pnpm install
./scripts/update-flake.sh
git add flake.nix
git commit -m "chore: update flake.nix for v0.18.0"
```

## postinstall.js

Post-installation script that runs after package installation.

## pack-version-check.mjs

Validates package version consistency before publishing.



================================================
FILE: scripts/pack-version-check.mjs
================================================
#!/usr/bin/env node
// Guard: Ensure the packed tarball's CLI `--version` matches package.json.
//
// Notes:
// - We intentionally use `npm pack` (not pnpm) because `npm pack --json` is
//   consistently supported and returns the tarball metadata we need. The
//   project uses pnpm for install/publish, but this guard only needs to pack
//   locally and verify the installed CLI output.
// - `npm pack` triggers the package's `prepare` script (build), and
//   `changeset publish` triggers `prepublishOnly` (also builds here). This
//   means an explicit build is not strictly necessary for the guard.

import { execFileSync } from 'child_process';
import { mkdtempSync, readFileSync, rmSync, writeFileSync } from 'fs';
import { tmpdir } from 'os';
import path from 'path';

function log(msg) {
  if (process.env.CI) return; // keep CI logs quiet by default
  console.log(msg);
}

function run(cmd, args, opts = {}) {
  return execFileSync(cmd, args, { encoding: 'utf-8', stdio: ['ignore', 'pipe', 'pipe'], ...opts });
}

function npmPack() {
  try {
    const jsonOut = run('npm', ['pack', '--json', '--silent']);
    const arr = JSON.parse(jsonOut);
    if (Array.isArray(arr) && arr.length > 0) {
      const last = arr[arr.length - 1];
      const file = (last && typeof last === 'object' && last.filename) || (typeof last === 'string' ? last : null);
      if (file) return String(file).trim();
    }
    // Unexpected JSON shape or empty array; fallback to plain output
    const out = run('npm', ['pack', '--silent']).trim();
    const lines = out.split(/\r?\n/);
    return lines[lines.length - 1].trim();
  } catch (e) {
    // Fallback for environments not supporting --json
    const out = run('npm', ['pack', '--silent']).trim();
    const lines = out.split(/\r?\n/);
    return lines[lines.length - 1].trim();
  }
}

function main() {
  const pkg = JSON.parse(readFileSync(path.join(process.cwd(), 'package.json'), 'utf-8'));
  const expected = pkg.version;

  let work;
  let tgzPath;

  try {
    log(`Packing @fission-ai/openspec@${expected}...`);
    const filename = npmPack();
    tgzPath = path.resolve(filename);
    log(`Created: ${tgzPath}`);

    work = mkdtempSync(path.join(tmpdir(), 'openspec-pack-check-'));
    log(`Temp dir: ${work}`);

    // Make a tiny project
    writeFileSync(
      path.join(work, 'package.json'),
      JSON.stringify({ name: 'pack-check', private: true }, null, 2)
    );

    // Try to avoid noisy output and speed up
    const env = {
      ...process.env,
      npm_config_loglevel: 'silent',
      npm_config_audit: 'false',
      npm_config_fund: 'false',
      npm_config_progress: 'false',
    };

    // Install the tarball
    run('npm', ['install', tgzPath, '--silent', '--no-audit', '--no-fund'], { cwd: work, env });

    // Run the installed CLI via Node to avoid bin resolution/platform issues
    const binRel = path.join('node_modules', '@fission-ai', 'openspec', 'bin', 'openspec.js');
    const actual = run(process.execPath, [binRel, '--version'], { cwd: work }).trim();

    if (actual !== expected) {
      throw new Error(
        `Packed CLI version mismatch: expected ${expected}, got ${actual}. ` +
          'Ensure the dist is built and the CLI reads version from package.json.'
      );
    }

    log('Version check passed.');
  } finally {
    // Always attempt cleanup
    if (work) {
      try { rmSync(work, { recursive: true, force: true }); } catch {}
    }
    if (tgzPath) {
      try { rmSync(tgzPath, { force: true }); } catch {}
    }
  }
}

try {
  main();
  console.log('âœ… pack-version-check: OK');
} catch (err) {
  console.error(`âŒ pack-version-check: ${err.message}`);
  process.exit(1);
}



================================================
FILE: scripts/postinstall.js
================================================
#!/usr/bin/env node

/**
 * Postinstall script for auto-installing shell completions
 *
 * This script runs automatically after npm install unless:
 * - CI=true environment variable is set
 * - OPENSPEC_NO_COMPLETIONS=1 environment variable is set
 * - dist/ directory doesn't exist (dev setup scenario)
 *
 * The script never fails npm install - all errors are caught and handled gracefully.
 */

import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * Check if we should skip installation
 */
function shouldSkipInstallation() {
  // Skip in CI environments
  if (process.env.CI === 'true' || process.env.CI === '1') {
    return { skip: true, reason: 'CI environment detected' };
  }

  // Skip if user opted out
  if (process.env.OPENSPEC_NO_COMPLETIONS === '1') {
    return { skip: true, reason: 'OPENSPEC_NO_COMPLETIONS=1 set' };
  }

  return { skip: false };
}

/**
 * Check if dist/ directory exists
 */
async function distExists() {
  const distPath = path.join(__dirname, '..', 'dist');
  try {
    const stat = await fs.stat(distPath);
    return stat.isDirectory();
  } catch {
    return false;
  }
}

/**
 * Detect the user's shell
 */
async function detectShell() {
  try {
    const { detectShell } = await import('../dist/utils/shell-detection.js');
    const result = detectShell();
    return result.shell;
  } catch (error) {
    // Fail silently if detection module doesn't exist
    return undefined;
  }
}

/**
 * Install completions for the detected shell
 */
async function installCompletions(shell) {
  try {
    const { CompletionFactory } = await import('../dist/core/completions/factory.js');
    const { COMMAND_REGISTRY } = await import('../dist/core/completions/command-registry.js');

    // Check if shell is supported
    if (!CompletionFactory.isSupported(shell)) {
      console.log(`\nTip: Run 'openspec completion install' for shell completions`);
      return;
    }

    // Generate completion script
    const generator = CompletionFactory.createGenerator(shell);
    const script = generator.generate(COMMAND_REGISTRY);

    // Install completion script
    const installer = CompletionFactory.createInstaller(shell);
    const result = await installer.install(script);

    if (result.success) {
      // Show success message based on installation type
      if (result.isOhMyZsh) {
        console.log(`âœ“ Shell completions installed`);
        console.log(`  Restart shell: exec zsh`);
      } else if (result.zshrcConfigured) {
        console.log(`âœ“ Shell completions installed and configured`);
        console.log(`  Restart shell: exec zsh`);
      } else {
        console.log(`âœ“ Shell completions installed to ~/.zsh/completions/`);
        console.log(`  Add to ~/.zshrc: fpath=(~/.zsh/completions $fpath)`);
        console.log(`  Then: exec zsh`);
      }
    } else {
      // Installation failed, show tip for manual install
      console.log(`\nTip: Run 'openspec completion install' for shell completions`);
    }
  } catch (error) {
    // Fail gracefully - show tip for manual install
    console.log(`\nTip: Run 'openspec completion install' for shell completions`);
  }
}

/**
 * Main function
 */
async function main() {
  try {
    // Check if we should skip
    const skipCheck = shouldSkipInstallation();
    if (skipCheck.skip) {
      // Silent skip - no output
      return;
    }

    // Check if dist/ exists (skip silently if not - expected during dev setup)
    if (!(await distExists())) {
      return;
    }

    // Detect shell
    const shell = await detectShell();
    if (!shell) {
      console.log(`\nTip: Run 'openspec completion install' for shell completions`);
      return;
    }

    // Install completions
    await installCompletions(shell);
  } catch (error) {
    // Fail gracefully - never break npm install
    // Show tip for manual install
    console.log(`\nTip: Run 'openspec completion install' for shell completions`);
  }
}

// Run main and handle any unhandled errors
main().catch(() => {
  // Silent failure - never break npm install
  process.exit(0);
});



================================================
FILE: scripts/test-postinstall.sh
================================================
#!/bin/bash

# Test script for postinstall.js
# Tests different scenarios: normal install, CI, opt-out

set -e

echo "======================================"
echo "Testing OpenSpec Postinstall Script"
echo "======================================"
echo ""

# Save original environment
ORIGINAL_CI="${CI:-}"
ORIGINAL_OPENSPEC_NO_COMPLETIONS="${OPENSPEC_NO_COMPLETIONS:-}"

# Test 1: Normal install
echo "Test 1: Normal install (should attempt to install completions)"
echo "--------------------------------------"
unset CI
unset OPENSPEC_NO_COMPLETIONS
node scripts/postinstall.js
echo ""

# Test 2: CI environment (should skip silently)
echo "Test 2: CI=true (should skip silently)"
echo "--------------------------------------"
export CI=true
node scripts/postinstall.js
echo "[No output expected - skipped due to CI]"
echo ""

# Test 3: Opt-out flag (should skip silently)
echo "Test 3: OPENSPEC_NO_COMPLETIONS=1 (should skip silently)"
echo "--------------------------------------"
unset CI
export OPENSPEC_NO_COMPLETIONS=1
node scripts/postinstall.js
echo "[No output expected - skipped due to opt-out]"
echo ""

# Restore original environment
if [ -n "$ORIGINAL_CI" ]; then
  export CI="$ORIGINAL_CI"
else
  unset CI
fi

if [ -n "$ORIGINAL_OPENSPEC_NO_COMPLETIONS" ]; then
  export OPENSPEC_NO_COMPLETIONS="$ORIGINAL_OPENSPEC_NO_COMPLETIONS"
else
  unset OPENSPEC_NO_COMPLETIONS
fi

echo "======================================"
echo "All tests completed successfully!"
echo "======================================"



================================================
FILE: scripts/update-flake.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

# Script to update flake.nix version and dependency hash
# Run this after updating package.json version

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
FLAKE_FILE="$PROJECT_ROOT/flake.nix"
PACKAGE_JSON="$PROJECT_ROOT/package.json"

# Detect OS and set sed in-place flag
if [[ "$OSTYPE" == "darwin"* ]]; then
  # macOS (BSD sed) requires empty string argument for -i
  SED_INPLACE=(-i '')
else
  # Linux (GNU sed)
  SED_INPLACE=(-i)
fi

echo "==> Updating flake.nix..."

# Extract version from package.json
VERSION=$(node -p "require('$PACKAGE_JSON').version")
echo "    Detected version: $VERSION"

# Update version in flake.nix
if ! grep -q "version = \"$VERSION\"" "$FLAKE_FILE"; then
  echo "    Updating version in flake.nix..."
  sed "${SED_INPLACE[@]}" "s|version = \"[^\"]*\"|version = \"$VERSION\"|" "$FLAKE_FILE"
else
  echo "    Version already up-to-date in flake.nix"
fi

# Set placeholder hash to trigger error
echo "    Setting placeholder hash..."
PLACEHOLDER="sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="
sed "${SED_INPLACE[@]}" "s|hash = \"sha256-[^\"]*\"|hash = \"$PLACEHOLDER\"|" "$FLAKE_FILE"

# Try to build and capture the correct hash
echo "    Building to get correct hash (this will fail)..."
BUILD_OUTPUT=$(nix build 2>&1 || true)

# Extract the correct hash from error output (portable - works on macOS and Linux)
CORRECT_HASH=$(echo "$BUILD_OUTPUT" | grep -o 'got:[[:space:]]*sha256-[A-Za-z0-9+/=]*' | head -1 | sed 's/got:[[:space:]]*//')

if [ -z "$CORRECT_HASH" ]; then
  echo "âŒ Error: Could not extract hash from build output"
  echo "Build output:"
  echo "$BUILD_OUTPUT"
  exit 1
fi

echo "    Detected hash: $CORRECT_HASH"

# Update flake.nix with correct hash
sed "${SED_INPLACE[@]}" "s|hash = \"$PLACEHOLDER\"|hash = \"$CORRECT_HASH\"|" "$FLAKE_FILE"

# Verify the build works
echo "    Verifying build..."
if nix build 2>&1 | grep -q "warning: Git tree.*is dirty"; then
  echo "âš ï¸  Warning: Git tree is dirty, but build succeeded"
else
  echo "âœ… Build successful"
fi

echo ""
echo "âœ… flake.nix updated successfully!"
echo "   Version: $VERSION"
echo "   Hash: $CORRECT_HASH"
echo ""
echo "Next steps:"
echo "  1. Test: nix run . -- --version"
echo "  2. Commit: git add flake.nix"
echo "  3. Include in version bump commit"



================================================
FILE: src/index.ts
================================================
export * from './cli/index.js';
export * from './core/index.js';


================================================
FILE: src/cli/index.ts
================================================
import { Command } from 'commander';
import { createRequire } from 'module';
import ora from 'ora';
import path from 'path';
import { promises as fs } from 'fs';
import { AI_TOOLS } from '../core/config.js';
import { UpdateCommand } from '../core/update.js';
import { ListCommand } from '../core/list.js';
import { ArchiveCommand } from '../core/archive.js';
import { ViewCommand } from '../core/view.js';
import { registerSpecCommand } from '../commands/spec.js';
import { ChangeCommand } from '../commands/change.js';
import { ValidateCommand } from '../commands/validate.js';
import { ShowCommand } from '../commands/show.js';
import { CompletionCommand } from '../commands/completion.js';
import { FeedbackCommand } from '../commands/feedback.js';
import { registerConfigCommand } from '../commands/config.js';
import { registerArtifactWorkflowCommands } from '../commands/experimental/index.js';
import { registerSchemaCommand } from '../commands/schema.js';
import { maybeShowTelemetryNotice, trackCommand, shutdown } from '../telemetry/index.js';

const program = new Command();
const require = createRequire(import.meta.url);
const { version } = require('../../package.json');

/**
 * Get the full command path for nested commands.
 * For example: 'change show' -> 'change:show'
 */
function getCommandPath(command: Command): string {
  const names: string[] = [];
  let current: Command | null = command;

  while (current) {
    const name = current.name();
    // Skip the root 'openspec' command
    if (name && name !== 'openspec') {
      names.unshift(name);
    }
    current = current.parent;
  }

  return names.join(':') || 'openspec';
}

program
  .name('openspec')
  .description('AI-native system for spec-driven development')
  .version(version);

// Global options
program.option('--no-color', 'Disable color output');

// Apply global flags and telemetry before any command runs
// Note: preAction receives (thisCommand, actionCommand) where:
// - thisCommand: the command where hook was added (root program)
// - actionCommand: the command actually being executed (subcommand)
program.hook('preAction', async (thisCommand, actionCommand) => {
  const opts = thisCommand.opts();
  if (opts.color === false) {
    process.env.NO_COLOR = '1';
  }

  // Show first-run telemetry notice (if not seen)
  await maybeShowTelemetryNotice();

  // Track command execution (use actionCommand to get the actual subcommand)
  const commandPath = getCommandPath(actionCommand);
  await trackCommand(commandPath, version);
});

// Shutdown telemetry after command completes
program.hook('postAction', async () => {
  await shutdown();
});

const availableToolIds = AI_TOOLS.filter((tool) => tool.available).map((tool) => tool.value);
const toolsOptionDescription = `Configure AI tools non-interactively. Use "all", "none", or a comma-separated list of: ${availableToolIds.join(', ')}`;

program
  .command('init [path]')
  .description('Initialize OpenSpec in your project')
  .option('--tools <tools>', toolsOptionDescription)
  .action(async (targetPath = '.', options?: { tools?: string }) => {
    try {
      // Validate that the path is a valid directory
      const resolvedPath = path.resolve(targetPath);
      
      try {
        const stats = await fs.stat(resolvedPath);
        if (!stats.isDirectory()) {
          throw new Error(`Path "${targetPath}" is not a directory`);
        }
      } catch (error: any) {
        if (error.code === 'ENOENT') {
          // Directory doesn't exist, but we can create it
          console.log(`Directory "${targetPath}" doesn't exist, it will be created.`);
        } else if (error.message && error.message.includes('not a directory')) {
          throw error;
        } else {
          throw new Error(`Cannot access path "${targetPath}": ${error.message}`);
        }
      }
      
      const { InitCommand } = await import('../core/init.js');
      const initCommand = new InitCommand({
        tools: options?.tools,
      });
      await initCommand.execute(targetPath);
    } catch (error) {
      console.log(); // Empty line for spacing
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

program
  .command('update [path]')
  .description('Update OpenSpec instruction files')
  .action(async (targetPath = '.') => {
    try {
      const resolvedPath = path.resolve(targetPath);
      const updateCommand = new UpdateCommand();
      await updateCommand.execute(resolvedPath);
    } catch (error) {
      console.log(); // Empty line for spacing
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

program
  .command('list')
  .description('List items (changes by default). Use --specs to list specs.')
  .option('--specs', 'List specs instead of changes')
  .option('--changes', 'List changes explicitly (default)')
  .option('--sort <order>', 'Sort order: "recent" (default) or "name"', 'recent')
  .option('--json', 'Output as JSON (for programmatic use)')
  .action(async (options?: { specs?: boolean; changes?: boolean; sort?: string; json?: boolean }) => {
    try {
      const listCommand = new ListCommand();
      const mode: 'changes' | 'specs' = options?.specs ? 'specs' : 'changes';
      const sort = options?.sort === 'name' ? 'name' : 'recent';
      await listCommand.execute('.', mode, { sort, json: options?.json });
    } catch (error) {
      console.log(); // Empty line for spacing
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

program
  .command('view')
  .description('Display an interactive dashboard of specs and changes')
  .action(async () => {
    try {
      const viewCommand = new ViewCommand();
      await viewCommand.execute('.');
    } catch (error) {
      console.log(); // Empty line for spacing
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

// Change command with subcommands
const changeCmd = program
  .command('change')
  .description('Manage OpenSpec change proposals');

// Deprecation notice for noun-based commands
changeCmd.hook('preAction', () => {
  console.error('Warning: The "openspec change ..." commands are deprecated. Prefer verb-first commands (e.g., "openspec list", "openspec validate --changes").');
});

changeCmd
  .command('show [change-name]')
  .description('Show a change proposal in JSON or markdown format')
  .option('--json', 'Output as JSON')
  .option('--deltas-only', 'Show only deltas (JSON only)')
  .option('--requirements-only', 'Alias for --deltas-only (deprecated)')
  .option('--no-interactive', 'Disable interactive prompts')
  .action(async (changeName?: string, options?: { json?: boolean; requirementsOnly?: boolean; deltasOnly?: boolean; noInteractive?: boolean }) => {
    try {
      const changeCommand = new ChangeCommand();
      await changeCommand.show(changeName, options);
    } catch (error) {
      console.error(`Error: ${(error as Error).message}`);
      process.exitCode = 1;
    }
  });

changeCmd
  .command('list')
  .description('List all active changes (DEPRECATED: use "openspec list" instead)')
  .option('--json', 'Output as JSON')
  .option('--long', 'Show id and title with counts')
  .action(async (options?: { json?: boolean; long?: boolean }) => {
    try {
      console.error('Warning: "openspec change list" is deprecated. Use "openspec list".');
      const changeCommand = new ChangeCommand();
      await changeCommand.list(options);
    } catch (error) {
      console.error(`Error: ${(error as Error).message}`);
      process.exitCode = 1;
    }
  });

changeCmd
  .command('validate [change-name]')
  .description('Validate a change proposal')
  .option('--strict', 'Enable strict validation mode')
  .option('--json', 'Output validation report as JSON')
  .option('--no-interactive', 'Disable interactive prompts')
  .action(async (changeName?: string, options?: { strict?: boolean; json?: boolean; noInteractive?: boolean }) => {
    try {
      const changeCommand = new ChangeCommand();
      await changeCommand.validate(changeName, options);
      if (typeof process.exitCode === 'number' && process.exitCode !== 0) {
        process.exit(process.exitCode);
      }
    } catch (error) {
      console.error(`Error: ${(error as Error).message}`);
      process.exitCode = 1;
    }
  });

program
  .command('archive [change-name]')
  .description('Archive a completed change and update main specs')
  .option('-y, --yes', 'Skip confirmation prompts')
  .option('--skip-specs', 'Skip spec update operations (useful for infrastructure, tooling, or doc-only changes)')
  .option('--no-validate', 'Skip validation (not recommended, requires confirmation)')
  .action(async (changeName?: string, options?: { yes?: boolean; skipSpecs?: boolean; noValidate?: boolean; validate?: boolean }) => {
    try {
      const archiveCommand = new ArchiveCommand();
      await archiveCommand.execute(changeName, options);
    } catch (error) {
      console.log(); // Empty line for spacing
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

registerSpecCommand(program);
registerConfigCommand(program);
registerSchemaCommand(program);

// Top-level validate command
program
  .command('validate [item-name]')
  .description('Validate changes and specs')
  .option('--all', 'Validate all changes and specs')
  .option('--changes', 'Validate all changes')
  .option('--specs', 'Validate all specs')
  .option('--type <type>', 'Specify item type when ambiguous: change|spec')
  .option('--strict', 'Enable strict validation mode')
  .option('--json', 'Output validation results as JSON')
  .option('--concurrency <n>', 'Max concurrent validations (defaults to env OPENSPEC_CONCURRENCY or 6)')
  .option('--no-interactive', 'Disable interactive prompts')
  .action(async (itemName?: string, options?: { all?: boolean; changes?: boolean; specs?: boolean; type?: string; strict?: boolean; json?: boolean; noInteractive?: boolean; concurrency?: string }) => {
    try {
      const validateCommand = new ValidateCommand();
      await validateCommand.execute(itemName, options);
    } catch (error) {
      console.log();
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

// Top-level show command
program
  .command('show [item-name]')
  .description('Show a change or spec')
  .option('--json', 'Output as JSON')
  .option('--type <type>', 'Specify item type when ambiguous: change|spec')
  .option('--no-interactive', 'Disable interactive prompts')
  // change-only flags
  .option('--deltas-only', 'Show only deltas (JSON only, change)')
  .option('--requirements-only', 'Alias for --deltas-only (deprecated, change)')
  // spec-only flags
  .option('--requirements', 'JSON only: Show only requirements (exclude scenarios)')
  .option('--no-scenarios', 'JSON only: Exclude scenario content')
  .option('-r, --requirement <id>', 'JSON only: Show specific requirement by ID (1-based)')
  // allow unknown options to pass-through to underlying command implementation
  .allowUnknownOption(true)
  .action(async (itemName?: string, options?: { json?: boolean; type?: string; noInteractive?: boolean; [k: string]: any }) => {
    try {
      const showCommand = new ShowCommand();
      await showCommand.execute(itemName, options ?? {});
    } catch (error) {
      console.log();
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

// Feedback command
program
  .command('feedback <message>')
  .description('Submit feedback about OpenSpec')
  .option('--body <text>', 'Detailed description for the feedback')
  .action(async (message: string, options?: { body?: string }) => {
    try {
      const feedbackCommand = new FeedbackCommand();
      await feedbackCommand.execute(message, options);
    } catch (error) {
      console.log();
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

// Completion command with subcommands
const completionCmd = program
  .command('completion')
  .description('Manage shell completions for OpenSpec CLI');

completionCmd
  .command('generate [shell]')
  .description('Generate completion script for a shell (outputs to stdout)')
  .action(async (shell?: string) => {
    try {
      const completionCommand = new CompletionCommand();
      await completionCommand.generate({ shell });
    } catch (error) {
      console.log();
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

completionCmd
  .command('install [shell]')
  .description('Install completion script for a shell')
  .option('--verbose', 'Show detailed installation output')
  .action(async (shell?: string, options?: { verbose?: boolean }) => {
    try {
      const completionCommand = new CompletionCommand();
      await completionCommand.install({ shell, verbose: options?.verbose });
    } catch (error) {
      console.log();
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

completionCmd
  .command('uninstall [shell]')
  .description('Uninstall completion script for a shell')
  .option('-y, --yes', 'Skip confirmation prompts')
  .action(async (shell?: string, options?: { yes?: boolean }) => {
    try {
      const completionCommand = new CompletionCommand();
      await completionCommand.uninstall({ shell, yes: options?.yes });
    } catch (error) {
      console.log();
      ora().fail(`Error: ${(error as Error).message}`);
      process.exit(1);
    }
  });

// Hidden command for machine-readable completion data
program
  .command('__complete <type>', { hidden: true })
  .description('Output completion data in machine-readable format (internal use)')
  .action(async (type: string) => {
    try {
      const completionCommand = new CompletionCommand();
      await completionCommand.complete({ type });
    } catch (error) {
      // Silently fail for graceful shell completion experience
      process.exitCode = 1;
    }
  });

// Register artifact workflow commands (experimental)
registerArtifactWorkflowCommands(program);

program.parse();



================================================
FILE: src/commands/change.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import { JsonConverter } from '../core/converters/json-converter.js';
import { Validator } from '../core/validation/validator.js';
import { ChangeParser } from '../core/parsers/change-parser.js';
import { Change } from '../core/schemas/index.js';
import { isInteractive } from '../utils/interactive.js';
import { getActiveChangeIds } from '../utils/item-discovery.js';

// Constants for better maintainability
const ARCHIVE_DIR = 'archive';
const TASK_PATTERN = /^[-*]\s+\[[\sx]\]/i;
const COMPLETED_TASK_PATTERN = /^[-*]\s+\[x\]/i;

export class ChangeCommand {
  private converter: JsonConverter;

  constructor() {
    this.converter = new JsonConverter();
  }

  /**
   * Show a change proposal.
   * - Text mode: raw markdown passthrough (no filters)
   * - JSON mode: minimal object with deltas; --deltas-only returns same object with filtered deltas
   *   Note: --requirements-only is deprecated alias for --deltas-only
   */
  async show(changeName?: string, options?: { json?: boolean; requirementsOnly?: boolean; deltasOnly?: boolean; noInteractive?: boolean }): Promise<void> {
    const changesPath = path.join(process.cwd(), 'openspec', 'changes');

    if (!changeName) {
      const canPrompt = isInteractive(options);
      const changes = await this.getActiveChanges(changesPath);
      if (canPrompt && changes.length > 0) {
        const { select } = await import('@inquirer/prompts');
        const selected = await select({
          message: 'Select a change to show',
          choices: changes.map(id => ({ name: id, value: id })),
        });
        changeName = selected;
      } else {
        if (changes.length === 0) {
          console.error('No change specified. No active changes found.');
        } else {
          console.error(`No change specified. Available IDs: ${changes.join(', ')}`);
        }
        console.error('Hint: use "openspec change list" to view available changes.');
        process.exitCode = 1;
        return;
      }
    }

    const proposalPath = path.join(changesPath, changeName, 'proposal.md');

    try {
      await fs.access(proposalPath);
    } catch {
      throw new Error(`Change "${changeName}" not found at ${proposalPath}`);
    }

    if (options?.json) {
      const jsonOutput = await this.converter.convertChangeToJson(proposalPath);

      if (options.requirementsOnly) {
        console.error('Flag --requirements-only is deprecated; use --deltas-only instead.');
      }

      const parsed: Change = JSON.parse(jsonOutput);
      const contentForTitle = await fs.readFile(proposalPath, 'utf-8');
      const title = this.extractTitle(contentForTitle, changeName);
      const id = parsed.name;
      const deltas = parsed.deltas || [];

      if (options.requirementsOnly || options.deltasOnly) {
        const output = { id, title, deltaCount: deltas.length, deltas };
        console.log(JSON.stringify(output, null, 2));
      } else {
        const output = {
          id,
          title,
          deltaCount: deltas.length,
          deltas,
        };
        console.log(JSON.stringify(output, null, 2));
      }
    } else {
      const content = await fs.readFile(proposalPath, 'utf-8');
      console.log(content);
    }
  }

  /**
   * List active changes.
   * - Text default: IDs only; --long prints minimal details (title, counts)
   * - JSON: array of { id, title, deltaCount, taskStatus }, sorted by id
   */
  async list(options?: { json?: boolean; long?: boolean }): Promise<void> {
    const changesPath = path.join(process.cwd(), 'openspec', 'changes');
    
    const changes = await this.getActiveChanges(changesPath);
    
    if (options?.json) {
      const changeDetails = await Promise.all(
        changes.map(async (changeName) => {
          const proposalPath = path.join(changesPath, changeName, 'proposal.md');
          const tasksPath = path.join(changesPath, changeName, 'tasks.md');
          
          try {
            const content = await fs.readFile(proposalPath, 'utf-8');
            const changeDir = path.join(changesPath, changeName);
            const parser = new ChangeParser(content, changeDir);
            const change = await parser.parseChangeWithDeltas(changeName);
            
            let taskStatus = { total: 0, completed: 0 };
            try {
              const tasksContent = await fs.readFile(tasksPath, 'utf-8');
              taskStatus = this.countTasks(tasksContent);
            } catch (error) {
              // Tasks file may not exist, which is okay
              if (process.env.DEBUG) {
                console.error(`Failed to read tasks file at ${tasksPath}:`, error);
              }
            }
            
            return {
              id: changeName,
              title: this.extractTitle(content, changeName),
              deltaCount: change.deltas.length,
              taskStatus,
            };
          } catch (error) {
            return {
              id: changeName,
              title: 'Unknown',
              deltaCount: 0,
              taskStatus: { total: 0, completed: 0 },
            };
          }
        })
      );
      
      const sorted = changeDetails.sort((a, b) => a.id.localeCompare(b.id));
      console.log(JSON.stringify(sorted, null, 2));
    } else {
      if (changes.length === 0) {
        console.log('No items found');
        return;
      }
      const sorted = [...changes].sort();
      if (!options?.long) {
        // IDs only
        sorted.forEach(id => console.log(id));
        return;
      }

      // Long format: id: title and minimal counts
      for (const changeName of sorted) {
        const proposalPath = path.join(changesPath, changeName, 'proposal.md');
        const tasksPath = path.join(changesPath, changeName, 'tasks.md');
        try {
          const content = await fs.readFile(proposalPath, 'utf-8');
          const title = this.extractTitle(content, changeName);
          let taskStatusText = '';
          try {
            const tasksContent = await fs.readFile(tasksPath, 'utf-8');
            const { total, completed } = this.countTasks(tasksContent);
            taskStatusText = ` [tasks ${completed}/${total}]`;
          } catch (error) {
            if (process.env.DEBUG) {
              console.error(`Failed to read tasks file at ${tasksPath}:`, error);
            }
          }
          const changeDir = path.join(changesPath, changeName);
          const parser = new ChangeParser(await fs.readFile(proposalPath, 'utf-8'), changeDir);
          const change = await parser.parseChangeWithDeltas(changeName);
          const deltaCountText = ` [deltas ${change.deltas.length}]`;
          console.log(`${changeName}: ${title}${deltaCountText}${taskStatusText}`);
        } catch {
          console.log(`${changeName}: (unable to read)`);
        }
      }
    }
  }

  async validate(changeName?: string, options?: { strict?: boolean; json?: boolean; noInteractive?: boolean }): Promise<void> {
    const changesPath = path.join(process.cwd(), 'openspec', 'changes');
    
    if (!changeName) {
      const canPrompt = isInteractive(options);
      const changes = await getActiveChangeIds();
      if (canPrompt && changes.length > 0) {
        const { select } = await import('@inquirer/prompts');
        const selected = await select({
          message: 'Select a change to validate',
          choices: changes.map(id => ({ name: id, value: id })),
        });
        changeName = selected;
      } else {
        if (changes.length === 0) {
          console.error('No change specified. No active changes found.');
        } else {
          console.error(`No change specified. Available IDs: ${changes.join(', ')}`);
        }
        console.error('Hint: use "openspec change list" to view available changes.');
        process.exitCode = 1;
        return;
      }
    }
    
    const changeDir = path.join(changesPath, changeName);
    
    try {
      await fs.access(changeDir);
    } catch {
      throw new Error(`Change "${changeName}" not found at ${changeDir}`);
    }
    
    const validator = new Validator(options?.strict || false);
    const report = await validator.validateChangeDeltaSpecs(changeDir);
    
    if (options?.json) {
      console.log(JSON.stringify(report, null, 2));
    } else {
      if (report.valid) {
        console.log(`Change "${changeName}" is valid`);
      } else {
        console.error(`Change "${changeName}" has issues`);
        report.issues.forEach(issue => {
          const label = issue.level === 'ERROR' ? 'ERROR' : 'WARNING';
          const prefix = issue.level === 'ERROR' ? 'âœ—' : 'âš ';
          console.error(`${prefix} [${label}] ${issue.path}: ${issue.message}`);
        });
        // Next steps footer to guide fixing issues
        this.printNextSteps();
        if (!options?.json) {
          process.exitCode = 1;
        }
      }
    }
  }

  private async getActiveChanges(changesPath: string): Promise<string[]> {
    try {
      const entries = await fs.readdir(changesPath, { withFileTypes: true });
      const result: string[] = [];
      for (const entry of entries) {
        if (!entry.isDirectory() || entry.name.startsWith('.') || entry.name === ARCHIVE_DIR) continue;
        const proposalPath = path.join(changesPath, entry.name, 'proposal.md');
        try {
          await fs.access(proposalPath);
          result.push(entry.name);
        } catch {
          // skip directories without proposal.md
        }
      }
      return result.sort();
    } catch {
      return [];
    }
  }

  private extractTitle(content: string, changeName: string): string {
    const match = content.match(/^#\s+(?:Change:\s+)?(.+)$/im);
    return match ? match[1].trim() : changeName;
  }

  private countTasks(content: string): { total: number; completed: number } {
    const lines = content.split('\n');
    let total = 0;
    let completed = 0;
    
    for (const line of lines) {
      if (line.match(TASK_PATTERN)) {
        total++;
        if (line.match(COMPLETED_TASK_PATTERN)) {
          completed++;
        }
      }
    }
    
    return { total, completed };
  }

  private printNextSteps(): void {
    const bullets: string[] = [];
    bullets.push('- Ensure change has deltas in specs/: use headers ## ADDED/MODIFIED/REMOVED/RENAMED Requirements');
    bullets.push('- Each requirement MUST include at least one #### Scenario: block');
    bullets.push('- Debug parsed deltas: openspec change show <id> --json --deltas-only');
    console.error('Next steps:');
    bullets.forEach(b => console.error(`  ${b}`));
  }
}



================================================
FILE: src/commands/completion.ts
================================================
import ora from 'ora';
import { CompletionFactory } from '../core/completions/factory.js';
import { COMMAND_REGISTRY } from '../core/completions/command-registry.js';
import { detectShell, SupportedShell } from '../utils/shell-detection.js';
import { CompletionProvider } from '../core/completions/completion-provider.js';
import { getArchivedChangeIds } from '../utils/item-discovery.js';

interface GenerateOptions {
  shell?: string;
}

interface InstallOptions {
  shell?: string;
  verbose?: boolean;
}

interface UninstallOptions {
  shell?: string;
  yes?: boolean;
}

interface CompleteOptions {
  type: string;
}

/**
 * Command for managing shell completions for OpenSpec CLI
 */
export class CompletionCommand {
  private completionProvider: CompletionProvider;

  constructor() {
    this.completionProvider = new CompletionProvider();
  }
  /**
   * Resolve shell parameter or exit with error
   *
   * @param shell - The shell parameter (may be undefined)
   * @param operationName - Name of the operation (for error messages)
   * @returns Resolved shell or null if should exit
   */
  private resolveShellOrExit(shell: string | undefined, operationName: string): SupportedShell | null {
    const normalizedShell = this.normalizeShell(shell);

    if (!normalizedShell) {
      const detectionResult = detectShell();

      if (detectionResult.shell && CompletionFactory.isSupported(detectionResult.shell)) {
        return detectionResult.shell;
      }

      // Shell was detected but not supported
      if (detectionResult.detected && !detectionResult.shell) {
        console.error(`Error: Shell '${detectionResult.detected}' is not supported yet. Currently supported: ${CompletionFactory.getSupportedShells().join(', ')}`);
        process.exitCode = 1;
        return null;
      }

      // No shell specified and cannot auto-detect
      console.error('Error: Could not auto-detect shell. Please specify shell explicitly.');
      console.error(`Usage: openspec completion ${operationName} [shell]`);
      console.error(`Currently supported: ${CompletionFactory.getSupportedShells().join(', ')}`);
      process.exitCode = 1;
      return null;
    }

    if (!CompletionFactory.isSupported(normalizedShell)) {
      console.error(`Error: Shell '${normalizedShell}' is not supported yet. Currently supported: ${CompletionFactory.getSupportedShells().join(', ')}`);
      process.exitCode = 1;
      return null;
    }

    return normalizedShell;
  }

  /**
   * Generate completion script and output to stdout
   *
   * @param options - Options for generation (shell type)
   */
  async generate(options: GenerateOptions = {}): Promise<void> {
    const shell = this.resolveShellOrExit(options.shell, 'generate');
    if (!shell) return;

    await this.generateForShell(shell);
  }

  /**
   * Install completion script to the appropriate location
   *
   * @param options - Options for installation (shell type, verbose output)
   */
  async install(options: InstallOptions = {}): Promise<void> {
    const shell = this.resolveShellOrExit(options.shell, 'install');
    if (!shell) return;

    await this.installForShell(shell, options.verbose || false);
  }

  /**
   * Uninstall completion script from the installation location
   *
   * @param options - Options for uninstallation (shell type, yes flag)
   */
  async uninstall(options: UninstallOptions = {}): Promise<void> {
    const shell = this.resolveShellOrExit(options.shell, 'uninstall');
    if (!shell) return;

    await this.uninstallForShell(shell, options.yes || false);
  }

  /**
   * Generate completion script for a specific shell
   */
  private async generateForShell(shell: SupportedShell): Promise<void> {
    const generator = CompletionFactory.createGenerator(shell);
    const script = generator.generate(COMMAND_REGISTRY);
    console.log(script);
  }

  /**
   * Install completion script for a specific shell
   */
  private async installForShell(shell: SupportedShell, verbose: boolean): Promise<void> {
    const generator = CompletionFactory.createGenerator(shell);
    const installer = CompletionFactory.createInstaller(shell);

    const spinner = ora(`Installing ${shell} completion script...`).start();

    try {
      // Generate the completion script
      const script = generator.generate(COMMAND_REGISTRY);

      // Install it
      const result = await installer.install(script);

      spinner.stop();

      if (result.success) {
        console.log(`âœ“ ${result.message}`);

        if (verbose && result.installedPath) {
          console.log(`  Installed to: ${result.installedPath}`);
          if (result.backupPath) {
            console.log(`  Backup created: ${result.backupPath}`);
          }

          // Check if any shell config was updated
          const configWasUpdated = result.zshrcConfigured || result.bashrcConfigured || result.profileConfigured;

          if (configWasUpdated) {
            const configPaths: Record<string, string> = {
              zsh: '~/.zshrc',
              bash: '~/.bashrc',
              fish: '~/.config/fish/config.fish',
              powershell: '$PROFILE',
            };
            const configPath = configPaths[shell] || 'config file';
            console.log(`  ${configPath} configured automatically`);
          }
        }

        // Display warnings if present
        if (result.warnings && result.warnings.length > 0) {
          console.log('');
          for (const warning of result.warnings) {
            console.log(warning);
          }
        }

        // Print instructions (only shown if .zshrc wasn't auto-configured)
        if (result.instructions && result.instructions.length > 0) {
          console.log('');
          for (const instruction of result.instructions) {
            console.log(instruction);
          }
        } else {
          // Check if any shell config was updated (InstallationResult has: zshrcConfigured, bashrcConfigured, profileConfigured)
          const configWasUpdated = result.zshrcConfigured || result.bashrcConfigured || result.profileConfigured;

          if (configWasUpdated) {
            console.log('');

            // Shell-specific reload instructions
            const reloadCommands: Record<string, string> = {
              zsh: 'exec zsh',
              bash: 'exec bash',
              fish: 'exec fish',
              powershell: '. $PROFILE',
            };
            const reloadCmd = reloadCommands[shell] || `restart your ${shell} shell`;

            console.log(`Restart your shell or run: ${reloadCmd}`);
          }
        }
      } else {
        console.error(`âœ— ${result.message}`);
        process.exitCode = 1;
      }
    } catch (error) {
      spinner.stop();
      console.error(`âœ— Failed to install completion script: ${error instanceof Error ? error.message : String(error)}`);
      process.exitCode = 1;
    }
  }

  /**
   * Uninstall completion script for a specific shell
   */
  private async uninstallForShell(shell: SupportedShell, skipConfirmation: boolean): Promise<void> {
    const installer = CompletionFactory.createInstaller(shell);

    // Prompt for confirmation unless --yes flag is provided
    if (!skipConfirmation) {
      const { confirm } = await import('@inquirer/prompts');

      // Get shell-specific config file path
      const configPaths: Record<string, string> = {
        zsh: '~/.zshrc',
        bash: '~/.bashrc',
        fish: 'Fish configuration',  // Fish doesn't modify profile, just removes script file
        powershell: '$PROFILE',
      };
      const configPath = configPaths[shell] || `${shell} configuration`;

      const confirmed = await confirm({
        message: `Remove OpenSpec configuration from ${configPath}?`,
        default: false,
      });

      if (!confirmed) {
        console.log('Uninstall cancelled.');
        return;
      }
    }

    const spinner = ora(`Uninstalling ${shell} completion script...`).start();

    try {
      const result = await installer.uninstall();

      spinner.stop();

      if (result.success) {
        console.log(`âœ“ ${result.message}`);
      } else {
        console.error(`âœ— ${result.message}`);
        process.exitCode = 1;
      }
    } catch (error) {
      spinner.stop();
      console.error(`âœ— Failed to uninstall completion script: ${error instanceof Error ? error.message : String(error)}`);
      process.exitCode = 1;
    }
  }

  /**
   * Output machine-readable completion data for shell consumption
   * Format: tab-separated "id\tdescription" per line
   *
   * @param options - Options specifying completion type
   */
  async complete(options: CompleteOptions): Promise<void> {
    const type = options.type.toLowerCase();

    try {
      switch (type) {
        case 'changes': {
          const changeIds = await this.completionProvider.getChangeIds();
          for (const id of changeIds) {
            console.log(`${id}\tactive change`);
          }
          break;
        }
        case 'specs': {
          const specIds = await this.completionProvider.getSpecIds();
          for (const id of specIds) {
            console.log(`${id}\tspecification`);
          }
          break;
        }
        case 'archived-changes': {
          const archivedIds = await getArchivedChangeIds();
          for (const id of archivedIds) {
            console.log(`${id}\tarchived change`);
          }
          break;
        }
        default:
          // Invalid type - silently exit with no output for graceful shell completion failure
          process.exitCode = 1;
          break;
      }
    } catch {
      // Silently fail for graceful shell completion experience
      process.exitCode = 1;
    }
  }

  /**
   * Normalize shell parameter to lowercase
   */
  private normalizeShell(shell?: string): string | undefined {
    return shell?.toLowerCase();
  }
}



================================================
FILE: src/commands/config.ts
================================================
import { Command } from 'commander';
import { spawn } from 'node:child_process';
import * as fs from 'node:fs';
import {
  getGlobalConfigPath,
  getGlobalConfig,
  saveGlobalConfig,
  GlobalConfig,
} from '../core/global-config.js';
import {
  getNestedValue,
  setNestedValue,
  deleteNestedValue,
  coerceValue,
  formatValueYaml,
  validateConfigKeyPath,
  validateConfig,
  DEFAULT_CONFIG,
} from '../core/config-schema.js';

/**
 * Register the config command and all its subcommands.
 *
 * @param program - The Commander program instance
 */
export function registerConfigCommand(program: Command): void {
  const configCmd = program
    .command('config')
    .description('View and modify global OpenSpec configuration')
    .option('--scope <scope>', 'Config scope (only "global" supported currently)')
    .hook('preAction', (thisCommand) => {
      const opts = thisCommand.opts();
      if (opts.scope && opts.scope !== 'global') {
        console.error('Error: Project-local config is not yet implemented');
        process.exit(1);
      }
    });

  // config path
  configCmd
    .command('path')
    .description('Show config file location')
    .action(() => {
      console.log(getGlobalConfigPath());
    });

  // config list
  configCmd
    .command('list')
    .description('Show all current settings')
    .option('--json', 'Output as JSON')
    .action((options: { json?: boolean }) => {
      const config = getGlobalConfig();

      if (options.json) {
        console.log(JSON.stringify(config, null, 2));
      } else {
        console.log(formatValueYaml(config));
      }
    });

  // config get
  configCmd
    .command('get <key>')
    .description('Get a specific value (raw, scriptable)')
    .action((key: string) => {
      const config = getGlobalConfig();
      const value = getNestedValue(config as Record<string, unknown>, key);

      if (value === undefined) {
        process.exitCode = 1;
        return;
      }

      if (typeof value === 'object' && value !== null) {
        console.log(JSON.stringify(value));
      } else {
        console.log(String(value));
      }
    });

  // config set
  configCmd
    .command('set <key> <value>')
    .description('Set a value (auto-coerce types)')
    .option('--string', 'Force value to be stored as string')
    .option('--allow-unknown', 'Allow setting unknown keys')
    .action((key: string, value: string, options: { string?: boolean; allowUnknown?: boolean }) => {
      const allowUnknown = Boolean(options.allowUnknown);
      const keyValidation = validateConfigKeyPath(key);
      if (!keyValidation.valid && !allowUnknown) {
        const reason = keyValidation.reason ? ` ${keyValidation.reason}.` : '';
        console.error(`Error: Invalid configuration key "${key}".${reason}`);
        console.error('Use "openspec config list" to see available keys.');
        console.error('Pass --allow-unknown to bypass this check.');
        process.exitCode = 1;
        return;
      }

      const config = getGlobalConfig() as Record<string, unknown>;
      const coercedValue = coerceValue(value, options.string || false);

      // Create a copy to validate before saving
      const newConfig = JSON.parse(JSON.stringify(config));
      setNestedValue(newConfig, key, coercedValue);

      // Validate the new config
      const validation = validateConfig(newConfig);
      if (!validation.success) {
        console.error(`Error: Invalid configuration - ${validation.error}`);
        process.exitCode = 1;
        return;
      }

      // Apply changes and save
      setNestedValue(config, key, coercedValue);
      saveGlobalConfig(config as GlobalConfig);

      const displayValue =
        typeof coercedValue === 'string' ? `"${coercedValue}"` : String(coercedValue);
      console.log(`Set ${key} = ${displayValue}`);
    });

  // config unset
  configCmd
    .command('unset <key>')
    .description('Remove a key (revert to default)')
    .action((key: string) => {
      const config = getGlobalConfig() as Record<string, unknown>;
      const existed = deleteNestedValue(config, key);

      if (existed) {
        saveGlobalConfig(config as GlobalConfig);
        console.log(`Unset ${key} (reverted to default)`);
      } else {
        console.log(`Key "${key}" was not set`);
      }
    });

  // config reset
  configCmd
    .command('reset')
    .description('Reset configuration to defaults')
    .option('--all', 'Reset all configuration (required)')
    .option('-y, --yes', 'Skip confirmation prompts')
    .action(async (options: { all?: boolean; yes?: boolean }) => {
      if (!options.all) {
        console.error('Error: --all flag is required for reset');
        console.error('Usage: openspec config reset --all [-y]');
        process.exitCode = 1;
        return;
      }

      if (!options.yes) {
        const { confirm } = await import('@inquirer/prompts');
        const confirmed = await confirm({
          message: 'Reset all configuration to defaults?',
          default: false,
        });

        if (!confirmed) {
          console.log('Reset cancelled.');
          return;
        }
      }

      saveGlobalConfig({ ...DEFAULT_CONFIG });
      console.log('Configuration reset to defaults');
    });

  // config edit
  configCmd
    .command('edit')
    .description('Open config in $EDITOR')
    .action(async () => {
      const editor = process.env.EDITOR || process.env.VISUAL;

      if (!editor) {
        console.error('Error: No editor configured');
        console.error('Set the EDITOR or VISUAL environment variable to your preferred editor');
        console.error('Example: export EDITOR=vim');
        process.exitCode = 1;
        return;
      }

      const configPath = getGlobalConfigPath();

      // Ensure config file exists with defaults
      if (!fs.existsSync(configPath)) {
        saveGlobalConfig({ ...DEFAULT_CONFIG });
      }

      // Spawn editor and wait for it to close
      // Avoid shell parsing to correctly handle paths with spaces in both
      // the editor path and config path
      const child = spawn(editor, [configPath], {
        stdio: 'inherit',
        shell: false,
      });

      await new Promise<void>((resolve, reject) => {
        child.on('close', (code) => {
          if (code === 0) {
            resolve();
          } else {
            reject(new Error(`Editor exited with code ${code}`));
          }
        });
        child.on('error', reject);
      });

      try {
        const rawConfig = fs.readFileSync(configPath, 'utf-8');
        const parsedConfig = JSON.parse(rawConfig);
        const validation = validateConfig(parsedConfig);

        if (!validation.success) {
          console.error(`Error: Invalid configuration - ${validation.error}`);
          process.exitCode = 1;
        }
      } catch (error) {
        if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
          console.error(`Error: Config file not found at ${configPath}`);
        } else if (error instanceof SyntaxError) {
          console.error(`Error: Invalid JSON in ${configPath}`);
          console.error(error.message);
        } else {
          console.error(`Error: Unable to validate configuration - ${error instanceof Error ? error.message : String(error)}`);
        }
        process.exitCode = 1;
      }
    });
}



================================================
FILE: src/commands/feedback.ts
================================================
import { execSync, execFileSync } from 'child_process';
import { createRequire } from 'module';
import os from 'os';

const require = createRequire(import.meta.url);

/**
 * Check if gh CLI is installed and available in PATH
 * Uses platform-appropriate command: 'where' on Windows, 'which' on Unix/macOS
 */
function isGhInstalled(): boolean {
  try {
    const command = process.platform === 'win32' ? 'where gh' : 'which gh';
    execSync(command, { stdio: 'pipe' });
    return true;
  } catch {
    return false;
  }
}

/**
 * Check if gh CLI is authenticated
 */
function isGhAuthenticated(): boolean {
  try {
    execSync('gh auth status', { stdio: 'pipe' });
    return true;
  } catch {
    return false;
  }
}

/**
 * Get OpenSpec version from package.json
 */
function getVersion(): string {
  try {
    const { version } = require('../../package.json');
    return version;
  } catch {
    return 'unknown';
  }
}

/**
 * Get platform name
 */
function getPlatform(): string {
  return os.platform();
}

/**
 * Get current timestamp in ISO format
 */
function getTimestamp(): string {
  return new Date().toISOString();
}

/**
 * Generate metadata footer for feedback
 */
function generateMetadata(): string {
  const version = getVersion();
  const platform = getPlatform();
  const timestamp = getTimestamp();

  return `---
Submitted via OpenSpec CLI
- Version: ${version}
- Platform: ${platform}
- Timestamp: ${timestamp}`;
}

/**
 * Format the feedback title
 */
function formatTitle(message: string): string {
  return `Feedback: ${message}`;
}

/**
 * Format the full feedback body
 */
function formatBody(bodyText?: string): string {
  const parts: string[] = [];

  if (bodyText) {
    parts.push(bodyText);
    parts.push(''); // Empty line before metadata
  }

  parts.push(generateMetadata());

  return parts.join('\n');
}

/**
 * Generate a pre-filled GitHub issue URL for manual submission
 */
function generateManualSubmissionUrl(title: string, body: string): string {
  const repo = 'Fission-AI/OpenSpec';
  const encodedTitle = encodeURIComponent(title);
  const encodedBody = encodeURIComponent(body);
  const encodedLabels = encodeURIComponent('feedback');

  return `https://github.com/${repo}/issues/new?title=${encodedTitle}&body=${encodedBody}&labels=${encodedLabels}`;
}

/**
 * Display formatted feedback content for manual submission
 */
function displayFormattedFeedback(title: string, body: string): void {
  console.log('\n--- FORMATTED FEEDBACK ---');
  console.log(`Title: ${title}`);
  console.log(`Labels: feedback`);
  console.log('\nBody:');
  console.log(body);
  console.log('--- END FEEDBACK ---\n');
}

/**
 * Submit feedback via gh CLI
 * Uses execFileSync to prevent shell injection vulnerabilities
 */
function submitViaGhCli(title: string, body: string): void {
  try {
    const result = execFileSync(
      'gh',
      [
        'issue',
        'create',
        '--repo',
        'Fission-AI/OpenSpec',
        '--title',
        title,
        '--body',
        body,
        '--label',
        'feedback',
      ],
      { encoding: 'utf-8', stdio: 'pipe' }
    );

    const issueUrl = result.trim();
    console.log(`\nâœ“ Feedback submitted successfully!`);
    console.log(`Issue URL: ${issueUrl}\n`);
  } catch (error: any) {
    // Display the error output from gh CLI
    if (error.stderr) {
      console.error(error.stderr.toString());
    } else if (error.message) {
      console.error(error.message);
    }

    // Exit with the same code as gh CLI
    process.exit(error.status ?? 1);
  }
}

/**
 * Handle fallback when gh CLI is not available or not authenticated
 */
function handleFallback(title: string, body: string, reason: 'missing' | 'unauthenticated'): void {
  if (reason === 'missing') {
    console.log('âš ï¸  GitHub CLI not found. Manual submission required.');
  } else {
    console.log('âš ï¸  GitHub authentication required. Manual submission required.');
  }

  displayFormattedFeedback(title, body);

  const manualUrl = generateManualSubmissionUrl(title, body);
  console.log('Please submit your feedback manually:');
  console.log(manualUrl);

  if (reason === 'unauthenticated') {
    console.log('\nTo auto-submit in the future: gh auth login');
  }

  // Exit with success code (fallback is successful)
  process.exit(0);
}

/**
 * Feedback command implementation
 */
export class FeedbackCommand {
  async execute(message: string, options?: { body?: string }): Promise<void> {
    // Format title and body once for all code paths
    const title = formatTitle(message);
    const body = formatBody(options?.body);

    // Check if gh CLI is installed
    if (!isGhInstalled()) {
      handleFallback(title, body, 'missing');
      return;
    }

    // Check if gh CLI is authenticated
    if (!isGhAuthenticated()) {
      handleFallback(title, body, 'unauthenticated');
      return;
    }

    // Submit via gh CLI
    submitViaGhCli(title, body);
  }
}



================================================
FILE: src/commands/schema.ts
================================================
import { Command } from 'commander';
import * as fs from 'node:fs';
import * as path from 'node:path';
import ora from 'ora';
import { stringify as stringifyYaml } from 'yaml';
import {
  getSchemaDir,
  getProjectSchemasDir,
  getUserSchemasDir,
  getPackageSchemasDir,
  listSchemas,
} from '../core/artifact-graph/resolver.js';
import { parseSchema, SchemaValidationError } from '../core/artifact-graph/schema.js';
import type { SchemaYaml, Artifact } from '../core/artifact-graph/types.js';

/**
 * Schema source location type
 */
type SchemaSource = 'project' | 'user' | 'package';

/**
 * Result of checking a schema location
 */
interface SchemaLocation {
  source: SchemaSource;
  path: string;
  exists: boolean;
}

/**
 * Schema resolution info with shadowing details
 */
interface SchemaResolution {
  name: string;
  source: SchemaSource;
  path: string;
  shadows: Array<{ source: SchemaSource; path: string }>;
}

/**
 * Validation issue structure
 */
interface ValidationIssue {
  level: 'error' | 'warning';
  path: string;
  message: string;
}

/**
 * Check all three locations for a schema and return which ones exist.
 */
function checkAllLocations(
  name: string,
  projectRoot: string
): SchemaLocation[] {
  const locations: SchemaLocation[] = [];

  // Project location
  const projectDir = path.join(getProjectSchemasDir(projectRoot), name);
  const projectSchemaPath = path.join(projectDir, 'schema.yaml');
  locations.push({
    source: 'project',
    path: projectDir,
    exists: fs.existsSync(projectSchemaPath),
  });

  // User location
  const userDir = path.join(getUserSchemasDir(), name);
  const userSchemaPath = path.join(userDir, 'schema.yaml');
  locations.push({
    source: 'user',
    path: userDir,
    exists: fs.existsSync(userSchemaPath),
  });

  // Package location
  const packageDir = path.join(getPackageSchemasDir(), name);
  const packageSchemaPath = path.join(packageDir, 'schema.yaml');
  locations.push({
    source: 'package',
    path: packageDir,
    exists: fs.existsSync(packageSchemaPath),
  });

  return locations;
}

/**
 * Get resolution info for a schema including shadow detection.
 */
function getSchemaResolution(
  name: string,
  projectRoot: string
): SchemaResolution | null {
  const locations = checkAllLocations(name, projectRoot);
  const existingLocations = locations.filter((loc) => loc.exists);

  if (existingLocations.length === 0) {
    return null;
  }

  const active = existingLocations[0];
  const shadows = existingLocations.slice(1).map((loc) => ({
    source: loc.source,
    path: loc.path,
  }));

  return {
    name,
    source: active.source,
    path: active.path,
    shadows,
  };
}

/**
 * Get all schemas with resolution info.
 */
function getAllSchemasWithResolution(
  projectRoot: string
): SchemaResolution[] {
  const schemaNames = listSchemas(projectRoot);
  const results: SchemaResolution[] = [];

  for (const name of schemaNames) {
    const resolution = getSchemaResolution(name, projectRoot);
    if (resolution) {
      results.push(resolution);
    }
  }

  return results;
}

/**
 * Validate a schema and return issues.
 */
function validateSchema(
  schemaDir: string,
  verbose: boolean = false
): { valid: boolean; issues: ValidationIssue[] } {
  const issues: ValidationIssue[] = [];
  const schemaPath = path.join(schemaDir, 'schema.yaml');

  // Check schema.yaml exists
  if (verbose) {
    console.log('  Checking schema.yaml exists...');
  }
  if (!fs.existsSync(schemaPath)) {
    issues.push({
      level: 'error',
      path: 'schema.yaml',
      message: 'schema.yaml not found',
    });
    return { valid: false, issues };
  }

  // Parse YAML
  if (verbose) {
    console.log('  Parsing YAML...');
  }
  let content: string;
  try {
    content = fs.readFileSync(schemaPath, 'utf-8');
  } catch (err) {
    issues.push({
      level: 'error',
      path: 'schema.yaml',
      message: `Failed to read file: ${(err as Error).message}`,
    });
    return { valid: false, issues };
  }

  // Validate against Zod schema
  if (verbose) {
    console.log('  Validating schema structure...');
  }
  let schema: SchemaYaml;
  try {
    schema = parseSchema(content);
  } catch (err) {
    if (err instanceof SchemaValidationError) {
      issues.push({
        level: 'error',
        path: 'schema.yaml',
        message: err.message,
      });
    } else {
      issues.push({
        level: 'error',
        path: 'schema.yaml',
        message: `Parse error: ${(err as Error).message}`,
      });
    }
    return { valid: false, issues };
  }

  // Check template files exist
  // Templates can be in schemaDir directly or in a templates/ subdirectory
  if (verbose) {
    console.log('  Checking template files...');
  }
  for (const artifact of schema.artifacts) {
    // Try templates subdirectory first (standard location), then root
    const templatePathInTemplates = path.join(schemaDir, 'templates', artifact.template);
    const templatePathInRoot = path.join(schemaDir, artifact.template);

    if (!fs.existsSync(templatePathInTemplates) && !fs.existsSync(templatePathInRoot)) {
      issues.push({
        level: 'error',
        path: `artifacts.${artifact.id}.template`,
        message: `Template file '${artifact.template}' not found for artifact '${artifact.id}'`,
      });
    }
  }

  // Dependency graph validation is already done by parseSchema
  // (it throws on cycles and invalid references)
  if (verbose) {
    console.log('  Dependency graph validation passed (via parseSchema)');
  }

  return { valid: issues.length === 0, issues };
}

/**
 * Validate schema name format (kebab-case).
 */
function isValidSchemaName(name: string): boolean {
  return /^[a-z][a-z0-9]*(-[a-z0-9]+)*$/.test(name);
}

/**
 * Copy a directory recursively.
 */
function copyDirRecursive(src: string, dest: string): void {
  fs.mkdirSync(dest, { recursive: true });

  const entries = fs.readdirSync(src, { withFileTypes: true });
  for (const entry of entries) {
    const srcPath = path.join(src, entry.name);
    const destPath = path.join(dest, entry.name);

    if (entry.isDirectory()) {
      copyDirRecursive(srcPath, destPath);
    } else {
      fs.copyFileSync(srcPath, destPath);
    }
  }
}

/**
 * Default artifacts with descriptions for schema init.
 */
const DEFAULT_ARTIFACTS: Array<{
  id: string;
  description: string;
  generates: string;
  template: string;
}> = [
  {
    id: 'proposal',
    description: 'High-level description of the change, its motivation, and scope',
    generates: 'proposal.md',
    template: 'proposal.md',
  },
  {
    id: 'specs',
    description: 'Detailed specifications with requirements and scenarios',
    generates: 'specs/**/*.md',
    template: 'specs/spec.md',
  },
  {
    id: 'design',
    description: 'Technical design decisions and implementation approach',
    generates: 'design.md',
    template: 'design.md',
  },
  {
    id: 'tasks',
    description: 'Implementation checklist with trackable tasks',
    generates: 'tasks.md',
    template: 'tasks.md',
  },
];

/**
 * Register the schema command and all its subcommands.
 */
export function registerSchemaCommand(program: Command): void {
  const schemaCmd = program
    .command('schema')
    .description('Manage workflow schemas [experimental]');

  // Experimental warning
  schemaCmd.hook('preAction', () => {
    console.error('Note: Schema commands are experimental and may change.');
  });

  // schema which
  schemaCmd
    .command('which [name]')
    .description('Show where a schema resolves from')
    .option('--json', 'Output as JSON')
    .option('--all', 'List all schemas with their resolution sources')
    .action(async (name?: string, options?: { json?: boolean; all?: boolean }) => {
      try {
        const projectRoot = process.cwd();

        if (options?.all) {
          // List all schemas
          const schemas = getAllSchemasWithResolution(projectRoot);

          if (options?.json) {
            console.log(JSON.stringify(schemas, null, 2));
          } else {
            if (schemas.length === 0) {
              console.log('No schemas found.');
              return;
            }

            // Group by source
            const bySource = {
              project: schemas.filter((s) => s.source === 'project'),
              user: schemas.filter((s) => s.source === 'user'),
              package: schemas.filter((s) => s.source === 'package'),
            };

            if (bySource.project.length > 0) {
              console.log('\nProject schemas:');
              for (const schema of bySource.project) {
                const shadowInfo = schema.shadows.length > 0
                  ? ` (shadows: ${schema.shadows.map((s) => s.source).join(', ')})`
                  : '';
                console.log(`  ${schema.name}${shadowInfo}`);
              }
            }

            if (bySource.user.length > 0) {
              console.log('\nUser schemas:');
              for (const schema of bySource.user) {
                const shadowInfo = schema.shadows.length > 0
                  ? ` (shadows: ${schema.shadows.map((s) => s.source).join(', ')})`
                  : '';
                console.log(`  ${schema.name}${shadowInfo}`);
              }
            }

            if (bySource.package.length > 0) {
              console.log('\nPackage schemas:');
              for (const schema of bySource.package) {
                console.log(`  ${schema.name}`);
              }
            }
          }
          return;
        }

        if (!name) {
          console.error('Error: Schema name is required (or use --all to list all schemas)');
          process.exitCode = 1;
          return;
        }

        const resolution = getSchemaResolution(name, projectRoot);

        if (!resolution) {
          const available = listSchemas(projectRoot);
          if (options?.json) {
            console.log(JSON.stringify({
              error: `Schema '${name}' not found`,
              available,
            }, null, 2));
          } else {
            console.error(`Error: Schema '${name}' not found`);
            console.error(`Available schemas: ${available.join(', ')}`);
          }
          process.exitCode = 1;
          return;
        }

        if (options?.json) {
          console.log(JSON.stringify(resolution, null, 2));
        } else {
          console.log(`Schema: ${resolution.name}`);
          console.log(`Source: ${resolution.source}`);
          console.log(`Path: ${resolution.path}`);

          if (resolution.shadows.length > 0) {
            console.log('\nShadows:');
            for (const shadow of resolution.shadows) {
              console.log(`  ${shadow.source}: ${shadow.path}`);
            }
          }
        }
      } catch (error) {
        console.error(`Error: ${(error as Error).message}`);
        process.exitCode = 1;
      }
    });

  // schema validate
  schemaCmd
    .command('validate [name]')
    .description('Validate a schema structure and templates')
    .option('--json', 'Output as JSON')
    .option('--verbose', 'Show detailed validation steps')
    .action(async (name?: string, options?: { json?: boolean; verbose?: boolean }) => {
      try {
        const projectRoot = process.cwd();

        if (!name) {
          // Validate all project schemas
          const projectSchemasDir = getProjectSchemasDir(projectRoot);

          if (!fs.existsSync(projectSchemasDir)) {
            if (options?.json) {
              console.log(JSON.stringify({
                valid: true,
                message: 'No project schemas directory found',
                schemas: [],
              }, null, 2));
            } else {
              console.log('No project schemas directory found.');
            }
            return;
          }

          const entries = fs.readdirSync(projectSchemasDir, { withFileTypes: true });
          const schemaResults: Array<{
            name: string;
            path: string;
            valid: boolean;
            issues: ValidationIssue[];
          }> = [];

          let anyInvalid = false;

          for (const entry of entries) {
            if (!entry.isDirectory()) continue;

            const schemaDir = path.join(projectSchemasDir, entry.name);
            const schemaPath = path.join(schemaDir, 'schema.yaml');

            if (!fs.existsSync(schemaPath)) continue;

            if (options?.verbose && !options?.json) {
              console.log(`\nValidating ${entry.name}...`);
            }

            const result = validateSchema(schemaDir, options?.verbose && !options?.json);
            schemaResults.push({
              name: entry.name,
              path: schemaDir,
              valid: result.valid,
              issues: result.issues,
            });

            if (!result.valid) {
              anyInvalid = true;
            }
          }

          if (options?.json) {
            console.log(JSON.stringify({
              valid: !anyInvalid,
              schemas: schemaResults,
            }, null, 2));
          } else {
            if (schemaResults.length === 0) {
              console.log('No schemas found in project.');
              return;
            }

            console.log('\nValidation Results:');
            for (const result of schemaResults) {
              const status = result.valid ? 'âœ“' : 'âœ—';
              console.log(`  ${status} ${result.name}`);
              for (const issue of result.issues) {
                console.log(`    ${issue.level}: ${issue.message}`);
              }
            }

            if (anyInvalid) {
              process.exitCode = 1;
            }
          }
          return;
        }

        // Validate specific schema
        const schemaDir = getSchemaDir(name, projectRoot);

        if (!schemaDir) {
          const available = listSchemas(projectRoot);
          if (options?.json) {
            console.log(JSON.stringify({
              valid: false,
              error: `Schema '${name}' not found`,
              available,
            }, null, 2));
          } else {
            console.error(`Error: Schema '${name}' not found`);
            console.error(`Available schemas: ${available.join(', ')}`);
          }
          process.exitCode = 1;
          return;
        }

        if (options?.verbose && !options?.json) {
          console.log(`Validating ${name}...`);
        }

        const result = validateSchema(schemaDir, options?.verbose && !options?.json);

        if (options?.json) {
          console.log(JSON.stringify({
            name,
            path: schemaDir,
            valid: result.valid,
            issues: result.issues,
          }, null, 2));
        } else {
          if (result.valid) {
            console.log(`âœ“ Schema '${name}' is valid`);
          } else {
            console.log(`âœ— Schema '${name}' has errors:`);
            for (const issue of result.issues) {
              console.log(`  ${issue.level}: ${issue.message}`);
            }
            process.exitCode = 1;
          }
        }
      } catch (error) {
        if (options?.json) {
          console.log(JSON.stringify({
            valid: false,
            error: (error as Error).message,
          }, null, 2));
        } else {
          console.error(`Error: ${(error as Error).message}`);
        }
        process.exitCode = 1;
      }
    });

  // schema fork
  schemaCmd
    .command('fork <source> [name]')
    .description('Copy an existing schema to project for customization')
    .option('--json', 'Output as JSON')
    .option('--force', 'Overwrite existing destination')
    .action(async (source: string, name?: string, options?: { json?: boolean; force?: boolean }) => {
      const spinner = options?.json ? null : ora();

      try {
        const projectRoot = process.cwd();
        const destinationName = name || `${source}-custom`;

        // Validate destination name
        if (!isValidSchemaName(destinationName)) {
          if (options?.json) {
            console.log(JSON.stringify({
              forked: false,
              error: `Invalid schema name '${destinationName}'. Use kebab-case (e.g., my-workflow)`,
            }, null, 2));
          } else {
            console.error(`Error: Invalid schema name '${destinationName}'`);
            console.error('Schema names must be kebab-case (e.g., my-workflow)');
          }
          process.exitCode = 1;
          return;
        }

        // Find source schema
        const sourceDir = getSchemaDir(source, projectRoot);
        if (!sourceDir) {
          const available = listSchemas(projectRoot);
          if (options?.json) {
            console.log(JSON.stringify({
              forked: false,
              error: `Schema '${source}' not found`,
              available,
            }, null, 2));
          } else {
            console.error(`Error: Schema '${source}' not found`);
            console.error(`Available schemas: ${available.join(', ')}`);
          }
          process.exitCode = 1;
          return;
        }

        // Determine source location
        const sourceResolution = getSchemaResolution(source, projectRoot);
        const sourceLocation = sourceResolution?.source || 'package';

        // Check destination
        const destinationDir = path.join(getProjectSchemasDir(projectRoot), destinationName);

        if (fs.existsSync(destinationDir)) {
          if (!options?.force) {
            if (options?.json) {
              console.log(JSON.stringify({
                forked: false,
                error: `Schema '${destinationName}' already exists`,
                suggestion: 'Use --force to overwrite',
              }, null, 2));
            } else {
              console.error(`Error: Schema '${destinationName}' already exists at ${destinationDir}`);
              console.error('Use --force to overwrite');
            }
            process.exitCode = 1;
            return;
          }

          // Remove existing
          if (spinner) spinner.start(`Removing existing schema '${destinationName}'...`);
          fs.rmSync(destinationDir, { recursive: true });
        }

        // Copy schema
        if (spinner) spinner.start(`Forking '${source}' to '${destinationName}'...`);
        copyDirRecursive(sourceDir, destinationDir);

        // Update name in schema.yaml
        const destSchemaPath = path.join(destinationDir, 'schema.yaml');
        const schemaContent = fs.readFileSync(destSchemaPath, 'utf-8');
        const schema = parseSchema(schemaContent);
        schema.name = destinationName;

        fs.writeFileSync(destSchemaPath, stringifyYaml(schema));

        if (spinner) spinner.succeed(`Forked '${source}' to '${destinationName}'`);

        if (options?.json) {
          console.log(JSON.stringify({
            forked: true,
            source,
            sourcePath: sourceDir,
            sourceLocation,
            destination: destinationName,
            destinationPath: destinationDir,
          }, null, 2));
        } else {
          console.log(`\nSource: ${sourceDir} (${sourceLocation})`);
          console.log(`Destination: ${destinationDir}`);
          console.log(`\nYou can now customize the schema at:`);
          console.log(`  ${destinationDir}/schema.yaml`);
        }
      } catch (error) {
        if (spinner) spinner.fail(`Fork failed`);
        if (options?.json) {
          console.log(JSON.stringify({
            forked: false,
            error: (error as Error).message,
          }, null, 2));
        } else {
          console.error(`Error: ${(error as Error).message}`);
        }
        process.exitCode = 1;
      }
    });

  // schema init
  schemaCmd
    .command('init <name>')
    .description('Create a new project-local schema')
    .option('--json', 'Output as JSON')
    .option('--description <text>', 'Schema description')
    .option('--artifacts <list>', 'Comma-separated artifact IDs (proposal,specs,design,tasks)')
    .option('--default', 'Set as project default schema')
    .option('--no-default', 'Do not prompt to set as default')
    .option('--force', 'Overwrite existing schema')
    .action(async (
      name: string,
      options?: {
        json?: boolean;
        description?: string;
        artifacts?: string;
        default?: boolean;
        force?: boolean;
      }
    ) => {
      const spinner = options?.json ? null : ora();

      try {
        const projectRoot = process.cwd();

        // Validate name
        if (!isValidSchemaName(name)) {
          if (options?.json) {
            console.log(JSON.stringify({
              created: false,
              error: `Invalid schema name '${name}'. Use kebab-case (e.g., my-workflow)`,
            }, null, 2));
          } else {
            console.error(`Error: Invalid schema name '${name}'`);
            console.error('Schema names must be kebab-case (e.g., my-workflow)');
          }
          process.exitCode = 1;
          return;
        }

        const schemaDir = path.join(getProjectSchemasDir(projectRoot), name);

        // Check if exists
        if (fs.existsSync(schemaDir)) {
          if (!options?.force) {
            if (options?.json) {
              console.log(JSON.stringify({
                created: false,
                error: `Schema '${name}' already exists`,
                suggestion: 'Use --force to overwrite or "openspec schema fork" to copy',
              }, null, 2));
            } else {
              console.error(`Error: Schema '${name}' already exists at ${schemaDir}`);
              console.error('Use --force to overwrite or "openspec schema fork" to copy');
            }
            process.exitCode = 1;
            return;
          }

          if (spinner) spinner.start(`Removing existing schema '${name}'...`);
          fs.rmSync(schemaDir, { recursive: true });
        }

        // Determine artifacts and description
        let description: string;
        let selectedArtifactIds: string[];

        // Check if we have explicit flags (non-interactive mode)
        const hasExplicitOptions = options?.description !== undefined || options?.artifacts !== undefined;
        const isInteractive = !options?.json && !hasExplicitOptions && process.stdout.isTTY;

        if (isInteractive) {
          // Interactive mode
          const { input, checkbox, confirm } = await import('@inquirer/prompts');

          description = await input({
            message: 'Schema description:',
            default: `Custom workflow schema for ${name}`,
          });

          const artifactChoices = DEFAULT_ARTIFACTS.map((a) => ({
            name: a.id,
            value: a.id,
            checked: true,
          }));

          selectedArtifactIds = await checkbox({
            message: 'Select artifacts to include:',
            choices: artifactChoices,
          });

          if (selectedArtifactIds.length === 0) {
            console.error('Error: At least one artifact must be selected');
            process.exitCode = 1;
            return;
          }

          // Ask about setting as default (unless --no-default was passed)
          if (options?.default === undefined) {
            const setAsDefault = await confirm({
              message: 'Set as project default schema?',
              default: false,
            });

            if (setAsDefault) {
              options = { ...options, default: true };
            }
          }
        } else {
          // Non-interactive mode
          description = options?.description || `Custom workflow schema for ${name}`;

          if (options?.artifacts) {
            selectedArtifactIds = options.artifacts.split(',').map((a) => a.trim());

            // Validate artifact IDs
            const validIds = DEFAULT_ARTIFACTS.map((a) => a.id);
            for (const id of selectedArtifactIds) {
              if (!validIds.includes(id)) {
                if (options?.json) {
                  console.log(JSON.stringify({
                    created: false,
                    error: `Unknown artifact '${id}'`,
                    valid: validIds,
                  }, null, 2));
                } else {
                  console.error(`Error: Unknown artifact '${id}'`);
                  console.error(`Valid artifacts: ${validIds.join(', ')}`);
                }
                process.exitCode = 1;
                return;
              }
            }
          } else {
            // Default to all artifacts
            selectedArtifactIds = DEFAULT_ARTIFACTS.map((a) => a.id);
          }
        }

        // Create schema directory
        if (spinner) spinner.start(`Creating schema '${name}'...`);
        fs.mkdirSync(schemaDir, { recursive: true });

        // Build artifacts array with proper dependencies
        const selectedArtifacts = selectedArtifactIds.map((id) => {
          const template = DEFAULT_ARTIFACTS.find((a) => a.id === id)!;
          const artifact: Artifact = {
            id: template.id,
            generates: template.generates,
            description: template.description,
            template: template.template,
            requires: [],
          };

          // Set up dependencies based on typical workflow
          if (id === 'specs' && selectedArtifactIds.includes('proposal')) {
            artifact.requires = ['proposal'];
          } else if (id === 'design' && selectedArtifactIds.includes('specs')) {
            artifact.requires = ['specs'];
          } else if (id === 'tasks') {
            const requires: string[] = [];
            if (selectedArtifactIds.includes('design')) requires.push('design');
            else if (selectedArtifactIds.includes('specs')) requires.push('specs');
            artifact.requires = requires;
          }

          return artifact;
        });

        // Create schema.yaml
        const schema: SchemaYaml = {
          name,
          version: 1,
          description,
          artifacts: selectedArtifacts,
        };

        // Add apply phase if tasks is included
        if (selectedArtifactIds.includes('tasks')) {
          schema.apply = {
            requires: ['tasks'],
            tracks: 'tasks.md',
          };
        }

        fs.writeFileSync(
          path.join(schemaDir, 'schema.yaml'),
          stringifyYaml(schema)
        );

        // Create template files in templates/ subdirectory (standard location)
        const templatesDir = path.join(schemaDir, 'templates');
        for (const artifact of selectedArtifacts) {
          const templatePath = path.join(templatesDir, artifact.template);
          const templateDir = path.dirname(templatePath);

          if (!fs.existsSync(templateDir)) {
            fs.mkdirSync(templateDir, { recursive: true });
          }

          // Create default template content
          const templateContent = createDefaultTemplate(artifact.id);
          fs.writeFileSync(templatePath, templateContent);
        }

        // Update config if --default
        if (options?.default) {
          const configPath = path.join(projectRoot, 'openspec', 'config.yaml');

          if (fs.existsSync(configPath)) {
            const { parse: parseYaml, stringify: stringifyYaml2 } = await import('yaml');
            const configContent = fs.readFileSync(configPath, 'utf-8');
            const config = parseYaml(configContent) || {};
            config.defaultSchema = name;
            fs.writeFileSync(configPath, stringifyYaml2(config));
          } else {
            // Create config file
            const configDir = path.dirname(configPath);
            if (!fs.existsSync(configDir)) {
              fs.mkdirSync(configDir, { recursive: true });
            }
            fs.writeFileSync(configPath, stringifyYaml({ defaultSchema: name }));
          }
        }

        if (spinner) spinner.succeed(`Created schema '${name}'`);

        if (options?.json) {
          console.log(JSON.stringify({
            created: true,
            path: schemaDir,
            schema: name,
            artifacts: selectedArtifactIds,
            setAsDefault: options?.default || false,
          }, null, 2));
        } else {
          console.log(`\nSchema created at: ${schemaDir}`);
          console.log(`\nArtifacts: ${selectedArtifactIds.join(', ')}`);
          if (options?.default) {
            console.log(`\nSet as project default schema.`);
          }
          console.log(`\nNext steps:`);
          console.log(`  1. Edit ${schemaDir}/schema.yaml to customize artifacts`);
          console.log(`  2. Modify templates in the schema directory`);
          console.log(`  3. Use with: openspec new --schema ${name}`);
        }
      } catch (error) {
        if (spinner) spinner.fail(`Creation failed`);
        if (options?.json) {
          console.log(JSON.stringify({
            created: false,
            error: (error as Error).message,
          }, null, 2));
        } else {
          console.error(`Error: ${(error as Error).message}`);
        }
        process.exitCode = 1;
      }
    });
}

/**
 * Create default template content for an artifact.
 */
function createDefaultTemplate(artifactId: string): string {
  switch (artifactId) {
    case 'proposal':
      return `## Why

<!-- Describe the motivation for this change -->

## What Changes

<!-- Describe what will change -->

## Capabilities

### New Capabilities
<!-- List new capabilities -->

### Modified Capabilities
<!-- List modified capabilities -->

## Impact

<!-- Describe the impact on existing functionality -->
`;

    case 'specs':
      return `## ADDED Requirements

### Requirement: Example requirement

Description of the requirement.

#### Scenario: Example scenario
- **WHEN** some condition
- **THEN** some outcome
`;

    case 'design':
      return `## Context

<!-- Background and context -->

## Goals / Non-Goals

**Goals:**
<!-- List goals -->

**Non-Goals:**
<!-- List non-goals -->

## Decisions

### 1. Decision Name

Description and rationale.

**Alternatives considered:**
- Alternative 1: Rejected because...

## Risks / Trade-offs

<!-- List risks and trade-offs -->
`;

    case 'tasks':
      return `## Implementation Tasks

- [ ] Task 1
- [ ] Task 2
- [ ] Task 3
`;

    default:
      return `## ${artifactId}

<!-- Add content here -->
`;
  }
}



================================================
FILE: src/commands/show.ts
================================================
import path from 'path';
import { isInteractive } from '../utils/interactive.js';
import { getActiveChangeIds, getSpecIds } from '../utils/item-discovery.js';
import { ChangeCommand } from './change.js';
import { SpecCommand } from './spec.js';
import { nearestMatches } from '../utils/match.js';

type ItemType = 'change' | 'spec';

const CHANGE_FLAG_KEYS = new Set(['deltasOnly', 'requirementsOnly']);
const SPEC_FLAG_KEYS = new Set(['requirements', 'scenarios', 'requirement']);

export class ShowCommand {
  async execute(itemName?: string, options: { json?: boolean; type?: string; noInteractive?: boolean; [k: string]: any } = {}): Promise<void> {
    const interactive = isInteractive(options);
    const typeOverride = this.normalizeType(options.type);

    if (!itemName) {
      if (interactive) {
        const { select } = await import('@inquirer/prompts');
        const type = await select<ItemType>({
          message: 'What would you like to show?',
          choices: [
            { name: 'Change', value: 'change' as const },
            { name: 'Spec', value: 'spec' as const },
          ],
        });
        await this.runInteractiveByType(type, options);
        return;
      }
      this.printNonInteractiveHint();
      process.exitCode = 1;
      return;
    }

    await this.showDirect(itemName, { typeOverride, options });
  }

  private normalizeType(value?: string): ItemType | undefined {
    if (!value) return undefined;
    const v = value.toLowerCase();
    if (v === 'change' || v === 'spec') return v;
    return undefined;
  }

  private async runInteractiveByType(type: ItemType, options: { json?: boolean; noInteractive?: boolean; [k: string]: any }): Promise<void> {
    const { select } = await import('@inquirer/prompts');
    if (type === 'change') {
      const changes = await getActiveChangeIds();
      if (changes.length === 0) {
        console.error('No changes found.');
        process.exitCode = 1;
        return;
      }
      const picked = await select<string>({ message: 'Pick a change', choices: changes.map(id => ({ name: id, value: id })) });
      const cmd = new ChangeCommand();
      await cmd.show(picked, options as any);
      return;
    }

    const specs = await getSpecIds();
    if (specs.length === 0) {
      console.error('No specs found.');
      process.exitCode = 1;
      return;
    }
    const picked = await select<string>({ message: 'Pick a spec', choices: specs.map(id => ({ name: id, value: id })) });
    const cmd = new SpecCommand();
    await cmd.show(picked, options as any);
  }

  private async showDirect(itemName: string, params: { typeOverride?: ItemType; options: { json?: boolean; [k: string]: any } }): Promise<void> {
    // Optimize lookups when type is pre-specified
    let isChange = false;
    let isSpec = false;
    let changes: string[] = [];
    let specs: string[] = [];
    if (params.typeOverride === 'change') {
      changes = await getActiveChangeIds();
      isChange = changes.includes(itemName);
    } else if (params.typeOverride === 'spec') {
      specs = await getSpecIds();
      isSpec = specs.includes(itemName);
    } else {
      [changes, specs] = await Promise.all([getActiveChangeIds(), getSpecIds()]);
      isChange = changes.includes(itemName);
      isSpec = specs.includes(itemName);
    }

    const resolvedType = params.typeOverride ?? (isChange ? 'change' : isSpec ? 'spec' : undefined);

    if (!resolvedType) {
      console.error(`Unknown item '${itemName}'`);
      const suggestions = nearestMatches(itemName, [...changes, ...specs]);
      if (suggestions.length) console.error(`Did you mean: ${suggestions.join(', ')}?`);
      process.exitCode = 1;
      return;
    }

    if (!params.typeOverride && isChange && isSpec) {
      console.error(`Ambiguous item '${itemName}' matches both a change and a spec.`);
      console.error('Pass --type change|spec, or use: openspec change show / openspec spec show');
      process.exitCode = 1;
      return;
    }

    this.warnIrrelevantFlags(resolvedType, params.options);
    if (resolvedType === 'change') {
      const cmd = new ChangeCommand();
      await cmd.show(itemName, params.options as any);
      return;
    }
    const cmd = new SpecCommand();
    await cmd.show(itemName, params.options as any);
  }

  private printNonInteractiveHint(): void {
    console.error('Nothing to show. Try one of:');
    console.error('  openspec show <item>');
    console.error('  openspec change show');
    console.error('  openspec spec show');
    console.error('Or run in an interactive terminal.');
  }

  private warnIrrelevantFlags(type: ItemType, options: { [k: string]: any }): boolean {
    const irrelevant: string[] = [];
    if (type === 'change') {
      for (const k of SPEC_FLAG_KEYS) if (k in options) irrelevant.push(k);
    } else {
      for (const k of CHANGE_FLAG_KEYS) if (k in options) irrelevant.push(k);
    }
    if (irrelevant.length > 0) {
      console.error(`Warning: Ignoring flags not applicable to ${type}: ${irrelevant.join(', ')}`);
      return true;
    }
    return false;
  }
}



================================================
FILE: src/commands/spec.ts
================================================
import { program } from 'commander';
import { existsSync, readdirSync, readFileSync } from 'fs';
import { join } from 'path';
import { MarkdownParser } from '../core/parsers/markdown-parser.js';
import { Validator } from '../core/validation/validator.js';
import type { Spec } from '../core/schemas/index.js';
import { isInteractive } from '../utils/interactive.js';
import { getSpecIds } from '../utils/item-discovery.js';

const SPECS_DIR = 'openspec/specs';

interface ShowOptions {
  json?: boolean;
  // JSON-only filters (raw-first text has no filters)
  requirements?: boolean;
  scenarios?: boolean; // --no-scenarios sets this to false (JSON only)
  requirement?: string; // JSON only
  noInteractive?: boolean;
}

function parseSpecFromFile(specPath: string, specId: string): Spec {
  const content = readFileSync(specPath, 'utf-8');
  const parser = new MarkdownParser(content);
  return parser.parseSpec(specId);
}

function validateRequirementIndex(spec: Spec, requirementOpt?: string): number | undefined {
  if (!requirementOpt) return undefined;
  const index = Number.parseInt(requirementOpt, 10);
  if (!Number.isInteger(index) || index < 1 || index > spec.requirements.length) {
    throw new Error(`Requirement ${requirementOpt} not found`);
  }
  return index - 1; // convert to 0-based
}

function filterSpec(spec: Spec, options: ShowOptions): Spec {
  const requirementIndex = validateRequirementIndex(spec, options.requirement);
  const includeScenarios = options.scenarios !== false && !options.requirements;

  const filteredRequirements = (requirementIndex !== undefined
    ? [spec.requirements[requirementIndex]]
    : spec.requirements
  ).map(req => ({
    text: req.text,
    scenarios: includeScenarios ? req.scenarios : [],
  }));

  const metadata = spec.metadata ?? { version: '1.0.0', format: 'openspec' as const };

  return {
    name: spec.name,
    overview: spec.overview,
    requirements: filteredRequirements,
    metadata,
  };
}

/**
 * Print the raw markdown content for a spec file without any formatting.
 * Raw-first behavior ensures text mode is a passthrough for deterministic output.
 */
function printSpecTextRaw(specPath: string): void {
  const content = readFileSync(specPath, 'utf-8');
  console.log(content);
}

export class SpecCommand {
  private SPECS_DIR = 'openspec/specs';

  async show(specId?: string, options: ShowOptions = {}): Promise<void> {
    if (!specId) {
      const canPrompt = isInteractive(options);
      const specIds = await getSpecIds();
      if (canPrompt && specIds.length > 0) {
        const { select } = await import('@inquirer/prompts');
        specId = await select({
          message: 'Select a spec to show',
          choices: specIds.map(id => ({ name: id, value: id })),
        });
      } else {
        throw new Error('Missing required argument <spec-id>');
      }
    }

    const specPath = join(this.SPECS_DIR, specId, 'spec.md');
    if (!existsSync(specPath)) {
      throw new Error(`Spec '${specId}' not found at openspec/specs/${specId}/spec.md`);
    }

    if (options.json) {
      if (options.requirements && options.requirement) {
        throw new Error('Options --requirements and --requirement cannot be used together');
      }
      const parsed = parseSpecFromFile(specPath, specId);
      const filtered = filterSpec(parsed, options);
      const output = {
        id: specId,
        title: parsed.name,
        overview: parsed.overview,
        requirementCount: filtered.requirements.length,
        requirements: filtered.requirements,
        metadata: parsed.metadata ?? { version: '1.0.0', format: 'openspec' as const },
      };
      console.log(JSON.stringify(output, null, 2));
      return;
    }
    printSpecTextRaw(specPath);
  }
}

export function registerSpecCommand(rootProgram: typeof program) {
  const specCommand = rootProgram
    .command('spec')
    .description('Manage and view OpenSpec specifications');

  // Deprecation notice for noun-based commands
  specCommand.hook('preAction', () => {
    console.error('Warning: The "openspec spec ..." commands are deprecated. Prefer verb-first commands (e.g., "openspec show", "openspec validate --specs").');
  });

  specCommand
    .command('show [spec-id]')
    .description('Display a specific specification')
    .option('--json', 'Output as JSON')
    .option('--requirements', 'JSON only: Show only requirements (exclude scenarios)')
    .option('--no-scenarios', 'JSON only: Exclude scenario content')
    .option('-r, --requirement <id>', 'JSON only: Show specific requirement by ID (1-based)')
    .option('--no-interactive', 'Disable interactive prompts')
    .action(async (specId: string | undefined, options: ShowOptions & { noInteractive?: boolean }) => {
      try {
        const cmd = new SpecCommand();
        await cmd.show(specId, options as any);
      } catch (error) {
        console.error(`Error: ${error instanceof Error ? error.message : 'Unknown error'}`);
        process.exitCode = 1;
      }
    });

  specCommand
    .command('list')
    .description('List all available specifications')
    .option('--json', 'Output as JSON')
    .option('--long', 'Show id and title with counts')
    .action((options: { json?: boolean; long?: boolean }) => {
      try {
        if (!existsSync(SPECS_DIR)) {
          console.log('No items found');
          return;
        }

        const specs = readdirSync(SPECS_DIR, { withFileTypes: true })
          .filter(dirent => dirent.isDirectory())
          .map(dirent => {
            const specPath = join(SPECS_DIR, dirent.name, 'spec.md');
            if (existsSync(specPath)) {
              try {
                const spec = parseSpecFromFile(specPath, dirent.name);
                
                return {
                  id: dirent.name,
                  title: spec.name,
                  requirementCount: spec.requirements.length
                };
              } catch {
                return {
                  id: dirent.name,
                  title: dirent.name,
                  requirementCount: 0
                };
              }
            }
            return null;
          })
          .filter((spec): spec is { id: string; title: string; requirementCount: number } => spec !== null)
          .sort((a, b) => a.id.localeCompare(b.id));

        if (options.json) {
          console.log(JSON.stringify(specs, null, 2));
        } else {
          if (specs.length === 0) {
            console.log('No items found');
            return;
          }
          if (!options.long) {
            specs.forEach(spec => console.log(spec.id));
            return;
          }
          specs.forEach(spec => {
            console.log(`${spec.id}: ${spec.title} [requirements ${spec.requirementCount}]`);
          });
        }
      } catch (error) {
        console.error(`Error: ${error instanceof Error ? error.message : 'Unknown error'}`);
        process.exitCode = 1;
      }
    });

  specCommand
    .command('validate [spec-id]')
    .description('Validate a specification structure')
    .option('--strict', 'Enable strict validation mode')
    .option('--json', 'Output validation report as JSON')
    .option('--no-interactive', 'Disable interactive prompts')
    .action(async (specId: string | undefined, options: { strict?: boolean; json?: boolean; noInteractive?: boolean }) => {
      try {
        if (!specId) {
          const canPrompt = isInteractive(options);
          const specIds = await getSpecIds();
          if (canPrompt && specIds.length > 0) {
            const { select } = await import('@inquirer/prompts');
            specId = await select({
              message: 'Select a spec to validate',
              choices: specIds.map(id => ({ name: id, value: id })),
            });
          } else {
            throw new Error('Missing required argument <spec-id>');
          }
        }

        const specPath = join(SPECS_DIR, specId, 'spec.md');
        
        if (!existsSync(specPath)) {
          throw new Error(`Spec '${specId}' not found at openspec/specs/${specId}/spec.md`);
        }

        const validator = new Validator(options.strict);
        const report = await validator.validateSpec(specPath);

        if (options.json) {
          console.log(JSON.stringify(report, null, 2));
        } else {
          if (report.valid) {
            console.log(`Specification '${specId}' is valid`);
          } else {
            console.error(`Specification '${specId}' has issues`);
            report.issues.forEach(issue => {
              const label = issue.level === 'ERROR' ? 'ERROR' : issue.level;
              const prefix = issue.level === 'ERROR' ? 'âœ—' : issue.level === 'WARNING' ? 'âš ' : 'â„¹';
              console.error(`${prefix} [${label}] ${issue.path}: ${issue.message}`);
            });
          }
        }
        process.exitCode = report.valid ? 0 : 1;
      } catch (error) {
        console.error(`Error: ${error instanceof Error ? error.message : 'Unknown error'}`);
        process.exitCode = 1;
      }
    });

  return specCommand;
}



================================================
FILE: src/commands/validate.ts
================================================
import ora from 'ora';
import path from 'path';
import { Validator } from '../core/validation/validator.js';
import { isInteractive, resolveNoInteractive } from '../utils/interactive.js';
import { getActiveChangeIds, getSpecIds } from '../utils/item-discovery.js';
import { nearestMatches } from '../utils/match.js';

type ItemType = 'change' | 'spec';

interface ExecuteOptions {
  all?: boolean;
  changes?: boolean;
  specs?: boolean;
  type?: string;
  strict?: boolean;
  json?: boolean;
  noInteractive?: boolean;
  interactive?: boolean; // Commander sets this to false when --no-interactive is used
  concurrency?: string;
}

interface BulkItemResult {
  id: string;
  type: ItemType;
  valid: boolean;
  issues: { level: 'ERROR' | 'WARNING' | 'INFO'; path: string; message: string }[];
  durationMs: number;
}

export class ValidateCommand {
  async execute(itemName: string | undefined, options: ExecuteOptions = {}): Promise<void> {
    const interactive = isInteractive(options);

    // Handle bulk flags first
    if (options.all || options.changes || options.specs) {
      await this.runBulkValidation({
        changes: !!options.all || !!options.changes,
        specs: !!options.all || !!options.specs,
      }, { strict: !!options.strict, json: !!options.json, concurrency: options.concurrency, noInteractive: resolveNoInteractive(options) });
      return;
    }

    // No item and no flags
    if (!itemName) {
      if (interactive) {
        await this.runInteractiveSelector({ strict: !!options.strict, json: !!options.json, concurrency: options.concurrency });
        return;
      }
      this.printNonInteractiveHint();
      process.exitCode = 1;
      return;
    }

    // Direct item validation with type detection or override
    const typeOverride = this.normalizeType(options.type);
    await this.validateDirectItem(itemName, { typeOverride, strict: !!options.strict, json: !!options.json });
  }

  private normalizeType(value?: string): ItemType | undefined {
    if (!value) return undefined;
    const v = value.toLowerCase();
    if (v === 'change' || v === 'spec') return v;
    return undefined;
  }

  private async runInteractiveSelector(opts: { strict: boolean; json: boolean; concurrency?: string }): Promise<void> {
    const { select } = await import('@inquirer/prompts');
    const choice = await select({
      message: 'What would you like to validate?',
      choices: [
        { name: 'All (changes + specs)', value: 'all' },
        { name: 'All changes', value: 'changes' },
        { name: 'All specs', value: 'specs' },
        { name: 'Pick a specific change or spec', value: 'one' },
      ],
    });

    if (choice === 'all') return this.runBulkValidation({ changes: true, specs: true }, opts);
    if (choice === 'changes') return this.runBulkValidation({ changes: true, specs: false }, opts);
    if (choice === 'specs') return this.runBulkValidation({ changes: false, specs: true }, opts);

    // one
    const [changes, specs] = await Promise.all([getActiveChangeIds(), getSpecIds()]);
    const items: { name: string; value: { type: ItemType; id: string } }[] = [];
    items.push(...changes.map(id => ({ name: `change/${id}`, value: { type: 'change' as const, id } })));
    items.push(...specs.map(id => ({ name: `spec/${id}`, value: { type: 'spec' as const, id } })));
    if (items.length === 0) {
      console.error('No items found to validate.');
      process.exitCode = 1;
      return;
    }
    const picked = await select<{ type: ItemType; id: string }>({ message: 'Pick an item', choices: items });
    await this.validateByType(picked.type, picked.id, opts);
  }

  private printNonInteractiveHint(): void {
    console.error('Nothing to validate. Try one of:');
    console.error('  openspec validate --all');
    console.error('  openspec validate --changes');
    console.error('  openspec validate --specs');
    console.error('  openspec validate <item-name>');
    console.error('Or run in an interactive terminal.');
  }

  private async validateDirectItem(itemName: string, opts: { typeOverride?: ItemType; strict: boolean; json: boolean }): Promise<void> {
    const [changes, specs] = await Promise.all([getActiveChangeIds(), getSpecIds()]);
    const isChange = changes.includes(itemName);
    const isSpec = specs.includes(itemName);

    const type = opts.typeOverride ?? (isChange ? 'change' : isSpec ? 'spec' : undefined);

    if (!type) {
      console.error(`Unknown item '${itemName}'`);
      const suggestions = nearestMatches(itemName, [...changes, ...specs]);
      if (suggestions.length) console.error(`Did you mean: ${suggestions.join(', ')}?`);
      process.exitCode = 1;
      return;
    }

    if (!opts.typeOverride && isChange && isSpec) {
      console.error(`Ambiguous item '${itemName}' matches both a change and a spec.`);
      console.error('Pass --type change|spec, or use: openspec change validate / openspec spec validate');
      process.exitCode = 1;
      return;
    }

    await this.validateByType(type, itemName, opts);
  }

  private async validateByType(type: ItemType, id: string, opts: { strict: boolean; json: boolean }): Promise<void> {
    const validator = new Validator(opts.strict);
    if (type === 'change') {
      const changeDir = path.join(process.cwd(), 'openspec', 'changes', id);
      const start = Date.now();
      const report = await validator.validateChangeDeltaSpecs(changeDir);
      const durationMs = Date.now() - start;
      this.printReport('change', id, report, durationMs, opts.json);
      // Non-zero exit if invalid (keeps enriched output test semantics)
      process.exitCode = report.valid ? 0 : 1;
      return;
    }
    const file = path.join(process.cwd(), 'openspec', 'specs', id, 'spec.md');
    const start = Date.now();
    const report = await validator.validateSpec(file);
    const durationMs = Date.now() - start;
    this.printReport('spec', id, report, durationMs, opts.json);
    process.exitCode = report.valid ? 0 : 1;
  }

  private printReport(type: ItemType, id: string, report: { valid: boolean; issues: any[] }, durationMs: number, json: boolean): void {
    if (json) {
      const out = { items: [{ id, type, valid: report.valid, issues: report.issues, durationMs }], summary: { totals: { items: 1, passed: report.valid ? 1 : 0, failed: report.valid ? 0 : 1 }, byType: { [type]: { items: 1, passed: report.valid ? 1 : 0, failed: report.valid ? 0 : 1 } } }, version: '1.0' };
      console.log(JSON.stringify(out, null, 2));
      return;
    }
    if (report.valid) {
      console.log(`${type === 'change' ? 'Change' : 'Specification'} '${id}' is valid`);
    } else {
      console.error(`${type === 'change' ? 'Change' : 'Specification'} '${id}' has issues`);
      for (const issue of report.issues) {
        const label = issue.level === 'ERROR' ? 'ERROR' : issue.level;
        const prefix = issue.level === 'ERROR' ? 'âœ—' : issue.level === 'WARNING' ? 'âš ' : 'â„¹';
        console.error(`${prefix} [${label}] ${issue.path}: ${issue.message}`);
      }
      this.printNextSteps(type);
    }
  }

  private printNextSteps(type: ItemType): void {
    const bullets: string[] = [];
    if (type === 'change') {
      bullets.push('- Ensure change has deltas in specs/: use headers ## ADDED/MODIFIED/REMOVED/RENAMED Requirements');
      bullets.push('- Each requirement MUST include at least one #### Scenario: block');
      bullets.push('- Debug parsed deltas: openspec change show <id> --json --deltas-only');
    } else {
      bullets.push('- Ensure spec includes ## Purpose and ## Requirements sections');
      bullets.push('- Each requirement MUST include at least one #### Scenario: block');
      bullets.push('- Re-run with --json to see structured report');
    }
    console.error('Next steps:');
    bullets.forEach(b => console.error(`  ${b}`));
  }

  private async runBulkValidation(scope: { changes: boolean; specs: boolean }, opts: { strict: boolean; json: boolean; concurrency?: string; noInteractive?: boolean }): Promise<void> {
    const spinner = !opts.json && !opts.noInteractive ? ora('Validating...').start() : undefined;
    const [changeIds, specIds] = await Promise.all([
      scope.changes ? getActiveChangeIds() : Promise.resolve<string[]>([]),
      scope.specs ? getSpecIds() : Promise.resolve<string[]>([]),
    ]);

    const DEFAULT_CONCURRENCY = 6;
    const maxSuggestions = 5; // used by nearestMatches
    const concurrency = normalizeConcurrency(opts.concurrency) ?? normalizeConcurrency(process.env.OPENSPEC_CONCURRENCY) ?? DEFAULT_CONCURRENCY;
    const validator = new Validator(opts.strict);
    const queue: Array<() => Promise<BulkItemResult>> = [];

    for (const id of changeIds) {
      queue.push(async () => {
        const start = Date.now();
        const changeDir = path.join(process.cwd(), 'openspec', 'changes', id);
        const report = await validator.validateChangeDeltaSpecs(changeDir);
        const durationMs = Date.now() - start;
        return { id, type: 'change' as const, valid: report.valid, issues: report.issues, durationMs };
      });
    }
    for (const id of specIds) {
      queue.push(async () => {
        const start = Date.now();
        const file = path.join(process.cwd(), 'openspec', 'specs', id, 'spec.md');
        const report = await validator.validateSpec(file);
        const durationMs = Date.now() - start;
        return { id, type: 'spec' as const, valid: report.valid, issues: report.issues, durationMs };
      });
    }

    if (queue.length === 0) {
      spinner?.stop();

      const summary = {
        totals: { items: 0, passed: 0, failed: 0 },
        byType: {
          ...(scope.changes ? { change: { items: 0, passed: 0, failed: 0 } } : {}),
          ...(scope.specs ? { spec: { items: 0, passed: 0, failed: 0 } } : {}),
        },
      } as const;

      if (opts.json) {
        const out = { items: [] as BulkItemResult[], summary, version: '1.0' };
        console.log(JSON.stringify(out, null, 2));
      } else {
        console.log('No items found to validate.');
      }

      process.exitCode = 0;
      return;
    }

    const results: BulkItemResult[] = [];
    let index = 0;
    let running = 0;
    let passed = 0;
    let failed = 0;

    await new Promise<void>((resolve) => {
      const next = () => {
        while (running < concurrency && index < queue.length) {
          const currentIndex = index++;
          const task = queue[currentIndex];
          running++;
          if (spinner) spinner.text = `Validating (${currentIndex + 1}/${queue.length})...`;
          task()
            .then(res => {
              results.push(res);
              if (res.valid) passed++; else failed++;
            })
            .catch((error: any) => {
              const message = error?.message || 'Unknown error';
              const res: BulkItemResult = { id: getPlannedId(currentIndex, changeIds, specIds) ?? 'unknown', type: getPlannedType(currentIndex, changeIds, specIds) ?? 'change', valid: false, issues: [{ level: 'ERROR', path: 'file', message }], durationMs: 0 };
              results.push(res);
              failed++;
            })
            .finally(() => {
              running--;
              if (index >= queue.length && running === 0) resolve();
              else next();
            });
        }
      };
      next();
    });

    spinner?.stop();

    results.sort((a, b) => a.id.localeCompare(b.id));
    const summary = {
      totals: { items: results.length, passed, failed },
      byType: {
        ...(scope.changes ? { change: summarizeType(results, 'change') } : {}),
        ...(scope.specs ? { spec: summarizeType(results, 'spec') } : {}),
      },
    } as const;

    if (opts.json) {
      const out = { items: results, summary, version: '1.0' };
      console.log(JSON.stringify(out, null, 2));
    } else {
      for (const res of results) {
        if (res.valid) console.log(`âœ“ ${res.type}/${res.id}`);
        else console.error(`âœ— ${res.type}/${res.id}`);
      }
      console.log(`Totals: ${summary.totals.passed} passed, ${summary.totals.failed} failed (${summary.totals.items} items)`);
    }

    process.exitCode = failed > 0 ? 1 : 0;
  }
}

function summarizeType(results: BulkItemResult[], type: ItemType) {
  const filtered = results.filter(r => r.type === type);
  const items = filtered.length;
  const passed = filtered.filter(r => r.valid).length;
  const failed = items - passed;
  return { items, passed, failed };
}

function normalizeConcurrency(value?: string): number | undefined {
  if (!value) return undefined;
  const n = parseInt(value, 10);
  if (Number.isNaN(n) || n <= 0) return undefined;
  return n;
}

function getPlannedId(index: number, changeIds: string[], specIds: string[]): string | undefined {
  const totalChanges = changeIds.length;
  if (index < totalChanges) return changeIds[index];
  const specIndex = index - totalChanges;
  return specIds[specIndex];
}

function getPlannedType(index: number, changeIds: string[], specIds: string[]): ItemType | undefined {
  const totalChanges = changeIds.length;
  if (index < totalChanges) return 'change';
  const specIndex = index - totalChanges;
  if (specIndex >= 0 && specIndex < specIds.length) return 'spec';
  return undefined;
}



================================================
FILE: src/commands/experimental/index.ts
================================================
/**
 * Artifact Workflow CLI Commands (Experimental)
 *
 * This module contains all artifact workflow commands in isolation for easy removal.
 * Commands expose the ArtifactGraph and InstructionLoader APIs to users and agents.
 *
 * To remove this feature:
 * 1. Delete this directory
 * 2. Remove the registerArtifactWorkflowCommands() call from src/cli/index.ts
 */

import type { Command } from 'commander';
import ora from 'ora';

import { DEFAULT_SCHEMA } from './shared.js';
import { statusCommand, type StatusOptions } from './status.js';
import {
  instructionsCommand,
  applyInstructionsCommand,
  type InstructionsOptions,
} from './instructions.js';
import { templatesCommand, type TemplatesOptions } from './templates.js';
import { schemasCommand, type SchemasOptions } from './schemas.js';
import { newChangeCommand, type NewChangeOptions } from './new-change.js';
import { artifactExperimentalSetupCommand, type ArtifactExperimentalSetupOptions } from './setup.js';

// -----------------------------------------------------------------------------
// Command Registration
// -----------------------------------------------------------------------------

/**
 * Registers all artifact workflow commands on the given program.
 * All commands are marked as experimental in their help text.
 */
export function registerArtifactWorkflowCommands(program: Command): void {
  // Status command
  program
    .command('status')
    .description('[Experimental] Display artifact completion status for a change')
    .option('--change <id>', 'Change name to show status for')
    .option('--schema <name>', 'Schema override (auto-detected from .openspec.yaml)')
    .option('--json', 'Output as JSON')
    .action(async (options: StatusOptions) => {
      try {
        await statusCommand(options);
      } catch (error) {
        console.log();
        ora().fail(`Error: ${(error as Error).message}`);
        process.exit(1);
      }
    });

  // Instructions command
  program
    .command('instructions [artifact]')
    .description('[Experimental] Output enriched instructions for creating an artifact or applying tasks')
    .option('--change <id>', 'Change name')
    .option('--schema <name>', 'Schema override (auto-detected from .openspec.yaml)')
    .option('--json', 'Output as JSON')
    .action(async (artifactId: string | undefined, options: InstructionsOptions) => {
      try {
        // Special case: "apply" is not an artifact, but a command to get apply instructions
        if (artifactId === 'apply') {
          await applyInstructionsCommand(options);
        } else {
          await instructionsCommand(artifactId, options);
        }
      } catch (error) {
        console.log();
        ora().fail(`Error: ${(error as Error).message}`);
        process.exit(1);
      }
    });

  // Templates command
  program
    .command('templates')
    .description('[Experimental] Show resolved template paths for all artifacts in a schema')
    .option('--schema <name>', `Schema to use (default: ${DEFAULT_SCHEMA})`)
    .option('--json', 'Output as JSON mapping artifact IDs to template paths')
    .action(async (options: TemplatesOptions) => {
      try {
        await templatesCommand(options);
      } catch (error) {
        console.log();
        ora().fail(`Error: ${(error as Error).message}`);
        process.exit(1);
      }
    });

  // Schemas command
  program
    .command('schemas')
    .description('[Experimental] List available workflow schemas with descriptions')
    .option('--json', 'Output as JSON (for agent use)')
    .action(async (options: SchemasOptions) => {
      try {
        await schemasCommand(options);
      } catch (error) {
        console.log();
        ora().fail(`Error: ${(error as Error).message}`);
        process.exit(1);
      }
    });

  // New command group with change subcommand
  const newCmd = program.command('new').description('[Experimental] Create new items');

  newCmd
    .command('change <name>')
    .description('[Experimental] Create a new change directory')
    .option('--description <text>', 'Description to add to README.md')
    .option('--schema <name>', `Workflow schema to use (default: ${DEFAULT_SCHEMA})`)
    .action(async (name: string, options: NewChangeOptions) => {
      try {
        await newChangeCommand(name, options);
      } catch (error) {
        console.log();
        ora().fail(`Error: ${(error as Error).message}`);
        process.exit(1);
      }
    });

  // Artifact experimental setup command
  program
    .command('experimental')
    .description('[Experimental] Setup Agent Skills for the experimental artifact workflow')
    .option('--tool <tool-id>', 'Target AI tool (e.g., claude, cursor, windsurf)')
    .option('--no-interactive', 'Disable interactive prompts')
    .action(async (options: ArtifactExperimentalSetupOptions) => {
      try {
        await artifactExperimentalSetupCommand(options);
      } catch (error) {
        console.log();
        ora().fail(`Error: ${(error as Error).message}`);
        process.exit(1);
      }
    });
}



================================================
FILE: src/commands/experimental/instructions.ts
================================================
/**
 * Instructions Command
 *
 * Generates enriched instructions for creating artifacts or applying tasks.
 * Includes both artifact instructions and apply instructions.
 */

import ora from 'ora';
import path from 'path';
import * as fs from 'fs';
import {
  loadChangeContext,
  generateInstructions,
  resolveSchema,
  type ArtifactInstructions,
} from '../../core/artifact-graph/index.js';
import {
  validateChangeExists,
  validateSchemaExists,
  type TaskItem,
  type ApplyInstructions,
} from './shared.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface InstructionsOptions {
  change?: string;
  schema?: string;
  json?: boolean;
}

export interface ApplyInstructionsOptions {
  change?: string;
  schema?: string;
  json?: boolean;
}

// -----------------------------------------------------------------------------
// Artifact Instructions Command
// -----------------------------------------------------------------------------

export async function instructionsCommand(
  artifactId: string | undefined,
  options: InstructionsOptions
): Promise<void> {
  const spinner = ora('Generating instructions...').start();

  try {
    const projectRoot = process.cwd();
    const changeName = await validateChangeExists(options.change, projectRoot);

    // Validate schema if explicitly provided
    if (options.schema) {
      validateSchemaExists(options.schema, projectRoot);
    }

    // loadChangeContext will auto-detect schema from metadata if not provided
    const context = loadChangeContext(projectRoot, changeName, options.schema);

    if (!artifactId) {
      spinner.stop();
      const validIds = context.graph.getAllArtifacts().map((a) => a.id);
      throw new Error(
        `Missing required argument <artifact>. Valid artifacts:\n  ${validIds.join('\n  ')}`
      );
    }

    const artifact = context.graph.getArtifact(artifactId);

    if (!artifact) {
      spinner.stop();
      const validIds = context.graph.getAllArtifacts().map((a) => a.id);
      throw new Error(
        `Artifact '${artifactId}' not found in schema '${context.schemaName}'. Valid artifacts:\n  ${validIds.join('\n  ')}`
      );
    }

    const instructions = generateInstructions(context, artifactId, projectRoot);
    const isBlocked = instructions.dependencies.some((d) => !d.done);

    spinner.stop();

    if (options.json) {
      console.log(JSON.stringify(instructions, null, 2));
      return;
    }

    printInstructionsText(instructions, isBlocked);
  } catch (error) {
    spinner.stop();
    throw error;
  }
}

export function printInstructionsText(instructions: ArtifactInstructions, isBlocked: boolean): void {
  const {
    artifactId,
    changeName,
    schemaName,
    changeDir,
    outputPath,
    description,
    instruction,
    context,
    rules,
    template,
    dependencies,
    unlocks,
  } = instructions;

  // Opening tag
  console.log(`<artifact id="${artifactId}" change="${changeName}" schema="${schemaName}">`);
  console.log();

  // Warning for blocked artifacts
  if (isBlocked) {
    const missing = dependencies.filter((d) => !d.done).map((d) => d.id);
    console.log('<warning>');
    console.log('This artifact has unmet dependencies. Complete them first or proceed with caution.');
    console.log(`Missing: ${missing.join(', ')}`);
    console.log('</warning>');
    console.log();
  }

  // Task directive
  console.log('<task>');
  console.log(`Create the ${artifactId} artifact for change "${changeName}".`);
  console.log(description);
  console.log('</task>');
  console.log();

  // Project context (AI constraint - do not include in output)
  if (context) {
    console.log('<project_context>');
    console.log('<!-- This is background information for you. Do NOT include this in your output. -->');
    console.log(context);
    console.log('</project_context>');
    console.log();
  }

  // Rules (AI constraint - do not include in output)
  if (rules && rules.length > 0) {
    console.log('<rules>');
    console.log('<!-- These are constraints for you to follow. Do NOT include this in your output. -->');
    for (const rule of rules) {
      console.log(`- ${rule}`);
    }
    console.log('</rules>');
    console.log();
  }

  // Dependencies (files to read for context)
  if (dependencies.length > 0) {
    console.log('<dependencies>');
    console.log('Read these files for context before creating this artifact:');
    console.log();
    for (const dep of dependencies) {
      const status = dep.done ? 'done' : 'missing';
      const fullPath = path.join(changeDir, dep.path);
      console.log(`<dependency id="${dep.id}" status="${status}">`);
      console.log(`  <path>${fullPath}</path>`);
      console.log(`  <description>${dep.description}</description>`);
      console.log('</dependency>');
    }
    console.log('</dependencies>');
    console.log();
  }

  // Output location
  console.log('<output>');
  console.log(`Write to: ${path.join(changeDir, outputPath)}`);
  console.log('</output>');
  console.log();

  // Instruction (guidance)
  if (instruction) {
    console.log('<instruction>');
    console.log(instruction.trim());
    console.log('</instruction>');
    console.log();
  }

  // Template
  console.log('<template>');
  console.log('<!-- Use this as the structure for your output file. Fill in the sections. -->');
  console.log(template.trim());
  console.log('</template>');
  console.log();

  // Success criteria placeholder
  console.log('<success_criteria>');
  console.log('<!-- To be defined in schema validation rules -->');
  console.log('</success_criteria>');
  console.log();

  // Unlocks
  if (unlocks.length > 0) {
    console.log('<unlocks>');
    console.log(`Completing this artifact enables: ${unlocks.join(', ')}`);
    console.log('</unlocks>');
    console.log();
  }

  // Closing tag
  console.log('</artifact>');
}

// -----------------------------------------------------------------------------
// Apply Instructions Command
// -----------------------------------------------------------------------------

/**
 * Parses tasks.md content and extracts task items with their completion status.
 */
function parseTasksFile(content: string): TaskItem[] {
  const tasks: TaskItem[] = [];
  const lines = content.split('\n');
  let taskIndex = 0;

  for (const line of lines) {
    // Match checkbox patterns: - [ ] or - [x] or - [X]
    const checkboxMatch = line.match(/^[-*]\s*\[([ xX])\]\s*(.+)$/);
    if (checkboxMatch) {
      taskIndex++;
      const done = checkboxMatch[1].toLowerCase() === 'x';
      const description = checkboxMatch[2].trim();
      tasks.push({
        id: `${taskIndex}`,
        description,
        done,
      });
    }
  }

  return tasks;
}

/**
 * Checks if an artifact output exists in the change directory.
 * Supports glob patterns (e.g., "specs/*.md") by verifying at least one matching file exists.
 */
function artifactOutputExists(changeDir: string, generates: string): boolean {
  // Normalize the generates path to use platform-specific separators
  const normalizedGenerates = generates.split('/').join(path.sep);
  const fullPath = path.join(changeDir, normalizedGenerates);

  // If it's a glob pattern (contains ** or *), check for matching files
  if (generates.includes('*')) {
    // Extract the directory part before the glob pattern
    const parts = normalizedGenerates.split(path.sep);
    const dirParts: string[] = [];
    let patternPart = '';
    for (const part of parts) {
      if (part.includes('*')) {
        patternPart = part;
        break;
      }
      dirParts.push(part);
    }
    const dirPath = path.join(changeDir, ...dirParts);

    // Check if directory exists
    if (!fs.existsSync(dirPath) || !fs.statSync(dirPath).isDirectory()) {
      return false;
    }

    // Extract expected extension from pattern (e.g., "*.md" -> ".md")
    const extMatch = patternPart.match(/\*(\.[a-zA-Z0-9]+)$/);
    const expectedExt = extMatch ? extMatch[1] : null;

    // Recursively check for matching files
    const hasMatchingFiles = (dir: string): boolean => {
      try {
        const entries = fs.readdirSync(dir, { withFileTypes: true });
        for (const entry of entries) {
          if (entry.isDirectory()) {
            // For ** patterns, recurse into subdirectories
            if (generates.includes('**') && hasMatchingFiles(path.join(dir, entry.name))) {
              return true;
            }
          } else if (entry.isFile()) {
            // Check if file matches expected extension (or any file if no extension specified)
            if (!expectedExt || entry.name.endsWith(expectedExt)) {
              return true;
            }
          }
        }
      } catch {
        return false;
      }
      return false;
    };

    return hasMatchingFiles(dirPath);
  }

  return fs.existsSync(fullPath);
}

/**
 * Generates apply instructions for implementing tasks from a change.
 * Schema-aware: reads apply phase configuration from schema to determine
 * required artifacts, tracking file, and instruction.
 */
export async function generateApplyInstructions(
  projectRoot: string,
  changeName: string,
  schemaName?: string
): Promise<ApplyInstructions> {
  // loadChangeContext will auto-detect schema from metadata if not provided
  const context = loadChangeContext(projectRoot, changeName, schemaName);
  const changeDir = path.join(projectRoot, 'openspec', 'changes', changeName);

  // Get the full schema to access the apply phase configuration
  const schema = resolveSchema(context.schemaName);
  const applyConfig = schema.apply;

  // Determine required artifacts and tracking file from schema
  // Fallback: if no apply block, require all artifacts
  const requiredArtifactIds = applyConfig?.requires ?? schema.artifacts.map((a) => a.id);
  const tracksFile = applyConfig?.tracks ?? null;
  const schemaInstruction = applyConfig?.instruction ?? null;

  // Check which required artifacts are missing
  const missingArtifacts: string[] = [];
  for (const artifactId of requiredArtifactIds) {
    const artifact = schema.artifacts.find((a) => a.id === artifactId);
    if (artifact && !artifactOutputExists(changeDir, artifact.generates)) {
      missingArtifacts.push(artifactId);
    }
  }

  // Build context files from all existing artifacts in schema
  const contextFiles: Record<string, string> = {};
  for (const artifact of schema.artifacts) {
    if (artifactOutputExists(changeDir, artifact.generates)) {
      contextFiles[artifact.id] = path.join(changeDir, artifact.generates);
    }
  }

  // Parse tasks if tracking file exists
  let tasks: TaskItem[] = [];
  let tracksFileExists = false;
  if (tracksFile) {
    const tracksPath = path.join(changeDir, tracksFile);
    tracksFileExists = fs.existsSync(tracksPath);
    if (tracksFileExists) {
      const tasksContent = await fs.promises.readFile(tracksPath, 'utf-8');
      tasks = parseTasksFile(tasksContent);
    }
  }

  // Calculate progress
  const total = tasks.length;
  const complete = tasks.filter((t) => t.done).length;
  const remaining = total - complete;

  // Determine state and instruction
  let state: ApplyInstructions['state'];
  let instruction: string;

  if (missingArtifacts.length > 0) {
    state = 'blocked';
    instruction = `Cannot apply this change yet. Missing artifacts: ${missingArtifacts.join(', ')}.\nUse the openspec-continue-change skill to create the missing artifacts first.`;
  } else if (tracksFile && !tracksFileExists) {
    // Tracking file configured but doesn't exist yet
    const tracksFilename = path.basename(tracksFile);
    state = 'blocked';
    instruction = `The ${tracksFilename} file is missing and must be created.\nUse openspec-continue-change to generate the tracking file.`;
  } else if (tracksFile && tracksFileExists && total === 0) {
    // Tracking file exists but contains no tasks
    const tracksFilename = path.basename(tracksFile);
    state = 'blocked';
    instruction = `The ${tracksFilename} file exists but contains no tasks.\nAdd tasks to ${tracksFilename} or regenerate it with openspec-continue-change.`;
  } else if (tracksFile && remaining === 0 && total > 0) {
    state = 'all_done';
    instruction = 'All tasks are complete! This change is ready to be archived.\nConsider running tests and reviewing the changes before archiving.';
  } else if (!tracksFile) {
    // No tracking file (e.g., TDD schema) - ready to apply
    state = 'ready';
    instruction = schemaInstruction?.trim() ?? 'All required artifacts complete. Proceed with implementation.';
  } else {
    state = 'ready';
    instruction = schemaInstruction?.trim() ?? 'Read context files, work through pending tasks, mark complete as you go.\nPause if you hit blockers or need clarification.';
  }

  return {
    changeName,
    changeDir,
    schemaName: context.schemaName,
    contextFiles,
    progress: { total, complete, remaining },
    tasks,
    state,
    missingArtifacts: missingArtifacts.length > 0 ? missingArtifacts : undefined,
    instruction,
  };
}

export async function applyInstructionsCommand(options: ApplyInstructionsOptions): Promise<void> {
  const spinner = ora('Generating apply instructions...').start();

  try {
    const projectRoot = process.cwd();
    const changeName = await validateChangeExists(options.change, projectRoot);

    // Validate schema if explicitly provided
    if (options.schema) {
      validateSchemaExists(options.schema, projectRoot);
    }

    // generateApplyInstructions uses loadChangeContext which auto-detects schema
    const instructions = await generateApplyInstructions(projectRoot, changeName, options.schema);

    spinner.stop();

    if (options.json) {
      console.log(JSON.stringify(instructions, null, 2));
      return;
    }

    printApplyInstructionsText(instructions);
  } catch (error) {
    spinner.stop();
    throw error;
  }
}

export function printApplyInstructionsText(instructions: ApplyInstructions): void {
  const { changeName, schemaName, contextFiles, progress, tasks, state, missingArtifacts, instruction } = instructions;

  console.log(`## Apply: ${changeName}`);
  console.log(`Schema: ${schemaName}`);
  console.log();

  // Warning for blocked state
  if (state === 'blocked' && missingArtifacts) {
    console.log('### âš ï¸ Blocked');
    console.log();
    console.log(`Missing artifacts: ${missingArtifacts.join(', ')}`);
    console.log('Use the openspec-continue-change skill to create these first.');
    console.log();
  }

  // Context files (dynamically from schema)
  const contextFileEntries = Object.entries(contextFiles);
  if (contextFileEntries.length > 0) {
    console.log('### Context Files');
    for (const [artifactId, filePath] of contextFileEntries) {
      console.log(`- ${artifactId}: ${filePath}`);
    }
    console.log();
  }

  // Progress (only show if we have tracking)
  if (progress.total > 0 || tasks.length > 0) {
    console.log('### Progress');
    if (state === 'all_done') {
      console.log(`${progress.complete}/${progress.total} complete âœ“`);
    } else {
      console.log(`${progress.complete}/${progress.total} complete`);
    }
    console.log();
  }

  // Tasks
  if (tasks.length > 0) {
    console.log('### Tasks');
    for (const task of tasks) {
      const checkbox = task.done ? '[x]' : '[ ]';
      console.log(`- ${checkbox} ${task.description}`);
    }
    console.log();
  }

  // Instruction
  console.log('### Instruction');
  console.log(instruction);
}



================================================
FILE: src/commands/experimental/new-change.ts
================================================
/**
 * New Change Command
 *
 * Creates a new change directory with optional description and schema.
 */

import ora from 'ora';
import path from 'path';
import { createChange, validateChangeName } from '../../utils/change-utils.js';
import { validateSchemaExists } from './shared.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface NewChangeOptions {
  description?: string;
  schema?: string;
}

// -----------------------------------------------------------------------------
// Command Implementation
// -----------------------------------------------------------------------------

export async function newChangeCommand(name: string | undefined, options: NewChangeOptions): Promise<void> {
  if (!name) {
    throw new Error('Missing required argument <name>');
  }

  const validation = validateChangeName(name);
  if (!validation.valid) {
    throw new Error(validation.error);
  }

  const projectRoot = process.cwd();

  // Validate schema if provided
  if (options.schema) {
    validateSchemaExists(options.schema, projectRoot);
  }

  const schemaDisplay = options.schema ? ` with schema '${options.schema}'` : '';
  const spinner = ora(`Creating change '${name}'${schemaDisplay}...`).start();

  try {
    const result = await createChange(projectRoot, name, { schema: options.schema });

    // If description provided, create README.md with description
    if (options.description) {
      const { promises: fs } = await import('fs');
      const changeDir = path.join(projectRoot, 'openspec', 'changes', name);
      const readmePath = path.join(changeDir, 'README.md');
      await fs.writeFile(readmePath, `# ${name}\n\n${options.description}\n`, 'utf-8');
    }

    spinner.succeed(`Created change '${name}' at openspec/changes/${name}/ (schema: ${result.schema})`);
  } catch (error) {
    spinner.fail(`Failed to create change '${name}'`);
    throw error;
  }
}



================================================
FILE: src/commands/experimental/schemas.ts
================================================
/**
 * Schemas Command
 *
 * Lists available workflow schemas with descriptions.
 */

import chalk from 'chalk';
import { listSchemasWithInfo } from '../../core/artifact-graph/index.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface SchemasOptions {
  json?: boolean;
}

// -----------------------------------------------------------------------------
// Command Implementation
// -----------------------------------------------------------------------------

export async function schemasCommand(options: SchemasOptions): Promise<void> {
  const projectRoot = process.cwd();
  const schemas = listSchemasWithInfo(projectRoot);

  if (options.json) {
    console.log(JSON.stringify(schemas, null, 2));
    return;
  }

  console.log('Available schemas:');
  console.log();

  for (const schema of schemas) {
    let sourceLabel = '';
    if (schema.source === 'project') {
      sourceLabel = chalk.cyan(' (project)');
    } else if (schema.source === 'user') {
      sourceLabel = chalk.dim(' (user override)');
    }
    console.log(`  ${chalk.bold(schema.name)}${sourceLabel}`);
    console.log(`    ${schema.description}`);
    console.log(`    Artifacts: ${schema.artifacts.join(' â†’ ')}`);
    console.log();
  }
}



================================================
FILE: src/commands/experimental/setup.ts
================================================
/**
 * Artifact Experimental Setup Command
 *
 * Generates Agent Skills and slash commands for the experimental artifact workflow.
 */

import ora from 'ora';
import chalk from 'chalk';
import path from 'path';
import * as fs from 'fs';
import { getExploreSkillTemplate, getNewChangeSkillTemplate, getContinueChangeSkillTemplate, getApplyChangeSkillTemplate, getFfChangeSkillTemplate, getSyncSpecsSkillTemplate, getArchiveChangeSkillTemplate, getBulkArchiveChangeSkillTemplate, getVerifyChangeSkillTemplate, getOpsxExploreCommandTemplate, getOpsxNewCommandTemplate, getOpsxContinueCommandTemplate, getOpsxApplyCommandTemplate, getOpsxFfCommandTemplate, getOpsxSyncCommandTemplate, getOpsxArchiveCommandTemplate, getOpsxBulkArchiveCommandTemplate, getOpsxVerifyCommandTemplate } from '../../core/templates/skill-templates.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { isInteractive } from '../../utils/interactive.js';
import { serializeConfig } from '../../core/config-prompts.js';
import { AI_TOOLS } from '../../core/config.js';
import {
  generateCommands,
  CommandAdapterRegistry,
  type CommandContent,
} from '../../core/command-generation/index.js';
import { DEFAULT_SCHEMA } from './shared.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface ArtifactExperimentalSetupOptions {
  tool?: string;
  interactive?: boolean;
  selectedTools?: string[];  // For multi-select from interactive prompt
}

/**
 * Status of experimental skill configuration for a tool.
 */
interface ToolExperimentalStatus {
  /** Whether the tool has any experimental skills configured */
  configured: boolean;
  /** Whether all 9 experimental skills are configured */
  fullyConfigured: boolean;
  /** Number of skills currently configured (0-9) */
  skillCount: number;
}

// -----------------------------------------------------------------------------
// Constants
// -----------------------------------------------------------------------------

/**
 * Names of experimental skill directories created by openspec experimental.
 */
const EXPERIMENTAL_SKILL_NAMES = [
  'openspec-explore',
  'openspec-new-change',
  'openspec-continue-change',
  'openspec-apply-change',
  'openspec-ff-change',
  'openspec-sync-specs',
  'openspec-archive-change',
  'openspec-bulk-archive-change',
  'openspec-verify-change',
];

// -----------------------------------------------------------------------------
// Helpers
// -----------------------------------------------------------------------------

/**
 * Gets the list of tools with skillsDir configured.
 */
export function getToolsWithSkillsDir(): string[] {
  return AI_TOOLS.filter((t) => t.skillsDir).map((t) => t.value);
}

/**
 * Checks which experimental skill files exist for a tool.
 */
function getToolExperimentalStatus(projectRoot: string, toolId: string): ToolExperimentalStatus {
  const tool = AI_TOOLS.find((t) => t.value === toolId);
  if (!tool?.skillsDir) {
    return { configured: false, fullyConfigured: false, skillCount: 0 };
  }

  const skillsDir = path.join(projectRoot, tool.skillsDir, 'skills');
  let skillCount = 0;

  for (const skillName of EXPERIMENTAL_SKILL_NAMES) {
    const skillFile = path.join(skillsDir, skillName, 'SKILL.md');
    if (fs.existsSync(skillFile)) {
      skillCount++;
    }
  }

  return {
    configured: skillCount > 0,
    fullyConfigured: skillCount === EXPERIMENTAL_SKILL_NAMES.length,
    skillCount,
  };
}

/**
 * Gets the experimental status for all tools with skillsDir configured.
 */
function getExperimentalToolStates(projectRoot: string): Map<string, ToolExperimentalStatus> {
  const states = new Map<string, ToolExperimentalStatus>();
  const toolIds = AI_TOOLS.filter((t) => t.skillsDir).map((t) => t.value);

  for (const toolId of toolIds) {
    states.set(toolId, getToolExperimentalStatus(projectRoot, toolId));
  }

  return states;
}

// -----------------------------------------------------------------------------
// Command Implementation
// -----------------------------------------------------------------------------

/**
 * Generates Agent Skills and slash commands for the experimental artifact workflow.
 * Creates <toolDir>/skills/ directory with SKILL.md files following Agent Skills spec.
 * Creates slash commands using tool-specific adapters.
 */
export async function artifactExperimentalSetupCommand(options: ArtifactExperimentalSetupOptions): Promise<void> {
  const projectRoot = process.cwd();

  // Validate --tool flag or selectedTools is provided, or prompt interactively
  const hasToolsSpecified = options.tool || (options.selectedTools && options.selectedTools.length > 0);
  if (!hasToolsSpecified) {
    const validTools = getToolsWithSkillsDir();
    const canPrompt = isInteractive(options);

    if (canPrompt && validTools.length > 0) {
      // Show animated welcome screen before tool selection
      const { showWelcomeScreen } = await import('../../ui/welcome-screen.js');
      await showWelcomeScreen();

      const { searchableMultiSelect } = await import('../../prompts/searchable-multi-select.js');

      // Get experimental status for all tools to show configured indicators
      const toolStates = getExperimentalToolStates(projectRoot);

      // Build choices with configured status and sort configured tools first
      const sortedChoices = validTools
        .map((toolId) => {
          const tool = AI_TOOLS.find((t) => t.value === toolId);
          const status = toolStates.get(toolId);
          const configured = status?.configured ?? false;

          return {
            name: tool?.name || toolId,
            value: toolId,
            configured,
            preSelected: configured,  // Pre-select configured tools for easy refresh
          };
        })
        .sort((a, b) => {
          // Configured tools first
          if (a.configured && !b.configured) return -1;
          if (!a.configured && b.configured) return 1;
          return 0;
        });

      const selectedTools = await searchableMultiSelect({
        message: `Select tools to set up (${validTools.length} available)`,
        pageSize: 15,
        choices: sortedChoices,
        validate: (selected: string[]) => selected.length > 0 || 'Select at least one tool',
      });

      if (selectedTools.length === 0) {
        throw new Error('At least one tool must be selected');
      }

      options.tool = selectedTools[0];
      options.selectedTools = selectedTools;
    } else {
      throw new Error(
        `Missing required option --tool. Valid tools with skill generation support:\n  ${validTools.join('\n  ')}`
      );
    }
  }

  // Determine tools to set up - prefer selectedTools if provided
  const toolsToSetup = options.selectedTools && options.selectedTools.length > 0
    ? options.selectedTools
    : [options.tool!];

  // Get tool states before processing to track created vs refreshed
  const preSetupStates = getExperimentalToolStates(projectRoot);

  // Validate all tools before starting
  const validatedTools: Array<{ value: string; name: string; skillsDir: string; wasConfigured: boolean }> = [];
  for (const toolId of toolsToSetup) {
    const tool = AI_TOOLS.find((t) => t.value === toolId);
    if (!tool) {
      const validToolIds = AI_TOOLS.map((t) => t.value);
      throw new Error(
        `Unknown tool '${toolId}'. Valid tools:\n  ${validToolIds.join('\n  ')}`
      );
    }

    if (!tool.skillsDir) {
      const validToolsWithSkills = getToolsWithSkillsDir();
      throw new Error(
        `Tool '${toolId}' does not support skill generation (no skillsDir configured).\nTools with skill generation support:\n  ${validToolsWithSkills.join('\n  ')}`
      );
    }

    const preState = preSetupStates.get(tool.value);
    validatedTools.push({
      value: tool.value,
      name: tool.name,
      skillsDir: tool.skillsDir,
      wasConfigured: preState?.configured ?? false,
    });
  }

  // Track all created files across all tools
  const allCreatedSkillFiles: string[] = [];
  const allCreatedCommandFiles: string[] = [];
  let anyCommandsSkipped = false;
  const toolsWithSkippedCommands: string[] = [];
  const failedTools: Array<{ name: string; error: Error }> = [];

  // Get skill and command templates once (shared across all tools)
  const exploreSkill = getExploreSkillTemplate();
  const newChangeSkill = getNewChangeSkillTemplate();
  const continueChangeSkill = getContinueChangeSkillTemplate();
  const applyChangeSkill = getApplyChangeSkillTemplate();
  const ffChangeSkill = getFfChangeSkillTemplate();
  const syncSpecsSkill = getSyncSpecsSkillTemplate();
  const archiveChangeSkill = getArchiveChangeSkillTemplate();
  const bulkArchiveChangeSkill = getBulkArchiveChangeSkillTemplate();
  const verifyChangeSkill = getVerifyChangeSkillTemplate();

  const skillTemplates = [
    { template: exploreSkill, dirName: 'openspec-explore' },
    { template: newChangeSkill, dirName: 'openspec-new-change' },
    { template: continueChangeSkill, dirName: 'openspec-continue-change' },
    { template: applyChangeSkill, dirName: 'openspec-apply-change' },
    { template: ffChangeSkill, dirName: 'openspec-ff-change' },
    { template: syncSpecsSkill, dirName: 'openspec-sync-specs' },
    { template: archiveChangeSkill, dirName: 'openspec-archive-change' },
    { template: bulkArchiveChangeSkill, dirName: 'openspec-bulk-archive-change' },
    { template: verifyChangeSkill, dirName: 'openspec-verify-change' },
  ];

  const commandTemplates = [
    { template: getOpsxExploreCommandTemplate(), id: 'explore' },
    { template: getOpsxNewCommandTemplate(), id: 'new' },
    { template: getOpsxContinueCommandTemplate(), id: 'continue' },
    { template: getOpsxApplyCommandTemplate(), id: 'apply' },
    { template: getOpsxFfCommandTemplate(), id: 'ff' },
    { template: getOpsxSyncCommandTemplate(), id: 'sync' },
    { template: getOpsxArchiveCommandTemplate(), id: 'archive' },
    { template: getOpsxBulkArchiveCommandTemplate(), id: 'bulk-archive' },
    { template: getOpsxVerifyCommandTemplate(), id: 'verify' },
  ];

  const commandContents: CommandContent[] = commandTemplates.map(({ template, id }) => ({
    id,
    name: template.name,
    description: template.description,
    category: template.category,
    tags: template.tags,
    body: template.content,
  }));

  // Process each tool
  for (const tool of validatedTools) {
    const spinner = ora(`Setting up experimental artifact workflow for ${tool.name}...`).start();

    try {
      // Use tool-specific skillsDir
      const skillsDir = path.join(projectRoot, tool.skillsDir, 'skills');

      // Create skill directories and SKILL.md files
      for (const { template, dirName } of skillTemplates) {
        const skillDir = path.join(skillsDir, dirName);
        const skillFile = path.join(skillDir, 'SKILL.md');

        // Generate SKILL.md content with YAML frontmatter
        const skillContent = `---
name: ${template.name}
description: ${template.description}
license: ${template.license || 'MIT'}
compatibility: ${template.compatibility || 'Requires openspec CLI.'}
metadata:
  author: ${template.metadata?.author || 'openspec'}
  version: "${template.metadata?.version || '1.0'}"
---

${template.instructions}
`;

        // Write the skill file
        await FileSystemUtils.writeFile(skillFile, skillContent);
        allCreatedSkillFiles.push(path.relative(projectRoot, skillFile));
      }

      // Generate commands using the adapter system
      const adapter = CommandAdapterRegistry.get(tool.value);
      if (adapter) {
        const generatedCommands = generateCommands(commandContents, adapter);

        for (const cmd of generatedCommands) {
          const commandFile = path.join(projectRoot, cmd.path);
          await FileSystemUtils.writeFile(commandFile, cmd.fileContent);
          allCreatedCommandFiles.push(cmd.path);
        }
      } else {
        anyCommandsSkipped = true;
        toolsWithSkippedCommands.push(tool.value);
      }

      spinner.succeed(`Setup complete for ${tool.name}!`);
    } catch (error) {
      spinner.fail(`Failed for ${tool.name}`);
      failedTools.push({ name: tool.name, error: error as Error });
    }
  }

  // If all tools failed, throw an error
  if (failedTools.length === validatedTools.length) {
    const errorMessages = failedTools.map(f => `  ${f.name}: ${f.error.message}`).join('\n');
    throw new Error(`All tools failed to set up:\n${errorMessages}`);
  }

  // Filter to only successfully configured tools
  const successfulTools = validatedTools.filter(t => !failedTools.some(f => f.name === t.name));

  // Print success summary
  console.log();
  console.log(chalk.bold('Experimental Artifact Workflow Setup Complete'));
  console.log();

  // Tools and counts (show unique counts, not total files across all tools)
  if (successfulTools.length > 0) {
    // Separate newly created tools from refreshed (previously configured) tools
    const createdTools = successfulTools.filter(t => !t.wasConfigured);
    const refreshedTools = successfulTools.filter(t => t.wasConfigured);

    if (createdTools.length > 0) {
      console.log(`Created: ${createdTools.map(t => t.name).join(', ')}`);
    }
    if (refreshedTools.length > 0) {
      console.log(`Refreshed: ${refreshedTools.map(t => t.name).join(', ')}`);
    }

    const uniqueSkillCount = skillTemplates.length;
    const uniqueCommandCount = commandContents.length;
    const toolDirs = [...new Set(successfulTools.map(t => t.skillsDir))].join(', ');
    // Only count commands if any were actually created (some tools may not have adapters)
    const hasCommands = allCreatedCommandFiles.length > 0;
    if (hasCommands) {
      console.log(`${uniqueSkillCount} skills and ${uniqueCommandCount} commands in ${toolDirs}/`);
    } else {
      console.log(`${uniqueSkillCount} skills in ${toolDirs}/`);
    }
  }

  if (failedTools.length > 0) {
    console.log(chalk.red(`Failed: ${failedTools.map(f => `${f.name} (${f.error.message})`).join(', ')}`));
  }

  if (anyCommandsSkipped) {
    console.log(chalk.dim(`Commands skipped for: ${toolsWithSkippedCommands.join(', ')} (no adapter)`));
  }

  // Config creation (simplified)
  const configPath = path.join(projectRoot, 'openspec', 'config.yaml');
  const configYmlPath = path.join(projectRoot, 'openspec', 'config.yml');
  const configYamlExists = fs.existsSync(configPath);
  const configYmlExists = fs.existsSync(configYmlPath);
  const configExists = configYamlExists || configYmlExists;

  if (configExists) {
    const existingConfigName = configYamlExists ? 'config.yaml' : 'config.yml';
    console.log(`Config: openspec/${existingConfigName} (exists)`);
  } else if (!isInteractive(options)) {
    console.log(chalk.dim(`Config: skipped (non-interactive mode)`));
  } else {
    const yamlContent = serializeConfig({ schema: DEFAULT_SCHEMA });
    try {
      await FileSystemUtils.writeFile(configPath, yamlContent);
      console.log(`Config: openspec/config.yaml (schema: ${DEFAULT_SCHEMA})`);
    } catch (writeError) {
      console.log(chalk.red(`Config: failed to create (${(writeError as Error).message})`));
    }
  }

  // Getting started
  console.log();
  console.log(chalk.bold('Getting started:'));
  console.log('  /opsx:new       Start a new change');
  console.log('  /opsx:continue  Create the next artifact');
  console.log('  /opsx:apply     Implement tasks');

  // Links
  console.log();
  console.log(`Learn more: ${chalk.cyan('https://github.com/Fission-AI/OpenSpec/blob/main/docs/experimental-workflow.md')}`);
  console.log(`Feedback:   ${chalk.cyan('https://github.com/Fission-AI/OpenSpec/issues')}`);
  console.log();
}



================================================
FILE: src/commands/experimental/shared.ts
================================================
/**
 * Shared Types and Utilities for Artifact Workflow Commands
 *
 * This module contains types, constants, and validation helpers used across
 * multiple artifact workflow commands.
 */

import chalk from 'chalk';
import path from 'path';
import * as fs from 'fs';
import { getSchemaDir, listSchemas } from '../../core/artifact-graph/index.js';
import { validateChangeName } from '../../utils/change-utils.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface TaskItem {
  id: string;
  description: string;
  done: boolean;
}

export interface ApplyInstructions {
  changeName: string;
  changeDir: string;
  schemaName: string;
  contextFiles: Record<string, string>;
  progress: {
    total: number;
    complete: number;
    remaining: number;
  };
  tasks: TaskItem[];
  state: 'blocked' | 'all_done' | 'ready';
  missingArtifacts?: string[];
  instruction: string;
}

// -----------------------------------------------------------------------------
// Constants
// -----------------------------------------------------------------------------

export const DEFAULT_SCHEMA = 'spec-driven';

// -----------------------------------------------------------------------------
// Utility Functions
// -----------------------------------------------------------------------------

/**
 * Checks if color output is disabled via NO_COLOR env or --no-color flag.
 */
export function isColorDisabled(): boolean {
  return process.env.NO_COLOR === '1' || process.env.NO_COLOR === 'true';
}

/**
 * Gets the color function based on status.
 */
export function getStatusColor(status: 'done' | 'ready' | 'blocked'): (text: string) => string {
  if (isColorDisabled()) {
    return (text: string) => text;
  }
  switch (status) {
    case 'done':
      return chalk.green;
    case 'ready':
      return chalk.yellow;
    case 'blocked':
      return chalk.red;
  }
}

/**
 * Gets the status indicator for an artifact.
 */
export function getStatusIndicator(status: 'done' | 'ready' | 'blocked'): string {
  const color = getStatusColor(status);
  switch (status) {
    case 'done':
      return color('[x]');
    case 'ready':
      return color('[ ]');
    case 'blocked':
      return color('[-]');
  }
}

/**
 * Validates that a change exists and returns available changes if not.
 * Checks directory existence directly to support scaffolded changes (without proposal.md).
 */
export async function validateChangeExists(
  changeName: string | undefined,
  projectRoot: string
): Promise<string> {
  const changesPath = path.join(projectRoot, 'openspec', 'changes');

  // Get all change directories (not just those with proposal.md)
  const getAvailableChanges = async (): Promise<string[]> => {
    try {
      const entries = await fs.promises.readdir(changesPath, { withFileTypes: true });
      return entries
        .filter((e) => e.isDirectory() && e.name !== 'archive' && !e.name.startsWith('.'))
        .map((e) => e.name);
    } catch {
      return [];
    }
  };

  if (!changeName) {
    const available = await getAvailableChanges();
    if (available.length === 0) {
      throw new Error('No changes found. Create one with: openspec new change <name>');
    }
    throw new Error(
      `Missing required option --change. Available changes:\n  ${available.join('\n  ')}`
    );
  }

  // Validate change name format to prevent path traversal
  const nameValidation = validateChangeName(changeName);
  if (!nameValidation.valid) {
    throw new Error(`Invalid change name '${changeName}': ${nameValidation.error}`);
  }

  // Check directory existence directly
  const changePath = path.join(changesPath, changeName);
  const exists = fs.existsSync(changePath) && fs.statSync(changePath).isDirectory();

  if (!exists) {
    const available = await getAvailableChanges();
    if (available.length === 0) {
      throw new Error(
        `Change '${changeName}' not found. No changes exist. Create one with: openspec new change <name>`
      );
    }
    throw new Error(
      `Change '${changeName}' not found. Available changes:\n  ${available.join('\n  ')}`
    );
  }

  return changeName;
}

/**
 * Validates that a schema exists and returns available schemas if not.
 *
 * @param schemaName - The schema name to validate
 * @param projectRoot - Optional project root for project-local schema resolution
 */
export function validateSchemaExists(schemaName: string, projectRoot?: string): string {
  const schemaDir = getSchemaDir(schemaName, projectRoot);
  if (!schemaDir) {
    const availableSchemas = listSchemas(projectRoot);
    throw new Error(
      `Schema '${schemaName}' not found. Available schemas:\n  ${availableSchemas.join('\n  ')}`
    );
  }
  return schemaName;
}



================================================
FILE: src/commands/experimental/status.ts
================================================
/**
 * Status Command
 *
 * Displays artifact completion status for a change.
 */

import ora from 'ora';
import chalk from 'chalk';
import {
  loadChangeContext,
  formatChangeStatus,
  type ChangeStatus,
} from '../../core/artifact-graph/index.js';
import {
  validateChangeExists,
  validateSchemaExists,
  getStatusIndicator,
  getStatusColor,
} from './shared.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface StatusOptions {
  change?: string;
  schema?: string;
  json?: boolean;
}

// -----------------------------------------------------------------------------
// Command Implementation
// -----------------------------------------------------------------------------

export async function statusCommand(options: StatusOptions): Promise<void> {
  const spinner = ora('Loading change status...').start();

  try {
    const projectRoot = process.cwd();
    const changeName = await validateChangeExists(options.change, projectRoot);

    // Validate schema if explicitly provided
    if (options.schema) {
      validateSchemaExists(options.schema, projectRoot);
    }

    // loadChangeContext will auto-detect schema from metadata if not provided
    const context = loadChangeContext(projectRoot, changeName, options.schema);
    const status = formatChangeStatus(context);

    spinner.stop();

    if (options.json) {
      console.log(JSON.stringify(status, null, 2));
      return;
    }

    printStatusText(status);
  } catch (error) {
    spinner.stop();
    throw error;
  }
}

export function printStatusText(status: ChangeStatus): void {
  const doneCount = status.artifacts.filter((a) => a.status === 'done').length;
  const total = status.artifacts.length;

  console.log(`Change: ${status.changeName}`);
  console.log(`Schema: ${status.schemaName}`);
  console.log(`Progress: ${doneCount}/${total} artifacts complete`);
  console.log();

  for (const artifact of status.artifacts) {
    const indicator = getStatusIndicator(artifact.status);
    const color = getStatusColor(artifact.status);
    let line = `${indicator} ${artifact.id}`;

    if (artifact.status === 'blocked' && artifact.missingDeps && artifact.missingDeps.length > 0) {
      line += color(` (blocked by: ${artifact.missingDeps.join(', ')})`);
    }

    console.log(line);
  }

  if (status.isComplete) {
    console.log();
    console.log(chalk.green('All artifacts complete!'));
  }
}



================================================
FILE: src/commands/experimental/templates.ts
================================================
/**
 * Templates Command
 *
 * Shows resolved template paths for all artifacts in a schema.
 */

import ora from 'ora';
import path from 'path';
import {
  resolveSchema,
  getSchemaDir,
  ArtifactGraph,
} from '../../core/artifact-graph/index.js';
import { validateSchemaExists, DEFAULT_SCHEMA } from './shared.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface TemplatesOptions {
  schema?: string;
  json?: boolean;
}

export interface TemplateInfo {
  artifactId: string;
  templatePath: string;
  source: 'project' | 'user' | 'package';
}

// -----------------------------------------------------------------------------
// Command Implementation
// -----------------------------------------------------------------------------

export async function templatesCommand(options: TemplatesOptions): Promise<void> {
  const spinner = ora('Loading templates...').start();

  try {
    const projectRoot = process.cwd();
    const schemaName = validateSchemaExists(options.schema ?? DEFAULT_SCHEMA, projectRoot);
    const schema = resolveSchema(schemaName, projectRoot);
    const graph = ArtifactGraph.fromSchema(schema);
    const schemaDir = getSchemaDir(schemaName, projectRoot)!;

    // Determine the source (project, user, or package)
    const {
      getUserSchemasDir,
      getProjectSchemasDir,
    } = await import('../../core/artifact-graph/resolver.js');
    const projectSchemasDir = getProjectSchemasDir(projectRoot);
    const userSchemasDir = getUserSchemasDir();

    // Determine source by checking if schemaDir is inside each base directory
    // Using path.relative is more robust than startsWith for path comparisons
    const isInsideDir = (child: string, parent: string): boolean => {
      const relative = path.relative(parent, child);
      return !relative.startsWith('..') && !path.isAbsolute(relative);
    };

    let source: 'project' | 'user' | 'package';
    if (isInsideDir(schemaDir, projectSchemasDir)) {
      source = 'project';
    } else if (isInsideDir(schemaDir, userSchemasDir)) {
      source = 'user';
    } else {
      source = 'package';
    }

    const templates: TemplateInfo[] = graph.getAllArtifacts().map((artifact) => ({
      artifactId: artifact.id,
      templatePath: path.join(schemaDir, 'templates', artifact.template),
      source,
    }));

    spinner.stop();

    if (options.json) {
      const output: Record<string, { path: string; source: string }> = {};
      for (const t of templates) {
        output[t.artifactId] = { path: t.templatePath, source: t.source };
      }
      console.log(JSON.stringify(output, null, 2));
      return;
    }

    console.log(`Schema: ${schemaName}`);
    console.log(`Source: ${source}`);
    console.log();

    for (const t of templates) {
      console.log(`${t.artifactId}:`);
      console.log(`  ${t.templatePath}`);
    }
  } catch (error) {
    spinner.stop();
    throw error;
  }
}



================================================
FILE: src/core/archive.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import { getTaskProgressForChange, formatTaskStatus } from '../utils/task-progress.js';
import { Validator } from './validation/validator.js';
import chalk from 'chalk';
import {
  findSpecUpdates,
  buildUpdatedSpec,
  writeUpdatedSpec,
  type SpecUpdate,
} from './specs-apply.js';

export class ArchiveCommand {
  async execute(
    changeName?: string,
    options: { yes?: boolean; skipSpecs?: boolean; noValidate?: boolean; validate?: boolean } = {}
  ): Promise<void> {
    const targetPath = '.';
    const changesDir = path.join(targetPath, 'openspec', 'changes');
    const archiveDir = path.join(changesDir, 'archive');
    const mainSpecsDir = path.join(targetPath, 'openspec', 'specs');

    // Check if changes directory exists
    try {
      await fs.access(changesDir);
    } catch {
      throw new Error("No OpenSpec changes directory found. Run 'openspec init' first.");
    }

    // Get change name interactively if not provided
    if (!changeName) {
      const selectedChange = await this.selectChange(changesDir);
      if (!selectedChange) {
        console.log('No change selected. Aborting.');
        return;
      }
      changeName = selectedChange;
    }

    const changeDir = path.join(changesDir, changeName);

    // Verify change exists
    try {
      const stat = await fs.stat(changeDir);
      if (!stat.isDirectory()) {
        throw new Error(`Change '${changeName}' not found.`);
      }
    } catch {
      throw new Error(`Change '${changeName}' not found.`);
    }

    const skipValidation = options.validate === false || options.noValidate === true;

    // Validate specs and change before archiving
    if (!skipValidation) {
      const validator = new Validator();
      let hasValidationErrors = false;

      // Validate proposal.md (non-blocking unless strict mode desired in future)
      const changeFile = path.join(changeDir, 'proposal.md');
      try {
        await fs.access(changeFile);
        const changeReport = await validator.validateChange(changeFile);
        // Proposal validation is informative only (do not block archive)
        if (!changeReport.valid) {
          console.log(chalk.yellow(`\nProposal warnings in proposal.md (non-blocking):`));
          for (const issue of changeReport.issues) {
            const symbol = issue.level === 'ERROR' ? 'âš ' : (issue.level === 'WARNING' ? 'âš ' : 'â„¹');
            console.log(chalk.yellow(`  ${symbol} ${issue.message}`));
          }
        }
      } catch {
        // Change file doesn't exist, skip validation
      }

      // Validate delta-formatted spec files under the change directory if present
      const changeSpecsDir = path.join(changeDir, 'specs');
      let hasDeltaSpecs = false;
      try {
        const candidates = await fs.readdir(changeSpecsDir, { withFileTypes: true });
        for (const c of candidates) {
          if (c.isDirectory()) {
            try {
              const candidatePath = path.join(changeSpecsDir, c.name, 'spec.md');
              await fs.access(candidatePath);
              const content = await fs.readFile(candidatePath, 'utf-8');
              if (/^##\s+(ADDED|MODIFIED|REMOVED|RENAMED)\s+Requirements/m.test(content)) {
                hasDeltaSpecs = true;
                break;
              }
            } catch {}
          }
        }
      } catch {}
      if (hasDeltaSpecs) {
        const deltaReport = await validator.validateChangeDeltaSpecs(changeDir);
        if (!deltaReport.valid) {
          hasValidationErrors = true;
          console.log(chalk.red(`\nValidation errors in change delta specs:`));
          for (const issue of deltaReport.issues) {
            if (issue.level === 'ERROR') {
              console.log(chalk.red(`  âœ— ${issue.message}`));
            } else if (issue.level === 'WARNING') {
              console.log(chalk.yellow(`  âš  ${issue.message}`));
            }
          }
        }
      }

      if (hasValidationErrors) {
        console.log(chalk.red('\nValidation failed. Please fix the errors before archiving.'));
        console.log(chalk.yellow('To skip validation (not recommended), use --no-validate flag.'));
        return;
      }
    } else {
      // Log warning when validation is skipped
      const timestamp = new Date().toISOString();
      
      if (!options.yes) {
        const { confirm } = await import('@inquirer/prompts');
        const proceed = await confirm({
          message: chalk.yellow('âš ï¸  WARNING: Skipping validation may archive invalid specs. Continue? (y/N)'),
          default: false
        });
        if (!proceed) {
          console.log('Archive cancelled.');
          return;
        }
      } else {
        console.log(chalk.yellow(`\nâš ï¸  WARNING: Skipping validation may archive invalid specs.`));
      }
      
      console.log(chalk.yellow(`[${timestamp}] Validation skipped for change: ${changeName}`));
      console.log(chalk.yellow(`Affected files: ${changeDir}`));
    }

    // Show progress and check for incomplete tasks
    const progress = await getTaskProgressForChange(changesDir, changeName);
    const status = formatTaskStatus(progress);
    console.log(`Task status: ${status}`);

    const incompleteTasks = Math.max(progress.total - progress.completed, 0);
    if (incompleteTasks > 0) {
      if (!options.yes) {
        const { confirm } = await import('@inquirer/prompts');
        const proceed = await confirm({
          message: `Warning: ${incompleteTasks} incomplete task(s) found. Continue?`,
          default: false
        });
        if (!proceed) {
          console.log('Archive cancelled.');
          return;
        }
      } else {
        console.log(`Warning: ${incompleteTasks} incomplete task(s) found. Continuing due to --yes flag.`);
      }
    }

    // Handle spec updates unless skipSpecs flag is set
    if (options.skipSpecs) {
      console.log('Skipping spec updates (--skip-specs flag provided).');
    } else {
      // Find specs to update
      const specUpdates = await findSpecUpdates(changeDir, mainSpecsDir);
      
      if (specUpdates.length > 0) {
        console.log('\nSpecs to update:');
        for (const update of specUpdates) {
          const status = update.exists ? 'update' : 'create';
          const capability = path.basename(path.dirname(update.target));
          console.log(`  ${capability}: ${status}`);
        }

        let shouldUpdateSpecs = true;
        if (!options.yes) {
          const { confirm } = await import('@inquirer/prompts');
          shouldUpdateSpecs = await confirm({
            message: 'Proceed with spec updates?',
            default: true
          });
          if (!shouldUpdateSpecs) {
            console.log('Skipping spec updates. Proceeding with archive.');
          }
        }

        if (shouldUpdateSpecs) {
          // Prepare all updates first (validation pass, no writes)
          const prepared: Array<{ update: SpecUpdate; rebuilt: string; counts: { added: number; modified: number; removed: number; renamed: number } }> = [];
          try {
            for (const update of specUpdates) {
              const built = await buildUpdatedSpec(update, changeName!);
              prepared.push({ update, rebuilt: built.rebuilt, counts: built.counts });
            }
          } catch (err: any) {
            console.log(String(err.message || err));
            console.log('Aborted. No files were changed.');
            return;
          }

          // All validations passed; pre-validate rebuilt full spec and then write files and display counts
          let totals = { added: 0, modified: 0, removed: 0, renamed: 0 };
          for (const p of prepared) {
            const specName = path.basename(path.dirname(p.update.target));
            if (!skipValidation) {
              const report = await new Validator().validateSpecContent(specName, p.rebuilt);
              if (!report.valid) {
                console.log(chalk.red(`\nValidation errors in rebuilt spec for ${specName} (will not write changes):`));
                for (const issue of report.issues) {
                  if (issue.level === 'ERROR') console.log(chalk.red(`  âœ— ${issue.message}`));
                  else if (issue.level === 'WARNING') console.log(chalk.yellow(`  âš  ${issue.message}`));
                }
                console.log('Aborted. No files were changed.');
                return;
              }
            }
            await writeUpdatedSpec(p.update, p.rebuilt, p.counts);
            totals.added += p.counts.added;
            totals.modified += p.counts.modified;
            totals.removed += p.counts.removed;
            totals.renamed += p.counts.renamed;
          }
          console.log(
            `Totals: + ${totals.added}, ~ ${totals.modified}, - ${totals.removed}, â†’ ${totals.renamed}`
          );
          console.log('Specs updated successfully.');
        }
      }
    }

    // Create archive directory with date prefix
    const archiveName = `${this.getArchiveDate()}-${changeName}`;
    const archivePath = path.join(archiveDir, archiveName);

    // Check if archive already exists
    try {
      await fs.access(archivePath);
      throw new Error(`Archive '${archiveName}' already exists.`);
    } catch (error: any) {
      if (error.code !== 'ENOENT') {
        throw error;
      }
    }

    // Create archive directory if needed
    await fs.mkdir(archiveDir, { recursive: true });

    // Move change to archive
    await fs.rename(changeDir, archivePath);
    
    console.log(`Change '${changeName}' archived as '${archiveName}'.`);
  }

  private async selectChange(changesDir: string): Promise<string | null> {
    const { select } = await import('@inquirer/prompts');
    // Get all directories in changes (excluding archive)
    const entries = await fs.readdir(changesDir, { withFileTypes: true });
    const changeDirs = entries
      .filter(entry => entry.isDirectory() && entry.name !== 'archive')
      .map(entry => entry.name)
      .sort();

    if (changeDirs.length === 0) {
      console.log('No active changes found.');
      return null;
    }

    // Build choices with progress inline to avoid duplicate lists
    let choices: Array<{ name: string; value: string }> = changeDirs.map(name => ({ name, value: name }));
    try {
      const progressList: Array<{ id: string; status: string }> = [];
      for (const id of changeDirs) {
        const progress = await getTaskProgressForChange(changesDir, id);
        const status = formatTaskStatus(progress);
        progressList.push({ id, status });
      }
      const nameWidth = Math.max(...progressList.map(p => p.id.length));
      choices = progressList.map(p => ({
        name: `${p.id.padEnd(nameWidth)}     ${p.status}`,
        value: p.id
      }));
    } catch {
      // If anything fails, fall back to simple names
      choices = changeDirs.map(name => ({ name, value: name }));
    }

    try {
      const answer = await select({
        message: 'Select a change to archive',
        choices
      });
      return answer;
    } catch (error) {
      // User cancelled (Ctrl+C)
      return null;
    }
  }

  private getArchiveDate(): string {
    // Returns date in YYYY-MM-DD format
    return new Date().toISOString().split('T')[0];
  }
}



================================================
FILE: src/core/config-prompts.ts
================================================
import type { ProjectConfig } from './project-config.js';

/**
 * Serialize config to YAML string with helpful comments.
 *
 * @param config - Partial config object (schema required, context/rules optional)
 * @returns YAML string ready to write to file
 */
export function serializeConfig(config: Partial<ProjectConfig>): string {
  const lines: string[] = [];

  // Schema (required)
  lines.push(`schema: ${config.schema}`);
  lines.push('');

  // Context section with comments
  lines.push('# Project context (optional)');
  lines.push('# This is shown to AI when creating artifacts.');
  lines.push('# Add your tech stack, conventions, style guides, domain knowledge, etc.');
  lines.push('# Example:');
  lines.push('#   context: |');
  lines.push('#     Tech stack: TypeScript, React, Node.js');
  lines.push('#     We use conventional commits');
  lines.push('#     Domain: e-commerce platform');
  lines.push('');

  // Rules section with comments
  lines.push('# Per-artifact rules (optional)');
  lines.push('# Add custom rules for specific artifacts.');
  lines.push('# Example:');
  lines.push('#   rules:');
  lines.push('#     proposal:');
  lines.push('#       - Keep proposals under 500 words');
  lines.push('#       - Always include a "Non-goals" section');
  lines.push('#     tasks:');
  lines.push('#       - Break tasks into chunks of max 2 hours');

  return lines.join('\n') + '\n';
}



================================================
FILE: src/core/config-schema.ts
================================================
import { z } from 'zod';

/**
 * Zod schema for global OpenSpec configuration.
 * Uses passthrough() to preserve unknown fields for forward compatibility.
 */
export const GlobalConfigSchema = z
  .object({
    featureFlags: z
      .record(z.string(), z.boolean())
      .optional()
      .default({}),
  })
  .passthrough();

export type GlobalConfigType = z.infer<typeof GlobalConfigSchema>;

/**
 * Default configuration values.
 */
export const DEFAULT_CONFIG: GlobalConfigType = {
  featureFlags: {},
};

const KNOWN_TOP_LEVEL_KEYS = new Set(Object.keys(DEFAULT_CONFIG));

/**
 * Validate a config key path for CLI set operations.
 * Unknown top-level keys are rejected unless explicitly allowed by the caller.
 */
export function validateConfigKeyPath(path: string): { valid: boolean; reason?: string } {
  const rawKeys = path.split('.');

  if (rawKeys.length === 0 || rawKeys.some((key) => key.trim() === '')) {
    return { valid: false, reason: 'Key path must not be empty' };
  }

  const rootKey = rawKeys[0];
  if (!KNOWN_TOP_LEVEL_KEYS.has(rootKey)) {
    return { valid: false, reason: `Unknown top-level key "${rootKey}"` };
  }

  if (rootKey === 'featureFlags') {
    if (rawKeys.length > 2) {
      return { valid: false, reason: 'featureFlags values are booleans and do not support nested keys' };
    }
    return { valid: true };
  }

  if (rawKeys.length > 1) {
    return { valid: false, reason: `"${rootKey}" does not support nested keys` };
  }

  return { valid: true };
}

/**
 * Get a nested value from an object using dot notation.
 *
 * @param obj - The object to access
 * @param path - Dot-separated path (e.g., "featureFlags.someFlag")
 * @returns The value at the path, or undefined if not found
 */
export function getNestedValue(obj: Record<string, unknown>, path: string): unknown {
  const keys = path.split('.');
  let current: unknown = obj;

  for (const key of keys) {
    if (current === null || current === undefined) {
      return undefined;
    }
    if (typeof current !== 'object') {
      return undefined;
    }
    current = (current as Record<string, unknown>)[key];
  }

  return current;
}

/**
 * Set a nested value in an object using dot notation.
 * Creates intermediate objects as needed.
 *
 * @param obj - The object to modify (mutated in place)
 * @param path - Dot-separated path (e.g., "featureFlags.someFlag")
 * @param value - The value to set
 */
export function setNestedValue(obj: Record<string, unknown>, path: string, value: unknown): void {
  const keys = path.split('.');
  let current: Record<string, unknown> = obj;

  for (let i = 0; i < keys.length - 1; i++) {
    const key = keys[i];
    if (current[key] === undefined || current[key] === null || typeof current[key] !== 'object') {
      current[key] = {};
    }
    current = current[key] as Record<string, unknown>;
  }

  const lastKey = keys[keys.length - 1];
  current[lastKey] = value;
}

/**
 * Delete a nested value from an object using dot notation.
 *
 * @param obj - The object to modify (mutated in place)
 * @param path - Dot-separated path (e.g., "featureFlags.someFlag")
 * @returns true if the key existed and was deleted, false otherwise
 */
export function deleteNestedValue(obj: Record<string, unknown>, path: string): boolean {
  const keys = path.split('.');
  let current: Record<string, unknown> = obj;

  for (let i = 0; i < keys.length - 1; i++) {
    const key = keys[i];
    if (current[key] === undefined || current[key] === null || typeof current[key] !== 'object') {
      return false;
    }
    current = current[key] as Record<string, unknown>;
  }

  const lastKey = keys[keys.length - 1];
  if (lastKey in current) {
    delete current[lastKey];
    return true;
  }
  return false;
}

/**
 * Coerce a string value to its appropriate type.
 * - "true" / "false" -> boolean
 * - Numeric strings -> number
 * - Everything else -> string
 *
 * @param value - The string value to coerce
 * @param forceString - If true, always return the value as a string
 * @returns The coerced value
 */
export function coerceValue(value: string, forceString: boolean = false): string | number | boolean {
  if (forceString) {
    return value;
  }

  // Boolean coercion
  if (value === 'true') {
    return true;
  }
  if (value === 'false') {
    return false;
  }

  // Number coercion - must be a valid finite number
  const num = Number(value);
  if (!isNaN(num) && isFinite(num) && value.trim() !== '') {
    return num;
  }

  return value;
}

/**
 * Format a value for YAML-like display.
 *
 * @param value - The value to format
 * @param indent - Current indentation level
 * @returns Formatted string
 */
export function formatValueYaml(value: unknown, indent: number = 0): string {
  const indentStr = '  '.repeat(indent);

  if (value === null || value === undefined) {
    return 'null';
  }

  if (typeof value === 'boolean' || typeof value === 'number') {
    return String(value);
  }

  if (typeof value === 'string') {
    return value;
  }

  if (Array.isArray(value)) {
    if (value.length === 0) {
      return '[]';
    }
    return value.map((item) => `${indentStr}- ${formatValueYaml(item, indent + 1)}`).join('\n');
  }

  if (typeof value === 'object') {
    const entries = Object.entries(value as Record<string, unknown>);
    if (entries.length === 0) {
      return '{}';
    }
    return entries
      .map(([key, val]) => {
        const formattedVal = formatValueYaml(val, indent + 1);
        if (typeof val === 'object' && val !== null && Object.keys(val).length > 0) {
          return `${indentStr}${key}:\n${formattedVal}`;
        }
        return `${indentStr}${key}: ${formattedVal}`;
      })
      .join('\n');
  }

  return String(value);
}

/**
 * Validate a configuration object against the schema.
 *
 * @param config - The configuration to validate
 * @returns Validation result with success status and optional error message
 */
export function validateConfig(config: unknown): { success: boolean; error?: string } {
  try {
    GlobalConfigSchema.parse(config);
    return { success: true };
  } catch (error) {
    if (error instanceof z.ZodError) {
      const zodError = error as z.ZodError;
      const messages = zodError.issues.map((e) => `${e.path.join('.')}: ${e.message}`);
      return { success: false, error: messages.join('; ') };
    }
    return { success: false, error: 'Unknown validation error' };
  }
}



================================================
FILE: src/core/config.ts
================================================
export const OPENSPEC_DIR_NAME = 'openspec';

export const OPENSPEC_MARKERS = {
  start: '<!-- OPENSPEC:START -->',
  end: '<!-- OPENSPEC:END -->'
};

export interface OpenSpecConfig {
  aiTools: string[];
}

export interface AIToolOption {
  name: string;
  value: string;
  available: boolean;
  successLabel?: string;
  skillsDir?: string; // e.g., '.claude' - /skills suffix per Agent Skills spec
}

export const AI_TOOLS: AIToolOption[] = [
  { name: 'Amazon Q Developer', value: 'amazon-q', available: true, successLabel: 'Amazon Q Developer', skillsDir: '.amazonq' },
  { name: 'Antigravity', value: 'antigravity', available: true, successLabel: 'Antigravity', skillsDir: '.agent' },
  { name: 'Auggie (Augment CLI)', value: 'auggie', available: true, successLabel: 'Auggie', skillsDir: '.augment' },
  { name: 'Claude Code', value: 'claude', available: true, successLabel: 'Claude Code', skillsDir: '.claude' },
  { name: 'Cline', value: 'cline', available: true, successLabel: 'Cline', skillsDir: '.cline' },
  { name: 'Codex', value: 'codex', available: true, successLabel: 'Codex', skillsDir: '.codex' },
  { name: 'CodeBuddy Code (CLI)', value: 'codebuddy', available: true, successLabel: 'CodeBuddy Code', skillsDir: '.codebuddy' },
  { name: 'Continue', value: 'continue', available: true, successLabel: 'Continue (VS Code / JetBrains / Cli)', skillsDir: '.continue' },
  { name: 'CoStrict', value: 'costrict', available: true, successLabel: 'CoStrict', skillsDir: '.cospec' },
  { name: 'Crush', value: 'crush', available: true, successLabel: 'Crush', skillsDir: '.crush' },
  { name: 'Cursor', value: 'cursor', available: true, successLabel: 'Cursor', skillsDir: '.cursor' },
  { name: 'Factory Droid', value: 'factory', available: true, successLabel: 'Factory Droid', skillsDir: '.factory' },
  { name: 'Gemini CLI', value: 'gemini', available: true, successLabel: 'Gemini CLI', skillsDir: '.gemini' },
  { name: 'GitHub Copilot', value: 'github-copilot', available: true, successLabel: 'GitHub Copilot', skillsDir: '.github' },
  { name: 'iFlow', value: 'iflow', available: true, successLabel: 'iFlow', skillsDir: '.iflow' },
  { name: 'Kilo Code', value: 'kilocode', available: true, successLabel: 'Kilo Code', skillsDir: '.kilocode' },
  { name: 'OpenCode', value: 'opencode', available: true, successLabel: 'OpenCode', skillsDir: '.opencode' },
  { name: 'Qoder', value: 'qoder', available: true, successLabel: 'Qoder', skillsDir: '.qoder' },
  { name: 'Qwen Code', value: 'qwen', available: true, successLabel: 'Qwen Code', skillsDir: '.qwen' },
  { name: 'RooCode', value: 'roocode', available: true, successLabel: 'RooCode', skillsDir: '.roo' },
  { name: 'Windsurf', value: 'windsurf', available: true, successLabel: 'Windsurf', skillsDir: '.windsurf' },
  { name: 'AGENTS.md (works with Amp, VS Code, â€¦)', value: 'agents', available: false, successLabel: 'your AGENTS.md-compatible assistant' }
];



================================================
FILE: src/core/global-config.ts
================================================
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';

// Constants
export const GLOBAL_CONFIG_DIR_NAME = 'openspec';
export const GLOBAL_CONFIG_FILE_NAME = 'config.json';
export const GLOBAL_DATA_DIR_NAME = 'openspec';

// TypeScript interfaces
export interface GlobalConfig {
  featureFlags?: Record<string, boolean>;
}

const DEFAULT_CONFIG: GlobalConfig = {
  featureFlags: {}
};

/**
 * Gets the global configuration directory path following XDG Base Directory Specification.
 *
 * - All platforms: $XDG_CONFIG_HOME/openspec/ if XDG_CONFIG_HOME is set
 * - Unix/macOS fallback: ~/.config/openspec/
 * - Windows fallback: %APPDATA%/openspec/
 */
export function getGlobalConfigDir(): string {
  // XDG_CONFIG_HOME takes precedence on all platforms when explicitly set
  const xdgConfigHome = process.env.XDG_CONFIG_HOME;
  if (xdgConfigHome) {
    return path.join(xdgConfigHome, GLOBAL_CONFIG_DIR_NAME);
  }

  const platform = os.platform();

  if (platform === 'win32') {
    // Windows: use %APPDATA%
    const appData = process.env.APPDATA;
    if (appData) {
      return path.join(appData, GLOBAL_CONFIG_DIR_NAME);
    }
    // Fallback for Windows if APPDATA is not set
    return path.join(os.homedir(), 'AppData', 'Roaming', GLOBAL_CONFIG_DIR_NAME);
  }

  // Unix/macOS fallback: ~/.config
  return path.join(os.homedir(), '.config', GLOBAL_CONFIG_DIR_NAME);
}

/**
 * Gets the global data directory path following XDG Base Directory Specification.
 * Used for user data like schema overrides.
 *
 * - All platforms: $XDG_DATA_HOME/openspec/ if XDG_DATA_HOME is set
 * - Unix/macOS fallback: ~/.local/share/openspec/
 * - Windows fallback: %LOCALAPPDATA%/openspec/
 */
export function getGlobalDataDir(): string {
  // XDG_DATA_HOME takes precedence on all platforms when explicitly set
  const xdgDataHome = process.env.XDG_DATA_HOME;
  if (xdgDataHome) {
    return path.join(xdgDataHome, GLOBAL_DATA_DIR_NAME);
  }

  const platform = os.platform();

  if (platform === 'win32') {
    // Windows: use %LOCALAPPDATA%
    const localAppData = process.env.LOCALAPPDATA;
    if (localAppData) {
      return path.join(localAppData, GLOBAL_DATA_DIR_NAME);
    }
    // Fallback for Windows if LOCALAPPDATA is not set
    return path.join(os.homedir(), 'AppData', 'Local', GLOBAL_DATA_DIR_NAME);
  }

  // Unix/macOS fallback: ~/.local/share
  return path.join(os.homedir(), '.local', 'share', GLOBAL_DATA_DIR_NAME);
}

/**
 * Gets the path to the global config file.
 */
export function getGlobalConfigPath(): string {
  return path.join(getGlobalConfigDir(), GLOBAL_CONFIG_FILE_NAME);
}

/**
 * Loads the global configuration from disk.
 * Returns default configuration if file doesn't exist or is invalid.
 * Merges loaded config with defaults to ensure new fields are available.
 */
export function getGlobalConfig(): GlobalConfig {
  const configPath = getGlobalConfigPath();

  try {
    if (!fs.existsSync(configPath)) {
      return { ...DEFAULT_CONFIG };
    }

    const content = fs.readFileSync(configPath, 'utf-8');
    const parsed = JSON.parse(content);

    // Merge with defaults (loaded values take precedence)
    return {
      ...DEFAULT_CONFIG,
      ...parsed,
      // Deep merge featureFlags
      featureFlags: {
        ...DEFAULT_CONFIG.featureFlags,
        ...(parsed.featureFlags || {})
      }
    };
  } catch (error) {
    // Log warning for parse errors, but not for missing files
    if (error instanceof SyntaxError) {
      console.error(`Warning: Invalid JSON in ${configPath}, using defaults`);
    }
    return { ...DEFAULT_CONFIG };
  }
}

/**
 * Saves the global configuration to disk.
 * Creates the config directory if it doesn't exist.
 */
export function saveGlobalConfig(config: GlobalConfig): void {
  const configDir = getGlobalConfigDir();
  const configPath = getGlobalConfigPath();

  // Create directory if it doesn't exist
  if (!fs.existsSync(configDir)) {
    fs.mkdirSync(configDir, { recursive: true });
  }

  fs.writeFileSync(configPath, JSON.stringify(config, null, 2) + '\n', 'utf-8');
}



================================================
FILE: src/core/index.ts
================================================
// Core OpenSpec logic will be implemented here
export {
  GLOBAL_CONFIG_DIR_NAME,
  GLOBAL_CONFIG_FILE_NAME,
  GLOBAL_DATA_DIR_NAME,
  type GlobalConfig,
  getGlobalConfigDir,
  getGlobalConfigPath,
  getGlobalConfig,
  saveGlobalConfig,
  getGlobalDataDir
} from './global-config.js';


================================================
FILE: src/core/init.ts
================================================
import path from 'path';
import chalk from 'chalk';
import ora from 'ora';
import { FileSystemUtils } from '../utils/file-system.js';
import { TemplateManager, ProjectContext } from './templates/index.js';
import { ToolRegistry } from './configurators/registry.js';
import { SlashCommandRegistry } from './configurators/slash/registry.js';
import {
  OpenSpecConfig,
  AI_TOOLS,
  OPENSPEC_DIR_NAME,
  AIToolOption,
  OPENSPEC_MARKERS,
} from './config.js';
import { PALETTE } from './styles/palette.js';
import {
  LETTER_MAP,
  ROOT_STUB_CHOICE_VALUE,
  OTHER_TOOLS_HEADING_VALUE,
  LIST_SPACER_VALUE,
  ToolWizardChoice,
  ToolSelectionPrompt,
  toolSelectionWizard,
  parseToolLabel,
} from './init/wizard.js';

const PROGRESS_SPINNER = {
  interval: 80,
  frames: ['â–‘â–‘â–‘', 'â–’â–‘â–‘', 'â–’â–’â–‘', 'â–’â–’â–’', 'â–“â–’â–’', 'â–“â–“â–’', 'â–“â–“â–“', 'â–’â–“â–“', 'â–‘â–’â–“'],
};

type RootStubStatus = 'created' | 'updated' | 'skipped';

type InitCommandOptions = {
  prompt?: ToolSelectionPrompt;
  tools?: string;
};

export class InitCommand {
  private readonly prompt: ToolSelectionPrompt;
  private readonly toolsArg?: string;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CONSTRUCTOR & MAIN ENTRY
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  constructor(options: InitCommandOptions = {}) {
    this.prompt = options.prompt ?? ((config) => toolSelectionWizard(config));
    this.toolsArg = options.tools;
  }

  async execute(targetPath: string): Promise<void> {
    const projectPath = path.resolve(targetPath);
    const openspecDir = OPENSPEC_DIR_NAME;
    const openspecPath = path.join(projectPath, openspecDir);

    // Validation happens silently in the background
    const extendMode = await this.validate(projectPath, openspecPath);
    const existingToolStates = await this.getExistingToolStates(projectPath, extendMode);

    this.renderBanner(extendMode);

    // Get configuration (after validation to avoid prompts if validation fails)
    const config = await this.getConfiguration(existingToolStates, extendMode);

    const availableTools = AI_TOOLS.filter((tool) => tool.available);
    const selectedIds = new Set(config.aiTools);
    const selectedTools = availableTools.filter((tool) =>
      selectedIds.has(tool.value)
    );
    const created = selectedTools.filter(
      (tool) => !existingToolStates[tool.value]
    );
    const refreshed = selectedTools.filter(
      (tool) => existingToolStates[tool.value]
    );
    const skippedExisting = availableTools.filter(
      (tool) => !selectedIds.has(tool.value) && existingToolStates[tool.value]
    );
    const skipped = availableTools.filter(
      (tool) => !selectedIds.has(tool.value) && !existingToolStates[tool.value]
    );

    // Step 1: Create directory structure
    if (!extendMode) {
      const structureSpinner = this.startSpinner(
        'Creating OpenSpec structure...'
      );
      await this.createDirectoryStructure(openspecPath);
      await this.generateFiles(openspecPath, config);
      structureSpinner.stopAndPersist({
        symbol: PALETTE.white('â–Œ'),
        text: PALETTE.white('OpenSpec structure created'),
      });
    } else {
      ora({ stream: process.stdout }).info(
        PALETTE.midGray(
          'â„¹ OpenSpec already initialized. Checking for missing files...'
        )
      );
      await this.createDirectoryStructure(openspecPath);
      await this.ensureTemplateFiles(openspecPath, config);
    }

    // Step 2: Configure AI tools
    const toolSpinner = this.startSpinner('Configuring AI tools...');
    const rootStubStatus = await this.configureAITools(
      projectPath,
      openspecDir,
      config.aiTools
    );
    toolSpinner.stopAndPersist({
      symbol: PALETTE.white('â–Œ'),
      text: PALETTE.white('AI tools configured'),
    });

    // Success message
    this.displaySuccessMessage(
      selectedTools,
      created,
      refreshed,
      skippedExisting,
      skipped,
      extendMode,
      rootStubStatus
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // VALIDATION & SETUP
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private async validate(
    projectPath: string,
    _openspecPath: string
  ): Promise<boolean> {
    const extendMode = await FileSystemUtils.directoryExists(_openspecPath);

    // Check write permissions
    if (!(await FileSystemUtils.ensureWritePermissions(projectPath))) {
      throw new Error(`Insufficient permissions to write to ${projectPath}`);
    }
    return extendMode;
  }

  private async getExistingToolStates(
    projectPath: string,
    extendMode: boolean
  ): Promise<Record<string, boolean>> {
    // Fresh initialization - no tools configured yet
    if (!extendMode) {
      return Object.fromEntries(AI_TOOLS.map(t => [t.value, false]));
    }

    // Extend mode - check all tools in parallel for better performance
    const entries = await Promise.all(
      AI_TOOLS.map(async (t) => [t.value, await this.isToolConfigured(projectPath, t.value)] as const)
    );
    return Object.fromEntries(entries);
  }

  private async isToolConfigured(
    projectPath: string,
    toolId: string
  ): Promise<boolean> {
    // A tool is only considered "configured by OpenSpec" if its files contain OpenSpec markers.
    // For tools with both config files and slash commands, BOTH must have markers.
    // For slash commands, at least one file with markers is sufficient (not all required).

    // Helper to check if a file exists and contains OpenSpec markers
    const fileHasMarkers = async (absolutePath: string): Promise<boolean> => {
      try {
        const content = await FileSystemUtils.readFile(absolutePath);
        return content.includes(OPENSPEC_MARKERS.start) && content.includes(OPENSPEC_MARKERS.end);
      } catch {
        return false;
      }
    };

    let hasConfigFile = false;
    let hasSlashCommands = false;

    // Check if the tool has a config file with OpenSpec markers
    const configFile = ToolRegistry.get(toolId)?.configFileName;
    if (configFile) {
      const configPath = path.join(projectPath, configFile);
      hasConfigFile = (await FileSystemUtils.fileExists(configPath)) && (await fileHasMarkers(configPath));
    }

    // Check if any slash command file exists with OpenSpec markers
    const slashConfigurator = SlashCommandRegistry.get(toolId);
    if (slashConfigurator) {
      for (const target of slashConfigurator.getTargets()) {
        const absolute = slashConfigurator.resolveAbsolutePath(projectPath, target.id);
        if ((await FileSystemUtils.fileExists(absolute)) && (await fileHasMarkers(absolute))) {
          hasSlashCommands = true;
          break; // At least one file with markers is sufficient
        }
      }
    }

    // Tool is only configured if BOTH exist with markers
    // OR if the tool has no config file requirement (slash commands only)
    // OR if the tool has no slash commands requirement (config file only)
    const hasConfigFileRequirement = configFile !== undefined;
    const hasSlashCommandRequirement = slashConfigurator !== undefined;

    if (hasConfigFileRequirement && hasSlashCommandRequirement) {
      // Both are required - both must be present with markers
      return hasConfigFile && hasSlashCommands;
    } else if (hasConfigFileRequirement) {
      // Only config file required
      return hasConfigFile;
    } else if (hasSlashCommandRequirement) {
      // Only slash commands required
      return hasSlashCommands;
    }

    return false;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CONFIGURATION & TOOL SELECTION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private async getConfiguration(
    existingTools: Record<string, boolean>,
    extendMode: boolean
  ): Promise<OpenSpecConfig> {
    const selectedTools = await this.getSelectedTools(existingTools, extendMode);
    return { aiTools: selectedTools };
  }

  private async getSelectedTools(
    existingTools: Record<string, boolean>,
    extendMode: boolean
  ): Promise<string[]> {
    const nonInteractiveSelection = this.resolveToolsArg();
    if (nonInteractiveSelection !== null) {
      return nonInteractiveSelection;
    }

    // Fall back to interactive mode
    return this.promptForAITools(existingTools, extendMode);
  }

  private resolveToolsArg(): string[] | null {
    if (typeof this.toolsArg === 'undefined') {
      return null;
    }

    const raw = this.toolsArg.trim();
    if (raw.length === 0) {
      throw new Error(
        'The --tools option requires a value. Use "all", "none", or a comma-separated list of tool IDs.'
      );
    }

    const availableTools = AI_TOOLS.filter((tool) => tool.available);
    const availableValues = availableTools.map((tool) => tool.value);
    const availableSet = new Set(availableValues);
    const availableList = ['all', 'none', ...availableValues].join(', ');

    const lowerRaw = raw.toLowerCase();
    if (lowerRaw === 'all') {
      return availableValues;
    }

    if (lowerRaw === 'none') {
      return [];
    }

    const tokens = raw
      .split(',')
      .map((token) => token.trim())
      .filter((token) => token.length > 0);

    if (tokens.length === 0) {
      throw new Error(
        'The --tools option requires at least one tool ID when not using "all" or "none".'
      );
    }

    const normalizedTokens = tokens.map((token) => token.toLowerCase());

    if (normalizedTokens.some((token) => token === 'all' || token === 'none')) {
      throw new Error('Cannot combine reserved values "all" or "none" with specific tool IDs.');
    }

    const invalidTokens = tokens.filter(
      (_token, index) => !availableSet.has(normalizedTokens[index])
    );

    if (invalidTokens.length > 0) {
      throw new Error(
        `Invalid tool(s): ${invalidTokens.join(', ')}. Available values: ${availableList}`
      );
    }

    const deduped: string[] = [];
    for (const token of normalizedTokens) {
      if (!deduped.includes(token)) {
        deduped.push(token);
      }
    }

    return deduped;
  }

  private async promptForAITools(
    existingTools: Record<string, boolean>,
    extendMode: boolean
  ): Promise<string[]> {
    const availableTools = AI_TOOLS.filter((tool) => tool.available);

    const baseMessage = extendMode
      ? 'Which natively supported AI tools would you like to add or refresh?'
      : 'Which natively supported AI tools do you use?';
    const initialNativeSelection = extendMode
      ? availableTools
          .filter((tool) => existingTools[tool.value])
          .map((tool) => tool.value)
      : [];

    const initialSelected = Array.from(new Set(initialNativeSelection));

    const choices: ToolWizardChoice[] = [
      {
        kind: 'heading',
        value: '__heading-native__',
        label: {
          primary:
            'Natively supported providers (âœ” OpenSpec custom slash commands available)',
        },
        selectable: false,
      },
      ...availableTools.map<ToolWizardChoice>((tool) => ({
        kind: 'option',
        value: tool.value,
        label: parseToolLabel(tool.name),
        configured: Boolean(existingTools[tool.value]),
        selectable: true,
      })),
      ...(availableTools.length
        ? ([
            {
              kind: 'info' as const,
              value: LIST_SPACER_VALUE,
              label: { primary: '' },
              selectable: false,
            },
          ] as ToolWizardChoice[])
        : []),
      {
        kind: 'heading',
        value: OTHER_TOOLS_HEADING_VALUE,
        label: {
          primary:
            'Other tools (use Universal AGENTS.md for Amp, VS Code, GitHub Copilot, â€¦)',
        },
        selectable: false,
      },
      {
        kind: 'option',
        value: ROOT_STUB_CHOICE_VALUE,
        label: {
          primary: 'Universal AGENTS.md',
          annotation: 'always available',
        },
        configured: extendMode,
        selectable: true,
      },
    ];

    return this.prompt({
      extendMode,
      baseMessage,
      choices,
      initialSelected,
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // FILE SYSTEM OPERATIONS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private async createDirectoryStructure(openspecPath: string): Promise<void> {
    const directories = [
      openspecPath,
      path.join(openspecPath, 'specs'),
      path.join(openspecPath, 'changes'),
      path.join(openspecPath, 'changes', 'archive'),
    ];

    for (const dir of directories) {
      await FileSystemUtils.createDirectory(dir);
    }
  }

  private async generateFiles(
    openspecPath: string,
    config: OpenSpecConfig
  ): Promise<void> {
    await this.writeTemplateFiles(openspecPath, config, false);
  }

  private async ensureTemplateFiles(
    openspecPath: string,
    config: OpenSpecConfig
  ): Promise<void> {
    await this.writeTemplateFiles(openspecPath, config, true);
  }

  private async writeTemplateFiles(
    openspecPath: string,
    config: OpenSpecConfig,
    skipExisting: boolean
  ): Promise<void> {
    const context: ProjectContext = {
      // Could be enhanced with prompts for project details
    };

    const templates = TemplateManager.getTemplates(context);

    for (const template of templates) {
      const filePath = path.join(openspecPath, template.path);

      // Skip if file exists and we're in skipExisting mode
      if (skipExisting && (await FileSystemUtils.fileExists(filePath))) {
        continue;
      }

      const content =
        typeof template.content === 'function'
          ? template.content(context)
          : template.content;

      await FileSystemUtils.writeFile(filePath, content);
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // TOOL CONFIGURATION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private async configureAITools(
    projectPath: string,
    openspecDir: string,
    toolIds: string[]
  ): Promise<RootStubStatus> {
    const rootStubStatus = await this.configureRootAgentsStub(
      projectPath,
      openspecDir
    );

    for (const toolId of toolIds) {
      const configurator = ToolRegistry.get(toolId);
      if (configurator && configurator.isAvailable) {
        await configurator.configure(projectPath, openspecDir);
      }

      const slashConfigurator = SlashCommandRegistry.get(toolId);
      if (slashConfigurator && slashConfigurator.isAvailable) {
        await slashConfigurator.generateAll(projectPath, openspecDir);
      }
    }

    return rootStubStatus;
  }

  private async configureRootAgentsStub(
    projectPath: string,
    openspecDir: string
  ): Promise<RootStubStatus> {
    const configurator = ToolRegistry.get('agents');
    if (!configurator || !configurator.isAvailable) {
      return 'skipped';
    }

    const stubPath = path.join(projectPath, configurator.configFileName);
    const existed = await FileSystemUtils.fileExists(stubPath);

    await configurator.configure(projectPath, openspecDir);

    return existed ? 'updated' : 'created';
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // UI & OUTPUT
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  private displaySuccessMessage(
    selectedTools: AIToolOption[],
    created: AIToolOption[],
    refreshed: AIToolOption[],
    skippedExisting: AIToolOption[],
    skipped: AIToolOption[],
    extendMode: boolean,
    rootStubStatus: RootStubStatus
  ): void {
    console.log(); // Empty line for spacing
    const successHeadline = extendMode
      ? 'OpenSpec tool configuration updated!'
      : 'OpenSpec initialized successfully!';
    ora().succeed(PALETTE.white(successHeadline));

    console.log();
    console.log(PALETTE.lightGray('Tool summary:'));
    const summaryLines = [
      rootStubStatus === 'created'
        ? `${PALETTE.white('â–Œ')} ${PALETTE.white(
            'Root AGENTS.md stub created for other assistants'
          )}`
        : null,
      rootStubStatus === 'updated'
        ? `${PALETTE.lightGray('â–Œ')} ${PALETTE.lightGray(
            'Root AGENTS.md stub refreshed for other assistants'
          )}`
        : null,
      created.length
        ? `${PALETTE.white('â–Œ')} ${PALETTE.white(
            'Created:'
          )} ${this.formatToolNames(created)}`
        : null,
      refreshed.length
        ? `${PALETTE.lightGray('â–Œ')} ${PALETTE.lightGray(
            'Refreshed:'
          )} ${this.formatToolNames(refreshed)}`
        : null,
      skippedExisting.length
        ? `${PALETTE.midGray('â–Œ')} ${PALETTE.midGray(
            'Skipped (already configured):'
          )} ${this.formatToolNames(skippedExisting)}`
        : null,
      skipped.length
        ? `${PALETTE.darkGray('â–Œ')} ${PALETTE.darkGray(
            'Skipped:'
          )} ${this.formatToolNames(skipped)}`
        : null,
    ].filter((line): line is string => Boolean(line));
    for (const line of summaryLines) {
      console.log(line);
    }

    console.log();
    console.log(
      PALETTE.midGray(
        'Use `openspec update` to refresh shared OpenSpec instructions in the future.'
      )
    );

    // Show restart instruction if any tools were configured
    if (created.length > 0 || refreshed.length > 0) {
      console.log();
      console.log(PALETTE.white('Important: Restart your IDE'));
      console.log(
        PALETTE.midGray(
          'Slash commands are loaded at startup. Please restart your coding assistant'
        )
      );
      console.log(
        PALETTE.midGray(
          'to ensure the new /openspec commands appear in your command palette.'
        )
      );
    }

    // Get the selected tool name(s) for display
    const toolName = this.formatToolNames(selectedTools);

    console.log();
    console.log(`Next steps - Copy these prompts to ${toolName}:`);
    console.log(
      chalk.gray('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
    );
    console.log(PALETTE.white('1. Populate your project context:'));
    console.log(
      PALETTE.lightGray(
        '   "Please read openspec/project.md and help me fill it out'
      )
    );
    console.log(
      PALETTE.lightGray(
        '    with details about my project, tech stack, and conventions"\n'
      )
    );
    console.log(PALETTE.white('2. Create your first change proposal:'));
    console.log(
      PALETTE.lightGray(
        '   "I want to add [YOUR FEATURE HERE]. Please create an'
      )
    );
    console.log(
      PALETTE.lightGray('    OpenSpec change proposal for this feature"\n')
    );
    console.log(PALETTE.white('3. Learn the OpenSpec workflow:'));
    console.log(
      PALETTE.lightGray(
        '   "Please explain the OpenSpec workflow from openspec/AGENTS.md'
      )
    );
    console.log(
      PALETTE.lightGray('    and how I should work with you on this project"')
    );
    console.log(
      PALETTE.darkGray(
        'â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n'
      )
    );

    // Codex heads-up: prompts installed globally
    const selectedToolIds = new Set(selectedTools.map((t) => t.value));
    if (selectedToolIds.has('codex')) {
      console.log(PALETTE.white('Codex setup note'));
      console.log(
        PALETTE.midGray('Prompts installed to ~/.codex/prompts (or $CODEX_HOME/prompts).')
      );
      console.log();
    }
  }

  private formatToolNames(tools: AIToolOption[]): string {
    const names = tools
      .map((tool) => tool.successLabel ?? tool.name)
      .filter((name): name is string => Boolean(name));

    if (names.length === 0)
      return PALETTE.lightGray('your AGENTS.md-compatible assistant');
    if (names.length === 1) return PALETTE.white(names[0]);

    const base = names.slice(0, -1).map((name) => PALETTE.white(name));
    const last = PALETTE.white(names[names.length - 1]);

    return `${base.join(PALETTE.midGray(', '))}${
      base.length ? PALETTE.midGray(', and ') : ''
    }${last}`;
  }

  private renderBanner(_extendMode: boolean): void {
    const rows = ['', '', '', '', ''];
    for (const char of 'OPENSPEC') {
      const glyph = LETTER_MAP[char] ?? LETTER_MAP[' '];
      for (let i = 0; i < rows.length; i += 1) {
        rows[i] += `${glyph[i]}  `;
      }
    }

    const rowStyles = [
      PALETTE.white,
      PALETTE.lightGray,
      PALETTE.midGray,
      PALETTE.lightGray,
      PALETTE.white,
    ];

    console.log();
    rows.forEach((row, index) => {
      console.log(rowStyles[index](row.replace(/\s+$/u, '')));
    });
    console.log();
    console.log(PALETTE.white('Welcome to OpenSpec!'));
    console.log();
  }

  private startSpinner(text: string) {
    return ora({
      text,
      stream: process.stdout,
      color: 'gray',
      spinner: PROGRESS_SPINNER,
    }).start();
  }
}



================================================
FILE: src/core/list.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import { getTaskProgressForChange, formatTaskStatus } from '../utils/task-progress.js';
import { readFileSync } from 'fs';
import { join } from 'path';
import { MarkdownParser } from './parsers/markdown-parser.js';

interface ChangeInfo {
  name: string;
  completedTasks: number;
  totalTasks: number;
  lastModified: Date;
}

interface ListOptions {
  sort?: 'recent' | 'name';
  json?: boolean;
}

/**
 * Get the most recent modification time of any file in a directory (recursive).
 * Falls back to the directory's own mtime if no files are found.
 */
async function getLastModified(dirPath: string): Promise<Date> {
  let latest: Date | null = null;

  async function walk(dir: string): Promise<void> {
    const entries = await fs.readdir(dir, { withFileTypes: true });
    for (const entry of entries) {
      const fullPath = path.join(dir, entry.name);
      if (entry.isDirectory()) {
        await walk(fullPath);
      } else {
        const stat = await fs.stat(fullPath);
        if (latest === null || stat.mtime > latest) {
          latest = stat.mtime;
        }
      }
    }
  }

  await walk(dirPath);

  // If no files found, use the directory's own modification time
  if (latest === null) {
    const dirStat = await fs.stat(dirPath);
    return dirStat.mtime;
  }

  return latest;
}

/**
 * Format a date as relative time (e.g., "2 hours ago", "3 days ago")
 */
function formatRelativeTime(date: Date): string {
  const now = new Date();
  const diffMs = now.getTime() - date.getTime();
  const diffSecs = Math.floor(diffMs / 1000);
  const diffMins = Math.floor(diffSecs / 60);
  const diffHours = Math.floor(diffMins / 60);
  const diffDays = Math.floor(diffHours / 24);

  if (diffDays > 30) {
    return date.toLocaleDateString();
  } else if (diffDays > 0) {
    return `${diffDays}d ago`;
  } else if (diffHours > 0) {
    return `${diffHours}h ago`;
  } else if (diffMins > 0) {
    return `${diffMins}m ago`;
  } else {
    return 'just now';
  }
}

export class ListCommand {
  async execute(targetPath: string = '.', mode: 'changes' | 'specs' = 'changes', options: ListOptions = {}): Promise<void> {
    const { sort = 'recent', json = false } = options;

    if (mode === 'changes') {
      const changesDir = path.join(targetPath, 'openspec', 'changes');

      // Check if changes directory exists
      try {
        await fs.access(changesDir);
      } catch {
        throw new Error("No OpenSpec changes directory found. Run 'openspec init' first.");
      }

      // Get all directories in changes (excluding archive)
      const entries = await fs.readdir(changesDir, { withFileTypes: true });
      const changeDirs = entries
        .filter(entry => entry.isDirectory() && entry.name !== 'archive')
        .map(entry => entry.name);

      if (changeDirs.length === 0) {
        if (json) {
          console.log(JSON.stringify({ changes: [] }));
        } else {
          console.log('No active changes found.');
        }
        return;
      }

      // Collect information about each change
      const changes: ChangeInfo[] = [];

      for (const changeDir of changeDirs) {
        const progress = await getTaskProgressForChange(changesDir, changeDir);
        const changePath = path.join(changesDir, changeDir);
        const lastModified = await getLastModified(changePath);
        changes.push({
          name: changeDir,
          completedTasks: progress.completed,
          totalTasks: progress.total,
          lastModified
        });
      }

      // Sort by preference (default: recent first)
      if (sort === 'recent') {
        changes.sort((a, b) => b.lastModified.getTime() - a.lastModified.getTime());
      } else {
        changes.sort((a, b) => a.name.localeCompare(b.name));
      }

      // JSON output for programmatic use
      if (json) {
        const jsonOutput = changes.map(c => ({
          name: c.name,
          completedTasks: c.completedTasks,
          totalTasks: c.totalTasks,
          lastModified: c.lastModified.toISOString(),
          status: c.totalTasks === 0 ? 'no-tasks' : c.completedTasks === c.totalTasks ? 'complete' : 'in-progress'
        }));
        console.log(JSON.stringify({ changes: jsonOutput }, null, 2));
        return;
      }

      // Display results
      console.log('Changes:');
      const padding = '  ';
      const nameWidth = Math.max(...changes.map(c => c.name.length));
      for (const change of changes) {
        const paddedName = change.name.padEnd(nameWidth);
        const status = formatTaskStatus({ total: change.totalTasks, completed: change.completedTasks });
        const timeAgo = formatRelativeTime(change.lastModified);
        console.log(`${padding}${paddedName}     ${status.padEnd(12)}  ${timeAgo}`);
      }
      return;
    }

    // specs mode
    const specsDir = path.join(targetPath, 'openspec', 'specs');
    try {
      await fs.access(specsDir);
    } catch {
      console.log('No specs found.');
      return;
    }

    const entries = await fs.readdir(specsDir, { withFileTypes: true });
    const specDirs = entries.filter(e => e.isDirectory()).map(e => e.name);
    if (specDirs.length === 0) {
      console.log('No specs found.');
      return;
    }

    type SpecInfo = { id: string; requirementCount: number };
    const specs: SpecInfo[] = [];
    for (const id of specDirs) {
      const specPath = join(specsDir, id, 'spec.md');
      try {
        const content = readFileSync(specPath, 'utf-8');
        const parser = new MarkdownParser(content);
        const spec = parser.parseSpec(id);
        specs.push({ id, requirementCount: spec.requirements.length });
      } catch {
        // If spec cannot be read or parsed, include with 0 count
        specs.push({ id, requirementCount: 0 });
      }
    }

    specs.sort((a, b) => a.id.localeCompare(b.id));
    console.log('Specs:');
    const padding = '  ';
    const nameWidth = Math.max(...specs.map(s => s.id.length));
    for (const spec of specs) {
      const padded = spec.id.padEnd(nameWidth);
      console.log(`${padding}${padded}     requirements ${spec.requirementCount}`);
    }
  }
}


================================================
FILE: src/core/project-config.ts
================================================
import { existsSync, readFileSync, statSync } from 'fs';
import path from 'path';
import { parse as parseYaml } from 'yaml';
import { z } from 'zod';

/**
 * Zod schema for project configuration.
 *
 * Purpose:
 * 1. Documentation - clearly defines the config file structure
 * 2. Type safety - TypeScript infers ProjectConfig type from schema
 * 3. Runtime validation - uses safeParse() for resilient field-by-field validation
 *
 * Why Zod over manual validation:
 * - Helps understand OpenSpec's data interfaces at a glance
 * - Single source of truth for type and validation
 * - Consistent with other OpenSpec schemas
 */
export const ProjectConfigSchema = z.object({
  // Required: which schema to use (e.g., "spec-driven", "tdd", or project-local schema name)
  schema: z
    .string()
    .min(1)
    .describe('The workflow schema to use (e.g., "spec-driven", "tdd")'),

  // Optional: project context (injected into all artifact instructions)
  // Max size: 50KB (enforced during parsing)
  context: z
    .string()
    .optional()
    .describe('Project context injected into all artifact instructions'),

  // Optional: per-artifact rules (additive to schema's built-in guidance)
  rules: z
    .record(
      z.string(), // artifact ID
      z.array(z.string()) // list of rules
    )
    .optional()
    .describe('Per-artifact rules, keyed by artifact ID'),
});

export type ProjectConfig = z.infer<typeof ProjectConfigSchema>;

const MAX_CONTEXT_SIZE = 50 * 1024; // 50KB hard limit

/**
 * Read and parse openspec/config.yaml from project root.
 * Uses resilient parsing - validates each field independently using Zod safeParse.
 * Returns null if file doesn't exist.
 * Returns partial config if some fields are invalid (with warnings).
 *
 * Performance note (Jan 2025):
 * Benchmarks showed direct file reads are fast enough without caching:
 * - Typical config (1KB): ~0.5ms per read
 * - Large config (50KB): ~1.6ms per read
 * - Missing config: ~0.01ms per read
 * Config is read 1-2 times per command (schema resolution + instruction loading),
 * adding ~1-3ms total overhead. Caching would add complexity (mtime checks,
 * invalidation logic) for negligible benefit. Direct reads also ensure config
 * changes are reflected immediately without stale cache issues.
 *
 * @param projectRoot - The root directory of the project (where `openspec/` lives)
 * @returns Parsed config or null if file doesn't exist
 */
export function readProjectConfig(projectRoot: string): ProjectConfig | null {
  // Try both .yaml and .yml, prefer .yaml
  let configPath = path.join(projectRoot, 'openspec', 'config.yaml');
  if (!existsSync(configPath)) {
    configPath = path.join(projectRoot, 'openspec', 'config.yml');
    if (!existsSync(configPath)) {
      return null; // No config is OK
    }
  }

  try {
    const content = readFileSync(configPath, 'utf-8');
    const raw = parseYaml(content);

    if (!raw || typeof raw !== 'object') {
      console.warn(`openspec/config.yaml is not a valid YAML object`);
      return null;
    }

    const config: Partial<ProjectConfig> = {};

    // Parse schema field using Zod
    const schemaField = z.string().min(1);
    const schemaResult = schemaField.safeParse(raw.schema);
    if (schemaResult.success) {
      config.schema = schemaResult.data;
    } else if (raw.schema !== undefined) {
      console.warn(`Invalid 'schema' field in config (must be non-empty string)`);
    }

    // Parse context field with size limit
    if (raw.context !== undefined) {
      const contextField = z.string();
      const contextResult = contextField.safeParse(raw.context);

      if (contextResult.success) {
        const contextSize = Buffer.byteLength(contextResult.data, 'utf-8');
        if (contextSize > MAX_CONTEXT_SIZE) {
          console.warn(
            `Context too large (${(contextSize / 1024).toFixed(1)}KB, limit: ${MAX_CONTEXT_SIZE / 1024}KB)`
          );
          console.warn(`Ignoring context field`);
        } else {
          config.context = contextResult.data;
        }
      } else {
        console.warn(`Invalid 'context' field in config (must be string)`);
      }
    }

    // Parse rules field using Zod
    if (raw.rules !== undefined) {
      const rulesField = z.record(z.string(), z.array(z.string()));

      // First check if it's an object structure (guard against null since typeof null === 'object')
      if (typeof raw.rules === 'object' && raw.rules !== null && !Array.isArray(raw.rules)) {
        const parsedRules: Record<string, string[]> = {};
        let hasValidRules = false;

        for (const [artifactId, rules] of Object.entries(raw.rules)) {
          const rulesArrayResult = z.array(z.string()).safeParse(rules);

          if (rulesArrayResult.success) {
            // Filter out empty strings
            const validRules = rulesArrayResult.data.filter((r) => r.length > 0);
            if (validRules.length > 0) {
              parsedRules[artifactId] = validRules;
              hasValidRules = true;
            }
            if (validRules.length < rulesArrayResult.data.length) {
              console.warn(
                `Some rules for '${artifactId}' are empty strings, ignoring them`
              );
            }
          } else {
            console.warn(
              `Rules for '${artifactId}' must be an array of strings, ignoring this artifact's rules`
            );
          }
        }

        if (hasValidRules) {
          config.rules = parsedRules;
        }
      } else {
        console.warn(`Invalid 'rules' field in config (must be object)`);
      }
    }

    // Return partial config even if some fields failed
    return Object.keys(config).length > 0 ? (config as ProjectConfig) : null;
  } catch (error) {
    console.warn(`Failed to parse openspec/config.yaml:`, error);
    return null;
  }
}

/**
 * Validate artifact IDs in rules against a schema's artifacts.
 * Called during instruction loading (when schema is known).
 * Returns warnings for unknown artifact IDs.
 *
 * @param rules - The rules object from config
 * @param validArtifactIds - Set of valid artifact IDs from the schema
 * @param schemaName - Name of the schema for error messages
 * @returns Array of warning messages for unknown artifact IDs
 */
export function validateConfigRules(
  rules: Record<string, string[]>,
  validArtifactIds: Set<string>,
  schemaName: string
): string[] {
  const warnings: string[] = [];

  for (const artifactId of Object.keys(rules)) {
    if (!validArtifactIds.has(artifactId)) {
      const validIds = Array.from(validArtifactIds).sort().join(', ');
      warnings.push(
        `Unknown artifact ID in rules: "${artifactId}". ` +
          `Valid IDs for schema "${schemaName}": ${validIds}`
      );
    }
  }

  return warnings;
}

/**
 * Suggest valid schema names when user provides invalid schema.
 * Uses fuzzy matching to find similar names.
 *
 * @param invalidSchemaName - The invalid schema name from config
 * @param availableSchemas - List of available schemas with their type (built-in or project-local)
 * @returns Error message with suggestions and available schemas
 */
export function suggestSchemas(
  invalidSchemaName: string,
  availableSchemas: { name: string; isBuiltIn: boolean }[]
): string {
  // Simple fuzzy match: Levenshtein distance
  function levenshtein(a: string, b: string): number {
    const matrix: number[][] = [];
    for (let i = 0; i <= b.length; i++) {
      matrix[i] = [i];
    }
    for (let j = 0; j <= a.length; j++) {
      matrix[0][j] = j;
    }
    for (let i = 1; i <= b.length; i++) {
      for (let j = 1; j <= a.length; j++) {
        if (b.charAt(i - 1) === a.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          );
        }
      }
    }
    return matrix[b.length][a.length];
  }

  // Find closest matches (distance <= 3)
  const suggestions = availableSchemas
    .map((s) => ({ ...s, distance: levenshtein(invalidSchemaName, s.name) }))
    .filter((s) => s.distance <= 3)
    .sort((a, b) => a.distance - b.distance)
    .slice(0, 3);

  const builtIn = availableSchemas.filter((s) => s.isBuiltIn).map((s) => s.name);
  const projectLocal = availableSchemas.filter((s) => !s.isBuiltIn).map((s) => s.name);

  let message = `Schema '${invalidSchemaName}' not found in openspec/config.yaml\n\n`;

  if (suggestions.length > 0) {
    message += `Did you mean one of these?\n`;
    suggestions.forEach((s) => {
      const type = s.isBuiltIn ? 'built-in' : 'project-local';
      message += `  - ${s.name} (${type})\n`;
    });
    message += '\n';
  }

  message += `Available schemas:\n`;
  if (builtIn.length > 0) {
    message += `  Built-in: ${builtIn.join(', ')}\n`;
  }
  if (projectLocal.length > 0) {
    message += `  Project-local: ${projectLocal.join(', ')}\n`;
  } else {
    message += `  Project-local: (none found)\n`;
  }

  message += `\nFix: Edit openspec/config.yaml and change 'schema: ${invalidSchemaName}' to a valid schema name`;

  return message;
}



================================================
FILE: src/core/specs-apply.ts
================================================
/**
 * Spec Application Logic
 *
 * Extracted from ArchiveCommand to enable standalone spec application.
 * Applies delta specs from a change to main specs without archiving.
 */

import { promises as fs } from 'fs';
import path from 'path';
import chalk from 'chalk';
import {
  extractRequirementsSection,
  parseDeltaSpec,
  normalizeRequirementName,
  type RequirementBlock,
} from './parsers/requirement-blocks.js';
import { Validator } from './validation/validator.js';

// -----------------------------------------------------------------------------
// Types
// -----------------------------------------------------------------------------

export interface SpecUpdate {
  source: string;
  target: string;
  exists: boolean;
}

export interface ApplyResult {
  capability: string;
  added: number;
  modified: number;
  removed: number;
  renamed: number;
}

export interface SpecsApplyOutput {
  changeName: string;
  capabilities: ApplyResult[];
  totals: {
    added: number;
    modified: number;
    removed: number;
    renamed: number;
  };
  noChanges: boolean;
}

// -----------------------------------------------------------------------------
// Public API
// -----------------------------------------------------------------------------

/**
 * Find all delta spec files that need to be applied from a change.
 */
export async function findSpecUpdates(changeDir: string, mainSpecsDir: string): Promise<SpecUpdate[]> {
  const updates: SpecUpdate[] = [];
  const changeSpecsDir = path.join(changeDir, 'specs');

  try {
    const entries = await fs.readdir(changeSpecsDir, { withFileTypes: true });

    for (const entry of entries) {
      if (entry.isDirectory()) {
        const specFile = path.join(changeSpecsDir, entry.name, 'spec.md');
        const targetFile = path.join(mainSpecsDir, entry.name, 'spec.md');

        try {
          await fs.access(specFile);

          // Check if target exists
          let exists = false;
          try {
            await fs.access(targetFile);
            exists = true;
          } catch {
            exists = false;
          }

          updates.push({
            source: specFile,
            target: targetFile,
            exists,
          });
        } catch {
          // Source spec doesn't exist, skip
        }
      }
    }
  } catch {
    // No specs directory in change
  }

  return updates;
}

/**
 * Build an updated spec by applying delta operations.
 * Returns the rebuilt content and counts of operations.
 */
export async function buildUpdatedSpec(
  update: SpecUpdate,
  changeName: string
): Promise<{ rebuilt: string; counts: { added: number; modified: number; removed: number; renamed: number } }> {
  // Read change spec content (delta-format expected)
  const changeContent = await fs.readFile(update.source, 'utf-8');

  // Parse deltas from the change spec file
  const plan = parseDeltaSpec(changeContent);
  const specName = path.basename(path.dirname(update.target));

  // Pre-validate duplicates within sections
  const addedNames = new Set<string>();
  for (const add of plan.added) {
    const name = normalizeRequirementName(add.name);
    if (addedNames.has(name)) {
      throw new Error(
        `${specName} validation failed - duplicate requirement in ADDED for header "### Requirement: ${add.name}"`
      );
    }
    addedNames.add(name);
  }
  const modifiedNames = new Set<string>();
  for (const mod of plan.modified) {
    const name = normalizeRequirementName(mod.name);
    if (modifiedNames.has(name)) {
      throw new Error(
        `${specName} validation failed - duplicate requirement in MODIFIED for header "### Requirement: ${mod.name}"`
      );
    }
    modifiedNames.add(name);
  }
  const removedNamesSet = new Set<string>();
  for (const rem of plan.removed) {
    const name = normalizeRequirementName(rem);
    if (removedNamesSet.has(name)) {
      throw new Error(
        `${specName} validation failed - duplicate requirement in REMOVED for header "### Requirement: ${rem}"`
      );
    }
    removedNamesSet.add(name);
  }
  const renamedFromSet = new Set<string>();
  const renamedToSet = new Set<string>();
  for (const { from, to } of plan.renamed) {
    const fromNorm = normalizeRequirementName(from);
    const toNorm = normalizeRequirementName(to);
    if (renamedFromSet.has(fromNorm)) {
      throw new Error(
        `${specName} validation failed - duplicate FROM in RENAMED for header "### Requirement: ${from}"`
      );
    }
    if (renamedToSet.has(toNorm)) {
      throw new Error(
        `${specName} validation failed - duplicate TO in RENAMED for header "### Requirement: ${to}"`
      );
    }
    renamedFromSet.add(fromNorm);
    renamedToSet.add(toNorm);
  }

  // Pre-validate cross-section conflicts
  const conflicts: Array<{ name: string; a: string; b: string }> = [];
  for (const n of modifiedNames) {
    if (removedNamesSet.has(n)) conflicts.push({ name: n, a: 'MODIFIED', b: 'REMOVED' });
    if (addedNames.has(n)) conflicts.push({ name: n, a: 'MODIFIED', b: 'ADDED' });
  }
  for (const n of addedNames) {
    if (removedNamesSet.has(n)) conflicts.push({ name: n, a: 'ADDED', b: 'REMOVED' });
  }
  // Renamed interplay: MODIFIED must reference the NEW header, not FROM
  for (const { from, to } of plan.renamed) {
    const fromNorm = normalizeRequirementName(from);
    const toNorm = normalizeRequirementName(to);
    if (modifiedNames.has(fromNorm)) {
      throw new Error(
        `${specName} validation failed - when a rename exists, MODIFIED must reference the NEW header "### Requirement: ${to}"`
      );
    }
    // Detect ADDED colliding with a RENAMED TO
    if (addedNames.has(toNorm)) {
      throw new Error(
        `${specName} validation failed - RENAMED TO header collides with ADDED for "### Requirement: ${to}"`
      );
    }
  }
  if (conflicts.length > 0) {
    const c = conflicts[0];
    throw new Error(
      `${specName} validation failed - requirement present in multiple sections (${c.a} and ${c.b}) for header "### Requirement: ${c.name}"`
    );
  }
  const hasAnyDelta = plan.added.length + plan.modified.length + plan.removed.length + plan.renamed.length > 0;
  if (!hasAnyDelta) {
    throw new Error(
      `Delta parsing found no operations for ${path.basename(path.dirname(update.source))}. ` +
        `Provide ADDED/MODIFIED/REMOVED/RENAMED sections in change spec.`
    );
  }

  // Load or create base target content
  let targetContent: string;
  let isNewSpec = false;
  try {
    targetContent = await fs.readFile(update.target, 'utf-8');
  } catch {
    // Target spec does not exist; MODIFIED and RENAMED are not allowed for new specs
    // REMOVED will be ignored with a warning since there's nothing to remove
    if (plan.modified.length > 0 || plan.renamed.length > 0) {
      throw new Error(
        `${specName}: target spec does not exist; only ADDED requirements are allowed for new specs. MODIFIED and RENAMED operations require an existing spec.`
      );
    }
    // Warn about REMOVED requirements being ignored for new specs
    if (plan.removed.length > 0) {
      console.log(
        chalk.yellow(
          `âš ï¸  Warning: ${specName} - ${plan.removed.length} REMOVED requirement(s) ignored for new spec (nothing to remove).`
        )
      );
    }
    isNewSpec = true;
    targetContent = buildSpecSkeleton(specName, changeName);
  }

  // Extract requirements section and build name->block map
  const parts = extractRequirementsSection(targetContent);
  const nameToBlock = new Map<string, RequirementBlock>();
  for (const block of parts.bodyBlocks) {
    nameToBlock.set(normalizeRequirementName(block.name), block);
  }

  // Apply operations in order: RENAMED â†’ REMOVED â†’ MODIFIED â†’ ADDED
  // RENAMED
  for (const r of plan.renamed) {
    const from = normalizeRequirementName(r.from);
    const to = normalizeRequirementName(r.to);
    if (!nameToBlock.has(from)) {
      throw new Error(`${specName} RENAMED failed for header "### Requirement: ${r.from}" - source not found`);
    }
    if (nameToBlock.has(to)) {
      throw new Error(`${specName} RENAMED failed for header "### Requirement: ${r.to}" - target already exists`);
    }
    const block = nameToBlock.get(from)!;
    const newHeader = `### Requirement: ${to}`;
    const rawLines = block.raw.split('\n');
    rawLines[0] = newHeader;
    const renamedBlock: RequirementBlock = {
      headerLine: newHeader,
      name: to,
      raw: rawLines.join('\n'),
    };
    nameToBlock.delete(from);
    nameToBlock.set(to, renamedBlock);
  }

  // REMOVED
  for (const name of plan.removed) {
    const key = normalizeRequirementName(name);
    if (!nameToBlock.has(key)) {
      // For new specs, REMOVED requirements are already warned about and ignored
      // For existing specs, missing requirements are an error
      if (!isNewSpec) {
        throw new Error(`${specName} REMOVED failed for header "### Requirement: ${name}" - not found`);
      }
      // Skip removal for new specs (already warned above)
      continue;
    }
    nameToBlock.delete(key);
  }

  // MODIFIED
  for (const mod of plan.modified) {
    const key = normalizeRequirementName(mod.name);
    if (!nameToBlock.has(key)) {
      throw new Error(`${specName} MODIFIED failed for header "### Requirement: ${mod.name}" - not found`);
    }
    // Replace block with provided raw (ensure header line matches key)
    const modHeaderMatch = mod.raw.split('\n')[0].match(/^###\s*Requirement:\s*(.+)\s*$/);
    if (!modHeaderMatch || normalizeRequirementName(modHeaderMatch[1]) !== key) {
      throw new Error(
        `${specName} MODIFIED failed for header "### Requirement: ${mod.name}" - header mismatch in content`
      );
    }
    nameToBlock.set(key, mod);
  }

  // ADDED
  for (const add of plan.added) {
    const key = normalizeRequirementName(add.name);
    if (nameToBlock.has(key)) {
      throw new Error(`${specName} ADDED failed for header "### Requirement: ${add.name}" - already exists`);
    }
    nameToBlock.set(key, add);
  }

  // Duplicates within resulting map are implicitly prevented by key uniqueness.

  // Recompose requirements section preserving original ordering where possible
  const keptOrder: RequirementBlock[] = [];
  const seen = new Set<string>();
  for (const block of parts.bodyBlocks) {
    const key = normalizeRequirementName(block.name);
    const replacement = nameToBlock.get(key);
    if (replacement) {
      keptOrder.push(replacement);
      seen.add(key);
    }
  }
  // Append any newly added that were not in original order
  for (const [key, block] of nameToBlock.entries()) {
    if (!seen.has(key)) {
      keptOrder.push(block);
    }
  }

  const reqBody = [parts.preamble && parts.preamble.trim() ? parts.preamble.trimEnd() : '']
    .filter(Boolean)
    .concat(keptOrder.map((b) => b.raw))
    .join('\n\n')
    .trimEnd();

  const rebuilt = [parts.before.trimEnd(), parts.headerLine, reqBody, parts.after]
    .filter((s, idx) => !(idx === 0 && s === ''))
    .join('\n')
    .replace(/\n{3,}/g, '\n\n');

  return {
    rebuilt,
    counts: {
      added: plan.added.length,
      modified: plan.modified.length,
      removed: plan.removed.length,
      renamed: plan.renamed.length,
    },
  };
}

/**
 * Write an updated spec to disk.
 */
export async function writeUpdatedSpec(
  update: SpecUpdate,
  rebuilt: string,
  counts: { added: number; modified: number; removed: number; renamed: number }
): Promise<void> {
  // Create target directory if needed
  const targetDir = path.dirname(update.target);
  await fs.mkdir(targetDir, { recursive: true });
  await fs.writeFile(update.target, rebuilt);

  const specName = path.basename(path.dirname(update.target));
  console.log(`Applying changes to openspec/specs/${specName}/spec.md:`);
  if (counts.added) console.log(`  + ${counts.added} added`);
  if (counts.modified) console.log(`  ~ ${counts.modified} modified`);
  if (counts.removed) console.log(`  - ${counts.removed} removed`);
  if (counts.renamed) console.log(`  â†’ ${counts.renamed} renamed`);
}

/**
 * Build a skeleton spec for new capabilities.
 */
export function buildSpecSkeleton(specFolderName: string, changeName: string): string {
  const titleBase = specFolderName;
  return `# ${titleBase} Specification\n\n## Purpose\nTBD - created by archiving change ${changeName}. Update Purpose after archive.\n\n## Requirements\n`;
}

/**
 * Apply all delta specs from a change to main specs.
 *
 * @param projectRoot - The project root directory
 * @param changeName - The name of the change to apply
 * @param options - Options for the operation
 * @returns Result of the operation with counts
 */
export async function applySpecs(
  projectRoot: string,
  changeName: string,
  options: {
    dryRun?: boolean;
    skipValidation?: boolean;
    silent?: boolean;
  } = {}
): Promise<SpecsApplyOutput> {
  const changeDir = path.join(projectRoot, 'openspec', 'changes', changeName);
  const mainSpecsDir = path.join(projectRoot, 'openspec', 'specs');

  // Verify change exists
  try {
    const stat = await fs.stat(changeDir);
    if (!stat.isDirectory()) {
      throw new Error(`Change '${changeName}' not found.`);
    }
  } catch {
    throw new Error(`Change '${changeName}' not found.`);
  }

  // Find specs to update
  const specUpdates = await findSpecUpdates(changeDir, mainSpecsDir);

  if (specUpdates.length === 0) {
    return {
      changeName,
      capabilities: [],
      totals: { added: 0, modified: 0, removed: 0, renamed: 0 },
      noChanges: true,
    };
  }

  // Prepare all updates first (validation pass, no writes)
  const prepared: Array<{
    update: SpecUpdate;
    rebuilt: string;
    counts: { added: number; modified: number; removed: number; renamed: number };
  }> = [];

  for (const update of specUpdates) {
    const built = await buildUpdatedSpec(update, changeName);
    prepared.push({ update, rebuilt: built.rebuilt, counts: built.counts });
  }

  // Validate rebuilt specs unless validation is skipped
  if (!options.skipValidation) {
    const validator = new Validator();
    for (const p of prepared) {
      const specName = path.basename(path.dirname(p.update.target));
      const report = await validator.validateSpecContent(specName, p.rebuilt);
      if (!report.valid) {
        const errors = report.issues
          .filter((i) => i.level === 'ERROR')
          .map((i) => `  âœ— ${i.message}`)
          .join('\n');
        throw new Error(`Validation errors in rebuilt spec for ${specName}:\n${errors}`);
      }
    }
  }

  // Build results
  const capabilities: ApplyResult[] = [];
  const totals = { added: 0, modified: 0, removed: 0, renamed: 0 };

  for (const p of prepared) {
    const capability = path.basename(path.dirname(p.update.target));

    if (!options.dryRun) {
      // Write the updated spec
      const targetDir = path.dirname(p.update.target);
      await fs.mkdir(targetDir, { recursive: true });
      await fs.writeFile(p.update.target, p.rebuilt);

      if (!options.silent) {
        console.log(`Applying changes to openspec/specs/${capability}/spec.md:`);
        if (p.counts.added) console.log(`  + ${p.counts.added} added`);
        if (p.counts.modified) console.log(`  ~ ${p.counts.modified} modified`);
        if (p.counts.removed) console.log(`  - ${p.counts.removed} removed`);
        if (p.counts.renamed) console.log(`  â†’ ${p.counts.renamed} renamed`);
      }
    } else if (!options.silent) {
      console.log(`Would apply changes to openspec/specs/${capability}/spec.md:`);
      if (p.counts.added) console.log(`  + ${p.counts.added} added`);
      if (p.counts.modified) console.log(`  ~ ${p.counts.modified} modified`);
      if (p.counts.removed) console.log(`  - ${p.counts.removed} removed`);
      if (p.counts.renamed) console.log(`  â†’ ${p.counts.renamed} renamed`);
    }

    capabilities.push({
      capability,
      ...p.counts,
    });

    totals.added += p.counts.added;
    totals.modified += p.counts.modified;
    totals.removed += p.counts.removed;
    totals.renamed += p.counts.renamed;
  }

  return {
    changeName,
    capabilities,
    totals,
    noChanges: false,
  };
}



================================================
FILE: src/core/update.ts
================================================
import path from 'path';
import { FileSystemUtils } from '../utils/file-system.js';
import { OPENSPEC_DIR_NAME } from './config.js';
import { ToolRegistry } from './configurators/registry.js';
import { SlashCommandRegistry } from './configurators/slash/registry.js';
import { agentsTemplate } from './templates/agents-template.js';

export class UpdateCommand {
  async execute(projectPath: string): Promise<void> {
    const resolvedProjectPath = path.resolve(projectPath);
    const openspecDirName = OPENSPEC_DIR_NAME;
    const openspecPath = path.join(resolvedProjectPath, openspecDirName);

    // 1. Check openspec directory exists
    if (!await FileSystemUtils.directoryExists(openspecPath)) {
      throw new Error(`No OpenSpec directory found. Run 'openspec init' first.`);
    }

    // 2. Update AGENTS.md (full replacement)
    const agentsPath = path.join(openspecPath, 'AGENTS.md');

    await FileSystemUtils.writeFile(agentsPath, agentsTemplate);

    // 3. Update existing AI tool configuration files only
    const configurators = ToolRegistry.getAll();
    const slashConfigurators = SlashCommandRegistry.getAll();
    const updatedFiles: string[] = [];
    const createdFiles: string[] = [];
    const failedFiles: string[] = [];
    const updatedSlashFiles: string[] = [];
    const failedSlashTools: string[] = [];

    for (const configurator of configurators) {
      const configFilePath = path.join(
        resolvedProjectPath,
        configurator.configFileName
      );
      const fileExists = await FileSystemUtils.fileExists(configFilePath);
      const shouldConfigure =
        fileExists || configurator.configFileName === 'AGENTS.md';

      if (!shouldConfigure) {
        continue;
      }

      try {
        if (fileExists && !await FileSystemUtils.canWriteFile(configFilePath)) {
          throw new Error(
            `Insufficient permissions to modify ${configurator.configFileName}`
          );
        }

        await configurator.configure(resolvedProjectPath, openspecPath);
        updatedFiles.push(configurator.configFileName);

        if (!fileExists) {
          createdFiles.push(configurator.configFileName);
        }
      } catch (error) {
        failedFiles.push(configurator.configFileName);
        console.error(
          `Failed to update ${configurator.configFileName}: ${
            error instanceof Error ? error.message : String(error)
          }`
        );
      }
    }

    for (const slashConfigurator of slashConfigurators) {
      if (!slashConfigurator.isAvailable) {
        continue;
      }

      try {
        const updated = await slashConfigurator.updateExisting(
          resolvedProjectPath,
          openspecPath
        );
        updatedSlashFiles.push(...updated);
      } catch (error) {
        failedSlashTools.push(slashConfigurator.toolId);
        console.error(
          `Failed to update slash commands for ${slashConfigurator.toolId}: ${
            error instanceof Error ? error.message : String(error)
          }`
        );
      }
    }

    const summaryParts: string[] = [];
    const instructionFiles: string[] = ['openspec/AGENTS.md'];

    if (updatedFiles.includes('AGENTS.md')) {
      instructionFiles.push(
        createdFiles.includes('AGENTS.md') ? 'AGENTS.md (created)' : 'AGENTS.md'
      );
    }

    summaryParts.push(
      `Updated OpenSpec instructions (${instructionFiles.join(', ')})`
    );

    const aiToolFiles = updatedFiles.filter((file) => file !== 'AGENTS.md');
    if (aiToolFiles.length > 0) {
      summaryParts.push(`Updated AI tool files: ${aiToolFiles.join(', ')}`);
    }

    if (updatedSlashFiles.length > 0) {
      // Normalize to forward slashes for cross-platform log consistency
      const normalized = updatedSlashFiles.map((p) => FileSystemUtils.toPosixPath(p));
      summaryParts.push(`Updated slash commands: ${normalized.join(', ')}`);
    }

    const failedItems = [
      ...failedFiles,
      ...failedSlashTools.map(
        (toolId) => `slash command refresh (${toolId})`
      ),
    ];

    if (failedItems.length > 0) {
      summaryParts.push(`Failed to update: ${failedItems.join(', ')}`);
    }

    console.log(summaryParts.join(' | '));

    // No additional notes
  }
}



================================================
FILE: src/core/view.ts
================================================
import * as fs from 'fs';
import * as path from 'path';
import chalk from 'chalk';
import { getTaskProgressForChange, formatTaskStatus } from '../utils/task-progress.js';
import { MarkdownParser } from './parsers/markdown-parser.js';

export class ViewCommand {
  async execute(targetPath: string = '.'): Promise<void> {
    const openspecDir = path.join(targetPath, 'openspec');
    
    if (!fs.existsSync(openspecDir)) {
      console.error(chalk.red('No openspec directory found'));
      process.exit(1);
    }

    console.log(chalk.bold('\nOpenSpec Dashboard\n'));
    console.log('â•'.repeat(60));

    // Get changes and specs data
    const changesData = await this.getChangesData(openspecDir);
    const specsData = await this.getSpecsData(openspecDir);

    // Display summary metrics
    this.displaySummary(changesData, specsData);

    // Display draft changes
    if (changesData.draft.length > 0) {
      console.log(chalk.bold.gray('\nDraft Changes'));
      console.log('â”€'.repeat(60));
      changesData.draft.forEach((change) => {
        console.log(`  ${chalk.gray('â—‹')} ${change.name}`);
      });
    }

    // Display active changes
    if (changesData.active.length > 0) {
      console.log(chalk.bold.cyan('\nActive Changes'));
      console.log('â”€'.repeat(60));
      changesData.active.forEach((change) => {
        const progressBar = this.createProgressBar(change.progress.completed, change.progress.total);
        const percentage =
          change.progress.total > 0
            ? Math.round((change.progress.completed / change.progress.total) * 100)
            : 0;

        console.log(
          `  ${chalk.yellow('â—‰')} ${chalk.bold(change.name.padEnd(30))} ${progressBar} ${chalk.dim(`${percentage}%`)}`
        );
      });
    }

    // Display completed changes
    if (changesData.completed.length > 0) {
      console.log(chalk.bold.green('\nCompleted Changes'));
      console.log('â”€'.repeat(60));
      changesData.completed.forEach((change) => {
        console.log(`  ${chalk.green('âœ“')} ${change.name}`);
      });
    }

    // Display specifications
    if (specsData.length > 0) {
      console.log(chalk.bold.blue('\nSpecifications'));
      console.log('â”€'.repeat(60));
      
      // Sort specs by requirement count (descending)
      specsData.sort((a, b) => b.requirementCount - a.requirementCount);
      
      specsData.forEach(spec => {
        const reqLabel = spec.requirementCount === 1 ? 'requirement' : 'requirements';
        console.log(
          `  ${chalk.blue('â–ª')} ${chalk.bold(spec.name.padEnd(30))} ${chalk.dim(`${spec.requirementCount} ${reqLabel}`)}`
        );
      });
    }

    console.log('\n' + 'â•'.repeat(60));
    console.log(chalk.dim(`\nUse ${chalk.white('openspec list --changes')} or ${chalk.white('openspec list --specs')} for detailed views`));
  }

  private async getChangesData(openspecDir: string): Promise<{
    draft: Array<{ name: string }>;
    active: Array<{ name: string; progress: { total: number; completed: number } }>;
    completed: Array<{ name: string }>;
  }> {
    const changesDir = path.join(openspecDir, 'changes');

    if (!fs.existsSync(changesDir)) {
      return { draft: [], active: [], completed: [] };
    }

    const draft: Array<{ name: string }> = [];
    const active: Array<{ name: string; progress: { total: number; completed: number } }> = [];
    const completed: Array<{ name: string }> = [];

    const entries = fs.readdirSync(changesDir, { withFileTypes: true });

    for (const entry of entries) {
      if (entry.isDirectory() && entry.name !== 'archive') {
        const progress = await getTaskProgressForChange(changesDir, entry.name);

        if (progress.total === 0) {
          // No tasks defined yet - still in planning/draft phase
          draft.push({ name: entry.name });
        } else if (progress.completed === progress.total) {
          // All tasks complete
          completed.push({ name: entry.name });
        } else {
          // Has tasks but not all complete
          active.push({ name: entry.name, progress });
        }
      }
    }

    // Sort all categories by name for deterministic ordering
    draft.sort((a, b) => a.name.localeCompare(b.name));

    // Sort active changes by completion percentage (ascending) and then by name
    active.sort((a, b) => {
      const percentageA = a.progress.total > 0 ? a.progress.completed / a.progress.total : 0;
      const percentageB = b.progress.total > 0 ? b.progress.completed / b.progress.total : 0;

      if (percentageA < percentageB) return -1;
      if (percentageA > percentageB) return 1;
      return a.name.localeCompare(b.name);
    });
    completed.sort((a, b) => a.name.localeCompare(b.name));

    return { draft, active, completed };
  }

  private async getSpecsData(openspecDir: string): Promise<Array<{ name: string; requirementCount: number }>> {
    const specsDir = path.join(openspecDir, 'specs');
    
    if (!fs.existsSync(specsDir)) {
      return [];
    }

    const specs: Array<{ name: string; requirementCount: number }> = [];
    const entries = fs.readdirSync(specsDir, { withFileTypes: true });
    
    for (const entry of entries) {
      if (entry.isDirectory()) {
        const specFile = path.join(specsDir, entry.name, 'spec.md');
        
        if (fs.existsSync(specFile)) {
          try {
            const content = fs.readFileSync(specFile, 'utf-8');
            const parser = new MarkdownParser(content);
            const spec = parser.parseSpec(entry.name);
            const requirementCount = spec.requirements.length;
            specs.push({ name: entry.name, requirementCount });
          } catch (error) {
            // If spec cannot be parsed, include with 0 count
            specs.push({ name: entry.name, requirementCount: 0 });
          }
        }
      }
    }

    return specs;
  }

  private displaySummary(
    changesData: { draft: any[]; active: any[]; completed: any[] },
    specsData: any[]
  ): void {
    const totalChanges =
      changesData.draft.length + changesData.active.length + changesData.completed.length;
    const totalSpecs = specsData.length;
    const totalRequirements = specsData.reduce((sum, spec) => sum + spec.requirementCount, 0);

    // Calculate total task progress
    let totalTasks = 0;
    let completedTasks = 0;

    changesData.active.forEach((change) => {
      totalTasks += change.progress.total;
      completedTasks += change.progress.completed;
    });

    changesData.completed.forEach(() => {
      // Completed changes count as 100% done (we don't know exact task count)
      // This is a simplification
    });

    console.log(chalk.bold('Summary:'));
    console.log(
      `  ${chalk.cyan('â—')} Specifications: ${chalk.bold(totalSpecs)} specs, ${chalk.bold(totalRequirements)} requirements`
    );
    if (changesData.draft.length > 0) {
      console.log(`  ${chalk.gray('â—')} Draft Changes: ${chalk.bold(changesData.draft.length)}`);
    }
    console.log(
      `  ${chalk.yellow('â—')} Active Changes: ${chalk.bold(changesData.active.length)} in progress`
    );
    console.log(`  ${chalk.green('â—')} Completed Changes: ${chalk.bold(changesData.completed.length)}`);

    if (totalTasks > 0) {
      const overallProgress = Math.round((completedTasks / totalTasks) * 100);
      console.log(
        `  ${chalk.magenta('â—')} Task Progress: ${chalk.bold(`${completedTasks}/${totalTasks}`)} (${overallProgress}% complete)`
      );
    }
  }

  private createProgressBar(completed: number, total: number, width: number = 20): string {
    if (total === 0) return chalk.dim('â”€'.repeat(width));
    
    const percentage = completed / total;
    const filled = Math.round(percentage * width);
    const empty = width - filled;
    
    const filledBar = chalk.green('â–ˆ'.repeat(filled));
    const emptyBar = chalk.dim('â–‘'.repeat(empty));
    
    return `[${filledBar}${emptyBar}]`;
  }
}


================================================
FILE: src/core/artifact-graph/graph.ts
================================================
import type { Artifact, SchemaYaml, CompletedSet, BlockedArtifacts } from './types.js';
import { loadSchema, parseSchema } from './schema.js';

/**
 * Represents an artifact dependency graph.
 * Provides methods for querying build order, ready artifacts, and completion status.
 */
export class ArtifactGraph {
  private artifacts: Map<string, Artifact>;
  private schema: SchemaYaml;

  private constructor(schema: SchemaYaml) {
    this.schema = schema;
    this.artifacts = new Map(schema.artifacts.map(a => [a.id, a]));
  }

  /**
   * Creates an ArtifactGraph from a YAML file path.
   */
  static fromYaml(filePath: string): ArtifactGraph {
    const schema = loadSchema(filePath);
    return new ArtifactGraph(schema);
  }

  /**
   * Creates an ArtifactGraph from YAML content string.
   */
  static fromYamlContent(yamlContent: string): ArtifactGraph {
    const schema = parseSchema(yamlContent);
    return new ArtifactGraph(schema);
  }

  /**
   * Creates an ArtifactGraph from a pre-validated schema object.
   */
  static fromSchema(schema: SchemaYaml): ArtifactGraph {
    return new ArtifactGraph(schema);
  }

  /**
   * Gets a single artifact by ID.
   */
  getArtifact(id: string): Artifact | undefined {
    return this.artifacts.get(id);
  }

  /**
   * Gets all artifacts in the graph.
   */
  getAllArtifacts(): Artifact[] {
    return Array.from(this.artifacts.values());
  }

  /**
   * Gets the schema name.
   */
  getName(): string {
    return this.schema.name;
  }

  /**
   * Gets the schema version.
   */
  getVersion(): number {
    return this.schema.version;
  }

  /**
   * Computes the topological build order using Kahn's algorithm.
   * Returns artifact IDs in the order they should be built.
   */
  getBuildOrder(): string[] {
    const inDegree = new Map<string, number>();
    const dependents = new Map<string, string[]>();

    // Initialize all artifacts
    for (const artifact of this.artifacts.values()) {
      inDegree.set(artifact.id, artifact.requires.length);
      dependents.set(artifact.id, []);
    }

    // Build reverse adjacency (who depends on whom)
    for (const artifact of this.artifacts.values()) {
      for (const req of artifact.requires) {
        dependents.get(req)!.push(artifact.id);
      }
    }

    // Start with roots (in-degree 0), sorted for determinism
    const queue = [...this.artifacts.keys()]
      .filter(id => inDegree.get(id) === 0)
      .sort();

    const result: string[] = [];

    while (queue.length > 0) {
      const current = queue.shift()!;
      result.push(current);

      // Collect newly ready artifacts, then sort before adding
      const newlyReady: string[] = [];
      for (const dep of dependents.get(current)!) {
        const newDegree = inDegree.get(dep)! - 1;
        inDegree.set(dep, newDegree);
        if (newDegree === 0) {
          newlyReady.push(dep);
        }
      }
      queue.push(...newlyReady.sort());
    }

    return result;
  }

  /**
   * Gets artifacts that are ready to be created (all dependencies completed).
   */
  getNextArtifacts(completed: CompletedSet): string[] {
    const ready: string[] = [];

    for (const artifact of this.artifacts.values()) {
      if (completed.has(artifact.id)) {
        continue; // Already completed
      }

      const allDepsCompleted = artifact.requires.every(req => completed.has(req));
      if (allDepsCompleted) {
        ready.push(artifact.id);
      }
    }

    // Sort for deterministic ordering
    return ready.sort();
  }

  /**
   * Checks if all artifacts in the graph are completed.
   */
  isComplete(completed: CompletedSet): boolean {
    for (const artifact of this.artifacts.values()) {
      if (!completed.has(artifact.id)) {
        return false;
      }
    }
    return true;
  }

  /**
   * Gets blocked artifacts and their unmet dependencies.
   */
  getBlocked(completed: CompletedSet): BlockedArtifacts {
    const blocked: BlockedArtifacts = {};

    for (const artifact of this.artifacts.values()) {
      if (completed.has(artifact.id)) {
        continue; // Already completed
      }

      const unmetDeps = artifact.requires.filter(req => !completed.has(req));
      if (unmetDeps.length > 0) {
        blocked[artifact.id] = unmetDeps.sort();
      }
    }

    return blocked;
  }
}



================================================
FILE: src/core/artifact-graph/index.ts
================================================
// Types
export {
  ArtifactSchema,
  SchemaYamlSchema,
  type Artifact,
  type SchemaYaml,
  type CompletedSet,
  type BlockedArtifacts,
} from './types.js';

// Schema loading and validation
export { loadSchema, parseSchema, SchemaValidationError } from './schema.js';

// Graph operations
export { ArtifactGraph } from './graph.js';

// State detection
export { detectCompleted } from './state.js';

// Schema resolution
export {
  resolveSchema,
  listSchemas,
  listSchemasWithInfo,
  getSchemaDir,
  getPackageSchemasDir,
  getUserSchemasDir,
  SchemaLoadError,
  type SchemaInfo,
} from './resolver.js';

// Instruction loading
export {
  loadTemplate,
  loadChangeContext,
  generateInstructions,
  formatChangeStatus,
  TemplateLoadError,
  type ChangeContext,
  type ArtifactInstructions,
  type DependencyInfo,
  type ArtifactStatus,
  type ChangeStatus,
} from './instruction-loader.js';



================================================
FILE: src/core/artifact-graph/instruction-loader.ts
================================================
import * as fs from 'node:fs';
import * as path from 'node:path';
import { getSchemaDir, resolveSchema } from './resolver.js';
import { ArtifactGraph } from './graph.js';
import { detectCompleted } from './state.js';
import { resolveSchemaForChange } from '../../utils/change-metadata.js';
import { readProjectConfig, validateConfigRules } from '../project-config.js';
import type { Artifact, CompletedSet } from './types.js';

// Session-level cache for validation warnings (avoid repeating same warnings)
const shownWarnings = new Set<string>();

/**
 * Error thrown when loading a template fails.
 */
export class TemplateLoadError extends Error {
  constructor(
    message: string,
    public readonly templatePath: string
  ) {
    super(message);
    this.name = 'TemplateLoadError';
  }
}

/**
 * Change context containing graph, completion state, and metadata.
 */
export interface ChangeContext {
  /** The artifact dependency graph */
  graph: ArtifactGraph;
  /** Set of completed artifact IDs */
  completed: CompletedSet;
  /** Schema name being used */
  schemaName: string;
  /** Change name */
  changeName: string;
  /** Path to the change directory */
  changeDir: string;
  /** Project root directory */
  projectRoot: string;
}

/**
 * Enriched instructions for creating an artifact.
 */
export interface ArtifactInstructions {
  /** Change name */
  changeName: string;
  /** Artifact ID */
  artifactId: string;
  /** Schema name */
  schemaName: string;
  /** Full path to change directory */
  changeDir: string;
  /** Output path pattern (e.g., "proposal.md") */
  outputPath: string;
  /** Artifact description */
  description: string;
  /** Guidance on how to create this artifact (from schema instruction field) */
  instruction: string | undefined;
  /** Project context from config (constraints/background for AI, not to be included in output) */
  context: string | undefined;
  /** Artifact-specific rules from config (constraints for AI, not to be included in output) */
  rules: string[] | undefined;
  /** Template content (structure to follow - this IS the output format) */
  template: string;
  /** Dependencies with completion status and paths */
  dependencies: DependencyInfo[];
  /** Artifacts that become available after completing this one */
  unlocks: string[];
}

/**
 * Dependency information including path and description.
 */
export interface DependencyInfo {
  /** Artifact ID */
  id: string;
  /** Whether the dependency is completed */
  done: boolean;
  /** Relative output path of the dependency (e.g., "proposal.md") */
  path: string;
  /** Description of the dependency artifact */
  description: string;
}

/**
 * Status of a single artifact in the workflow.
 */
export interface ArtifactStatus {
  /** Artifact ID */
  id: string;
  /** Output path pattern */
  outputPath: string;
  /** Status: done, ready, or blocked */
  status: 'done' | 'ready' | 'blocked';
  /** Missing dependencies (only for blocked) */
  missingDeps?: string[];
}

/**
 * Formatted change status.
 */
export interface ChangeStatus {
  /** Change name */
  changeName: string;
  /** Schema name */
  schemaName: string;
  /** Whether all artifacts are complete */
  isComplete: boolean;
  /** Artifact IDs required before apply phase (from schema's apply.requires) */
  applyRequires: string[];
  /** Status of each artifact */
  artifacts: ArtifactStatus[];
}

/**
 * Loads a template from a schema's templates directory.
 *
 * @param schemaName - Schema name (e.g., "spec-driven")
 * @param templatePath - Relative path within the templates directory (e.g., "proposal.md")
 * @param projectRoot - Optional project root for project-local schema resolution
 * @returns The template content
 * @throws TemplateLoadError if the template cannot be loaded
 */
export function loadTemplate(
  schemaName: string,
  templatePath: string,
  projectRoot?: string
): string {
  const schemaDir = getSchemaDir(schemaName, projectRoot);
  if (!schemaDir) {
    throw new TemplateLoadError(
      `Schema '${schemaName}' not found`,
      templatePath
    );
  }

  const fullPath = path.join(schemaDir, 'templates', templatePath);

  if (!fs.existsSync(fullPath)) {
    throw new TemplateLoadError(
      `Template not found: ${fullPath}`,
      fullPath
    );
  }

  try {
    return fs.readFileSync(fullPath, 'utf-8');
  } catch (err) {
    const ioError = err instanceof Error ? err : new Error(String(err));
    throw new TemplateLoadError(
      `Failed to read template: ${ioError.message}`,
      fullPath
    );
  }
}

/**
 * Loads change context combining graph and completion state.
 *
 * Schema resolution order:
 * 1. Explicit schemaName parameter (if provided)
 * 2. Schema from .openspec.yaml metadata (if exists in change directory)
 * 3. Default 'spec-driven'
 *
 * @param projectRoot - Project root directory
 * @param changeName - Change name
 * @param schemaName - Optional schema name override. If not provided, auto-detected from metadata.
 * @returns Change context with graph, completed set, and metadata
 */
export function loadChangeContext(
  projectRoot: string,
  changeName: string,
  schemaName?: string
): ChangeContext {
  const changeDir = path.join(projectRoot, 'openspec', 'changes', changeName);

  // Resolve schema: explicit > metadata > default
  const resolvedSchemaName = resolveSchemaForChange(changeDir, schemaName);

  const schema = resolveSchema(resolvedSchemaName, projectRoot);
  const graph = ArtifactGraph.fromSchema(schema);
  const completed = detectCompleted(graph, changeDir);

  return {
    graph,
    completed,
    schemaName: resolvedSchemaName,
    changeName,
    changeDir,
    projectRoot,
  };
}

/**
 * Generates enriched instructions for creating an artifact.
 *
 * Instruction injection order:
 * 1. <context> - Project context from config (if present)
 * 2. <rules> - Artifact-specific rules from config (if present)
 * 3. <template> - Schema's template content
 *
 * @param context - Change context
 * @param artifactId - Artifact ID to generate instructions for
 * @param projectRoot - Project root directory (for reading config)
 * @returns Enriched artifact instructions
 * @throws Error if artifact not found
 */
export function generateInstructions(
  context: ChangeContext,
  artifactId: string,
  projectRoot?: string
): ArtifactInstructions {
  const artifact = context.graph.getArtifact(artifactId);
  if (!artifact) {
    throw new Error(`Artifact '${artifactId}' not found in schema '${context.schemaName}'`);
  }

  const templateContent = loadTemplate(context.schemaName, artifact.template, context.projectRoot);
  const dependencies = getDependencyInfo(artifact, context.graph, context.completed);
  const unlocks = getUnlockedArtifacts(context.graph, artifactId);

  // Use projectRoot from context if not explicitly provided
  const effectiveProjectRoot = projectRoot ?? context.projectRoot;

  // Try to read project config for context and rules
  let projectConfig = null;
  if (effectiveProjectRoot) {
    try {
      projectConfig = readProjectConfig(effectiveProjectRoot);
    } catch {
      // If config read fails, continue without config
    }
  }

  // Validate rules artifact IDs if config has rules (only once per session)
  if (projectConfig?.rules) {
    const validArtifactIds = new Set(context.graph.getAllArtifacts().map((a) => a.id));
    const warnings = validateConfigRules(
      projectConfig.rules,
      validArtifactIds,
      context.schemaName
    );

    // Show each unique warning only once per session
    for (const warning of warnings) {
      if (!shownWarnings.has(warning)) {
        console.warn(warning);
        shownWarnings.add(warning);
      }
    }
  }

  // Extract context and rules as separate fields (not prepended to template)
  const configContext = projectConfig?.context?.trim() || undefined;
  const rulesForArtifact = projectConfig?.rules?.[artifactId];
  const configRules = rulesForArtifact && rulesForArtifact.length > 0 ? rulesForArtifact : undefined;

  return {
    changeName: context.changeName,
    artifactId: artifact.id,
    schemaName: context.schemaName,
    changeDir: context.changeDir,
    outputPath: artifact.generates,
    description: artifact.description,
    instruction: artifact.instruction,
    context: configContext,
    rules: configRules,
    template: templateContent,
    dependencies,
    unlocks,
  };
}

/**
 * Gets dependency info including paths and descriptions.
 */
function getDependencyInfo(
  artifact: Artifact,
  graph: ArtifactGraph,
  completed: CompletedSet
): DependencyInfo[] {
  return artifact.requires.map(id => {
    const depArtifact = graph.getArtifact(id);
    return {
      id,
      done: completed.has(id),
      path: depArtifact?.generates ?? id,
      description: depArtifact?.description ?? '',
    };
  });
}

/**
 * Gets artifacts that become available after completing the given artifact.
 */
function getUnlockedArtifacts(graph: ArtifactGraph, artifactId: string): string[] {
  const unlocks: string[] = [];

  for (const artifact of graph.getAllArtifacts()) {
    if (artifact.requires.includes(artifactId)) {
      unlocks.push(artifact.id);
    }
  }

  return unlocks.sort();
}

/**
 * Formats the status of all artifacts in a change.
 *
 * @param context - Change context
 * @returns Formatted change status
 */
export function formatChangeStatus(context: ChangeContext): ChangeStatus {
  // Load schema to get apply phase configuration
  const schema = resolveSchema(context.schemaName, context.projectRoot);
  const applyRequires = schema.apply?.requires ?? schema.artifacts.map(a => a.id);

  const artifacts = context.graph.getAllArtifacts();
  const ready = new Set(context.graph.getNextArtifacts(context.completed));
  const blocked = context.graph.getBlocked(context.completed);

  const artifactStatuses: ArtifactStatus[] = artifacts.map(artifact => {
    if (context.completed.has(artifact.id)) {
      return {
        id: artifact.id,
        outputPath: artifact.generates,
        status: 'done' as const,
      };
    }

    if (ready.has(artifact.id)) {
      return {
        id: artifact.id,
        outputPath: artifact.generates,
        status: 'ready' as const,
      };
    }

    return {
      id: artifact.id,
      outputPath: artifact.generates,
      status: 'blocked' as const,
      missingDeps: blocked[artifact.id] ?? [],
    };
  });

  // Sort by build order for consistent output
  const buildOrder = context.graph.getBuildOrder();
  const orderMap = new Map(buildOrder.map((id, idx) => [id, idx]));
  artifactStatuses.sort((a, b) => (orderMap.get(a.id) ?? 0) - (orderMap.get(b.id) ?? 0));

  return {
    changeName: context.changeName,
    schemaName: context.schemaName,
    isComplete: context.graph.isComplete(context.completed),
    applyRequires,
    artifacts: artifactStatuses,
  };
}



================================================
FILE: src/core/artifact-graph/resolver.ts
================================================
import * as fs from 'node:fs';
import * as path from 'node:path';
import { fileURLToPath } from 'node:url';
import { getGlobalDataDir } from '../global-config.js';
import { parseSchema, SchemaValidationError } from './schema.js';
import type { SchemaYaml } from './types.js';

/**
 * Error thrown when loading a schema fails.
 */
export class SchemaLoadError extends Error {
  constructor(
    message: string,
    public readonly schemaPath: string,
    public readonly cause?: Error
  ) {
    super(message);
    this.name = 'SchemaLoadError';
  }
}

/**
 * Gets the package's built-in schemas directory path.
 * Uses import.meta.url to resolve relative to the current module.
 */
export function getPackageSchemasDir(): string {
  const currentFile = fileURLToPath(import.meta.url);
  // Navigate from dist/core/artifact-graph/ to package root's schemas/
  return path.join(path.dirname(currentFile), '..', '..', '..', 'schemas');
}

/**
 * Gets the user's schema override directory path.
 */
export function getUserSchemasDir(): string {
  return path.join(getGlobalDataDir(), 'schemas');
}

/**
 * Gets the project-local schemas directory path.
 * @param projectRoot - The project root directory
 * @returns The path to the project's schemas directory
 */
export function getProjectSchemasDir(projectRoot: string): string {
  return path.join(projectRoot, 'openspec', 'schemas');
}

/**
 * Resolves a schema name to its directory path.
 *
 * Resolution order (when projectRoot is provided):
 * 1. Project-local: <projectRoot>/openspec/schemas/<name>/schema.yaml
 * 2. User override: ${XDG_DATA_HOME}/openspec/schemas/<name>/schema.yaml
 * 3. Package built-in: <package>/schemas/<name>/schema.yaml
 *
 * When projectRoot is not provided, only user override and package built-in are checked
 * (backward compatible behavior).
 *
 * @param name - Schema name (e.g., "spec-driven")
 * @param projectRoot - Optional project root directory for project-local schema resolution
 * @returns The path to the schema directory, or null if not found
 */
export function getSchemaDir(
  name: string,
  projectRoot?: string
): string | null {
  // 1. Check project-local directory (if projectRoot provided)
  if (projectRoot) {
    const projectDir = path.join(getProjectSchemasDir(projectRoot), name);
    const projectSchemaPath = path.join(projectDir, 'schema.yaml');
    if (fs.existsSync(projectSchemaPath)) {
      return projectDir;
    }
  }

  // 2. Check user override directory
  const userDir = path.join(getUserSchemasDir(), name);
  const userSchemaPath = path.join(userDir, 'schema.yaml');
  if (fs.existsSync(userSchemaPath)) {
    return userDir;
  }

  // 3. Check package built-in directory
  const packageDir = path.join(getPackageSchemasDir(), name);
  const packageSchemaPath = path.join(packageDir, 'schema.yaml');
  if (fs.existsSync(packageSchemaPath)) {
    return packageDir;
  }

  return null;
}

/**
 * Resolves a schema name to a SchemaYaml object.
 *
 * Resolution order (when projectRoot is provided):
 * 1. Project-local: <projectRoot>/openspec/schemas/<name>/schema.yaml
 * 2. User override: ${XDG_DATA_HOME}/openspec/schemas/<name>/schema.yaml
 * 3. Package built-in: <package>/schemas/<name>/schema.yaml
 *
 * When projectRoot is not provided, only user override and package built-in are checked
 * (backward compatible behavior).
 *
 * @param name - Schema name (e.g., "spec-driven")
 * @param projectRoot - Optional project root directory for project-local schema resolution
 * @returns The resolved schema object
 * @throws Error if schema is not found in any location
 */
export function resolveSchema(name: string, projectRoot?: string): SchemaYaml {
  // Normalize name (remove .yaml extension if provided)
  const normalizedName = name.replace(/\.ya?ml$/, '');

  const schemaDir = getSchemaDir(normalizedName, projectRoot);
  if (!schemaDir) {
    const availableSchemas = listSchemas(projectRoot);
    throw new Error(
      `Schema '${normalizedName}' not found. Available schemas: ${availableSchemas.join(', ')}`
    );
  }

  const schemaPath = path.join(schemaDir, 'schema.yaml');

  // Load and parse the schema
  let content: string;
  try {
    content = fs.readFileSync(schemaPath, 'utf-8');
  } catch (err) {
    const ioError = err instanceof Error ? err : new Error(String(err));
    throw new SchemaLoadError(
      `Failed to read schema at '${schemaPath}': ${ioError.message}`,
      schemaPath,
      ioError
    );
  }

  try {
    return parseSchema(content);
  } catch (err) {
    if (err instanceof SchemaValidationError) {
      throw new SchemaLoadError(
        `Invalid schema at '${schemaPath}': ${err.message}`,
        schemaPath,
        err
      );
    }
    const parseError = err instanceof Error ? err : new Error(String(err));
    throw new SchemaLoadError(
      `Failed to parse schema at '${schemaPath}': ${parseError.message}`,
      schemaPath,
      parseError
    );
  }
}

/**
 * Lists all available schema names.
 * Combines project-local, user override, and package built-in schemas.
 *
 * @param projectRoot - Optional project root directory for project-local schema resolution
 */
export function listSchemas(projectRoot?: string): string[] {
  const schemas = new Set<string>();

  // Add package built-in schemas
  const packageDir = getPackageSchemasDir();
  if (fs.existsSync(packageDir)) {
    for (const entry of fs.readdirSync(packageDir, { withFileTypes: true })) {
      if (entry.isDirectory()) {
        const schemaPath = path.join(packageDir, entry.name, 'schema.yaml');
        if (fs.existsSync(schemaPath)) {
          schemas.add(entry.name);
        }
      }
    }
  }

  // Add user override schemas (may override package schemas)
  const userDir = getUserSchemasDir();
  if (fs.existsSync(userDir)) {
    for (const entry of fs.readdirSync(userDir, { withFileTypes: true })) {
      if (entry.isDirectory()) {
        const schemaPath = path.join(userDir, entry.name, 'schema.yaml');
        if (fs.existsSync(schemaPath)) {
          schemas.add(entry.name);
        }
      }
    }
  }

  // Add project-local schemas (if projectRoot provided)
  if (projectRoot) {
    const projectDir = getProjectSchemasDir(projectRoot);
    if (fs.existsSync(projectDir)) {
      for (const entry of fs.readdirSync(projectDir, { withFileTypes: true })) {
        if (entry.isDirectory()) {
          const schemaPath = path.join(projectDir, entry.name, 'schema.yaml');
          if (fs.existsSync(schemaPath)) {
            schemas.add(entry.name);
          }
        }
      }
    }
  }

  return Array.from(schemas).sort();
}

/**
 * Schema info with metadata (name, description, artifacts).
 */
export interface SchemaInfo {
  name: string;
  description: string;
  artifacts: string[];
  source: 'project' | 'user' | 'package';
}

/**
 * Lists all available schemas with their descriptions and artifact lists.
 * Useful for agent skills to present schema selection to users.
 *
 * @param projectRoot - Optional project root directory for project-local schema resolution
 */
export function listSchemasWithInfo(projectRoot?: string): SchemaInfo[] {
  const schemas: SchemaInfo[] = [];
  const seenNames = new Set<string>();

  // Add project-local schemas first (highest priority, if projectRoot provided)
  if (projectRoot) {
    const projectDir = getProjectSchemasDir(projectRoot);
    if (fs.existsSync(projectDir)) {
      for (const entry of fs.readdirSync(projectDir, { withFileTypes: true })) {
        if (entry.isDirectory()) {
          const schemaPath = path.join(projectDir, entry.name, 'schema.yaml');
          if (fs.existsSync(schemaPath)) {
            try {
              const schema = parseSchema(fs.readFileSync(schemaPath, 'utf-8'));
              schemas.push({
                name: entry.name,
                description: schema.description || '',
                artifacts: schema.artifacts.map((a) => a.id),
                source: 'project',
              });
              seenNames.add(entry.name);
            } catch {
              // Skip invalid schemas
            }
          }
        }
      }
    }
  }

  // Add user override schemas (if not overridden by project)
  const userDir = getUserSchemasDir();
  if (fs.existsSync(userDir)) {
    for (const entry of fs.readdirSync(userDir, { withFileTypes: true })) {
      if (entry.isDirectory() && !seenNames.has(entry.name)) {
        const schemaPath = path.join(userDir, entry.name, 'schema.yaml');
        if (fs.existsSync(schemaPath)) {
          try {
            const schema = parseSchema(fs.readFileSync(schemaPath, 'utf-8'));
            schemas.push({
              name: entry.name,
              description: schema.description || '',
              artifacts: schema.artifacts.map((a) => a.id),
              source: 'user',
            });
            seenNames.add(entry.name);
          } catch {
            // Skip invalid schemas
          }
        }
      }
    }
  }

  // Add package built-in schemas (if not overridden by project or user)
  const packageDir = getPackageSchemasDir();
  if (fs.existsSync(packageDir)) {
    for (const entry of fs.readdirSync(packageDir, { withFileTypes: true })) {
      if (entry.isDirectory() && !seenNames.has(entry.name)) {
        const schemaPath = path.join(packageDir, entry.name, 'schema.yaml');
        if (fs.existsSync(schemaPath)) {
          try {
            const schema = parseSchema(fs.readFileSync(schemaPath, 'utf-8'));
            schemas.push({
              name: entry.name,
              description: schema.description || '',
              artifacts: schema.artifacts.map((a) => a.id),
              source: 'package',
            });
          } catch {
            // Skip invalid schemas
          }
        }
      }
    }
  }

  return schemas.sort((a, b) => a.name.localeCompare(b.name));
}



================================================
FILE: src/core/artifact-graph/schema.ts
================================================
import * as fs from 'node:fs';
import { parse as parseYaml } from 'yaml';
import { SchemaYamlSchema, type SchemaYaml, type Artifact } from './types.js';

export class SchemaValidationError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'SchemaValidationError';
  }
}

/**
 * Loads and validates an artifact schema from a YAML file.
 */
export function loadSchema(filePath: string): SchemaYaml {
  const content = fs.readFileSync(filePath, 'utf-8');
  return parseSchema(content);
}

/**
 * Parses and validates an artifact schema from YAML content.
 */
export function parseSchema(yamlContent: string): SchemaYaml {
  const parsed = parseYaml(yamlContent);

  // Validate with Zod
  const result = SchemaYamlSchema.safeParse(parsed);
  if (!result.success) {
    const errors = result.error.issues.map(e => `${e.path.join('.')}: ${e.message}`).join(', ');
    throw new SchemaValidationError(`Invalid schema: ${errors}`);
  }

  const schema = result.data;

  // Check for duplicate artifact IDs
  validateNoDuplicateIds(schema.artifacts);

  // Check that all requires references are valid
  validateRequiresReferences(schema.artifacts);

  // Check for cycles
  validateNoCycles(schema.artifacts);

  return schema;
}

/**
 * Validates that there are no duplicate artifact IDs.
 */
function validateNoDuplicateIds(artifacts: Artifact[]): void {
  const seen = new Set<string>();
  for (const artifact of artifacts) {
    if (seen.has(artifact.id)) {
      throw new SchemaValidationError(`Duplicate artifact ID: ${artifact.id}`);
    }
    seen.add(artifact.id);
  }
}

/**
 * Validates that all `requires` references point to valid artifact IDs.
 */
function validateRequiresReferences(artifacts: Artifact[]): void {
  const validIds = new Set(artifacts.map(a => a.id));

  for (const artifact of artifacts) {
    for (const req of artifact.requires) {
      if (!validIds.has(req)) {
        throw new SchemaValidationError(
          `Invalid dependency reference in artifact '${artifact.id}': '${req}' does not exist`
        );
      }
    }
  }
}

/**
 * Validates that there are no cyclic dependencies.
 * Uses DFS to detect cycles and reports the full cycle path.
 */
function validateNoCycles(artifacts: Artifact[]): void {
  const artifactMap = new Map(artifacts.map(a => [a.id, a]));
  const visited = new Set<string>();
  const inStack = new Set<string>();
  const parent = new Map<string, string>();

  function dfs(id: string): string | null {
    visited.add(id);
    inStack.add(id);

    const artifact = artifactMap.get(id);
    if (!artifact) return null;

    for (const dep of artifact.requires) {
      if (!visited.has(dep)) {
        parent.set(dep, id);
        const cycle = dfs(dep);
        if (cycle) return cycle;
      } else if (inStack.has(dep)) {
        // Found a cycle - reconstruct the path
        const cyclePath = [dep];
        let current = id;
        while (current !== dep) {
          cyclePath.unshift(current);
          current = parent.get(current)!;
        }
        cyclePath.unshift(dep);
        return cyclePath.join(' â†’ ');
      }
    }

    inStack.delete(id);
    return null;
  }

  for (const artifact of artifacts) {
    if (!visited.has(artifact.id)) {
      const cycle = dfs(artifact.id);
      if (cycle) {
        throw new SchemaValidationError(`Cyclic dependency detected: ${cycle}`);
      }
    }
  }
}



================================================
FILE: src/core/artifact-graph/state.ts
================================================
import * as fs from 'node:fs';
import * as path from 'node:path';
import fg from 'fast-glob';
import type { CompletedSet } from './types.js';
import type { ArtifactGraph } from './graph.js';
import { FileSystemUtils } from '../../utils/file-system.js';

/**
 * Detects which artifacts are completed by checking file existence in the change directory.
 * Returns a Set of completed artifact IDs.
 *
 * @param graph - The artifact graph to check
 * @param changeDir - The change directory to scan for files
 * @returns Set of artifact IDs whose generated files exist
 */
export function detectCompleted(graph: ArtifactGraph, changeDir: string): CompletedSet {
  const completed = new Set<string>();

  // Handle missing change directory gracefully
  if (!fs.existsSync(changeDir)) {
    return completed;
  }

  for (const artifact of graph.getAllArtifacts()) {
    if (isArtifactComplete(artifact.generates, changeDir)) {
      completed.add(artifact.id);
    }
  }

  return completed;
}

/**
 * Checks if an artifact is complete by checking if its generated file(s) exist.
 * Supports both simple paths and glob patterns.
 */
function isArtifactComplete(generates: string, changeDir: string): boolean {
  const fullPattern = path.join(changeDir, generates);

  // Check if it's a glob pattern
  if (isGlobPattern(generates)) {
    return hasGlobMatches(fullPattern);
  }

  // Simple file path - check if file exists
  return fs.existsSync(fullPattern);
}

/**
 * Checks if a path contains glob pattern characters.
 */
function isGlobPattern(pattern: string): boolean {
  return pattern.includes('*') || pattern.includes('?') || pattern.includes('[');
}

/**
 * Checks if a glob pattern has any matches.
 * Normalizes Windows backslashes to forward slashes for cross-platform glob compatibility.
 */
function hasGlobMatches(pattern: string): boolean {
  const normalizedPattern = FileSystemUtils.toPosixPath(pattern);
  const matches = fg.sync(normalizedPattern, { onlyFiles: true });
  return matches.length > 0;
}



================================================
FILE: src/core/artifact-graph/types.ts
================================================
import { z } from 'zod';

// Artifact definition schema
export const ArtifactSchema = z.object({
  id: z.string().min(1, { error: 'Artifact ID is required' }),
  generates: z.string().min(1, { error: 'generates field is required' }),
  description: z.string(),
  template: z.string().min(1, { error: 'template field is required' }),
  instruction: z.string().optional(),
  requires: z.array(z.string()).default([]),
});

// Apply phase configuration for schema-aware apply instructions
export const ApplyPhaseSchema = z.object({
  // Artifact IDs that must exist before apply is available
  requires: z.array(z.string()).min(1, { error: 'At least one required artifact' }),
  // Path to file with checkboxes for progress (relative to change dir), or null if no tracking
  tracks: z.string().nullable().optional(),
  // Custom guidance for the apply phase
  instruction: z.string().optional(),
});

// Full schema YAML structure
export const SchemaYamlSchema = z.object({
  name: z.string().min(1, { error: 'Schema name is required' }),
  version: z.number().int().positive({ error: 'Version must be a positive integer' }),
  description: z.string().optional(),
  artifacts: z.array(ArtifactSchema).min(1, { error: 'At least one artifact required' }),
  // Optional apply phase configuration (for schema-aware apply instructions)
  apply: ApplyPhaseSchema.optional(),
});

// Derived TypeScript types
export type Artifact = z.infer<typeof ArtifactSchema>;
export type ApplyPhase = z.infer<typeof ApplyPhaseSchema>;
export type SchemaYaml = z.infer<typeof SchemaYamlSchema>;

// Per-change metadata schema
// Note: schema field is validated at parse time against available schemas
// using a lazy import to avoid circular dependencies
export const ChangeMetadataSchema = z.object({
  // Required: which workflow schema this change uses
  schema: z.string().min(1, { message: 'schema is required' }),

  // Optional: creation timestamp (ISO date string)
  created: z
    .string()
    .regex(/^\d{4}-\d{2}-\d{2}$/, {
      message: 'created must be YYYY-MM-DD format',
    })
    .optional(),
});

export type ChangeMetadata = z.infer<typeof ChangeMetadataSchema>;

// Runtime state types (not Zod - internal only)

// Slice 1: Simple completion tracking via filesystem
export type CompletedSet = Set<string>;

// Return type for blocked query
export interface BlockedArtifacts {
  [artifactId: string]: string[];
}




================================================
FILE: src/core/command-generation/generator.ts
================================================
/**
 * Command Generator
 *
 * Functions for generating command files using tool adapters.
 */

import type { CommandContent, ToolCommandAdapter, GeneratedCommand } from './types.js';

/**
 * Generate a single command file using the provided adapter.
 * @param content - The tool-agnostic command content
 * @param adapter - The tool-specific adapter
 * @returns Generated command with path and file content
 */
export function generateCommand(
  content: CommandContent,
  adapter: ToolCommandAdapter
): GeneratedCommand {
  return {
    path: adapter.getFilePath(content.id),
    fileContent: adapter.formatFile(content),
  };
}

/**
 * Generate multiple command files using the provided adapter.
 * @param contents - Array of tool-agnostic command contents
 * @param adapter - The tool-specific adapter
 * @returns Array of generated commands with paths and file contents
 */
export function generateCommands(
  contents: CommandContent[],
  adapter: ToolCommandAdapter
): GeneratedCommand[] {
  return contents.map((content) => generateCommand(content, adapter));
}



================================================
FILE: src/core/command-generation/index.ts
================================================
/**
 * Command Generation Module
 *
 * Generic command generation system with tool-specific adapters.
 *
 * Usage:
 * ```typescript
 * import { generateCommands, CommandAdapterRegistry, type CommandContent } from './command-generation/index.js';
 *
 * const contents: CommandContent[] = [...];
 * const adapter = CommandAdapterRegistry.get('cursor');
 * if (adapter) {
 *   const commands = generateCommands(contents, adapter);
 *   // Write commands to disk
 * }
 * ```
 */

// Types
export type {
  CommandContent,
  ToolCommandAdapter,
  GeneratedCommand,
} from './types.js';

// Registry
export { CommandAdapterRegistry } from './registry.js';

// Generator functions
export { generateCommand, generateCommands } from './generator.js';

// Adapters (for direct access if needed)
export { claudeAdapter, cursorAdapter, windsurfAdapter } from './adapters/index.js';



================================================
FILE: src/core/command-generation/registry.ts
================================================
/**
 * Command Adapter Registry
 *
 * Centralized registry for tool command adapters.
 * Similar pattern to existing SlashCommandRegistry in the codebase.
 */

import type { ToolCommandAdapter } from './types.js';
import { amazonQAdapter } from './adapters/amazon-q.js';
import { antigravityAdapter } from './adapters/antigravity.js';
import { auggieAdapter } from './adapters/auggie.js';
import { claudeAdapter } from './adapters/claude.js';
import { clineAdapter } from './adapters/cline.js';
import { codexAdapter } from './adapters/codex.js';
import { codebuddyAdapter } from './adapters/codebuddy.js';
import { continueAdapter } from './adapters/continue.js';
import { costrictAdapter } from './adapters/costrict.js';
import { crushAdapter } from './adapters/crush.js';
import { cursorAdapter } from './adapters/cursor.js';
import { factoryAdapter } from './adapters/factory.js';
import { geminiAdapter } from './adapters/gemini.js';
import { githubCopilotAdapter } from './adapters/github-copilot.js';
import { iflowAdapter } from './adapters/iflow.js';
import { kilocodeAdapter } from './adapters/kilocode.js';
import { opencodeAdapter } from './adapters/opencode.js';
import { qoderAdapter } from './adapters/qoder.js';
import { qwenAdapter } from './adapters/qwen.js';
import { roocodeAdapter } from './adapters/roocode.js';
import { windsurfAdapter } from './adapters/windsurf.js';

/**
 * Registry for looking up tool command adapters.
 */
export class CommandAdapterRegistry {
  private static adapters: Map<string, ToolCommandAdapter> = new Map();

  // Static initializer - register built-in adapters
  static {
    CommandAdapterRegistry.register(amazonQAdapter);
    CommandAdapterRegistry.register(antigravityAdapter);
    CommandAdapterRegistry.register(auggieAdapter);
    CommandAdapterRegistry.register(claudeAdapter);
    CommandAdapterRegistry.register(clineAdapter);
    CommandAdapterRegistry.register(codexAdapter);
    CommandAdapterRegistry.register(codebuddyAdapter);
    CommandAdapterRegistry.register(continueAdapter);
    CommandAdapterRegistry.register(costrictAdapter);
    CommandAdapterRegistry.register(crushAdapter);
    CommandAdapterRegistry.register(cursorAdapter);
    CommandAdapterRegistry.register(factoryAdapter);
    CommandAdapterRegistry.register(geminiAdapter);
    CommandAdapterRegistry.register(githubCopilotAdapter);
    CommandAdapterRegistry.register(iflowAdapter);
    CommandAdapterRegistry.register(kilocodeAdapter);
    CommandAdapterRegistry.register(opencodeAdapter);
    CommandAdapterRegistry.register(qoderAdapter);
    CommandAdapterRegistry.register(qwenAdapter);
    CommandAdapterRegistry.register(roocodeAdapter);
    CommandAdapterRegistry.register(windsurfAdapter);
  }

  /**
   * Register a tool command adapter.
   * @param adapter - The adapter to register
   */
  static register(adapter: ToolCommandAdapter): void {
    CommandAdapterRegistry.adapters.set(adapter.toolId, adapter);
  }

  /**
   * Get an adapter by tool ID.
   * @param toolId - The tool identifier (e.g., 'claude', 'cursor')
   * @returns The adapter or undefined if not registered
   */
  static get(toolId: string): ToolCommandAdapter | undefined {
    return CommandAdapterRegistry.adapters.get(toolId);
  }

  /**
   * Get all registered adapters.
   * @returns Array of all registered adapters
   */
  static getAll(): ToolCommandAdapter[] {
    return Array.from(CommandAdapterRegistry.adapters.values());
  }

  /**
   * Check if an adapter is registered for a tool.
   * @param toolId - The tool identifier
   * @returns True if an adapter exists
   */
  static has(toolId: string): boolean {
    return CommandAdapterRegistry.adapters.has(toolId);
  }
}



================================================
FILE: src/core/command-generation/types.ts
================================================
/**
 * Command Generation Types
 *
 * Tool-agnostic interfaces for command generation.
 * These types separate "what to generate" from "how to format it".
 */

/**
 * Tool-agnostic command data.
 * Represents the content of a command without any tool-specific formatting.
 */
export interface CommandContent {
  /** Command identifier (e.g., 'explore', 'apply', 'new') */
  id: string;
  /** Human-readable name (e.g., 'OpenSpec Explore') */
  name: string;
  /** Brief description of command purpose */
  description: string;
  /** Grouping category (e.g., 'Workflow') */
  category: string;
  /** Array of tag strings */
  tags: string[];
  /** The command instruction content (body text) */
  body: string;
}

/**
 * Per-tool formatting strategy.
 * Each AI tool implements this interface to handle its specific file path
 * and frontmatter format requirements.
 */
export interface ToolCommandAdapter {
  /** Tool identifier matching AIToolOption.value (e.g., 'claude', 'cursor') */
  toolId: string;
  /**
   * Returns the relative file path for a command.
   * @param commandId - The command identifier (e.g., 'explore')
   * @returns Relative path from project root (e.g., '.claude/commands/opsx/explore.md')
   */
  getFilePath(commandId: string): string;
  /**
   * Formats the complete file content including frontmatter.
   * @param content - The tool-agnostic command content
   * @returns Complete file content ready to write
   */
  formatFile(content: CommandContent): string;
}

/**
 * Result of generating a command file.
 */
export interface GeneratedCommand {
  /** Relative file path from project root */
  path: string;
  /** Complete file content (frontmatter + body) */
  fileContent: string;
}



================================================
FILE: src/core/command-generation/adapters/amazon-q.ts
================================================
/**
 * Amazon Q Developer Command Adapter
 *
 * Formats commands for Amazon Q Developer following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Amazon Q adapter for command generation.
 * File path: .amazonq/prompts/opsx-<id>.md
 * Frontmatter: description
 */
export const amazonQAdapter: ToolCommandAdapter = {
  toolId: 'amazon-q',

  getFilePath(commandId: string): string {
    return path.join('.amazonq', 'prompts', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/antigravity.ts
================================================
/**
 * Antigravity Command Adapter
 *
 * Formats commands for Antigravity following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Antigravity adapter for command generation.
 * File path: .agent/workflows/opsx-<id>.md
 * Frontmatter: description
 */
export const antigravityAdapter: ToolCommandAdapter = {
  toolId: 'antigravity',

  getFilePath(commandId: string): string {
    return path.join('.agent', 'workflows', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/auggie.ts
================================================
/**
 * Auggie (Augment CLI) Command Adapter
 *
 * Formats commands for Auggie following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Auggie adapter for command generation.
 * File path: .augment/commands/opsx-<id>.md
 * Frontmatter: description, argument-hint
 */
export const auggieAdapter: ToolCommandAdapter = {
  toolId: 'auggie',

  getFilePath(commandId: string): string {
    return path.join('.augment', 'commands', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
argument-hint: command arguments
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/claude.ts
================================================
/**
 * Claude Code Command Adapter
 *
 * Formats commands for Claude Code following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Escapes a string value for safe YAML output.
 * Quotes the string if it contains special YAML characters.
 */
function escapeYamlValue(value: string): string {
  // Check if value needs quoting (contains special YAML characters or starts/ends with whitespace)
  const needsQuoting = /[:\n\r#{}[\],&*!|>'"%@`]|^\s|\s$/.test(value);
  if (needsQuoting) {
    // Use double quotes and escape internal double quotes and backslashes
    const escaped = value.replace(/\\/g, '\\\\').replace(/"/g, '\\"').replace(/\n/g, '\\n');
    return `"${escaped}"`;
  }
  return value;
}

/**
 * Formats a tags array as a YAML array with proper escaping.
 */
function formatTagsArray(tags: string[]): string {
  const escapedTags = tags.map((tag) => escapeYamlValue(tag));
  return `[${escapedTags.join(', ')}]`;
}

/**
 * Claude Code adapter for command generation.
 * File path: .claude/commands/opsx/<id>.md
 * Frontmatter: name, description, category, tags
 */
export const claudeAdapter: ToolCommandAdapter = {
  toolId: 'claude',

  getFilePath(commandId: string): string {
    return path.join('.claude', 'commands', 'opsx', `${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
name: ${escapeYamlValue(content.name)}
description: ${escapeYamlValue(content.description)}
category: ${escapeYamlValue(content.category)}
tags: ${formatTagsArray(content.tags)}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/cline.ts
================================================
/**
 * Cline Command Adapter
 *
 * Formats commands for Cline following its workflow specification.
 * Cline uses markdown headers instead of YAML frontmatter.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Cline adapter for command generation.
 * File path: .clinerules/workflows/opsx-<id>.md
 * Format: Markdown header with description
 */
export const clineAdapter: ToolCommandAdapter = {
  toolId: 'cline',

  getFilePath(commandId: string): string {
    return path.join('.clinerules', 'workflows', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `# ${content.name}

${content.description}

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/codebuddy.ts
================================================
/**
 * CodeBuddy Command Adapter
 *
 * Formats commands for CodeBuddy following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * CodeBuddy adapter for command generation.
 * File path: .codebuddy/commands/opsx/<id>.md
 * Frontmatter: name, description, argument-hint
 */
export const codebuddyAdapter: ToolCommandAdapter = {
  toolId: 'codebuddy',

  getFilePath(commandId: string): string {
    return path.join('.codebuddy', 'commands', 'opsx', `${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
name: ${content.name}
description: "${content.description}"
argument-hint: "[command arguments]"
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/codex.ts
================================================
/**
 * Codex Command Adapter
 *
 * Formats commands for Codex following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Codex adapter for command generation.
 * File path: .codex/prompts/opsx-<id>.md
 * Frontmatter: description, argument-hint
 */
export const codexAdapter: ToolCommandAdapter = {
  toolId: 'codex',

  getFilePath(commandId: string): string {
    return path.join('.codex', 'prompts', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
argument-hint: command arguments
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/continue.ts
================================================
/**
 * Continue Command Adapter
 *
 * Formats commands for Continue following its .prompt specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Continue adapter for command generation.
 * File path: .continue/prompts/opsx-<id>.prompt
 * Frontmatter: name, description, invokable
 */
export const continueAdapter: ToolCommandAdapter = {
  toolId: 'continue',

  getFilePath(commandId: string): string {
    return path.join('.continue', 'prompts', `opsx-${commandId}.prompt`);
  },

  formatFile(content: CommandContent): string {
    return `---
name: opsx-${content.id}
description: ${content.description}
invokable: true
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/costrict.ts
================================================
/**
 * CoStrict Command Adapter
 *
 * Formats commands for CoStrict following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * CoStrict adapter for command generation.
 * File path: .cospec/openspec/commands/opsx-<id>.md
 * Frontmatter: description, argument-hint
 */
export const costrictAdapter: ToolCommandAdapter = {
  toolId: 'costrict',

  getFilePath(commandId: string): string {
    return path.join('.cospec', 'openspec', 'commands', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: "${content.description}"
argument-hint: command arguments
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/crush.ts
================================================
/**
 * Crush Command Adapter
 *
 * Formats commands for Crush following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Crush adapter for command generation.
 * File path: .crush/commands/opsx/<id>.md
 * Frontmatter: name, description, category, tags
 */
export const crushAdapter: ToolCommandAdapter = {
  toolId: 'crush',

  getFilePath(commandId: string): string {
    return path.join('.crush', 'commands', 'opsx', `${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    const tagsStr = content.tags.join(', ');
    return `---
name: ${content.name}
description: ${content.description}
category: ${content.category}
tags: [${tagsStr}]
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/cursor.ts
================================================
/**
 * Cursor Command Adapter
 *
 * Formats commands for Cursor following its frontmatter specification.
 * Cursor uses a different frontmatter format and file naming convention.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Escapes a string value for safe YAML output.
 * Quotes the string if it contains special YAML characters.
 */
function escapeYamlValue(value: string): string {
  // Check if value needs quoting (contains special YAML characters or starts/ends with whitespace)
  const needsQuoting = /[:\n\r#{}[\],&*!|>'"%@`]|^\s|\s$/.test(value);
  if (needsQuoting) {
    // Use double quotes and escape internal double quotes and backslashes
    const escaped = value.replace(/\\/g, '\\\\').replace(/"/g, '\\"').replace(/\n/g, '\\n');
    return `"${escaped}"`;
  }
  return value;
}

/**
 * Cursor adapter for command generation.
 * File path: .cursor/commands/opsx-<id>.md
 * Frontmatter: name (as /opsx-<id>), id, category, description
 */
export const cursorAdapter: ToolCommandAdapter = {
  toolId: 'cursor',

  getFilePath(commandId: string): string {
    return path.join('.cursor', 'commands', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
name: /opsx-${content.id}
id: opsx-${content.id}
category: ${escapeYamlValue(content.category)}
description: ${escapeYamlValue(content.description)}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/factory.ts
================================================
/**
 * Factory Droid Command Adapter
 *
 * Formats commands for Factory Droid following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Factory adapter for command generation.
 * File path: .factory/commands/opsx-<id>.md
 * Frontmatter: description, argument-hint
 */
export const factoryAdapter: ToolCommandAdapter = {
  toolId: 'factory',

  getFilePath(commandId: string): string {
    return path.join('.factory', 'commands', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
argument-hint: command arguments
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/gemini.ts
================================================
/**
 * Gemini CLI Command Adapter
 *
 * Formats commands for Gemini CLI following its TOML specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Gemini adapter for command generation.
 * File path: .gemini/commands/opsx/<id>.toml
 * Format: TOML with description and prompt fields
 */
export const geminiAdapter: ToolCommandAdapter = {
  toolId: 'gemini',

  getFilePath(commandId: string): string {
    return path.join('.gemini', 'commands', 'opsx', `${commandId}.toml`);
  },

  formatFile(content: CommandContent): string {
    return `description = "${content.description}"

prompt = """
${content.body}
"""
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/github-copilot.ts
================================================
/**
 * GitHub Copilot Command Adapter
 *
 * Formats commands for GitHub Copilot following its .prompt.md specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * GitHub Copilot adapter for command generation.
 * File path: .github/prompts/opsx-<id>.prompt.md
 * Frontmatter: description
 */
export const githubCopilotAdapter: ToolCommandAdapter = {
  toolId: 'github-copilot',

  getFilePath(commandId: string): string {
    return path.join('.github', 'prompts', `opsx-${commandId}.prompt.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/iflow.ts
================================================
/**
 * iFlow Command Adapter
 *
 * Formats commands for iFlow following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * iFlow adapter for command generation.
 * File path: .iflow/commands/opsx-<id>.md
 * Frontmatter: name, id, category, description
 */
export const iflowAdapter: ToolCommandAdapter = {
  toolId: 'iflow',

  getFilePath(commandId: string): string {
    return path.join('.iflow', 'commands', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
name: /opsx-${content.id}
id: opsx-${content.id}
category: ${content.category}
description: ${content.description}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/index.ts
================================================
/**
 * Command Adapters Index
 *
 * Re-exports all tool command adapters.
 */

export { amazonQAdapter } from './amazon-q.js';
export { antigravityAdapter } from './antigravity.js';
export { auggieAdapter } from './auggie.js';
export { claudeAdapter } from './claude.js';
export { clineAdapter } from './cline.js';
export { codexAdapter } from './codex.js';
export { codebuddyAdapter } from './codebuddy.js';
export { continueAdapter } from './continue.js';
export { costrictAdapter } from './costrict.js';
export { crushAdapter } from './crush.js';
export { cursorAdapter } from './cursor.js';
export { factoryAdapter } from './factory.js';
export { geminiAdapter } from './gemini.js';
export { githubCopilotAdapter } from './github-copilot.js';
export { iflowAdapter } from './iflow.js';
export { kilocodeAdapter } from './kilocode.js';
export { opencodeAdapter } from './opencode.js';
export { qoderAdapter } from './qoder.js';
export { qwenAdapter } from './qwen.js';
export { roocodeAdapter } from './roocode.js';
export { windsurfAdapter } from './windsurf.js';



================================================
FILE: src/core/command-generation/adapters/kilocode.ts
================================================
/**
 * Kilo Code Command Adapter
 *
 * Formats commands for Kilo Code following its workflow specification.
 * Kilo Code workflows don't use frontmatter.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Kilo Code adapter for command generation.
 * File path: .kilocode/workflows/opsx-<id>.md
 * Format: Plain markdown without frontmatter
 */
export const kilocodeAdapter: ToolCommandAdapter = {
  toolId: 'kilocode',

  getFilePath(commandId: string): string {
    return path.join('.kilocode', 'workflows', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/opencode.ts
================================================
/**
 * OpenCode Command Adapter
 *
 * Formats commands for OpenCode following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * OpenCode adapter for command generation.
 * File path: .opencode/command/opsx-<id>.md
 * Frontmatter: description
 */
export const opencodeAdapter: ToolCommandAdapter = {
  toolId: 'opencode',

  getFilePath(commandId: string): string {
    return path.join('.opencode', 'command', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
description: ${content.description}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/qoder.ts
================================================
/**
 * Qoder Command Adapter
 *
 * Formats commands for Qoder following its frontmatter specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Qoder adapter for command generation.
 * File path: .qoder/commands/opsx/<id>.md
 * Frontmatter: name, description, category, tags
 */
export const qoderAdapter: ToolCommandAdapter = {
  toolId: 'qoder',

  getFilePath(commandId: string): string {
    return path.join('.qoder', 'commands', 'opsx', `${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    const tagsStr = content.tags.join(', ');
    return `---
name: ${content.name}
description: ${content.description}
category: ${content.category}
tags: [${tagsStr}]
---

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/qwen.ts
================================================
/**
 * Qwen Code Command Adapter
 *
 * Formats commands for Qwen Code following its TOML specification.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Qwen adapter for command generation.
 * File path: .qwen/commands/opsx-<id>.toml
 * Format: TOML with description and prompt fields
 */
export const qwenAdapter: ToolCommandAdapter = {
  toolId: 'qwen',

  getFilePath(commandId: string): string {
    return path.join('.qwen', 'commands', `opsx-${commandId}.toml`);
  },

  formatFile(content: CommandContent): string {
    return `description = "${content.description}"

prompt = """
${content.body}
"""
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/roocode.ts
================================================
/**
 * RooCode Command Adapter
 *
 * Formats commands for RooCode following its workflow specification.
 * RooCode uses markdown headers instead of YAML frontmatter.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * RooCode adapter for command generation.
 * File path: .roo/commands/opsx-<id>.md
 * Format: Markdown header with description
 */
export const roocodeAdapter: ToolCommandAdapter = {
  toolId: 'roocode',

  getFilePath(commandId: string): string {
    return path.join('.roo', 'commands', `opsx-${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `# ${content.name}

${content.description}

${content.body}
`;
  },
};



================================================
FILE: src/core/command-generation/adapters/windsurf.ts
================================================
/**
 * Windsurf Command Adapter
 *
 * Formats commands for Windsurf following its frontmatter specification.
 * Windsurf uses a similar format to Claude but may have different conventions.
 */

import path from 'path';
import type { CommandContent, ToolCommandAdapter } from '../types.js';

/**
 * Escapes a string value for safe YAML output.
 * Quotes the string if it contains special YAML characters.
 */
function escapeYamlValue(value: string): string {
  // Check if value needs quoting (contains special YAML characters or starts/ends with whitespace)
  const needsQuoting = /[:\n\r#{}[\],&*!|>'"%@`]|^\s|\s$/.test(value);
  if (needsQuoting) {
    // Use double quotes and escape internal double quotes and backslashes
    const escaped = value.replace(/\\/g, '\\\\').replace(/"/g, '\\"').replace(/\n/g, '\\n');
    return `"${escaped}"`;
  }
  return value;
}

/**
 * Formats a tags array as a YAML array with proper escaping.
 */
function formatTagsArray(tags: string[]): string {
  const escapedTags = tags.map((tag) => escapeYamlValue(tag));
  return `[${escapedTags.join(', ')}]`;
}

/**
 * Windsurf adapter for command generation.
 * File path: .windsurf/commands/opsx/<id>.md
 * Frontmatter: name, description, category, tags
 */
export const windsurfAdapter: ToolCommandAdapter = {
  toolId: 'windsurf',

  getFilePath(commandId: string): string {
    return path.join('.windsurf', 'commands', 'opsx', `${commandId}.md`);
  },

  formatFile(content: CommandContent): string {
    return `---
name: ${escapeYamlValue(content.name)}
description: ${escapeYamlValue(content.description)}
category: ${escapeYamlValue(content.category)}
tags: ${formatTagsArray(content.tags)}
---

${content.body}
`;
  },
};



================================================
FILE: src/core/completions/command-registry.ts
================================================
import { CommandDefinition, FlagDefinition } from './types.js';

/**
 * Common flags used across multiple commands
 */
const COMMON_FLAGS = {
  json: {
    name: 'json',
    description: 'Output as JSON',
  } as FlagDefinition,
  jsonValidation: {
    name: 'json',
    description: 'Output validation results as JSON',
  } as FlagDefinition,
  strict: {
    name: 'strict',
    description: 'Enable strict validation mode',
  } as FlagDefinition,
  noInteractive: {
    name: 'no-interactive',
    description: 'Disable interactive prompts',
  } as FlagDefinition,
  type: {
    name: 'type',
    description: 'Specify item type when ambiguous',
    takesValue: true,
    values: ['change', 'spec'],
  } as FlagDefinition,
} as const;

/**
 * Registry of all OpenSpec CLI commands with their flags and metadata.
 * This registry is used to generate shell completion scripts.
 */
export const COMMAND_REGISTRY: CommandDefinition[] = [
  {
    name: 'init',
    description: 'Initialize OpenSpec in your project',
    acceptsPositional: true,
    positionalType: 'path',
    flags: [
      {
        name: 'tools',
        description: 'Configure AI tools non-interactively (e.g., "all", "none", or comma-separated tool IDs)',
        takesValue: true,
      },
    ],
  },
  {
    name: 'update',
    description: 'Update OpenSpec instruction files',
    acceptsPositional: true,
    positionalType: 'path',
    flags: [],
  },
  {
    name: 'list',
    description: 'List items (changes by default, or specs with --specs)',
    flags: [
      {
        name: 'specs',
        description: 'List specs instead of changes',
      },
      {
        name: 'changes',
        description: 'List changes explicitly (default)',
      },
    ],
  },
  {
    name: 'view',
    description: 'Display an interactive dashboard of specs and changes',
    flags: [],
  },
  {
    name: 'validate',
    description: 'Validate changes and specs',
    acceptsPositional: true,
    positionalType: 'change-or-spec-id',
    flags: [
      {
        name: 'all',
        description: 'Validate all changes and specs',
      },
      {
        name: 'changes',
        description: 'Validate all changes',
      },
      {
        name: 'specs',
        description: 'Validate all specs',
      },
      COMMON_FLAGS.type,
      COMMON_FLAGS.strict,
      COMMON_FLAGS.jsonValidation,
      {
        name: 'concurrency',
        description: 'Max concurrent validations (defaults to env OPENSPEC_CONCURRENCY or 6)',
        takesValue: true,
      },
      COMMON_FLAGS.noInteractive,
    ],
  },
  {
    name: 'show',
    description: 'Show a change or spec',
    acceptsPositional: true,
    positionalType: 'change-or-spec-id',
    flags: [
      COMMON_FLAGS.json,
      COMMON_FLAGS.type,
      COMMON_FLAGS.noInteractive,
      {
        name: 'deltas-only',
        description: 'Show only deltas (JSON only, change-specific)',
      },
      {
        name: 'requirements-only',
        description: 'Alias for --deltas-only (deprecated, change-specific)',
      },
      {
        name: 'requirements',
        description: 'Show only requirements, exclude scenarios (JSON only, spec-specific)',
      },
      {
        name: 'no-scenarios',
        description: 'Exclude scenario content (JSON only, spec-specific)',
      },
      {
        name: 'requirement',
        short: 'r',
        description: 'Show specific requirement by ID (JSON only, spec-specific)',
        takesValue: true,
      },
    ],
  },
  {
    name: 'archive',
    description: 'Archive a completed change and update main specs',
    acceptsPositional: true,
    positionalType: 'change-id',
    flags: [
      {
        name: 'yes',
        short: 'y',
        description: 'Skip confirmation prompts',
      },
      {
        name: 'skip-specs',
        description: 'Skip spec update operations',
      },
      {
        name: 'no-validate',
        description: 'Skip validation (not recommended)',
      },
    ],
  },
  {
    name: 'feedback',
    description: 'Submit feedback about OpenSpec',
    acceptsPositional: true,
    flags: [
      {
        name: 'body',
        description: 'Detailed description for the feedback',
        takesValue: true,
      },
    ],
  },
  {
    name: 'change',
    description: 'Manage OpenSpec change proposals (deprecated)',
    flags: [],
    subcommands: [
      {
        name: 'show',
        description: 'Show a change proposal',
        acceptsPositional: true,
        positionalType: 'change-id',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'deltas-only',
            description: 'Show only deltas (JSON only)',
          },
          {
            name: 'requirements-only',
            description: 'Alias for --deltas-only (deprecated)',
          },
          COMMON_FLAGS.noInteractive,
        ],
      },
      {
        name: 'list',
        description: 'List all active changes (deprecated)',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'long',
            description: 'Show id and title with counts',
          },
        ],
      },
      {
        name: 'validate',
        description: 'Validate a change proposal',
        acceptsPositional: true,
        positionalType: 'change-id',
        flags: [
          COMMON_FLAGS.strict,
          COMMON_FLAGS.jsonValidation,
          COMMON_FLAGS.noInteractive,
        ],
      },
    ],
  },
  {
    name: 'spec',
    description: 'Manage OpenSpec specifications',
    flags: [],
    subcommands: [
      {
        name: 'show',
        description: 'Show a specification',
        acceptsPositional: true,
        positionalType: 'spec-id',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'requirements',
            description: 'Show only requirements, exclude scenarios (JSON only)',
          },
          {
            name: 'no-scenarios',
            description: 'Exclude scenario content (JSON only)',
          },
          {
            name: 'requirement',
            short: 'r',
            description: 'Show specific requirement by ID (JSON only)',
            takesValue: true,
          },
          COMMON_FLAGS.noInteractive,
        ],
      },
      {
        name: 'list',
        description: 'List all specifications',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'long',
            description: 'Show id and title with counts',
          },
        ],
      },
      {
        name: 'validate',
        description: 'Validate a specification',
        acceptsPositional: true,
        positionalType: 'spec-id',
        flags: [
          COMMON_FLAGS.strict,
          COMMON_FLAGS.jsonValidation,
          COMMON_FLAGS.noInteractive,
        ],
      },
    ],
  },
  {
    name: 'completion',
    description: 'Manage shell completions for OpenSpec CLI',
    flags: [],
    subcommands: [
      {
        name: 'generate',
        description: 'Generate completion script for a shell (outputs to stdout)',
        acceptsPositional: true,
        positionalType: 'shell',
        flags: [],
      },
      {
        name: 'install',
        description: 'Install completion script for a shell',
        acceptsPositional: true,
        positionalType: 'shell',
        flags: [
          {
            name: 'verbose',
            description: 'Show detailed installation output',
          },
        ],
      },
      {
        name: 'uninstall',
        description: 'Uninstall completion script for a shell',
        acceptsPositional: true,
        positionalType: 'shell',
        flags: [
          {
            name: 'yes',
            short: 'y',
            description: 'Skip confirmation prompts',
          },
        ],
      },
    ],
  },
  {
    name: 'config',
    description: 'View and modify global OpenSpec configuration',
    flags: [
      {
        name: 'scope',
        description: 'Config scope (only "global" supported currently)',
        takesValue: true,
        values: ['global'],
      },
    ],
    subcommands: [
      {
        name: 'path',
        description: 'Show config file location',
        flags: [],
      },
      {
        name: 'list',
        description: 'Show all current settings',
        flags: [
          COMMON_FLAGS.json,
        ],
      },
      {
        name: 'get',
        description: 'Get a specific value (raw, scriptable)',
        acceptsPositional: true,
        flags: [],
      },
      {
        name: 'set',
        description: 'Set a value (auto-coerce types)',
        acceptsPositional: true,
        flags: [
          {
            name: 'string',
            description: 'Force value to be stored as string',
          },
          {
            name: 'allow-unknown',
            description: 'Allow setting unknown keys',
          },
        ],
      },
      {
        name: 'unset',
        description: 'Remove a key (revert to default)',
        acceptsPositional: true,
        flags: [],
      },
      {
        name: 'reset',
        description: 'Reset configuration to defaults',
        flags: [
          {
            name: 'all',
            description: 'Reset all configuration (required)',
          },
          {
            name: 'yes',
            short: 'y',
            description: 'Skip confirmation prompts',
          },
        ],
      },
      {
        name: 'edit',
        description: 'Open config in $EDITOR',
        flags: [],
      },
    ],
  },
  {
    name: 'schema',
    description: 'Manage workflow schemas',
    flags: [],
    subcommands: [
      {
        name: 'which',
        description: 'Show where a schema resolves from',
        acceptsPositional: true,
        positionalType: 'schema-name',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'all',
            description: 'List all schemas with their resolution sources',
          },
        ],
      },
      {
        name: 'validate',
        description: 'Validate a schema structure and templates',
        acceptsPositional: true,
        positionalType: 'schema-name',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'verbose',
            description: 'Show detailed validation steps',
          },
        ],
      },
      {
        name: 'fork',
        description: 'Copy an existing schema to project for customization',
        acceptsPositional: true,
        positionalType: 'schema-name',
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'force',
            description: 'Overwrite existing destination',
          },
        ],
      },
      {
        name: 'init',
        description: 'Create a new project-local schema',
        acceptsPositional: true,
        flags: [
          COMMON_FLAGS.json,
          {
            name: 'description',
            description: 'Schema description',
            takesValue: true,
          },
          {
            name: 'artifacts',
            description: 'Comma-separated artifact IDs',
            takesValue: true,
          },
          {
            name: 'default',
            description: 'Set as project default schema',
          },
          {
            name: 'no-default',
            description: 'Do not prompt to set as default',
          },
          {
            name: 'force',
            description: 'Overwrite existing schema',
          },
        ],
      },
    ],
  },
];



================================================
FILE: src/core/completions/completion-provider.ts
================================================
import { getActiveChangeIds, getSpecIds } from '../../utils/item-discovery.js';

/**
 * Cache entry for completion data
 */
interface CacheEntry<T> {
  data: T;
  timestamp: number;
}

/**
 * Provides dynamic completion suggestions for OpenSpec items (changes and specs).
 * Implements a 2-second cache to avoid excessive file system operations during
 * tab completion.
 */
export class CompletionProvider {
  private readonly cacheTTL: number;
  private changeCache: CacheEntry<string[]> | null = null;
  private specCache: CacheEntry<string[]> | null = null;

  /**
   * Creates a new completion provider
   *
   * @param cacheTTLMs - Cache time-to-live in milliseconds (default: 2000ms)
   * @param projectRoot - Project root directory (default: process.cwd())
   */
  constructor(
    private readonly cacheTTLMs: number = 2000,
    private readonly projectRoot: string = process.cwd()
  ) {
    this.cacheTTL = cacheTTLMs;
  }

  /**
   * Get all active change IDs for completion
   *
   * @returns Array of change IDs
   */
  async getChangeIds(): Promise<string[]> {
    const now = Date.now();

    // Check if cache is valid
    if (this.changeCache && now - this.changeCache.timestamp < this.cacheTTL) {
      return this.changeCache.data;
    }

    // Fetch fresh data
    const changeIds = await getActiveChangeIds(this.projectRoot);

    // Update cache
    this.changeCache = {
      data: changeIds,
      timestamp: now,
    };

    return changeIds;
  }

  /**
   * Get all spec IDs for completion
   *
   * @returns Array of spec IDs
   */
  async getSpecIds(): Promise<string[]> {
    const now = Date.now();

    // Check if cache is valid
    if (this.specCache && now - this.specCache.timestamp < this.cacheTTL) {
      return this.specCache.data;
    }

    // Fetch fresh data
    const specIds = await getSpecIds(this.projectRoot);

    // Update cache
    this.specCache = {
      data: specIds,
      timestamp: now,
    };

    return specIds;
  }

  /**
   * Get both change and spec IDs for completion
   *
   * @returns Object with changeIds and specIds arrays
   */
  async getAllIds(): Promise<{ changeIds: string[]; specIds: string[] }> {
    const [changeIds, specIds] = await Promise.all([
      this.getChangeIds(),
      this.getSpecIds(),
    ]);

    return { changeIds, specIds };
  }

  /**
   * Clear all cached data
   */
  clearCache(): void {
    this.changeCache = null;
    this.specCache = null;
  }

  /**
   * Get cache statistics for debugging
   *
   * @returns Cache status information
   */
  getCacheStats(): {
    changeCache: { valid: boolean; age?: number };
    specCache: { valid: boolean; age?: number };
  } {
    const now = Date.now();

    return {
      changeCache: {
        valid: this.changeCache !== null && now - this.changeCache.timestamp < this.cacheTTL,
        age: this.changeCache ? now - this.changeCache.timestamp : undefined,
      },
      specCache: {
        valid: this.specCache !== null && now - this.specCache.timestamp < this.cacheTTL,
        age: this.specCache ? now - this.specCache.timestamp : undefined,
      },
    };
  }
}



================================================
FILE: src/core/completions/factory.ts
================================================
import { CompletionGenerator } from './types.js';
import { ZshGenerator } from './generators/zsh-generator.js';
import { BashGenerator } from './generators/bash-generator.js';
import { FishGenerator } from './generators/fish-generator.js';
import { PowerShellGenerator } from './generators/powershell-generator.js';
import { ZshInstaller } from './installers/zsh-installer.js';
import { BashInstaller } from './installers/bash-installer.js';
import { FishInstaller } from './installers/fish-installer.js';
import { PowerShellInstaller } from './installers/powershell-installer.js';
import { SupportedShell } from '../../utils/shell-detection.js';

/**
 * Common installation result interface
 */
export interface InstallationResult {
  success: boolean;
  installedPath?: string;
  backupPath?: string;
  message: string;
  instructions?: string[];
  warnings?: string[];
  // Shell-specific optional fields
  isOhMyZsh?: boolean;
  zshrcConfigured?: boolean;
  bashrcConfigured?: boolean;
  profileConfigured?: boolean;
}

/**
 * Interface for completion installers
 */
export interface CompletionInstaller {
  install(script: string): Promise<InstallationResult>;
  uninstall(): Promise<{ success: boolean; message: string }>;
}

/**
 * Factory for creating completion generators and installers
 * This design makes it easy to add support for additional shells
 */
export class CompletionFactory {
  private static readonly SUPPORTED_SHELLS: SupportedShell[] = ['zsh', 'bash', 'fish', 'powershell'];

  /**
   * Create a completion generator for the specified shell
   *
   * @param shell - The target shell
   * @returns CompletionGenerator instance
   * @throws Error if shell is not supported
   */
  static createGenerator(shell: SupportedShell): CompletionGenerator {
    switch (shell) {
      case 'zsh':
        return new ZshGenerator();
      case 'bash':
        return new BashGenerator();
      case 'fish':
        return new FishGenerator();
      case 'powershell':
        return new PowerShellGenerator();
      default:
        throw new Error(`Unsupported shell: ${shell}`);
    }
  }

  /**
   * Create a completion installer for the specified shell
   *
   * @param shell - The target shell
   * @returns CompletionInstaller instance
   * @throws Error if shell is not supported
   */
  static createInstaller(shell: SupportedShell): CompletionInstaller {
    switch (shell) {
      case 'zsh':
        return new ZshInstaller();
      case 'bash':
        return new BashInstaller();
      case 'fish':
        return new FishInstaller();
      case 'powershell':
        return new PowerShellInstaller();
      default:
        throw new Error(`Unsupported shell: ${shell}`);
    }
  }

  /**
   * Check if a shell is supported
   *
   * @param shell - The shell to check
   * @returns true if the shell is supported
   */
  static isSupported(shell: string): shell is SupportedShell {
    return this.SUPPORTED_SHELLS.includes(shell as SupportedShell);
  }

  /**
   * Get list of all supported shells
   *
   * @returns Array of supported shell names
   */
  static getSupportedShells(): SupportedShell[] {
    return [...this.SUPPORTED_SHELLS];
  }
}



================================================
FILE: src/core/completions/types.ts
================================================
import { SupportedShell } from '../../utils/shell-detection.js';

/**
 * Definition of a command-line flag/option
 */
export interface FlagDefinition {
  /**
   * Flag name without dashes (e.g., "json", "strict", "no-interactive")
   */
  name: string;

  /**
   * Short flag name without dash (e.g., "y" for "-y")
   */
  short?: string;

  /**
   * Human-readable description of what the flag does
   */
  description: string;

  /**
   * Whether the flag takes an argument value
   */
  takesValue?: boolean;

  /**
   * Possible values for the flag (for completion suggestions)
   */
  values?: string[];
}

/**
 * Definition of a CLI command
 */
export interface CommandDefinition {
  /**
   * Command name (e.g., "init", "validate", "show")
   */
  name: string;

  /**
   * Human-readable description of the command
   */
  description: string;

  /**
   * Flags/options supported by this command
   */
  flags: FlagDefinition[];

  /**
   * Subcommands (e.g., "change show", "spec validate")
   */
  subcommands?: CommandDefinition[];

  /**
   * Whether this command accepts a positional argument (e.g., item name, path)
   */
  acceptsPositional?: boolean;

  /**
   * Type of positional argument for dynamic completion
   * - 'change-id': Complete with active change IDs
   * - 'spec-id': Complete with spec IDs
   * - 'change-or-spec-id': Complete with both changes and specs
   * - 'path': Complete with file paths
   * - 'shell': Complete with supported shell names
   * - 'schema-name': Complete with available schema names
   * - undefined: No specific completion
   */
  positionalType?: 'change-id' | 'spec-id' | 'change-or-spec-id' | 'path' | 'shell' | 'schema-name';
}

/**
 * Interface for shell-specific completion script generators
 */
export interface CompletionGenerator {
  /**
   * The shell type this generator targets
   */
  readonly shell: SupportedShell;

  /**
   * Generate the completion script content
   *
   * @param commands - Command definitions to generate completions for
   * @returns The shell-specific completion script as a string
   */
  generate(commands: CommandDefinition[]): string;
}



================================================
FILE: src/core/completions/generators/bash-generator.ts
================================================
import { CompletionGenerator, CommandDefinition, FlagDefinition } from '../types.js';
import { BASH_DYNAMIC_HELPERS } from '../templates/bash-templates.js';

/**
 * Generates Bash completion scripts for the OpenSpec CLI.
 * Follows Bash completion conventions using complete builtin and COMPREPLY array.
 */
export class BashGenerator implements CompletionGenerator {
  readonly shell = 'bash' as const;

  /**
   * Generate a Bash completion script
   *
   * @param commands - Command definitions to generate completions for
   * @returns Bash completion script as a string
   */
  generate(commands: CommandDefinition[]): string {
    // Build command list for top-level completions
    const commandList = commands.map(c => this.escapeCommandName(c.name)).join(' ');

    // Build command cases using push() for loop clarity
    const caseLines: string[] = [];
    for (const cmd of commands) {
      caseLines.push(`    ${cmd.name})`);
      caseLines.push(...this.generateCommandCase(cmd, '      '));
      caseLines.push('      ;;');
    }
    const commandCases = caseLines.join('\n');

    // Dynamic completion helpers from template
    const helpers = BASH_DYNAMIC_HELPERS;

    // Assemble final script with template literal
    return `# Bash completion script for OpenSpec CLI
# Auto-generated - do not edit manually

_openspec_completion() {
  local cur prev words cword

  # Use _init_completion if available (from bash-completion package)
  # The -n : option prevents colons from being treated as word separators
  # (important for spec/change IDs that may contain colons)
  # Otherwise, fall back to manual initialization
  if declare -F _init_completion >/dev/null 2>&1; then
    _init_completion -n : || return
  else
    # Manual fallback when bash-completion is not installed
    COMPREPLY=()
    cur="\${COMP_WORDS[COMP_CWORD]}"
    prev="\${COMP_WORDS[COMP_CWORD-1]}"
    words=("\${COMP_WORDS[@]}")
    cword=$COMP_CWORD
  fi

  local cmd="\${words[1]}"
  local subcmd="\${words[2]}"

  # Top-level commands
  if [[ $cword -eq 1 ]]; then
    local commands="${commandList}"
    COMPREPLY=($(compgen -W "$commands" -- "$cur"))
    return 0
  fi

  # Command-specific completion
  case "$cmd" in
${commandCases}
  esac

  return 0
}

${helpers}
complete -F _openspec_completion openspec
`;
  }

  /**
   * Generate completion case logic for a command
   */
  private generateCommandCase(cmd: CommandDefinition, indent: string): string[] {
    const lines: string[] = [];

    // Handle subcommands
    if (cmd.subcommands && cmd.subcommands.length > 0) {
      // First, check if user is typing a flag for the parent command
      if (cmd.flags.length > 0) {
        lines.push(`${indent}if [[ "$cur" == -* ]]; then`);
        const flags = cmd.flags.map(f => {
          const parts: string[] = [];
          if (f.short) parts.push(`-${f.short}`);
          parts.push(`--${f.name}`);
          return parts.join(' ');
        }).join(' ');
        lines.push(`${indent}  local flags="${flags}"`);
        lines.push(`${indent}  COMPREPLY=($(compgen -W "$flags" -- "$cur"))`);
        lines.push(`${indent}  return 0`);
        lines.push(`${indent}fi`);
        lines.push('');
      }

      lines.push(`${indent}if [[ $cword -eq 2 ]]; then`);
      lines.push(`${indent}  local subcommands="` + cmd.subcommands.map(s => this.escapeCommandName(s.name)).join(' ') + '"');
      lines.push(`${indent}  COMPREPLY=($(compgen -W "$subcommands" -- "$cur"))`);
      lines.push(`${indent}  return 0`);
      lines.push(`${indent}fi`);
      lines.push('');
      lines.push(`${indent}case "$subcmd" in`);

      for (const subcmd of cmd.subcommands) {
        lines.push(`${indent}  ${subcmd.name})`);
        lines.push(...this.generateArgumentCompletion(subcmd, indent + '    '));
        lines.push(`${indent}    ;;`);
      }

      lines.push(`${indent}esac`);
    } else {
      // No subcommands, just complete arguments
      lines.push(...this.generateArgumentCompletion(cmd, indent));
    }

    return lines;
  }

  /**
   * Generate argument completion (flags and positional arguments)
   */
  private generateArgumentCompletion(cmd: CommandDefinition, indent: string): string[] {
    const lines: string[] = [];

    // Check for flag completion
    if (cmd.flags.length > 0) {
      lines.push(`${indent}if [[ "$cur" == -* ]]; then`);
      const flags = cmd.flags.map(f => {
        const parts: string[] = [];
        if (f.short) parts.push(`-${f.short}`);
        parts.push(`--${f.name}`);
        return parts.join(' ');
      }).join(' ');
      lines.push(`${indent}  local flags="${flags}"`);
      lines.push(`${indent}  COMPREPLY=($(compgen -W "$flags" -- "$cur"))`);
      lines.push(`${indent}  return 0`);
      lines.push(`${indent}fi`);
      lines.push('');
    }

    // Handle positional completions
    if (cmd.acceptsPositional) {
      lines.push(...this.generatePositionalCompletion(cmd.positionalType, indent));
    }

    return lines;
  }

  /**
   * Generate positional argument completion based on type
   */
  private generatePositionalCompletion(positionalType: string | undefined, indent: string): string[] {
    const lines: string[] = [];

    switch (positionalType) {
      case 'change-id':
        lines.push(`${indent}_openspec_complete_changes`);
        break;
      case 'spec-id':
        lines.push(`${indent}_openspec_complete_specs`);
        break;
      case 'change-or-spec-id':
        lines.push(`${indent}_openspec_complete_items`);
        break;
      case 'shell':
        lines.push(`${indent}local shells="zsh bash fish powershell"`);
        lines.push(`${indent}COMPREPLY=($(compgen -W "$shells" -- "$cur"))`);
        break;
      case 'path':
        lines.push(`${indent}COMPREPLY=($(compgen -f -- "$cur"))`);
        break;
    }

    return lines;
  }


  /**
   * Escape command/subcommand names for safe use in Bash scripts
   */
  private escapeCommandName(name: string): string {
    // Escape shell metacharacters to prevent command injection
    return name.replace(/["\$`\\]/g, '\\$&');
  }
}



================================================
FILE: src/core/completions/generators/fish-generator.ts
================================================
import { CompletionGenerator, CommandDefinition, FlagDefinition } from '../types.js';
import { FISH_STATIC_HELPERS, FISH_DYNAMIC_HELPERS } from '../templates/fish-templates.js';

/**
 * Generates Fish completion scripts for the OpenSpec CLI.
 * Follows Fish completion conventions using the complete command.
 */
export class FishGenerator implements CompletionGenerator {
  readonly shell = 'fish' as const;

  /**
   * Generate a Fish completion script
   *
   * @param commands - Command definitions to generate completions for
   * @returns Fish completion script as a string
   */
  generate(commands: CommandDefinition[]): string {
    // Build top-level commands using push() for loop clarity
    const topLevelLines: string[] = [];
    for (const cmd of commands) {
      topLevelLines.push(`# ${cmd.name} command`);
      topLevelLines.push(
        `complete -c openspec -n '__fish_openspec_no_subcommand' -a '${cmd.name}' -d '${this.escapeDescription(cmd.description)}'`
      );
    }
    const topLevelCommands = topLevelLines.join('\n');

    // Build command-specific completions using push() for loop clarity
    const commandCompletionLines: string[] = [];
    for (const cmd of commands) {
      commandCompletionLines.push(...this.generateCommandCompletions(cmd));
      commandCompletionLines.push('');
    }
    const commandCompletions = commandCompletionLines.join('\n');

    // Static helper functions from template
    const helperFunctions = FISH_STATIC_HELPERS;

    // Dynamic completion helpers from template
    const dynamicHelpers = FISH_DYNAMIC_HELPERS;

    // Assemble final script with template literal
    return `# Fish completion script for OpenSpec CLI
# Auto-generated - do not edit manually

${helperFunctions}
${dynamicHelpers}
${topLevelCommands}

${commandCompletions}`;
  }

  /**
   * Generate completions for a specific command
   */
  private generateCommandCompletions(cmd: CommandDefinition): string[] {
    const lines: string[] = [];

    // If command has subcommands
    if (cmd.subcommands && cmd.subcommands.length > 0) {
      // Add subcommand completions
      for (const subcmd of cmd.subcommands) {
        lines.push(
          `complete -c openspec -n '__fish_openspec_using_subcommand ${cmd.name}; and not __fish_openspec_using_subcommand ${subcmd.name}' -a '${subcmd.name}' -d '${this.escapeDescription(subcmd.description)}'`
        );
      }
      lines.push('');

      // Add flags for parent command
      for (const flag of cmd.flags) {
        lines.push(...this.generateFlagCompletion(flag, `__fish_openspec_using_subcommand ${cmd.name}`));
      }

      // Add completions for each subcommand
      for (const subcmd of cmd.subcommands) {
        lines.push(`# ${cmd.name} ${subcmd.name} flags`);
        for (const flag of subcmd.flags) {
          lines.push(...this.generateFlagCompletion(flag, `__fish_openspec_using_subcommand ${cmd.name}; and __fish_openspec_using_subcommand ${subcmd.name}`));
        }

        // Add positional completions for subcommand
        if (subcmd.acceptsPositional) {
          lines.push(...this.generatePositionalCompletion(subcmd.positionalType, `__fish_openspec_using_subcommand ${cmd.name}; and __fish_openspec_using_subcommand ${subcmd.name}`));
        }
      }
    } else {
      // Command without subcommands
      lines.push(`# ${cmd.name} flags`);
      for (const flag of cmd.flags) {
        lines.push(...this.generateFlagCompletion(flag, `__fish_openspec_using_subcommand ${cmd.name}`));
      }

      // Add positional completions
      if (cmd.acceptsPositional) {
        lines.push(...this.generatePositionalCompletion(cmd.positionalType, `__fish_openspec_using_subcommand ${cmd.name}`));
      }
    }

    return lines;
  }

  /**
   * Generate flag completion
   */
  private generateFlagCompletion(flag: FlagDefinition, condition: string): string[] {
    const lines: string[] = [];
    const longFlag = `--${flag.name}`;
    const shortFlag = flag.short ? `-${flag.short}` : undefined;

    if (flag.takesValue && flag.values) {
      // Flag with enum values
      for (const value of flag.values) {
        if (shortFlag) {
          lines.push(
            `complete -c openspec -n '${condition}' -s ${flag.short} -l ${flag.name} -a '${value}' -d '${this.escapeDescription(flag.description)}'`
          );
        } else {
          lines.push(
            `complete -c openspec -n '${condition}' -l ${flag.name} -a '${value}' -d '${this.escapeDescription(flag.description)}'`
          );
        }
      }
    } else if (flag.takesValue) {
      // Flag that takes a value but no specific values defined
      if (shortFlag) {
        lines.push(
          `complete -c openspec -n '${condition}' -s ${flag.short} -l ${flag.name} -r -d '${this.escapeDescription(flag.description)}'`
        );
      } else {
        lines.push(
          `complete -c openspec -n '${condition}' -l ${flag.name} -r -d '${this.escapeDescription(flag.description)}'`
        );
      }
    } else {
      // Boolean flag
      if (shortFlag) {
        lines.push(
          `complete -c openspec -n '${condition}' -s ${flag.short} -l ${flag.name} -d '${this.escapeDescription(flag.description)}'`
        );
      } else {
        lines.push(
          `complete -c openspec -n '${condition}' -l ${flag.name} -d '${this.escapeDescription(flag.description)}'`
        );
      }
    }

    return lines;
  }

  /**
   * Generate positional argument completion
   */
  private generatePositionalCompletion(positionalType: string | undefined, condition: string): string[] {
    const lines: string[] = [];

    switch (positionalType) {
      case 'change-id':
        lines.push(`complete -c openspec -n '${condition}' -a '(__fish_openspec_changes)' -f`);
        break;
      case 'spec-id':
        lines.push(`complete -c openspec -n '${condition}' -a '(__fish_openspec_specs)' -f`);
        break;
      case 'change-or-spec-id':
        lines.push(`complete -c openspec -n '${condition}' -a '(__fish_openspec_items)' -f`);
        break;
      case 'shell':
        lines.push(`complete -c openspec -n '${condition}' -a 'zsh bash fish powershell' -f`);
        break;
      case 'path':
        // Fish automatically completes files, no need to specify
        break;
    }

    return lines;
  }


  /**
   * Escape description text for Fish
   */
  private escapeDescription(description: string): string {
    return description
      .replace(/\\/g, '\\\\')  // Backslashes first
      .replace(/'/g, "\\'")    // Single quotes
      .replace(/\$/g, '\\$')   // Dollar signs (prevents $())
      .replace(/`/g, '\\`');   // Backticks
  }
}



================================================
FILE: src/core/completions/generators/powershell-generator.ts
================================================
import { CompletionGenerator, CommandDefinition, FlagDefinition } from '../types.js';
import { POWERSHELL_DYNAMIC_HELPERS } from '../templates/powershell-templates.js';

/**
 * Generates PowerShell completion scripts for the OpenSpec CLI.
 * Uses Register-ArgumentCompleter for command completion.
 */
export class PowerShellGenerator implements CompletionGenerator {
  readonly shell = 'powershell' as const;

  private stripTrailingCommaFromLastLine(lines: string[]): void {
    if (lines.length === 0) return;
    lines[lines.length - 1] = lines[lines.length - 1].replace(/,\s*$/, '');
  }

  /**
   * Generate a PowerShell completion script
   *
   * @param commands - Command definitions to generate completions for
   * @returns PowerShell completion script as a string
   */
  generate(commands: CommandDefinition[]): string {
    // Build top-level commands using push() for loop clarity
    const commandLines: string[] = [];
    for (const cmd of commands) {
      commandLines.push(`            @{Name="${cmd.name}"; Description="${this.escapeDescription(cmd.description)}"},`);
    }
    this.stripTrailingCommaFromLastLine(commandLines);
    const topLevelCommands = commandLines.join('\n');

    // Build command cases using push() for loop clarity
    const commandCaseLines: string[] = [];
    for (const cmd of commands) {
      commandCaseLines.push(`        "${cmd.name}" {`);
      commandCaseLines.push(...this.generateCommandCase(cmd, '            '));
      commandCaseLines.push('        }');
    }
    const commandCases = commandCaseLines.join('\n');

    // Dynamic completion helpers from template
    const helpers = POWERSHELL_DYNAMIC_HELPERS;

    // Assemble final script with template literal
    return `# PowerShell completion script for OpenSpec CLI
# Auto-generated - do not edit manually

${helpers}
$openspecCompleter = {
    param($wordToComplete, $commandAst, $cursorPosition)

    $tokens = $commandAst.ToString() -split "\\s+"
    $commandCount = ($tokens | Measure-Object).Count

    # Top-level commands
    if ($commandCount -eq 1 -or ($commandCount -eq 2 -and $wordToComplete)) {
        $commands = @(
${topLevelCommands}
        )
        $commands | Where-Object { $_.Name -like "$wordToComplete*" } | ForEach-Object {
            [System.Management.Automation.CompletionResult]::new($_.Name, $_.Name, "ParameterValue", $_.Description)
        }
        return
    }

    $command = $tokens[1]

    switch ($command) {
${commandCases}
    }
}

Register-ArgumentCompleter -CommandName openspec -ScriptBlock $openspecCompleter
`;
  }

  /**
   * Generate completion case for a command
   */
  private generateCommandCase(cmd: CommandDefinition, indent: string): string[] {
    const lines: string[] = [];

    if (cmd.subcommands && cmd.subcommands.length > 0) {
      // First, check if user is typing a flag for the parent command
      if (cmd.flags.length > 0) {
        lines.push(`${indent}if ($wordToComplete -like "-*") {`);
        lines.push(`${indent}    $flags = @(`);
        for (const flag of cmd.flags) {
          const longFlag = `--${flag.name}`;
          const shortFlag = flag.short ? `-${flag.short}` : undefined;
          if (shortFlag) {
            lines.push(`${indent}        @{Name="${longFlag}"; Description="${this.escapeDescription(flag.description)}"},`);
            lines.push(`${indent}        @{Name="${shortFlag}"; Description="${this.escapeDescription(flag.description)}"},`);
          } else {
            lines.push(`${indent}        @{Name="${longFlag}"; Description="${this.escapeDescription(flag.description)}"},`);
          }
        }
        this.stripTrailingCommaFromLastLine(lines);
        lines.push(`${indent}    )`);
        lines.push(`${indent}    $flags | Where-Object { $_.Name -like "$wordToComplete*" } | ForEach-Object {`);
        lines.push(`${indent}        [System.Management.Automation.CompletionResult]::new($_.Name, $_.Name, "ParameterName", $_.Description)`);
        lines.push(`${indent}    }`);
        lines.push(`${indent}    return`);
        lines.push(`${indent}}`);
        lines.push('');
      }

      // Handle subcommands
      lines.push(`${indent}if ($commandCount -eq 2 -or ($commandCount -eq 3 -and $wordToComplete)) {`);
      lines.push(`${indent}    $subcommands = @(`);
      for (const subcmd of cmd.subcommands) {
        lines.push(`${indent}        @{Name="${subcmd.name}"; Description="${this.escapeDescription(subcmd.description)}"},`);
      }
      this.stripTrailingCommaFromLastLine(lines);
      lines.push(`${indent}    )`);
      lines.push(`${indent}    $subcommands | Where-Object { $_.Name -like "$wordToComplete*" } | ForEach-Object {`);
      lines.push(`${indent}        [System.Management.Automation.CompletionResult]::new($_.Name, $_.Name, "ParameterValue", $_.Description)`);
      lines.push(`${indent}    }`);
      lines.push(`${indent}    return`);
      lines.push(`${indent}}`);
      lines.push('');
      lines.push(`${indent}$subcommand = if ($commandCount -gt 2) { $tokens[2] } else { "" }`);
      lines.push(`${indent}switch ($subcommand) {`);

      for (const subcmd of cmd.subcommands) {
        lines.push(`${indent}    "${subcmd.name}" {`);
        lines.push(...this.generateArgumentCompletion(subcmd, indent + '        '));
        lines.push(`${indent}    }`);
      }

      lines.push(`${indent}}`);
    } else {
      // No subcommands
      lines.push(...this.generateArgumentCompletion(cmd, indent));
    }

    return lines;
  }

  /**
   * Generate argument completion (flags and positional)
   */
  private generateArgumentCompletion(cmd: CommandDefinition, indent: string): string[] {
    const lines: string[] = [];

    // Flag completion
    if (cmd.flags.length > 0) {
      lines.push(`${indent}if ($wordToComplete -like "-*") {`);
      lines.push(`${indent}    $flags = @(`);
      for (const flag of cmd.flags) {
        const longFlag = `--${flag.name}`;
        const shortFlag = flag.short ? `-${flag.short}` : undefined;
        if (shortFlag) {
          lines.push(`${indent}        @{Name="${longFlag}"; Description="${this.escapeDescription(flag.description)}"},`);
          lines.push(`${indent}        @{Name="${shortFlag}"; Description="${this.escapeDescription(flag.description)}"},`);
        } else {
          lines.push(`${indent}        @{Name="${longFlag}"; Description="${this.escapeDescription(flag.description)}"},`);
        }
      }
      this.stripTrailingCommaFromLastLine(lines);
      lines.push(`${indent}    )`);
      lines.push(`${indent}    $flags | Where-Object { $_.Name -like "$wordToComplete*" } | ForEach-Object {`);
      lines.push(`${indent}        [System.Management.Automation.CompletionResult]::new($_.Name, $_.Name, "ParameterName", $_.Description)`);
      lines.push(`${indent}    }`);
      lines.push(`${indent}    return`);
      lines.push(`${indent}}`);
      lines.push('');
    }

    // Positional completion
    if (cmd.acceptsPositional) {
      lines.push(...this.generatePositionalCompletion(cmd.positionalType, indent));
    }

    return lines;
  }

  /**
   * Generate positional argument completion
   */
  private generatePositionalCompletion(positionalType: string | undefined, indent: string): string[] {
    const lines: string[] = [];

    switch (positionalType) {
      case 'change-id':
        lines.push(`${indent}Get-OpenSpecChanges | Where-Object { $_ -like "$wordToComplete*" } | ForEach-Object {`);
        lines.push(`${indent}    [System.Management.Automation.CompletionResult]::new($_, $_, "ParameterValue", "Change: $_")`);
        lines.push(`${indent}}`);
        break;
      case 'spec-id':
        lines.push(`${indent}Get-OpenSpecSpecs | Where-Object { $_ -like "$wordToComplete*" } | ForEach-Object {`);
        lines.push(`${indent}    [System.Management.Automation.CompletionResult]::new($_, $_, "ParameterValue", "Spec: $_")`);
        lines.push(`${indent}}`);
        break;
      case 'change-or-spec-id':
        lines.push(`${indent}$items = @(Get-OpenSpecChanges) + @(Get-OpenSpecSpecs)`);
        lines.push(`${indent}$items | Where-Object { $_ -like "$wordToComplete*" } | ForEach-Object {`);
        lines.push(`${indent}    [System.Management.Automation.CompletionResult]::new($_, $_, "ParameterValue", $_)`);
        lines.push(`${indent}}`);
        break;
      case 'shell':
        lines.push(`${indent}$shells = @("zsh", "bash", "fish", "powershell")`);
        lines.push(`${indent}$shells | Where-Object { $_ -like "$wordToComplete*" } | ForEach-Object {`);
        lines.push(`${indent}    [System.Management.Automation.CompletionResult]::new($_, $_, "ParameterValue", "Shell: $_")`);
        lines.push(`${indent}}`);
        break;
      case 'path':
        // PowerShell handles file path completion automatically
        break;
    }

    return lines;
  }

  /**
   * Escape description text for PowerShell
   */
  private escapeDescription(description: string): string {
    return description
      .replace(/`/g, '``')     // Backticks (escape sequences)
      .replace(/\$/g, '`$')    // Dollar signs (prevents $())
      .replace(/"/g, '""');    // Double quotes
  }
}



================================================
FILE: src/core/completions/generators/zsh-generator.ts
================================================
import { CompletionGenerator, CommandDefinition, FlagDefinition } from '../types.js';
import { ZSH_DYNAMIC_HELPERS } from '../templates/zsh-templates.js';

/**
 * Generates Zsh completion scripts for the OpenSpec CLI.
 * Follows Zsh completion system conventions using the _openspec function.
 */
export class ZshGenerator implements CompletionGenerator {
  readonly shell = 'zsh' as const;

  /**
   * Generate a Zsh completion script
   *
   * @param commands - Command definitions to generate completions for
   * @returns Zsh completion script as a string
   */
  generate(commands: CommandDefinition[]): string {
    // Build command list using push() for loop clarity
    const commandLines: string[] = [];
    for (const cmd of commands) {
      const escapedDesc = this.escapeDescription(cmd.description);
      commandLines.push(`    '${cmd.name}:${escapedDesc}'`);
    }
    const commandList = commandLines.join('\n');

    // Build command cases using push() for loop clarity
    const commandCaseLines: string[] = [];
    for (const cmd of commands) {
      commandCaseLines.push(`        ${cmd.name})`);
      commandCaseLines.push(`          _openspec_${this.sanitizeFunctionName(cmd.name)}`);
      commandCaseLines.push('          ;;');
    }
    const commandCases = commandCaseLines.join('\n');

    // Build command functions using push() for loop clarity
    const commandFunctionLines: string[] = [];
    for (const cmd of commands) {
      commandFunctionLines.push(...this.generateCommandFunction(cmd));
      commandFunctionLines.push('');
    }
    const commandFunctions = commandFunctionLines.join('\n');

    // Dynamic completion helpers from template
    const helpers = ZSH_DYNAMIC_HELPERS;

    // Assemble final script with template literal
    return `#compdef openspec

# Zsh completion script for OpenSpec CLI
# Auto-generated - do not edit manually

_openspec() {
  local context state line
  typeset -A opt_args

  local -a commands
  commands=(
${commandList}
  )

  _arguments -C \\
    "1: :->command" \\
    "*::arg:->args"

  case $state in
    command)
      _describe "openspec command" commands
      ;;
    args)
      case $words[1] in
${commandCases}
      esac
      ;;
  esac
}

${commandFunctions}
${helpers}
compdef _openspec openspec
`;
  }

  /**
   * Generate completion function for a specific command
   */
  private generateCommandFunction(cmd: CommandDefinition): string[] {
    const funcName = `_openspec_${this.sanitizeFunctionName(cmd.name)}`;
    const lines: string[] = [];

    lines.push(`${funcName}() {`);

    // If command has subcommands, handle them
    if (cmd.subcommands && cmd.subcommands.length > 0) {
      lines.push('  local context state line');
      lines.push('  typeset -A opt_args');
      lines.push('');
      lines.push('  local -a subcommands');
      lines.push('  subcommands=(');

      for (const subcmd of cmd.subcommands) {
        const escapedDesc = this.escapeDescription(subcmd.description);
        lines.push(`    '${subcmd.name}:${escapedDesc}'`);
      }

      lines.push('  )');
      lines.push('');
      lines.push('  _arguments -C \\');

      // Add command flags
      for (const flag of cmd.flags) {
        lines.push('    ' + this.generateFlagSpec(flag) + ' \\');
      }

      lines.push('    "1: :->subcommand" \\');
      lines.push('    "*::arg:->args"');
      lines.push('');
      lines.push('  case $state in');
      lines.push('    subcommand)');
      lines.push('      _describe "subcommand" subcommands');
      lines.push('      ;;');
      lines.push('    args)');
      lines.push('      case $words[1] in');

      for (const subcmd of cmd.subcommands) {
        lines.push(`        ${subcmd.name})`);
        lines.push(`          _openspec_${this.sanitizeFunctionName(cmd.name)}_${this.sanitizeFunctionName(subcmd.name)}`);
        lines.push('          ;;');
      }

      lines.push('      esac');
      lines.push('      ;;');
      lines.push('  esac');
    } else {
      // Command without subcommands
      lines.push('  _arguments \\');

      // Add flags
      for (const flag of cmd.flags) {
        lines.push('    ' + this.generateFlagSpec(flag) + ' \\');
      }

      // Add positional argument completion
      if (cmd.acceptsPositional) {
        const positionalSpec = this.generatePositionalSpec(cmd.positionalType);
        lines.push('    ' + positionalSpec);
      } else {
        // Remove trailing backslash from last flag
        if (lines[lines.length - 1].endsWith(' \\')) {
          lines[lines.length - 1] = lines[lines.length - 1].slice(0, -2);
        }
      }
    }

    lines.push('}');

    // Generate subcommand functions if they exist
    if (cmd.subcommands) {
      for (const subcmd of cmd.subcommands) {
        lines.push('');
        lines.push(...this.generateSubcommandFunction(cmd.name, subcmd));
      }
    }

    return lines;
  }

  /**
   * Generate completion function for a subcommand
   */
  private generateSubcommandFunction(parentName: string, subcmd: CommandDefinition): string[] {
    const funcName = `_openspec_${this.sanitizeFunctionName(parentName)}_${this.sanitizeFunctionName(subcmd.name)}`;
    const lines: string[] = [];

    lines.push(`${funcName}() {`);
    lines.push('  _arguments \\');

    // Add flags
    for (const flag of subcmd.flags) {
      lines.push('    ' + this.generateFlagSpec(flag) + ' \\');
    }

    // Add positional argument completion
    if (subcmd.acceptsPositional) {
      const positionalSpec = this.generatePositionalSpec(subcmd.positionalType);
      lines.push('    ' + positionalSpec);
    } else {
      // Remove trailing backslash from last flag
      if (lines[lines.length - 1].endsWith(' \\')) {
        lines[lines.length - 1] = lines[lines.length - 1].slice(0, -2);
      }
    }

    lines.push('}');

    return lines;
  }

  /**
   * Generate flag specification for _arguments
   */
  private generateFlagSpec(flag: FlagDefinition): string {
    const parts: string[] = [];

    // Handle mutually exclusive short and long forms
    if (flag.short) {
      parts.push(`'(-${flag.short} --${flag.name})'{-${flag.short},--${flag.name}}'`);
    } else {
      parts.push(`'--${flag.name}`);
    }

    // Add description
    const escapedDesc = this.escapeDescription(flag.description);
    parts.push(`[${escapedDesc}]`);

    // Add value completion if flag takes a value
    if (flag.takesValue) {
      if (flag.values && flag.values.length > 0) {
        // Provide specific value completions
        const valueList = flag.values.map(v => this.escapeValue(v)).join(' ');
        parts.push(`:value:(${valueList})`);
      } else {
        // Generic value placeholder
        parts.push(':value:');
      }
    }

    // Close the quote (needed for both short and long forms)
    parts.push("'");

    return parts.join('');
  }

  /**
   * Generate positional argument specification
   */
  private generatePositionalSpec(positionalType?: string): string {
    switch (positionalType) {
      case 'change-id':
        return "'*: :_openspec_complete_changes'";
      case 'spec-id':
        return "'*: :_openspec_complete_specs'";
      case 'change-or-spec-id':
        return "'*: :_openspec_complete_items'";
      case 'path':
        return "'*:path:_files'";
      case 'shell':
        return "'*:shell:(zsh bash fish powershell)'";
      default:
        return "'*: :_default'";
    }
  }

  /**
   * Escape special characters in descriptions
   */
  private escapeDescription(desc: string): string {
    return desc
      .replace(/\\/g, '\\\\')
      .replace(/'/g, "\\'")
      .replace(/\[/g, '\\[')
      .replace(/]/g, '\\]')
      .replace(/:/g, '\\:');
  }

  /**
   * Escape special characters in values
   */
  private escapeValue(value: string): string {
    return value
      .replace(/\\/g, '\\\\')
      .replace(/'/g, "\\'")
      .replace(/ /g, '\\ ');
  }

  /**
   * Sanitize command names for use in function names
   */
  private sanitizeFunctionName(name: string): string {
    return name.replace(/-/g, '_');
  }
}



================================================
FILE: src/core/completions/installers/bash-installer.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { FileSystemUtils } from '../../../utils/file-system.js';
import { InstallationResult } from '../factory.js';

/**
 * Installer for Bash completion scripts.
 * Supports bash-completion package and standalone installations.
 */
export class BashInstaller {
  private readonly homeDir: string;

  /**
   * Markers for .bashrc configuration management
   */
  private readonly BASHRC_MARKERS = {
    start: '# OPENSPEC:START',
    end: '# OPENSPEC:END',
  };

  constructor(homeDir: string = os.homedir()) {
    this.homeDir = homeDir;
  }

  /**
   * Check if bash-completion is installed
   *
   * @returns true if bash-completion directories exist
   */
  async isBashCompletionInstalled(): Promise<boolean> {
    const paths = [
      '/usr/share/bash-completion',              // Linux system-wide
      '/usr/local/share/bash-completion',        // Homebrew Intel (main)
      '/opt/homebrew/etc/bash_completion.d',     // Homebrew Apple Silicon
      '/usr/local/etc/bash_completion.d',        // Homebrew Intel (alt path)
      '/etc/bash_completion.d',                   // Legacy fallback
    ];

    for (const p of paths) {
      try {
        const stat = await fs.stat(p);
        if (stat.isDirectory()) {
          return true;
        }
      } catch {
        // Continue checking other paths
      }
    }

    return false;
  }

  /**
   * Get the appropriate installation path for the completion script
   *
   * @returns Installation path
   */
  async getInstallationPath(): Promise<string> {
    // Try user-local bash-completion directory first
    const localCompletionDir = path.join(this.homeDir, '.local', 'share', 'bash-completion', 'completions');

    // For user installation, use local directory
    return path.join(localCompletionDir, 'openspec');
  }

  /**
   * Backup an existing completion file if it exists
   *
   * @param targetPath - Path to the file to backup
   * @returns Path to the backup file, or undefined if no backup was needed
   */
  async backupExistingFile(targetPath: string): Promise<string | undefined> {
    try {
      await fs.access(targetPath);
      // File exists, create a backup
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupPath = `${targetPath}.backup-${timestamp}`;
      await fs.copyFile(targetPath, backupPath);
      return backupPath;
    } catch {
      // File doesn't exist, no backup needed
      return undefined;
    }
  }

  /**
   * Get the path to .bashrc file
   *
   * @returns Path to .bashrc
   */
  private getBashrcPath(): string {
    return path.join(this.homeDir, '.bashrc');
  }

  /**
   * Generate .bashrc configuration content
   *
   * @param completionsDir - Directory containing completion scripts
   * @returns Configuration content
   */
  private generateBashrcConfig(completionsDir: string): string {
    return [
      '# OpenSpec shell completions configuration',
      `if [ -d "${completionsDir}" ]; then`,
      `  for f in "${completionsDir}"/*; do`,
      '    [ -f "$f" ] && . "$f"',
      '  done',
      'fi',
    ].join('\n');
  }

  /**
   * Configure .bashrc to enable completions
   *
   * @param completionsDir - Directory containing completion scripts
   * @returns true if configured successfully, false otherwise
   */
  async configureBashrc(completionsDir: string): Promise<boolean> {
    // Check if auto-configuration is disabled
    if (process.env.OPENSPEC_NO_AUTO_CONFIG === '1') {
      return false;
    }

    try {
      const bashrcPath = this.getBashrcPath();
      const config = this.generateBashrcConfig(completionsDir);

      // Check write permissions
      const canWrite = await FileSystemUtils.canWriteFile(bashrcPath);
      if (!canWrite) {
        return false;
      }

      // Use marker-based update
      await FileSystemUtils.updateFileWithMarkers(
        bashrcPath,
        config,
        this.BASHRC_MARKERS.start,
        this.BASHRC_MARKERS.end
      );

      return true;
    } catch (error: any) {
      // Fail gracefully - don't break installation
      console.debug(`Unable to configure .bashrc for completions: ${error.message}`);
      return false;
    }
  }

  /**
   * Remove .bashrc configuration
   * Used during uninstallation
   *
   * @returns true if removed successfully, false otherwise
   */
  async removeBashrcConfig(): Promise<boolean> {
    try {
      const bashrcPath = this.getBashrcPath();

      // Check if file exists
      try {
        await fs.access(bashrcPath);
      } catch {
        // File doesn't exist, nothing to remove
        return true;
      }

      // Read file content
      const content = await fs.readFile(bashrcPath, 'utf-8');

      // Check if markers exist
      if (!content.includes(this.BASHRC_MARKERS.start) || !content.includes(this.BASHRC_MARKERS.end)) {
        // Markers don't exist, nothing to remove
        return true;
      }

      // Remove content between markers (including markers)
      const lines = content.split('\n');
      const startIndex = lines.findIndex((line) => line.trim() === this.BASHRC_MARKERS.start);
      const endIndex = lines.findIndex((line) => line.trim() === this.BASHRC_MARKERS.end);

      if (startIndex === -1 || endIndex === -1 || endIndex < startIndex) {
        // Invalid marker placement
        return false;
      }

      // Remove lines between markers (inclusive)
      lines.splice(startIndex, endIndex - startIndex + 1);

      // Remove trailing empty lines
      while (lines.length > 0 && lines[lines.length - 1].trim() === '') {
        lines.pop();
      }

      // Write back
      await fs.writeFile(bashrcPath, lines.join('\n'), 'utf-8');

      return true;
    } catch (error: any) {
      // Fail gracefully
      console.debug(`Unable to remove .bashrc configuration: ${error.message}`);
      return false;
    }
  }

  /**
   * Install the completion script
   *
   * @param completionScript - The completion script content to install
   * @returns Installation result with status and instructions
   */
  async install(completionScript: string): Promise<InstallationResult> {
    try {
      const targetPath = await this.getInstallationPath();

      // Check for bash-completion package
      const hasBashCompletion = await this.isBashCompletionInstalled();

      // Check if already installed with same content
      let isUpdate = false;
      try {
        const existingContent = await fs.readFile(targetPath, 'utf-8');
        if (existingContent === completionScript) {
          // Already installed and up to date
          return {
            success: true,
            installedPath: targetPath,
            message: 'Completion script is already installed (up to date)',
            instructions: [
              'The completion script is already installed and up to date.',
              'If completions are not working, try: exec bash',
            ],
          };
        }
        // File exists but content is different - this is an update
        isUpdate = true;
      } catch (error: any) {
        // File doesn't exist or can't be read, proceed with installation
        console.debug(`Unable to read existing completion file at ${targetPath}: ${error.message}`);
      }

      // Ensure the directory exists
      const targetDir = path.dirname(targetPath);
      await fs.mkdir(targetDir, { recursive: true });

      // Backup existing file if updating
      const backupPath = isUpdate ? await this.backupExistingFile(targetPath) : undefined;

      // Write the completion script
      await fs.writeFile(targetPath, completionScript, 'utf-8');

      // Auto-configure .bashrc
      const bashrcConfigured = await this.configureBashrc(targetDir);

      // Generate instructions if .bashrc wasn't auto-configured
      const instructions = bashrcConfigured ? undefined : this.generateInstructions(targetPath);

      // Collect warnings
      const warnings: string[] = [];
      if (!hasBashCompletion) {
        warnings.push(
          'âš ï¸  Warning: bash-completion package not detected',
          '',
          'The completion script requires bash-completion to function.',
          'Install it with:',
          '  brew install bash-completion@2',
          '',
          'Then add to your ~/.bash_profile:',
          '  [[ -r "/opt/homebrew/etc/profile.d/bash_completion.sh" ]] && . "/opt/homebrew/etc/profile.d/bash_completion.sh"'
        );
      }

      // Determine appropriate message
      let message: string;
      if (isUpdate) {
        message = backupPath
          ? 'Completion script updated successfully (previous version backed up)'
          : 'Completion script updated successfully';
      } else {
        message = bashrcConfigured
          ? 'Completion script installed and .bashrc configured successfully'
          : 'Completion script installed successfully for Bash';
      }

      return {
        success: true,
        installedPath: targetPath,
        backupPath,
        bashrcConfigured,
        message,
        instructions,
        warnings: warnings.length > 0 ? warnings : undefined,
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to install completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }

  /**
   * Generate user instructions for enabling completions
   *
   * @param installedPath - Path where the script was installed
   * @returns Array of instruction strings
   */
  private generateInstructions(installedPath: string): string[] {
    const completionsDir = path.dirname(installedPath);

    return [
      'Completion script installed successfully.',
      '',
      'To enable completions, add the following to your ~/.bashrc file:',
      '',
      `  # Source OpenSpec completions`,
      `  if [ -d "${completionsDir}" ]; then`,
      `    for f in "${completionsDir}"/*; do`,
      '      [ -f "$f" ] && . "$f"',
      '    done',
      '  fi',
      '',
      'Then restart your shell or run: exec bash',
    ];
  }

  /**
   * Uninstall the completion script
   *
   * @param options - Optional uninstall options
   * @param options.yes - Skip confirmation prompt (handled by command layer)
   * @returns Uninstallation result
   */
  async uninstall(options?: { yes?: boolean }): Promise<{ success: boolean; message: string }> {
    try {
      const targetPath = await this.getInstallationPath();

      // Check if installed
      try {
        await fs.access(targetPath);
      } catch {
        return {
          success: false,
          message: 'Completion script is not installed',
        };
      }

      // Remove the completion script
      await fs.unlink(targetPath);

      // Remove .bashrc configuration
      await this.removeBashrcConfig();

      return {
        success: true,
        message: 'Completion script uninstalled successfully',
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to uninstall completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }
}



================================================
FILE: src/core/completions/installers/fish-installer.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { InstallationResult } from '../factory.js';

/**
 * Installer for Fish completion scripts.
 * Fish automatically loads completions from ~/.config/fish/completions/
 */
export class FishInstaller {
  private readonly homeDir: string;

  constructor(homeDir: string = os.homedir()) {
    this.homeDir = homeDir;
  }

  /**
   * Get the installation path for Fish completions
   *
   * @returns Installation path
   */
  getInstallationPath(): string {
    return path.join(this.homeDir, '.config', 'fish', 'completions', 'openspec.fish');
  }

  /**
   * Backup an existing completion file if it exists
   *
   * @param targetPath - Path to the file to backup
   * @returns Path to the backup file, or undefined if no backup was needed
   */
  async backupExistingFile(targetPath: string): Promise<string | undefined> {
    try {
      await fs.access(targetPath);
      // File exists, create a backup
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupPath = `${targetPath}.backup-${timestamp}`;
      await fs.copyFile(targetPath, backupPath);
      return backupPath;
    } catch {
      // File doesn't exist, no backup needed
      return undefined;
    }
  }

  /**
   * Install the completion script
   *
   * @param completionScript - The completion script content to install
   * @returns Installation result with status and instructions
   */
  async install(completionScript: string): Promise<InstallationResult> {
    try {
      const targetPath = this.getInstallationPath();

      // Check if already installed with same content
      let isUpdate = false;
      try {
        const existingContent = await fs.readFile(targetPath, 'utf-8');
        if (existingContent === completionScript) {
          // Already installed and up to date
          return {
            success: true,
            installedPath: targetPath,
            message: 'Completion script is already installed (up to date)',
            instructions: [
              'The completion script is already installed and up to date.',
              'Fish automatically loads completions - they should be available immediately.',
            ],
          };
        }
        // File exists but content is different - this is an update
        isUpdate = true;
      } catch (error: any) {
        // File doesn't exist or can't be read, proceed with installation
        console.debug(`Unable to read existing completion file at ${targetPath}: ${error.message}`);
      }

      // Ensure the directory exists
      const targetDir = path.dirname(targetPath);
      await fs.mkdir(targetDir, { recursive: true });

      // Backup existing file if updating
      const backupPath = isUpdate ? await this.backupExistingFile(targetPath) : undefined;

      // Write the completion script
      await fs.writeFile(targetPath, completionScript, 'utf-8');

      // Determine appropriate message
      let message: string;
      if (isUpdate) {
        message = backupPath
          ? 'Completion script updated successfully (previous version backed up)'
          : 'Completion script updated successfully';
      } else {
        message = 'Completion script installed successfully for Fish';
      }

      return {
        success: true,
        installedPath: targetPath,
        backupPath,
        message,
        instructions: [
          'Fish automatically loads completions from ~/.config/fish/completions/',
          'Completions are available immediately - no shell restart needed.',
        ],
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to install completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }

  /**
   * Uninstall the completion script
   *
   * @param options - Optional uninstall options
   * @param options.yes - Skip confirmation prompt (handled by command layer)
   * @returns Uninstallation result
   */
  async uninstall(options?: { yes?: boolean }): Promise<{ success: boolean; message: string }> {
    try {
      const targetPath = this.getInstallationPath();

      // Check if installed
      try {
        await fs.access(targetPath);
      } catch {
        return {
          success: false,
          message: 'Completion script is not installed',
        };
      }

      // Remove the completion script
      await fs.unlink(targetPath);

      return {
        success: true,
        message: 'Completion script uninstalled successfully',
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to uninstall completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }
}



================================================
FILE: src/core/completions/installers/powershell-installer.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { FileSystemUtils } from '../../../utils/file-system.js';
import { InstallationResult } from '../factory.js';

/**
 * Installer for PowerShell completion scripts.
 * Works with both Windows PowerShell 5.1 and PowerShell Core 7+
 */
export class PowerShellInstaller {
  private readonly homeDir: string;

  /**
   * Markers for PowerShell profile configuration management
   */
  private readonly PROFILE_MARKERS = {
    start: '# OPENSPEC:START',
    end: '# OPENSPEC:END',
  };

  constructor(homeDir: string = os.homedir()) {
    this.homeDir = homeDir;
  }

  /**
   * Get PowerShell profile path
   * Prefers $PROFILE environment variable, falls back to platform defaults
   *
   * @returns Profile path
   */
  getProfilePath(): string {
    // Check $PROFILE environment variable (set when running in PowerShell)
    if (process.env.PROFILE) {
      return process.env.PROFILE;
    }

    // Fall back to platform-specific defaults
    if (process.platform === 'win32') {
      // Windows: Documents/PowerShell/Microsoft.PowerShell_profile.ps1
      return path.join(this.homeDir, 'Documents', 'PowerShell', 'Microsoft.PowerShell_profile.ps1');
    } else {
      // macOS/Linux: .config/powershell/Microsoft.PowerShell_profile.ps1
      return path.join(this.homeDir, '.config', 'powershell', 'Microsoft.PowerShell_profile.ps1');
    }
  }

  /**
   * Get all PowerShell profile paths to configure.
   * On Windows, returns both PowerShell Core and Windows PowerShell 5.1 paths.
   * On Unix, returns PowerShell Core path only.
   */
  private getAllProfilePaths(): string[] {
    // If PROFILE env var is set, use only that path
    if (process.env.PROFILE) {
      return [process.env.PROFILE];
    }

    if (process.platform === 'win32') {
      return [
        // PowerShell Core 6+ (cross-platform)
        path.join(this.homeDir, 'Documents', 'PowerShell', 'Microsoft.PowerShell_profile.ps1'),
        // Windows PowerShell 5.1 (Windows-only)
        path.join(this.homeDir, 'Documents', 'WindowsPowerShell', 'Microsoft.PowerShell_profile.ps1'),
      ];
    } else {
      // Unix systems: PowerShell Core only
      return [path.join(this.homeDir, '.config', 'powershell', 'Microsoft.PowerShell_profile.ps1')];
    }
  }

  /**
   * Get the installation path for the completion script
   *
   * @returns Installation path
   */
  getInstallationPath(): string {
    const profilePath = this.getProfilePath();
    const profileDir = path.dirname(profilePath);
    return path.join(profileDir, 'OpenSpecCompletion.ps1');
  }

  /**
   * Backup an existing completion file if it exists
   *
   * @param targetPath - Path to the file to backup
   * @returns Path to the backup file, or undefined if no backup was needed
   */
  async backupExistingFile(targetPath: string): Promise<string | undefined> {
    try {
      await fs.access(targetPath);
      // File exists, create a backup
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupPath = `${targetPath}.backup-${timestamp}`;
      await fs.copyFile(targetPath, backupPath);
      return backupPath;
    } catch {
      // File doesn't exist, no backup needed
      return undefined;
    }
  }

  /**
   * Generate PowerShell profile configuration content
   *
   * @param scriptPath - Path to the completion script
   * @returns Configuration content
   */
  private generateProfileConfig(scriptPath: string): string {
    return [
      '# OpenSpec shell completions configuration',
      `if (Test-Path "${scriptPath}") {`,
      `    . "${scriptPath}"`,
      '}',
    ].join('\n');
  }

  /**
   * Configure PowerShell profile to source the completion script
   *
   * @param scriptPath - Path to the completion script
   * @returns true if configured successfully, false otherwise
   */
  async configureProfile(scriptPath: string): Promise<boolean> {
    const profilePaths = this.getAllProfilePaths();
    let anyConfigured = false;

    for (const profilePath of profilePaths) {
      try {
        // Create profile file if it doesn't exist
        const profileDir = path.dirname(profilePath);
        await fs.mkdir(profileDir, { recursive: true });

        let profileContent = '';
        try {
          profileContent = await fs.readFile(profilePath, 'utf-8');
        } catch {
          // Profile doesn't exist yet, that's fine
        }

        // Check if already configured
        const scriptLine = `. "${scriptPath}"`;
        if (profileContent.includes(scriptLine)) {
          continue; // Already configured, skip
        }

        // Add OpenSpec completion configuration with markers
        const openspecBlock = [
          '',
          '# OPENSPEC:START - OpenSpec completion (managed block, do not edit manually)',
          scriptLine,
          '# OPENSPEC:END',
          '',
        ].join('\n');

        const newContent = profileContent + openspecBlock;
        await fs.writeFile(profilePath, newContent, 'utf-8');
        anyConfigured = true;
      } catch (error) {
        // Continue to next profile if this one fails
        console.warn(`Warning: Could not configure ${profilePath}: ${error}`);
      }
    }

    return anyConfigured;
  }

  /**
   * Remove PowerShell profile configuration
   * Used during uninstallation
   *
   * @returns true if removed successfully, false otherwise
   */
  async removeProfileConfig(): Promise<boolean> {
    const profilePaths = this.getAllProfilePaths();
    let anyRemoved = false;

    for (const profilePath of profilePaths) {
      try {
        // Read profile content
        let profileContent: string;
        try {
          profileContent = await fs.readFile(profilePath, 'utf-8');
        } catch {
          continue; // Profile doesn't exist, nothing to remove
        }

        // Remove OPENSPEC:START -> OPENSPEC:END block
        const startMarker = '# OPENSPEC:START';
        const endMarker = '# OPENSPEC:END';
        const startIndex = profileContent.indexOf(startMarker);

        if (startIndex === -1) {
          continue; // No OpenSpec block found
        }

        const endIndex = profileContent.indexOf(endMarker, startIndex);
        if (endIndex === -1) {
          console.warn(`Warning: Found start marker but no end marker in ${profilePath}`);
          continue;
        }

        // Remove the block (including markers and surrounding newlines)
        const beforeBlock = profileContent.substring(0, startIndex);
        const afterBlock = profileContent.substring(endIndex + endMarker.length);

        // Clean up extra newlines
        const newContent = (beforeBlock.trimEnd() + '\n' + afterBlock.trimStart()).trim() + '\n';

        await fs.writeFile(profilePath, newContent, 'utf-8');
        anyRemoved = true;
      } catch (error) {
        console.warn(`Warning: Could not clean ${profilePath}: ${error}`);
      }
    }

    return anyRemoved;
  }

  /**
   * Install the completion script
   *
   * @param completionScript - The completion script content to install
   * @returns Installation result with status and instructions
   */
  async install(completionScript: string): Promise<InstallationResult> {
    try {
      const targetPath = this.getInstallationPath();

      // Check if already installed with same content
      let isUpdate = false;
      try {
        const existingContent = await fs.readFile(targetPath, 'utf-8');
        if (existingContent === completionScript) {
          // Already installed and up to date
          return {
            success: true,
            installedPath: targetPath,
            message: 'Completion script is already installed (up to date)',
            instructions: [
              'The completion script is already installed and up to date.',
              'If completions are not working, try restarting PowerShell or run: . $PROFILE',
            ],
          };
        }
        // File exists but content is different - this is an update
        isUpdate = true;
      } catch (error: any) {
        // File doesn't exist or can't be read, proceed with installation
        console.debug(`Unable to read existing completion file at ${targetPath}: ${error.message}`);
      }

      // Ensure the directory exists
      const targetDir = path.dirname(targetPath);
      await fs.mkdir(targetDir, { recursive: true });

      // Backup existing file if updating
      const backupPath = isUpdate ? await this.backupExistingFile(targetPath) : undefined;

      // Write the completion script
      await fs.writeFile(targetPath, completionScript, 'utf-8');

      // Auto-configure PowerShell profile
      const profileConfigured = await this.configureProfile(targetPath);

      // Generate instructions if profile wasn't auto-configured
      const instructions = profileConfigured ? undefined : this.generateInstructions(targetPath);

      // Determine appropriate message
      let message: string;
      if (isUpdate) {
        message = backupPath
          ? 'Completion script updated successfully (previous version backed up)'
          : 'Completion script updated successfully';
      } else {
        message = profileConfigured
          ? 'Completion script installed and PowerShell profile configured successfully'
          : 'Completion script installed successfully for PowerShell';
      }

      return {
        success: true,
        installedPath: targetPath,
        backupPath,
        profileConfigured,
        message,
        instructions,
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to install completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }

  /**
   * Generate user instructions for enabling completions
   *
   * @param installedPath - Path where the script was installed
   * @returns Array of instruction strings
   */
  private generateInstructions(installedPath: string): string[] {
    const profilePath = this.getProfilePath();

    return [
      'Completion script installed successfully.',
      '',
      `To enable completions, add the following to your PowerShell profile (${profilePath}):`,
      '',
      '  # Source OpenSpec completions',
      `  if (Test-Path "${installedPath}") {`,
      `      . "${installedPath}"`,
      '  }',
      '',
      'Then restart PowerShell or run: . $PROFILE',
    ];
  }

  /**
   * Uninstall the completion script
   *
   * @param options - Optional uninstall options
   * @param options.yes - Skip confirmation prompt (handled by command layer)
   * @returns Uninstallation result
   */
  async uninstall(options?: { yes?: boolean }): Promise<{ success: boolean; message: string }> {
    try {
      const targetPath = this.getInstallationPath();

      // Check if installed
      try {
        await fs.access(targetPath);
      } catch {
        return {
          success: false,
          message: 'Completion script is not installed',
        };
      }

      // Remove the completion script
      await fs.unlink(targetPath);

      // Remove profile configuration
      await this.removeProfileConfig();

      return {
        success: true,
        message: 'Completion script uninstalled successfully',
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to uninstall completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }
}



================================================
FILE: src/core/completions/installers/zsh-installer.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { FileSystemUtils } from '../../../utils/file-system.js';
import { InstallationResult } from '../factory.js';

/**
 * Installer for Zsh completion scripts.
 * Supports both Oh My Zsh and standard Zsh configurations.
 */
export class ZshInstaller {
  private readonly homeDir: string;

  /**
   * Markers for .zshrc configuration management
   */
  private readonly ZSHRC_MARKERS = {
    start: '# OPENSPEC:START',
    end: '# OPENSPEC:END',
  };

  constructor(homeDir: string = os.homedir()) {
    this.homeDir = homeDir;
  }

  /**
   * Check if Oh My Zsh is installed
   *
   * @returns true if Oh My Zsh is detected via $ZSH env var or directory exists
   */
  async isOhMyZshInstalled(): Promise<boolean> {
    // First check for $ZSH environment variable (standard OMZ setup)
    if (process.env.ZSH) {
      return true;
    }

    // Fall back to checking for ~/.oh-my-zsh directory
    const ohMyZshPath = path.join(this.homeDir, '.oh-my-zsh');

    try {
      const stat = await fs.stat(ohMyZshPath);
      return stat.isDirectory();
    } catch {
      return false;
    }
  }

  /**
   * Get the appropriate installation path for the completion script
   *
   * @returns Object with installation path and whether it's Oh My Zsh
   */
  async getInstallationPath(): Promise<{ path: string; isOhMyZsh: boolean }> {
    const isOhMyZsh = await this.isOhMyZshInstalled();

    if (isOhMyZsh) {
      // Oh My Zsh custom completions directory
      return {
        path: path.join(this.homeDir, '.oh-my-zsh', 'custom', 'completions', '_openspec'),
        isOhMyZsh: true,
      };
    } else {
      // Standard Zsh completions directory
      return {
        path: path.join(this.homeDir, '.zsh', 'completions', '_openspec'),
        isOhMyZsh: false,
      };
    }
  }

  /**
   * Backup an existing completion file if it exists
   *
   * @param targetPath - Path to the file to backup
   * @returns Path to the backup file, or undefined if no backup was needed
   */
  async backupExistingFile(targetPath: string): Promise<string | undefined> {
    try {
      await fs.access(targetPath);
      // File exists, create a backup
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupPath = `${targetPath}.backup-${timestamp}`;
      await fs.copyFile(targetPath, backupPath);
      return backupPath;
    } catch {
      // File doesn't exist, no backup needed
      return undefined;
    }
  }

  /**
   * Get the path to .zshrc file
   *
   * @returns Path to .zshrc
   */
  private getZshrcPath(): string {
    return path.join(this.homeDir, '.zshrc');
  }

  /**
   * Generate .zshrc configuration content
   *
   * @param completionsDir - Directory containing completion scripts
   * @returns Configuration content
   */
  private generateZshrcConfig(completionsDir: string): string {
    return [
      '# OpenSpec shell completions configuration',
      `fpath=("${completionsDir}" $fpath)`,
      'autoload -Uz compinit',
      'compinit',
    ].join('\n');
  }

  /**
   * Configure .zshrc to enable completions
   * Only applies to standard Zsh (not Oh My Zsh)
   *
   * @param completionsDir - Directory containing completion scripts
   * @returns true if configured successfully, false otherwise
   */
  async configureZshrc(completionsDir: string): Promise<boolean> {
    // Check if auto-configuration is disabled
    if (process.env.OPENSPEC_NO_AUTO_CONFIG === '1') {
      return false;
    }

    try {
      const zshrcPath = this.getZshrcPath();
      const config = this.generateZshrcConfig(completionsDir);

      // Check write permissions
      const canWrite = await FileSystemUtils.canWriteFile(zshrcPath);
      if (!canWrite) {
        return false;
      }

      // Use marker-based update
      await FileSystemUtils.updateFileWithMarkers(
        zshrcPath,
        config,
        this.ZSHRC_MARKERS.start,
        this.ZSHRC_MARKERS.end
      );

      return true;
    } catch (error: any) {
      // Fail gracefully - don't break installation
      console.debug(`Unable to configure .zshrc for completions: ${error.message}`);
      return false;
    }
  }

  /**
   * Check if .zshrc has OpenSpec configuration markers
   *
   * @returns true if .zshrc exists and has markers
   */
  private async hasZshrcConfig(): Promise<boolean> {
    try {
      const zshrcPath = this.getZshrcPath();
      const content = await fs.readFile(zshrcPath, 'utf-8');
      return content.includes(this.ZSHRC_MARKERS.start) && content.includes(this.ZSHRC_MARKERS.end);
    } catch {
      return false;
    }
  }

  /**
   * Check if fpath configuration is needed for a given directory
   * Used to verify if Oh My Zsh (or other) completions directory is already in fpath
   *
   * @param completionsDir - Directory to check for in fpath
   * @returns true if configuration is needed, false if directory is already referenced
   */
  private async needsFpathConfig(completionsDir: string): Promise<boolean> {
    try {
      const zshrcPath = this.getZshrcPath();
      const content = await fs.readFile(zshrcPath, 'utf-8');

      // Check if fpath already includes this directory
      return !content.includes(completionsDir);
    } catch (error) {
      // If we can't read .zshrc, assume config is needed
      console.debug(`Unable to read .zshrc to check fpath config: ${error instanceof Error ? error.message : String(error)}`);
      return true;
    }
  }

  /**
   * Remove .zshrc configuration
   * Used during uninstallation
   *
   * @returns true if removed successfully, false otherwise
   */
  async removeZshrcConfig(): Promise<boolean> {
    try {
      const zshrcPath = this.getZshrcPath();

      // Check if file exists
      try {
        await fs.access(zshrcPath);
      } catch {
        // File doesn't exist, nothing to remove
        return true;
      }

      // Read file content
      const content = await fs.readFile(zshrcPath, 'utf-8');

      // Check if markers exist
      if (!content.includes(this.ZSHRC_MARKERS.start) || !content.includes(this.ZSHRC_MARKERS.end)) {
        // Markers don't exist, nothing to remove
        return true;
      }

      // Remove content between markers (including markers)
      const lines = content.split('\n');
      const startIndex = lines.findIndex((line) => line.trim() === this.ZSHRC_MARKERS.start);
      const endIndex = lines.findIndex((line) => line.trim() === this.ZSHRC_MARKERS.end);

      if (startIndex === -1 || endIndex === -1 || endIndex < startIndex) {
        // Invalid marker placement
        return false;
      }

      // Remove lines between markers (inclusive)
      lines.splice(startIndex, endIndex - startIndex + 1);

      // Remove trailing empty lines at the start if the markers were at the top
      while (lines.length > 0 && lines[0].trim() === '') {
        lines.shift();
      }

      // Write back
      await fs.writeFile(zshrcPath, lines.join('\n'), 'utf-8');

      return true;
    } catch (error: any) {
      // Fail gracefully
      console.debug(`Unable to remove .zshrc configuration: ${error.message}`);
      return false;
    }
  }

  /**
   * Install the completion script
   *
   * @param completionScript - The completion script content to install
   * @returns Installation result with status and instructions
   */
  async install(completionScript: string): Promise<InstallationResult> {
    try {
      const { path: targetPath, isOhMyZsh } = await this.getInstallationPath();

      // Check if already installed with same content
      let isUpdate = false;
      try {
        const existingContent = await fs.readFile(targetPath, 'utf-8');
        if (existingContent === completionScript) {
          // Already installed and up to date
          return {
            success: true,
            installedPath: targetPath,
            isOhMyZsh,
            message: 'Completion script is already installed (up to date)',
            instructions: [
              'The completion script is already installed and up to date.',
              'If completions are not working, try: exec zsh',
            ],
          };
        }
        // File exists but content is different - this is an update
        isUpdate = true;
      } catch (error: any) {
        // File doesn't exist or can't be read, proceed with installation
        console.debug(`Unable to read existing completion file at ${targetPath}: ${error.message}`);
      }

      // Ensure the directory exists
      const targetDir = path.dirname(targetPath);
      await fs.mkdir(targetDir, { recursive: true });

      // Backup existing file if updating
      const backupPath = isUpdate ? await this.backupExistingFile(targetPath) : undefined;

      // Write the completion script
      await fs.writeFile(targetPath, completionScript, 'utf-8');

      // Auto-configure .zshrc
      let zshrcConfigured = false;
      if (isOhMyZsh) {
        // For Oh My Zsh, verify that custom/completions is in fpath
        // If not, add it to .zshrc
        const needsConfig = await this.needsFpathConfig(targetDir);
        if (needsConfig) {
          zshrcConfigured = await this.configureZshrc(targetDir);
        }
      } else {
        // Standard Zsh always needs .zshrc configuration
        zshrcConfigured = await this.configureZshrc(targetDir);
      }

      // Generate instructions (only if .zshrc wasn't auto-configured)
      let instructions = zshrcConfigured ? undefined : this.generateInstructions(isOhMyZsh, targetPath);

      // Add fpath guidance for Oh My Zsh installations
      if (isOhMyZsh) {
        const fpathGuidance = this.generateOhMyZshFpathGuidance(targetDir);
        if (fpathGuidance) {
          instructions = instructions ? [...instructions, '', ...fpathGuidance] : fpathGuidance;
        }
      }

      // Determine appropriate message based on update status
      let message: string;
      if (isUpdate) {
        message = backupPath
          ? 'Completion script updated successfully (previous version backed up)'
          : 'Completion script updated successfully';
      } else {
        message = isOhMyZsh
          ? 'Completion script installed successfully for Oh My Zsh'
          : zshrcConfigured
            ? 'Completion script installed and .zshrc configured successfully'
            : 'Completion script installed successfully for Zsh';
      }

      return {
        success: true,
        installedPath: targetPath,
        backupPath,
        isOhMyZsh,
        zshrcConfigured,
        message,
        instructions,
      };
    } catch (error) {
      return {
        success: false,
        isOhMyZsh: false,
        message: `Failed to install completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }

  /**
   * Generate Oh My Zsh fpath verification guidance
   *
   * @param completionsDir - Custom completions directory path
   * @returns Array of guidance strings, or undefined if not needed
   */
  private generateOhMyZshFpathGuidance(completionsDir: string): string[] | undefined {
    return [
      'Note: Oh My Zsh typically auto-loads completions from custom/completions.',
      `Verify that ${completionsDir} is in your fpath by running:`,
      '  echo $fpath | grep "custom/completions"',
      '',
      'If not found, completions may not work. Restart your shell to ensure changes take effect.',
    ];
  }

  /**
   * Generate user instructions for enabling completions
   *
   * @param isOhMyZsh - Whether Oh My Zsh is being used
   * @param installedPath - Path where the script was installed
   * @returns Array of instruction strings
   */
  private generateInstructions(isOhMyZsh: boolean, installedPath: string): string[] {
    if (isOhMyZsh) {
      return [
        'Completion script installed to Oh My Zsh completions directory.',
        'Restart your shell or run: exec zsh',
        'Completions should activate automatically.',
      ];
    } else {
      const completionsDir = path.dirname(installedPath);
      const zshrcPath = path.join(this.homeDir, '.zshrc');

      return [
        'Completion script installed to ~/.zsh/completions/',
        '',
        'To enable completions, add the following to your ~/.zshrc file:',
        '',
        `  # Add completions directory to fpath`,
        `  fpath=(${completionsDir} $fpath)`,
        '',
        '  # Initialize completion system',
        '  autoload -Uz compinit',
        '  compinit',
        '',
        'Then restart your shell or run: exec zsh',
        '',
        `Check if these lines already exist in ${zshrcPath} before adding.`,
      ];
    }
  }

  /**
   * Uninstall the completion script
   *
   * @returns true if uninstalled successfully, false otherwise
   */
  async uninstall(): Promise<{ success: boolean; message: string }> {
    try {
      const { path: targetPath, isOhMyZsh } = await this.getInstallationPath();

      // Try to remove completion script
      let scriptRemoved = false;
      try {
        await fs.access(targetPath);
        await fs.unlink(targetPath);
        scriptRemoved = true;
      } catch {
        // Script not installed
      }

      // Try to remove .zshrc configuration (only for standard Zsh)
      let zshrcWasPresent = false;
      let zshrcCleaned = false;
      if (!isOhMyZsh) {
        zshrcWasPresent = await this.hasZshrcConfig();
        if (zshrcWasPresent) {
          zshrcCleaned = await this.removeZshrcConfig();
        }
      }

      if (!scriptRemoved && !zshrcWasPresent) {
        return {
          success: false,
          message: 'Completion script is not installed',
        };
      }

      const messages: string[] = [];
      if (scriptRemoved) {
        messages.push(`Completion script removed from ${targetPath}`);
      }
      if (zshrcCleaned && !isOhMyZsh) {
        messages.push('Removed OpenSpec configuration from ~/.zshrc');
      }

      return {
        success: true,
        message: messages.join('. '),
      };
    } catch (error) {
      return {
        success: false,
        message: `Failed to uninstall completion script: ${error instanceof Error ? error.message : String(error)}`,
      };
    }
  }

  /**
   * Check if completion script is currently installed
   *
   * @returns true if the completion script exists
   */
  async isInstalled(): Promise<boolean> {
    try {
      const { path: targetPath } = await this.getInstallationPath();
      await fs.access(targetPath);
      return true;
    } catch {
      return false;
    }
  }

  /**
   * Get information about the current installation
   *
   * @returns Installation status information
   */
  async getInstallationInfo(): Promise<{
    installed: boolean;
    path?: string;
    isOhMyZsh?: boolean;
  }> {
    const installed = await this.isInstalled();

    if (!installed) {
      return { installed: false };
    }

    const { path: targetPath, isOhMyZsh } = await this.getInstallationPath();

    return {
      installed: true,
      path: targetPath,
      isOhMyZsh,
    };
  }
}



================================================
FILE: src/core/completions/templates/bash-templates.ts
================================================
/**
 * Static template strings for Bash completion scripts.
 * These are Bash-specific helper functions that never change.
 */

export const BASH_DYNAMIC_HELPERS = `# Dynamic completion helpers

_openspec_complete_changes() {
  local changes
  changes=$(openspec __complete changes 2>/dev/null | cut -f1)
  COMPREPLY=($(compgen -W "$changes" -- "$cur"))
}

_openspec_complete_specs() {
  local specs
  specs=$(openspec __complete specs 2>/dev/null | cut -f1)
  COMPREPLY=($(compgen -W "$specs" -- "$cur"))
}

_openspec_complete_items() {
  local items
  items=$(openspec __complete changes 2>/dev/null | cut -f1; openspec __complete specs 2>/dev/null | cut -f1)
  COMPREPLY=($(compgen -W "$items" -- "$cur"))
}`;



================================================
FILE: src/core/completions/templates/fish-templates.ts
================================================
/**
 * Static template strings for Fish completion scripts.
 * These are Fish-specific helper functions that never change.
 */

export const FISH_STATIC_HELPERS = `# Helper function to check if a subcommand is present
function __fish_openspec_using_subcommand
    set -l cmd (commandline -opc)
    set -e cmd[1]
    for i in $argv
        if contains -- $i $cmd
            return 0
        end
    end
    return 1
end

function __fish_openspec_no_subcommand
    set -l cmd (commandline -opc)
    test (count $cmd) -eq 1
end`;

export const FISH_DYNAMIC_HELPERS = `# Dynamic completion helpers

function __fish_openspec_changes
    openspec __complete changes 2>/dev/null | while read -l id desc
        printf '%s\\t%s\\n' "$id" "$desc"
    end
end

function __fish_openspec_specs
    openspec __complete specs 2>/dev/null | while read -l id desc
        printf '%s\\t%s\\n' "$id" "$desc"
    end
end

function __fish_openspec_items
    __fish_openspec_changes
    __fish_openspec_specs
end`;



================================================
FILE: src/core/completions/templates/powershell-templates.ts
================================================
/**
 * Static template strings for PowerShell completion scripts.
 * These are PowerShell-specific helper functions that never change.
 */

export const POWERSHELL_DYNAMIC_HELPERS = `# Dynamic completion helpers

function Get-OpenSpecChanges {
    $output = openspec __complete changes 2>$null
    if ($output) {
        $output | ForEach-Object {
            ($_ -split "\\t")[0]
        }
    }
}

function Get-OpenSpecSpecs {
    $output = openspec __complete specs 2>$null
    if ($output) {
        $output | ForEach-Object {
            ($_ -split "\\t")[0]
        }
    }
}
`;



================================================
FILE: src/core/completions/templates/zsh-templates.ts
================================================
/**
 * Static template strings for Zsh completion scripts.
 * These are Zsh-specific helper functions that never change.
 */

export const ZSH_DYNAMIC_HELPERS = `# Dynamic completion helpers

# Use openspec __complete to get available changes
_openspec_complete_changes() {
  local -a changes
  while IFS=$'\\t' read -r id desc; do
    changes+=("$id:$desc")
  done < <(openspec __complete changes 2>/dev/null)
  _describe "change" changes
}

# Use openspec __complete to get available specs
_openspec_complete_specs() {
  local -a specs
  while IFS=$'\\t' read -r id desc; do
    specs+=("$id:$desc")
  done < <(openspec __complete specs 2>/dev/null)
  _describe "spec" specs
}

# Get both changes and specs
_openspec_complete_items() {
  local -a items
  while IFS=$'\\t' read -r id desc; do
    items+=("$id:$desc")
  done < <(openspec __complete changes 2>/dev/null)
  while IFS=$'\\t' read -r id desc; do
    items+=("$id:$desc")
  done < <(openspec __complete specs 2>/dev/null)
  _describe "item" items
}`;



================================================
FILE: src/core/configurators/agents.ts
================================================
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

export class AgentsStandardConfigurator implements ToolConfigurator {
  name = 'AGENTS.md standard';
  configFileName = 'AGENTS.md';
  isAvailable = true;

  async configure(projectPath: string, _openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getAgentsStandardTemplate();

    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}



================================================
FILE: src/core/configurators/base.ts
================================================
export interface ToolConfigurator {
  name: string;
  configFileName: string;
  isAvailable: boolean;
  configure(projectPath: string, openspecDir: string): Promise<void>;
}


================================================
FILE: src/core/configurators/claude.ts
================================================
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

export class ClaudeConfigurator implements ToolConfigurator {
  name = 'Claude Code';
  configFileName = 'CLAUDE.md';
  isAvailable = true;

  async configure(projectPath: string, openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getClaudeTemplate();
    
    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}


================================================
FILE: src/core/configurators/cline.ts
================================================
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

export class ClineConfigurator implements ToolConfigurator {
  name = 'Cline';
  configFileName = 'CLINE.md';
  isAvailable = true;

  async configure(projectPath: string, openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getClineTemplate();
    
    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}



================================================
FILE: src/core/configurators/codebuddy.ts
================================================
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

export class CodeBuddyConfigurator implements ToolConfigurator {
  name = 'CodeBuddy';
  configFileName = 'CODEBUDDY.md';
  isAvailable = true;

  async configure(projectPath: string, openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getClaudeTemplate();
    
    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}




================================================
FILE: src/core/configurators/costrict.ts
================================================
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

export class CostrictConfigurator implements ToolConfigurator {
  name = 'CoStrict';
  configFileName = 'COSTRICT.md';
  isAvailable = true;

  async configure(projectPath: string, openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getCostrictTemplate();
    
    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}


================================================
FILE: src/core/configurators/iflow.ts
================================================
import path from "path";
import { ToolConfigurator } from "./base.js";
import { FileSystemUtils } from "../../utils/file-system.js";
import { TemplateManager } from "../templates/index.js";
import { OPENSPEC_MARKERS } from "../config.js";

export class IflowConfigurator implements ToolConfigurator {
  name = "iFlow";
  configFileName = "IFLOW.md";
  isAvailable = true;

  async configure(projectPath: string, openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getClaudeTemplate();

    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}



================================================
FILE: src/core/configurators/qoder.ts
================================================
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

/**
 * Qoder AI Tool Configurator
 * 
 * Configures OpenSpec integration for Qoder AI coding assistant.
 * Creates and manages QODER.md configuration file with OpenSpec instructions.
 * 
 * @implements {ToolConfigurator}
 */
export class QoderConfigurator implements ToolConfigurator {
  /** Display name for the Qoder tool */
  name = 'Qoder';
  
  /** Configuration file name at project root */
  configFileName = 'QODER.md';
  
  /** Indicates tool is available for configuration */
  isAvailable = true;

  /**
   * Configure Qoder integration for a project
   * 
   * Creates or updates QODER.md file with OpenSpec instructions.
   * Uses Claude-compatible template for instruction content.
   * Wrapped with OpenSpec markers for future updates.
   * 
   * @param {string} projectPath - Absolute path to project root directory
   * @param {string} openspecDir - Path to openspec directory (unused but required by interface)
   * @returns {Promise<void>} Resolves when configuration is complete
   */
  async configure(projectPath: string, openspecDir: string): Promise<void> {
    // Construct full path to QODER.md at project root
    const filePath = path.join(projectPath, this.configFileName);
    
    // Get Claude-compatible instruction template
    // This ensures Qoder receives the same high-quality OpenSpec instructions
    const content = TemplateManager.getClaudeTemplate();
    
    // Write or update file with managed content between markers
    // This allows future updates to refresh instructions automatically
    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}



================================================
FILE: src/core/configurators/qwen.ts
================================================
/**
 * Qwen Code configurator for OpenSpec integration.
 * This class handles the configuration of Qwen Code as an AI tool within OpenSpec.
 * 
 * @implements {ToolConfigurator}
 */
import path from 'path';
import { ToolConfigurator } from './base.js';
import { FileSystemUtils } from '../../utils/file-system.js';
import { TemplateManager } from '../templates/index.js';
import { OPENSPEC_MARKERS } from '../config.js';

/**
 * QwenConfigurator class provides integration with Qwen Code
 * by creating and managing the necessary configuration files.
 * Currently configures the QWEN.md file with OpenSpec instructions.
 */
export class QwenConfigurator implements ToolConfigurator {
  /** Display name for the Qwen Code tool */
  name = 'Qwen Code';
  
  /** Configuration file name for Qwen Code */
  configFileName = 'QWEN.md';
  
  /** Availability status for the Qwen Code tool */
  isAvailable = true;

  /**
   * Configures the Qwen Code integration by creating or updating the QWEN.md file
   * with OpenSpec instructions and markers.
   * 
   * @param {string} projectPath - The path to the project root
   * @param {string} _openspecDir - The path to the openspec directory (unused)
   * @returns {Promise<void>} A promise that resolves when configuration is complete
   */
  async configure(projectPath: string, _openspecDir: string): Promise<void> {
    const filePath = path.join(projectPath, this.configFileName);
    const content = TemplateManager.getAgentsStandardTemplate();
    
    await FileSystemUtils.updateFileWithMarkers(
      filePath,
      content,
      OPENSPEC_MARKERS.start,
      OPENSPEC_MARKERS.end
    );
  }
}


================================================
FILE: src/core/configurators/registry.ts
================================================
import { ToolConfigurator } from './base.js';
import { ClaudeConfigurator } from './claude.js';
import { ClineConfigurator } from './cline.js';
import { CodeBuddyConfigurator } from './codebuddy.js';
import { CostrictConfigurator } from './costrict.js';
import { QoderConfigurator } from './qoder.js';
import { IflowConfigurator } from './iflow.js';
import { AgentsStandardConfigurator } from './agents.js';
import { QwenConfigurator } from './qwen.js';

export class ToolRegistry {
  private static tools: Map<string, ToolConfigurator> = new Map();

  static {
    const claudeConfigurator = new ClaudeConfigurator();
    const clineConfigurator = new ClineConfigurator();
    const codeBuddyConfigurator = new CodeBuddyConfigurator();
    const costrictConfigurator = new CostrictConfigurator();
    const qoderConfigurator = new QoderConfigurator();
    const iflowConfigurator = new IflowConfigurator();
    const agentsConfigurator = new AgentsStandardConfigurator();
    const qwenConfigurator = new QwenConfigurator();
    // Register with the ID that matches the checkbox value
    this.tools.set('claude', claudeConfigurator);
    this.tools.set('cline', clineConfigurator);
    this.tools.set('codebuddy', codeBuddyConfigurator);
    this.tools.set('costrict', costrictConfigurator);
    this.tools.set('qoder', qoderConfigurator);
    this.tools.set('iflow', iflowConfigurator);
    this.tools.set('agents', agentsConfigurator);
    this.tools.set('qwen', qwenConfigurator);
  }

  static register(tool: ToolConfigurator): void {
    this.tools.set(tool.name.toLowerCase().replace(/\s+/g, '-'), tool);
  }

  static get(toolId: string): ToolConfigurator | undefined {
    return this.tools.get(toolId);
  }

  static getAll(): ToolConfigurator[] {
    return Array.from(this.tools.values());
  }

  static getAvailable(): ToolConfigurator[] {
    return this.getAll().filter(tool => tool.isAvailable);
  }
}



================================================
FILE: src/core/configurators/slash/amazon-q.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.amazonq/prompts/openspec-proposal.md',
  apply: '.amazonq/prompts/openspec-apply.md',
  archive: '.amazonq/prompts/openspec-archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
description: Scaffold a new OpenSpec change and validate strictly.
---

The user has requested the following change proposal. Use the openspec instructions to create their change proposal.

<UserRequest>
  $ARGUMENTS
</UserRequest>`,
  apply: `---
description: Implement an approved OpenSpec change and keep tasks in sync.
---

The user wants to apply the following change. Use the openspec instructions to implement the approved change.

<ChangeId>
  $ARGUMENTS
</ChangeId>`,
  archive: `---
description: Archive a deployed OpenSpec change and update specs.
---

The user wants to archive the following deployed change. Use the openspec instructions to archive the change and update specs.

<ChangeId>
  $ARGUMENTS
</ChangeId>`
};

export class AmazonQSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'amazon-q';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}


================================================
FILE: src/core/configurators/slash/antigravity.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.agent/workflows/openspec-proposal.md',
  apply: '.agent/workflows/openspec-apply.md',
  archive: '.agent/workflows/openspec-archive.md'
};

const DESCRIPTIONS: Record<SlashCommandId, string> = {
  proposal: 'Scaffold a new OpenSpec change and validate strictly.',
  apply: 'Implement an approved OpenSpec change and keep tasks in sync.',
  archive: 'Archive a deployed OpenSpec change and update specs.'
};

export class AntigravitySlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'antigravity';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    const description = DESCRIPTIONS[id];
    return `---\ndescription: ${description}\n---`;
  }
}



================================================
FILE: src/core/configurators/slash/auggie.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.augment/commands/openspec-proposal.md',
  apply: '.augment/commands/openspec-apply.md',
  archive: '.augment/commands/openspec-archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
description: Scaffold a new OpenSpec change and validate strictly.
argument-hint: feature description or request
---`,
  apply: `---
description: Implement an approved OpenSpec change and keep tasks in sync.
argument-hint: change-id
---`,
  archive: `---
description: Archive a deployed OpenSpec change and update specs.
argument-hint: change-id
---`
};

export class AuggieSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'auggie';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}




================================================
FILE: src/core/configurators/slash/base.ts
================================================
import { FileSystemUtils } from '../../../utils/file-system.js';
import { TemplateManager, SlashCommandId } from '../../templates/index.js';
import { OPENSPEC_MARKERS } from '../../config.js';

export interface SlashCommandTarget {
  id: SlashCommandId;
  path: string;
  kind: 'slash';
}

const ALL_COMMANDS: SlashCommandId[] = ['proposal', 'apply', 'archive'];

export abstract class SlashCommandConfigurator {
  abstract readonly toolId: string;
  abstract readonly isAvailable: boolean;

  getTargets(): SlashCommandTarget[] {
    return ALL_COMMANDS.map((id) => ({
      id,
      path: this.getRelativePath(id),
      kind: 'slash'
    }));
  }

  async generateAll(projectPath: string, _openspecDir: string): Promise<string[]> {
    const createdOrUpdated: string[] = [];

    for (const target of this.getTargets()) {
      const body = this.getBody(target.id);
      const filePath = FileSystemUtils.joinPath(projectPath, target.path);

      if (await FileSystemUtils.fileExists(filePath)) {
        await this.updateBody(filePath, body);
      } else {
        const frontmatter = this.getFrontmatter(target.id);
        const sections: string[] = [];
        if (frontmatter) {
          sections.push(frontmatter.trim());
        }
        sections.push(`${OPENSPEC_MARKERS.start}\n${body}\n${OPENSPEC_MARKERS.end}`);
        const content = sections.join('\n') + '\n';
        await FileSystemUtils.writeFile(filePath, content);
      }

      createdOrUpdated.push(target.path);
    }

    return createdOrUpdated;
  }

  async updateExisting(projectPath: string, _openspecDir: string): Promise<string[]> {
    const updated: string[] = [];

    for (const target of this.getTargets()) {
      const filePath = FileSystemUtils.joinPath(projectPath, target.path);
      if (await FileSystemUtils.fileExists(filePath)) {
        const body = this.getBody(target.id);
        await this.updateBody(filePath, body);
        updated.push(target.path);
      }
    }

    return updated;
  }

  protected abstract getRelativePath(id: SlashCommandId): string;
  protected abstract getFrontmatter(id: SlashCommandId): string | undefined;

  protected getBody(id: SlashCommandId): string {
    return TemplateManager.getSlashCommandBody(id).trim();
  }

  // Resolve absolute path for a given slash command target. Subclasses may override
  // to redirect to tool-specific locations (e.g., global directories).
  resolveAbsolutePath(projectPath: string, id: SlashCommandId): string {
    const rel = this.getRelativePath(id);
    return FileSystemUtils.joinPath(projectPath, rel);
  }

  protected async updateBody(filePath: string, body: string): Promise<void> {
    const content = await FileSystemUtils.readFile(filePath);
    const startIndex = content.indexOf(OPENSPEC_MARKERS.start);
    const endIndex = content.indexOf(OPENSPEC_MARKERS.end);

    if (startIndex === -1 || endIndex === -1 || endIndex <= startIndex) {
      throw new Error(`Missing OpenSpec markers in ${filePath}`);
    }

    const before = content.slice(0, startIndex + OPENSPEC_MARKERS.start.length);
    const after = content.slice(endIndex);
    const updatedContent = `${before}\n${body}\n${after}`;

    await FileSystemUtils.writeFile(filePath, updatedContent);
  }
}



================================================
FILE: src/core/configurators/slash/claude.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.claude/commands/openspec/proposal.md',
  apply: '.claude/commands/openspec/apply.md',
  archive: '.claude/commands/openspec/archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: OpenSpec - Proposal
description: Scaffold a new OpenSpec change and validate strictly.
category: OpenSpec
tags: [openspec, change]
---`,
  apply: `---
name: OpenSpec - Apply
description: Implement an approved OpenSpec change and keep tasks in sync.
category: OpenSpec
tags: [openspec, apply]
---`,
  archive: `---
name: OpenSpec - Archive
description: Archive a deployed OpenSpec change and update specs.
category: OpenSpec
tags: [openspec, archive]
---`
};

export class ClaudeSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'claude';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}



================================================
FILE: src/core/configurators/slash/cline.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.clinerules/workflows/openspec-proposal.md',
  apply: '.clinerules/workflows/openspec-apply.md',
  archive: '.clinerules/workflows/openspec-archive.md'
};

export class ClineSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'cline';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    const descriptions: Record<SlashCommandId, string> = {
      proposal: 'Scaffold a new OpenSpec change and validate strictly.',
      apply: 'Implement an approved OpenSpec change and keep tasks in sync.',
      archive: 'Archive a deployed OpenSpec change and update specs.'
    };
    const description = descriptions[id];
    return `# OpenSpec: ${id.charAt(0).toUpperCase() + id.slice(1)}\n\n${description}`;
  }
}



================================================
FILE: src/core/configurators/slash/codebuddy.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.codebuddy/commands/openspec/proposal.md',
  apply: '.codebuddy/commands/openspec/apply.md',
  archive: '.codebuddy/commands/openspec/archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: OpenSpec: Proposal
description: "Scaffold a new OpenSpec change and validate strictly."
argument-hint: "[feature description or request]"
---`,
  apply: `---
name: OpenSpec: Apply
description: "Implement an approved OpenSpec change and keep tasks in sync."
argument-hint: "[change-id]"
---`,
  archive: `---
name: OpenSpec: Archive
description: "Archive a deployed OpenSpec change and update specs."
argument-hint: "[change-id]"
---`
};

export class CodeBuddySlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'codebuddy';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}




================================================
FILE: src/core/configurators/slash/codex.ts
================================================
import path from "path";
import os from "os";
import { SlashCommandConfigurator } from "./base.js";
import { SlashCommandId, TemplateManager } from "../../templates/index.js";
import { FileSystemUtils } from "../../../utils/file-system.js";
import { OPENSPEC_MARKERS } from "../../config.js";

// Use POSIX-style paths for consistent logging across platforms.
const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: ".codex/prompts/openspec-proposal.md",
  apply: ".codex/prompts/openspec-apply.md",
  archive: ".codex/prompts/openspec-archive.md",
};

export class CodexSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = "codex";
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    // Codex supports YAML frontmatter with description and argument-hint fields,
    // plus $ARGUMENTS to capture all arguments as a single string.
    const frontmatter: Record<SlashCommandId, string> = {
      proposal: `---
description: Scaffold a new OpenSpec change and validate strictly.
argument-hint: request or feature description
---

$ARGUMENTS`,
      apply: `---
description: Implement an approved OpenSpec change and keep tasks in sync.
argument-hint: change-id
---

$ARGUMENTS`,
      archive: `---
description: Archive a deployed OpenSpec change and update specs.
argument-hint: change-id
---

$ARGUMENTS`,
    };
    return frontmatter[id];
  }

  private getGlobalPromptsDir(): string {
    const home = (process.env.CODEX_HOME && process.env.CODEX_HOME.trim())
      ? process.env.CODEX_HOME.trim()
      : FileSystemUtils.joinPath(os.homedir(), ".codex");
    return FileSystemUtils.joinPath(home, "prompts");
  }

  // Codex discovers prompts globally. Generate directly in the global directory
  // and wrap shared body with markers.
  async generateAll(projectPath: string, _openspecDir: string): Promise<string[]> {
    const createdOrUpdated: string[] = [];
    for (const target of this.getTargets()) {
      const body = TemplateManager.getSlashCommandBody(target.id).trim();
      const promptsDir = this.getGlobalPromptsDir();
      const filePath = FileSystemUtils.joinPath(
        promptsDir,
        path.basename(target.path)
      );

      await FileSystemUtils.createDirectory(path.dirname(filePath));

      if (await FileSystemUtils.fileExists(filePath)) {
        await this.updateFullFile(filePath, target.id, body);
      } else {
        const frontmatter = this.getFrontmatter(target.id);
        const sections: string[] = [];
        if (frontmatter) sections.push(frontmatter.trim());
        sections.push(`${OPENSPEC_MARKERS.start}\n${body}\n${OPENSPEC_MARKERS.end}`);
        await FileSystemUtils.writeFile(filePath, sections.join("\n") + "\n");
      }

      createdOrUpdated.push(target.path);
    }
    return createdOrUpdated;
  }

  async updateExisting(projectPath: string, _openspecDir: string): Promise<string[]> {
    const updated: string[] = [];
    for (const target of this.getTargets()) {
      const promptsDir = this.getGlobalPromptsDir();
      const filePath = FileSystemUtils.joinPath(
        promptsDir,
        path.basename(target.path)
      );
      if (await FileSystemUtils.fileExists(filePath)) {
        const body = TemplateManager.getSlashCommandBody(target.id).trim();
        await this.updateFullFile(filePath, target.id, body);
        updated.push(target.path);
      }
    }
    return updated;
  }

  // Update both frontmatter and body in an existing file
  private async updateFullFile(filePath: string, id: SlashCommandId, body: string): Promise<void> {
    const content = await FileSystemUtils.readFile(filePath);
    const startIndex = content.indexOf(OPENSPEC_MARKERS.start);

    if (startIndex === -1) {
      throw new Error(`Missing OpenSpec start marker in ${filePath}`);
    }

    // Replace everything before the start marker with the new frontmatter
    const frontmatter = this.getFrontmatter(id);
    const sections: string[] = [];
    if (frontmatter) sections.push(frontmatter.trim());
    sections.push(`${OPENSPEC_MARKERS.start}\n${body}\n${OPENSPEC_MARKERS.end}`);

    await FileSystemUtils.writeFile(filePath, sections.join("\n") + "\n");
  }

  // Resolve to the global prompts location for configuration detection
  resolveAbsolutePath(_projectPath: string, id: SlashCommandId): string {
    const promptsDir = this.getGlobalPromptsDir();
    const fileName = path.basename(FILE_PATHS[id]);
    return FileSystemUtils.joinPath(promptsDir, fileName);
  }
}



================================================
FILE: src/core/configurators/slash/continue.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.continue/prompts/openspec-proposal.prompt',
  apply: '.continue/prompts/openspec-apply.prompt',
  archive: '.continue/prompts/openspec-archive.prompt'
};

/*
 * Continue .prompt format requires YAML frontmatter:
 * ---
 * name: commandName
 * description: description
 * invokable: true
 * ---
 * Body...
 *
 * The 'invokable: true' field is required to make the prompt available as a slash command.
 * We use 'openspec-proposal' as the name so the command becomes /openspec-proposal.
 */
const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: openspec-proposal
description: Scaffold a new OpenSpec change and validate strictly.
invokable: true
---`,
  apply: `---
name: openspec-apply
description: Implement an approved OpenSpec change and keep tasks in sync.
invokable: true
---`,
  archive: `---
name: openspec-archive
description: Archive a deployed OpenSpec change and update specs.
invokable: true
---`
};

export class ContinueSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'continue';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}



================================================
FILE: src/core/configurators/slash/costrict.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS = {
  proposal: '.cospec/openspec/commands/openspec-proposal.md',
  apply: '.cospec/openspec/commands/openspec-apply.md',
  archive: '.cospec/openspec/commands/openspec-archive.md',
} as const satisfies Record<SlashCommandId, string>;

const FRONTMATTER = {
  proposal: `---
description: "Scaffold a new OpenSpec change and validate strictly."
argument-hint: feature description or request
---`,
  apply: `---
description: "Implement an approved OpenSpec change and keep tasks in sync."
argument-hint: change-id
---`,
  archive: `---
description: "Archive a deployed OpenSpec change and update specs."
argument-hint: change-id
---`
} as const satisfies Record<SlashCommandId, string>;

export class CostrictSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'costrict';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    return FRONTMATTER[id];
  }
}


================================================
FILE: src/core/configurators/slash/crush.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.crush/commands/openspec/proposal.md',
  apply: '.crush/commands/openspec/apply.md',
  archive: '.crush/commands/openspec/archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: OpenSpec: Proposal
description: Scaffold a new OpenSpec change and validate strictly.
category: OpenSpec
tags: [openspec, change]
---`,
  apply: `---
name: OpenSpec: Apply
description: Implement an approved OpenSpec change and keep tasks in sync.
category: OpenSpec
tags: [openspec, apply]
---`,
  archive: `---
name: OpenSpec: Archive
description: Archive a deployed OpenSpec change and update specs.
category: OpenSpec
tags: [openspec, archive]
---`
};

export class CrushSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'crush';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}


================================================
FILE: src/core/configurators/slash/cursor.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.cursor/commands/openspec-proposal.md',
  apply: '.cursor/commands/openspec-apply.md',
  archive: '.cursor/commands/openspec-archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: /openspec-proposal
id: openspec-proposal
category: OpenSpec
description: Scaffold a new OpenSpec change and validate strictly.
---`,
  apply: `---
name: /openspec-apply
id: openspec-apply
category: OpenSpec
description: Implement an approved OpenSpec change and keep tasks in sync.
---`,
  archive: `---
name: /openspec-archive
id: openspec-archive
category: OpenSpec
description: Archive a deployed OpenSpec change and update specs.
---`
};

export class CursorSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'cursor';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}



================================================
FILE: src/core/configurators/slash/factory.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.factory/commands/openspec-proposal.md',
  apply: '.factory/commands/openspec-apply.md',
  archive: '.factory/commands/openspec-archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
description: Scaffold a new OpenSpec change and validate strictly.
argument-hint: request or feature description
---`,
  apply: `---
description: Implement an approved OpenSpec change and keep tasks in sync.
argument-hint: change-id
---`,
  archive: `---
description: Archive a deployed OpenSpec change and update specs.
argument-hint: change-id
---`
};

export class FactorySlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'factory';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }

  protected getBody(id: SlashCommandId): string {
    const baseBody = super.getBody(id);
    return `${baseBody}\n\n$ARGUMENTS`;
  }
}



================================================
FILE: src/core/configurators/slash/gemini.ts
================================================
import { TomlSlashCommandConfigurator } from './toml-base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.gemini/commands/openspec/proposal.toml',
  apply: '.gemini/commands/openspec/apply.toml',
  archive: '.gemini/commands/openspec/archive.toml'
};

const DESCRIPTIONS: Record<SlashCommandId, string> = {
  proposal: 'Scaffold a new OpenSpec change and validate strictly.',
  apply: 'Implement an approved OpenSpec change and keep tasks in sync.',
  archive: 'Archive a deployed OpenSpec change and update specs.'
};

export class GeminiSlashCommandConfigurator extends TomlSlashCommandConfigurator {
  readonly toolId = 'gemini';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getDescription(id: SlashCommandId): string {
    return DESCRIPTIONS[id];
  }
}



================================================
FILE: src/core/configurators/slash/github-copilot.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.github/prompts/openspec-proposal.prompt.md',
  apply: '.github/prompts/openspec-apply.prompt.md',
  archive: '.github/prompts/openspec-archive.prompt.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
description: Scaffold a new OpenSpec change and validate strictly.
---

$ARGUMENTS`,
  apply: `---
description: Implement an approved OpenSpec change and keep tasks in sync.
---

$ARGUMENTS`,
  archive: `---
description: Archive a deployed OpenSpec change and update specs.
---

$ARGUMENTS`
};

export class GitHubCopilotSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'github-copilot';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}



================================================
FILE: src/core/configurators/slash/iflow.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.iflow/commands/openspec-proposal.md',
  apply: '.iflow/commands/openspec-apply.md',
  archive: '.iflow/commands/openspec-archive.md'
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: /openspec-proposal
id: openspec-proposal
category: OpenSpec
description: Scaffold a new OpenSpec change and validate strictly.
---`,
  apply: `---
name: /openspec-apply
id: openspec-apply
category: OpenSpec
description: Implement an approved OpenSpec change and keep tasks in sync.
---`,
  archive: `---
name: /openspec-archive
id: openspec-archive
category: OpenSpec
description: Archive a deployed OpenSpec change and update specs.
---`
};

export class IflowSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'iflow';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}



================================================
FILE: src/core/configurators/slash/kilocode.ts
================================================
import { SlashCommandConfigurator } from "./base.js";
import { SlashCommandId } from "../../templates/index.js";

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: ".kilocode/workflows/openspec-proposal.md",
  apply: ".kilocode/workflows/openspec-apply.md",
  archive: ".kilocode/workflows/openspec-archive.md"
};

export class KiloCodeSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = "kilocode";
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(_id: SlashCommandId): string | undefined {
    return undefined;
  }
}



================================================
FILE: src/core/configurators/slash/opencode.ts
================================================
import { SlashCommandConfigurator } from "./base.js";
import { SlashCommandId } from "../../templates/index.js";
import { FileSystemUtils } from "../../../utils/file-system.js";
import { OPENSPEC_MARKERS } from "../../config.js";

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: ".opencode/command/openspec-proposal.md",
  apply: ".opencode/command/openspec-apply.md",
  archive: ".opencode/command/openspec-archive.md",
};

const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
description: Scaffold a new OpenSpec change and validate strictly.
---
The user has requested the following change proposal. Use the openspec instructions to create their change proposal.
<UserRequest>
  $ARGUMENTS
</UserRequest>
`,
  apply: `---
description: Implement an approved OpenSpec change and keep tasks in sync.
---
The user has requested to implement the following change proposal. Find the change proposal and follow the instructions below. If you're not sure or if ambiguous, ask for clarification from the user.
<UserRequest>
  $ARGUMENTS
</UserRequest>
`,
  archive: `---
description: Archive a deployed OpenSpec change and update specs.
---
<ChangeId>
  $ARGUMENTS
</ChangeId>
`,
};

export class OpenCodeSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = "opencode";
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    return FRONTMATTER[id];
  }

  async generateAll(projectPath: string, _openspecDir: string): Promise<string[]> {
    const createdOrUpdated = await super.generateAll(projectPath, _openspecDir);
    await this.rewriteArchiveFile(projectPath);
    return createdOrUpdated;
  }

  async updateExisting(projectPath: string, _openspecDir: string): Promise<string[]> {
    const updated = await super.updateExisting(projectPath, _openspecDir);
    const rewroteArchive = await this.rewriteArchiveFile(projectPath);
    if (rewroteArchive && !updated.includes(FILE_PATHS.archive)) {
      updated.push(FILE_PATHS.archive);
    }
    return updated;
  }

  private async rewriteArchiveFile(projectPath: string): Promise<boolean> {
    const archivePath = FileSystemUtils.joinPath(projectPath, FILE_PATHS.archive);
    if (!await FileSystemUtils.fileExists(archivePath)) {
      return false;
    }

    const body = this.getBody("archive");
    const frontmatter = this.getFrontmatter("archive");
    const sections: string[] = [];

    if (frontmatter) {
      sections.push(frontmatter.trim());
    }

    sections.push(`${OPENSPEC_MARKERS.start}\n${body}\n${OPENSPEC_MARKERS.end}`);
    await FileSystemUtils.writeFile(archivePath, sections.join("\n") + "\n");
    return true;
  }
}



================================================
FILE: src/core/configurators/slash/qoder.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

/**
 * File paths for Qoder slash commands
 * Maps each OpenSpec workflow stage to its command file location
 * Commands are stored in .qoder/commands/openspec/ directory
 */
const FILE_PATHS: Record<SlashCommandId, string> = {
  // Create and validate new change proposals
  proposal: '.qoder/commands/openspec/proposal.md',
  
  // Implement approved changes with task tracking
  apply: '.qoder/commands/openspec/apply.md',
  
  // Archive completed changes and update specs
  archive: '.qoder/commands/openspec/archive.md'
};

/**
 * YAML frontmatter for Qoder slash commands
 * Defines metadata displayed in Qoder's command palette
 * Each command is categorized and tagged for easy discovery
 */
const FRONTMATTER: Record<SlashCommandId, string> = {
  proposal: `---
name: OpenSpec: Proposal
description: Scaffold a new OpenSpec change and validate strictly.
category: OpenSpec
tags: [openspec, change]
---`,
  apply: `---
name: OpenSpec: Apply
description: Implement an approved OpenSpec change and keep tasks in sync.
category: OpenSpec
tags: [openspec, apply]
---`,
  archive: `---
name: OpenSpec: Archive
description: Archive a deployed OpenSpec change and update specs.
category: OpenSpec
tags: [openspec, archive]
---`
};

/**
 * Qoder Slash Command Configurator
 * 
 * Manages OpenSpec slash commands for Qoder AI assistant.
 * Creates three workflow commands: proposal, apply, and archive.
 * Uses colon-separated command format (/openspec:proposal).
 * 
 * @extends {SlashCommandConfigurator}
 */
export class QoderSlashCommandConfigurator extends SlashCommandConfigurator {
  /** Unique identifier for Qoder tool */
  readonly toolId = 'qoder';
  
  /** Indicates slash commands are available for this tool */
  readonly isAvailable = true;

  /**
   * Get relative file path for a slash command
   * 
   * @param {SlashCommandId} id - Command identifier (proposal, apply, or archive)
   * @returns {string} Relative path from project root to command file
   */
  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  /**
   * Get YAML frontmatter for a slash command
   * 
   * Frontmatter defines how the command appears in Qoder's UI,
   * including display name, description, and categorization.
   * 
   * @param {SlashCommandId} id - Command identifier (proposal, apply, or archive)
   * @returns {string} YAML frontmatter block with command metadata
   */
  protected getFrontmatter(id: SlashCommandId): string {
    return FRONTMATTER[id];
  }
}


================================================
FILE: src/core/configurators/slash/qwen.ts
================================================
/**
 * Qwen slash command configurator for OpenSpec integration.
 * This class handles the generation of Qwen-specific slash command files
 * in the .qwen/commands directory structure.
 * 
 * @implements {SlashCommandConfigurator}
 */
import { TomlSlashCommandConfigurator } from './toml-base.js';
import { SlashCommandId } from '../../templates/index.js';

/** 
 * Mapping of slash command IDs to their corresponding file paths in .qwen/commands directory.
 * @type {Record<SlashCommandId, string>}
 */
const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.qwen/commands/openspec-proposal.toml',
  apply: '.qwen/commands/openspec-apply.toml',
  archive: '.qwen/commands/openspec-archive.toml'
};

const DESCRIPTIONS: Record<SlashCommandId, string> = {
  proposal: 'Scaffold a new OpenSpec change and validate strictly.',
  apply: 'Implement an approved OpenSpec change and keep tasks in sync.',
  archive: 'Archive a deployed OpenSpec change and update specs.'
};

/**
 * QwenSlashCommandConfigurator class provides integration with Qwen Code
 * by creating the necessary slash command files in the .qwen/commands directory.
 * 
 * The slash commands include:
 * - /openspec-proposal: Create an OpenSpec change proposal
 * - /openspec-apply: Apply an approved OpenSpec change
 * - /openspec-archive: Archive a deployed OpenSpec change
 */
export class QwenSlashCommandConfigurator extends TomlSlashCommandConfigurator {
  /** Unique identifier for the Qwen tool */
  readonly toolId = 'qwen';

  /** Availability status for the Qwen tool */
  readonly isAvailable = true;

  /**
   * Returns the relative file path for a given slash command ID.
   * @param {SlashCommandId} id - The slash command identifier
   * @returns {string} The relative path to the command file
   */
  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getDescription(id: SlashCommandId): string {
    return DESCRIPTIONS[id];
  }
}


================================================
FILE: src/core/configurators/slash/registry.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { ClaudeSlashCommandConfigurator } from './claude.js';
import { CodeBuddySlashCommandConfigurator } from './codebuddy.js';
import { QoderSlashCommandConfigurator } from './qoder.js';
import { CursorSlashCommandConfigurator } from './cursor.js';
import { WindsurfSlashCommandConfigurator } from './windsurf.js';
import { KiloCodeSlashCommandConfigurator } from './kilocode.js';
import { OpenCodeSlashCommandConfigurator } from './opencode.js';
import { CodexSlashCommandConfigurator } from './codex.js';
import { GitHubCopilotSlashCommandConfigurator } from './github-copilot.js';
import { AmazonQSlashCommandConfigurator } from './amazon-q.js';
import { FactorySlashCommandConfigurator } from './factory.js';
import { GeminiSlashCommandConfigurator } from './gemini.js';
import { AuggieSlashCommandConfigurator } from './auggie.js';
import { ClineSlashCommandConfigurator } from './cline.js';
import { CrushSlashCommandConfigurator } from './crush.js';
import { CostrictSlashCommandConfigurator } from './costrict.js';
import { QwenSlashCommandConfigurator } from './qwen.js';
import { RooCodeSlashCommandConfigurator } from './roocode.js';
import { AntigravitySlashCommandConfigurator } from './antigravity.js';
import { IflowSlashCommandConfigurator } from './iflow.js';
import { ContinueSlashCommandConfigurator } from './continue.js';

export class SlashCommandRegistry {
  private static configurators: Map<string, SlashCommandConfigurator> = new Map();

  static {
    const claude = new ClaudeSlashCommandConfigurator();
    const codeBuddy = new CodeBuddySlashCommandConfigurator();
    const qoder = new QoderSlashCommandConfigurator();
    const cursor = new CursorSlashCommandConfigurator();
    const windsurf = new WindsurfSlashCommandConfigurator();
    const kilocode = new KiloCodeSlashCommandConfigurator();
    const opencode = new OpenCodeSlashCommandConfigurator();
    const codex = new CodexSlashCommandConfigurator();
    const githubCopilot = new GitHubCopilotSlashCommandConfigurator();
    const amazonQ = new AmazonQSlashCommandConfigurator();
    const factory = new FactorySlashCommandConfigurator();
    const gemini = new GeminiSlashCommandConfigurator();
    const auggie = new AuggieSlashCommandConfigurator();
    const cline = new ClineSlashCommandConfigurator();
    const crush = new CrushSlashCommandConfigurator();
    const costrict = new CostrictSlashCommandConfigurator();
    const qwen = new QwenSlashCommandConfigurator();
    const roocode = new RooCodeSlashCommandConfigurator();
    const antigravity = new AntigravitySlashCommandConfigurator();
    const iflow = new IflowSlashCommandConfigurator();
    const continueTool = new ContinueSlashCommandConfigurator();

    this.configurators.set(claude.toolId, claude);
    this.configurators.set(codeBuddy.toolId, codeBuddy);
    this.configurators.set(qoder.toolId, qoder);
    this.configurators.set(cursor.toolId, cursor);
    this.configurators.set(windsurf.toolId, windsurf);
    this.configurators.set(kilocode.toolId, kilocode);
    this.configurators.set(opencode.toolId, opencode);
    this.configurators.set(codex.toolId, codex);
    this.configurators.set(githubCopilot.toolId, githubCopilot);
    this.configurators.set(amazonQ.toolId, amazonQ);
    this.configurators.set(factory.toolId, factory);
    this.configurators.set(gemini.toolId, gemini);
    this.configurators.set(auggie.toolId, auggie);
    this.configurators.set(cline.toolId, cline);
    this.configurators.set(crush.toolId, crush);
    this.configurators.set(costrict.toolId, costrict);
    this.configurators.set(qwen.toolId, qwen);
    this.configurators.set(roocode.toolId, roocode);
    this.configurators.set(antigravity.toolId, antigravity);
    this.configurators.set(iflow.toolId, iflow);
    this.configurators.set(continueTool.toolId, continueTool);
  }

  static register(configurator: SlashCommandConfigurator): void {
    this.configurators.set(configurator.toolId, configurator);
  }

  static get(toolId: string): SlashCommandConfigurator | undefined {
    return this.configurators.get(toolId);
  }

  static getAll(): SlashCommandConfigurator[] {
    return Array.from(this.configurators.values());
  }
}



================================================
FILE: src/core/configurators/slash/roocode.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const NEW_FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.roo/commands/openspec-proposal.md',
  apply: '.roo/commands/openspec-apply.md',
  archive: '.roo/commands/openspec-archive.md'
};

export class RooCodeSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'roocode';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return NEW_FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    const descriptions: Record<SlashCommandId, string> = {
      proposal: 'Scaffold a new OpenSpec change and validate strictly.',
      apply: 'Implement an approved OpenSpec change and keep tasks in sync.',
      archive: 'Archive a deployed OpenSpec change and update specs.'
    };
    const description = descriptions[id];
    return `# OpenSpec: ${id.charAt(0).toUpperCase() + id.slice(1)}\n\n${description}`;
  }
}



================================================
FILE: src/core/configurators/slash/toml-base.ts
================================================
import { FileSystemUtils } from '../../../utils/file-system.js';
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';
import { OPENSPEC_MARKERS } from '../../config.js';

export abstract class TomlSlashCommandConfigurator extends SlashCommandConfigurator {
  protected getFrontmatter(_id: SlashCommandId): string | undefined {
    // TOML doesn't use separate frontmatter - it's all in one structure
    return undefined;
  }

  protected abstract getDescription(id: SlashCommandId): string;

  // Override to generate TOML format with markers inside the prompt field
  async generateAll(projectPath: string, _openspecDir: string): Promise<string[]> {
    const createdOrUpdated: string[] = [];

    for (const target of this.getTargets()) {
      const body = this.getBody(target.id);
      const filePath = FileSystemUtils.joinPath(projectPath, target.path);

      if (await FileSystemUtils.fileExists(filePath)) {
        await this.updateBody(filePath, body);
      } else {
        const tomlContent = this.generateTOML(target.id, body);
        await FileSystemUtils.writeFile(filePath, tomlContent);
      }

      createdOrUpdated.push(target.path);
    }

    return createdOrUpdated;
  }

  private generateTOML(id: SlashCommandId, body: string): string {
    const description = this.getDescription(id);

    // TOML format with triple-quoted string for multi-line prompt
    // Markers are inside the prompt value
    return `description = "${description}"

prompt = """
${OPENSPEC_MARKERS.start}
${body}
${OPENSPEC_MARKERS.end}
"""
`;
  }

  // Override updateBody to handle TOML format
  protected async updateBody(filePath: string, body: string): Promise<void> {
    const content = await FileSystemUtils.readFile(filePath);
    const startIndex = content.indexOf(OPENSPEC_MARKERS.start);
    const endIndex = content.indexOf(OPENSPEC_MARKERS.end);

    if (startIndex === -1 || endIndex === -1 || endIndex <= startIndex) {
      throw new Error(`Missing OpenSpec markers in ${filePath}`);
    }

    const before = content.slice(0, startIndex + OPENSPEC_MARKERS.start.length);
    const after = content.slice(endIndex);
    const updatedContent = `${before}\n${body}\n${after}`;

    await FileSystemUtils.writeFile(filePath, updatedContent);
  }
}



================================================
FILE: src/core/configurators/slash/windsurf.ts
================================================
import { SlashCommandConfigurator } from './base.js';
import { SlashCommandId } from '../../templates/index.js';

const FILE_PATHS: Record<SlashCommandId, string> = {
  proposal: '.windsurf/workflows/openspec-proposal.md',
  apply: '.windsurf/workflows/openspec-apply.md',
  archive: '.windsurf/workflows/openspec-archive.md'
};

export class WindsurfSlashCommandConfigurator extends SlashCommandConfigurator {
  readonly toolId = 'windsurf';
  readonly isAvailable = true;

  protected getRelativePath(id: SlashCommandId): string {
    return FILE_PATHS[id];
  }

  protected getFrontmatter(id: SlashCommandId): string | undefined {
    const descriptions: Record<SlashCommandId, string> = {
      proposal: 'Scaffold a new OpenSpec change and validate strictly.',
      apply: 'Implement an approved OpenSpec change and keep tasks in sync.',
      archive: 'Archive a deployed OpenSpec change and update specs.'
    };
    const description = descriptions[id];
    return `---\ndescription: ${description}\nauto_execution_mode: 3\n---`;
  }
}



================================================
FILE: src/core/converters/json-converter.ts
================================================
import { readFileSync } from 'fs';
import path from 'path';
import { MarkdownParser } from '../parsers/markdown-parser.js';
import { ChangeParser } from '../parsers/change-parser.js';
import { Spec, Change } from '../schemas/index.js';
import { FileSystemUtils } from '../../utils/file-system.js';

export class JsonConverter {
  convertSpecToJson(filePath: string): string {
    const content = readFileSync(filePath, 'utf-8');
    const parser = new MarkdownParser(content);
    const specName = this.extractNameFromPath(filePath);
    
    const spec = parser.parseSpec(specName);
    
    const jsonSpec = {
      ...spec,
      metadata: {
        ...spec.metadata,
        sourcePath: filePath,
      },
    };
    
    return JSON.stringify(jsonSpec, null, 2);
  }

  async convertChangeToJson(filePath: string): Promise<string> {
    const content = readFileSync(filePath, 'utf-8');
    const changeName = this.extractNameFromPath(filePath);
    const changeDir = path.dirname(filePath);
    const parser = new ChangeParser(content, changeDir);
    
    const change = await parser.parseChangeWithDeltas(changeName);
    
    const jsonChange = {
      ...change,
      metadata: {
        ...change.metadata,
        sourcePath: filePath,
      },
    };
    
    return JSON.stringify(jsonChange, null, 2);
  }

  private extractNameFromPath(filePath: string): string {
    const normalizedPath = FileSystemUtils.toPosixPath(filePath);
    const parts = normalizedPath.split('/');
    
    for (let i = parts.length - 1; i >= 0; i--) {
      if (parts[i] === 'specs' || parts[i] === 'changes') {
        if (i < parts.length - 1) {
          return parts[i + 1];
        }
      }
    }
    
    const fileName = parts[parts.length - 1] ?? '';
    const dotIndex = fileName.lastIndexOf('.');
    return dotIndex > 0 ? fileName.slice(0, dotIndex) : fileName;
  }
}



================================================
FILE: src/core/init/wizard.ts
================================================
import chalk from 'chalk';
import { PALETTE } from '../styles/palette.js';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONSTANTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const LETTER_MAP: Record<string, string[]> = {
  O: [' â–ˆâ–ˆâ–ˆâ–ˆ ', 'â–ˆâ–ˆ  â–ˆâ–ˆ', 'â–ˆâ–ˆ  â–ˆâ–ˆ', 'â–ˆâ–ˆ  â–ˆâ–ˆ', ' â–ˆâ–ˆâ–ˆâ–ˆ '],
  P: ['â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ', 'â–ˆâ–ˆ  â–ˆâ–ˆ', 'â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ', 'â–ˆâ–ˆ    ', 'â–ˆâ–ˆ    '],
  E: ['â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ', 'â–ˆâ–ˆ    ', 'â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ', 'â–ˆâ–ˆ    ', 'â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ'],
  N: ['â–ˆâ–ˆ  â–ˆâ–ˆ', 'â–ˆâ–ˆâ–ˆ â–ˆâ–ˆ', 'â–ˆâ–ˆ â–ˆâ–ˆâ–ˆ', 'â–ˆâ–ˆ  â–ˆâ–ˆ', 'â–ˆâ–ˆ  â–ˆâ–ˆ'],
  S: [' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ', 'â–ˆâ–ˆ    ', ' â–ˆâ–ˆâ–ˆâ–ˆ ', '    â–ˆâ–ˆ', 'â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ '],
  C: [' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ', 'â–ˆâ–ˆ    ', 'â–ˆâ–ˆ    ', 'â–ˆâ–ˆ    ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ'],
  ' ': ['  ', '  ', '  ', '  ', '  '],
};

export const ROOT_STUB_CHOICE_VALUE = '__root_stub__';
export const OTHER_TOOLS_HEADING_VALUE = '__heading-other__';
export const LIST_SPACER_VALUE = '__list-spacer__';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export type ToolLabel = {
  primary: string;
  annotation?: string;
};

export type ToolWizardChoice =
  | {
      kind: 'heading' | 'info';
      value: string;
      label: ToolLabel;
      selectable: false;
    }
  | {
      kind: 'option';
      value: string;
      label: ToolLabel;
      configured: boolean;
      selectable: true;
    };

export type ToolWizardConfig = {
  extendMode: boolean;
  baseMessage: string;
  choices: ToolWizardChoice[];
  initialSelected?: string[];
};

export type WizardStep = 'intro' | 'select' | 'review';

export type ToolSelectionPrompt = (config: ToolWizardConfig) => Promise<string[]>;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// HELPERS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const sanitizeToolLabel = (raw: string): string =>
  raw.replace(/âœ…/gu, 'âœ”').trim();

export const parseToolLabel = (raw: string): ToolLabel => {
  const sanitized = sanitizeToolLabel(raw);
  const match = sanitized.match(/^(.*?)\s*\((.+)\)$/u);
  if (!match) {
    return { primary: sanitized };
  }
  return {
    primary: match[1].trim(),
    annotation: match[2].trim(),
  };
};

export const isSelectableChoice = (
  choice: ToolWizardChoice
): choice is Extract<ToolWizardChoice, { selectable: true }> => choice.selectable;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// WIZARD PROMPT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Singleton cache for the dynamically created prompt
let toolSelectionWizardPromptCached: ((config: ToolWizardConfig) => Promise<string[]>) | null = null;

/**
 * Run the tool selection wizard prompt.
 * This function lazily initializes the prompt on first call by dynamically
 * importing @inquirer/core to avoid static import overhead.
 */
export async function toolSelectionWizard(config: ToolWizardConfig): Promise<string[]> {
  if (!toolSelectionWizardPromptCached) {
    const {
      createPrompt,
      useKeypress,
      usePagination,
      useState,
      isEnterKey,
      isSpaceKey,
      isUpKey,
      isDownKey,
      isBackspaceKey,
    } = await import('@inquirer/core');

    toolSelectionWizardPromptCached = createPrompt<string[], ToolWizardConfig>(
      (promptConfig, done) => {
        const totalSteps = 3;
        const [step, setStep] = useState<WizardStep>('intro');
        const selectableChoices = promptConfig.choices.filter(isSelectableChoice);
        const initialCursorIndex = promptConfig.choices.findIndex((choice) =>
          choice.selectable
        );
        const [cursor, setCursor] = useState<number>(
          initialCursorIndex === -1 ? 0 : initialCursorIndex
        );
        const [selected, setSelected] = useState<string[]>(() => {
          const initial = new Set(
            (promptConfig.initialSelected ?? []).filter((value) =>
              selectableChoices.some((choice) => choice.value === value)
            )
          );
          return selectableChoices
            .map((choice) => choice.value)
            .filter((value) => initial.has(value));
        });
        const [error, setError] = useState<string | null>(null);

        const selectedSet = new Set(selected);
        const pageSize = Math.max(promptConfig.choices.length, 1);

        const updateSelected = (next: Set<string>) => {
          const ordered = selectableChoices
            .map((choice) => choice.value)
            .filter((value) => next.has(value));
          setSelected(ordered);
        };

        const page = usePagination({
          items: promptConfig.choices,
          active: cursor,
          pageSize,
          loop: false,
          renderItem: ({ item, isActive }) => {
            if (!item.selectable) {
              const prefix = item.kind === 'info' ? '  ' : '';
              const textColor =
                item.kind === 'heading' ? PALETTE.lightGray : PALETTE.midGray;
              return `${PALETTE.midGray(' ')} ${PALETTE.midGray(' ')} ${textColor(
                `${prefix}${item.label.primary}`
              )}`;
            }

            const isSelected = selectedSet.has(item.value);
            const cursorSymbol = isActive
              ? PALETTE.white('â€º')
              : PALETTE.midGray(' ');
            const indicator = isSelected
              ? PALETTE.white('â—‰')
              : PALETTE.midGray('â—‹');
            const nameColor = isActive ? PALETTE.white : PALETTE.midGray;
            const annotation = item.label.annotation
              ? PALETTE.midGray(` (${item.label.annotation})`)
              : '';
            const configuredNote = item.configured
              ? PALETTE.midGray(' (already configured)')
              : '';
            const label = `${nameColor(item.label.primary)}${annotation}${configuredNote}`;
            return `${cursorSymbol} ${indicator} ${label}`;
          },
        });

        const moveCursor = (direction: 1 | -1) => {
          if (selectableChoices.length === 0) {
            return;
          }

          let nextIndex = cursor;
          while (true) {
            nextIndex = nextIndex + direction;
            if (nextIndex < 0 || nextIndex >= promptConfig.choices.length) {
              return;
            }

            if (promptConfig.choices[nextIndex]?.selectable) {
              setCursor(nextIndex);
              return;
            }
          }
        };

        useKeypress((key) => {
          if (step === 'intro') {
            if (isEnterKey(key)) {
              setStep('select');
            }
            return;
          }

          if (step === 'select') {
            if (isUpKey(key)) {
              moveCursor(-1);
              setError(null);
              return;
            }

            if (isDownKey(key)) {
              moveCursor(1);
              setError(null);
              return;
            }

            if (isSpaceKey(key)) {
              const current = promptConfig.choices[cursor];
              if (!current || !current.selectable) return;

              const next = new Set(selected);
              if (next.has(current.value)) {
                next.delete(current.value);
              } else {
                next.add(current.value);
              }

              updateSelected(next);
              setError(null);
              return;
            }

            if (isEnterKey(key)) {
              const current = promptConfig.choices[cursor];
              if (
                current &&
                current.selectable &&
                !selectedSet.has(current.value)
              ) {
                const next = new Set(selected);
                next.add(current.value);
                updateSelected(next);
              }
              setStep('review');
              setError(null);
              return;
            }

            if (key.name === 'escape') {
              const next = new Set<string>();
              updateSelected(next);
              setError(null);
            }
            return;
          }

          if (step === 'review') {
            if (isEnterKey(key)) {
              const finalSelection = promptConfig.choices
                .map((choice) => choice.value)
                .filter(
                  (value) =>
                    selectedSet.has(value) && value !== ROOT_STUB_CHOICE_VALUE
                );
              done(finalSelection);
              return;
            }

            if (isBackspaceKey(key) || key.name === 'escape') {
              setStep('select');
              setError(null);
            }
          }
        });

        const rootStubChoice = selectableChoices.find(
          (choice) => choice.value === ROOT_STUB_CHOICE_VALUE
        );
        const rootStubSelected = rootStubChoice
          ? selectedSet.has(ROOT_STUB_CHOICE_VALUE)
          : false;
        const nativeChoices = selectableChoices.filter(
          (choice) => choice.value !== ROOT_STUB_CHOICE_VALUE
        );
        const selectedNativeChoices = nativeChoices.filter((choice) =>
          selectedSet.has(choice.value)
        );

        const formatSummaryLabel = (
          choice: Extract<ToolWizardChoice, { selectable: true }>
        ) => {
          const annotation = choice.label.annotation
            ? PALETTE.midGray(` (${choice.label.annotation})`)
            : '';
          const configuredNote = choice.configured
            ? PALETTE.midGray(' (already configured)')
            : '';
          return `${PALETTE.white(choice.label.primary)}${annotation}${configuredNote}`;
        };

        const stepIndex = step === 'intro' ? 1 : step === 'select' ? 2 : 3;
        const lines: string[] = [];
        lines.push(PALETTE.midGray(`Step ${stepIndex}/${totalSteps}`));
        lines.push('');

        if (step === 'intro') {
          const introHeadline = promptConfig.extendMode
            ? 'Extend your OpenSpec tooling'
            : 'Configure your OpenSpec tooling';
          const introBody = promptConfig.extendMode
            ? 'We detected an existing setup. We will help you refresh or add integrations.'
            : "Let's get your AI assistants connected so they understand OpenSpec.";

          lines.push(PALETTE.white(introHeadline));
          lines.push(PALETTE.midGray(introBody));
          lines.push('');
          lines.push(PALETTE.midGray('Press Enter to continue.'));
        } else if (step === 'select') {
          lines.push(PALETTE.white(promptConfig.baseMessage));
          lines.push(
            PALETTE.midGray(
              'Use â†‘/â†“ to move Â· Space to toggle Â· Enter selects highlighted tool and reviews.'
            )
          );
          lines.push('');
          lines.push(page);
          lines.push('');
          lines.push(PALETTE.midGray('Selected configuration:'));
          if (rootStubSelected && rootStubChoice) {
            lines.push(
              `  ${PALETTE.white('-')} ${formatSummaryLabel(rootStubChoice)}`
            );
          }
          if (selectedNativeChoices.length === 0) {
            lines.push(
              `  ${PALETTE.midGray('- No natively supported providers selected')}`
            );
          } else {
            selectedNativeChoices.forEach((choice) => {
              lines.push(
                `  ${PALETTE.white('-')} ${formatSummaryLabel(choice)}`
              );
            });
          }
        } else {
          lines.push(PALETTE.white('Review selections'));
          lines.push(
            PALETTE.midGray('Press Enter to confirm or Backspace to adjust.')
          );
          lines.push('');

          if (rootStubSelected && rootStubChoice) {
            lines.push(
              `${PALETTE.white('â–Œ')} ${formatSummaryLabel(rootStubChoice)}`
            );
          }

          if (selectedNativeChoices.length === 0) {
            lines.push(
              PALETTE.midGray(
                'No natively supported providers selected. Universal instructions will still be applied.'
              )
            );
          } else {
            selectedNativeChoices.forEach((choice) => {
              lines.push(
                `${PALETTE.white('â–Œ')} ${formatSummaryLabel(choice)}`
              );
            });
          }
        }

        if (error) {
          return [lines.join('\n'), chalk.red(error)];
        }

        return lines.join('\n');
      }
    );
  }

  return toolSelectionWizardPromptCached(config);
}



================================================
FILE: src/core/parsers/change-parser.ts
================================================
import { MarkdownParser, Section } from './markdown-parser.js';
import { Change, Delta, DeltaOperation, Requirement } from '../schemas/index.js';
import path from 'path';
import { promises as fs } from 'fs';

interface DeltaSection {
  operation: DeltaOperation;
  requirements: Requirement[];
  renames?: Array<{ from: string; to: string }>;
}

export class ChangeParser extends MarkdownParser {
  private changeDir: string;

  constructor(content: string, changeDir: string) {
    super(content);
    this.changeDir = changeDir;
  }

  async parseChangeWithDeltas(name: string): Promise<Change> {
    const sections = this.parseSections();
    const why = this.findSection(sections, 'Why')?.content || '';
    const whatChanges = this.findSection(sections, 'What Changes')?.content || '';
    
    if (!why) {
      throw new Error('Change must have a Why section');
    }
    
    if (!whatChanges) {
      throw new Error('Change must have a What Changes section');
    }

    // Parse deltas from the What Changes section (simple format)
    const simpleDeltas = this.parseDeltas(whatChanges);
    
    // Check if there are spec files with delta format
    const specsDir = path.join(this.changeDir, 'specs');
    const deltaDeltas = await this.parseDeltaSpecs(specsDir);
    
    // Combine both types of deltas, preferring delta format if available
    const deltas = deltaDeltas.length > 0 ? deltaDeltas : simpleDeltas;

    return {
      name,
      why: why.trim(),
      whatChanges: whatChanges.trim(),
      deltas,
      metadata: {
        version: '1.0.0',
        format: 'openspec-change',
      },
    };
  }

  private async parseDeltaSpecs(specsDir: string): Promise<Delta[]> {
    const deltas: Delta[] = [];
    
    try {
      const specDirs = await fs.readdir(specsDir, { withFileTypes: true });
      
      for (const dir of specDirs) {
        if (!dir.isDirectory()) continue;
        
        const specName = dir.name;
        const specFile = path.join(specsDir, specName, 'spec.md');
        
        try {
          const content = await fs.readFile(specFile, 'utf-8');
          const specDeltas = this.parseSpecDeltas(specName, content);
          deltas.push(...specDeltas);
        } catch (error) {
          // Spec file might not exist, which is okay
          continue;
        }
      }
    } catch (error) {
      // Specs directory might not exist, which is okay
      return [];
    }
    
    return deltas;
  }

  private parseSpecDeltas(specName: string, content: string): Delta[] {
    const deltas: Delta[] = [];
    const sections = this.parseSectionsFromContent(content);
    
    // Parse ADDED requirements
    const addedSection = this.findSection(sections, 'ADDED Requirements');
    if (addedSection) {
      const requirements = this.parseRequirements(addedSection);
      requirements.forEach(req => {
        deltas.push({
          spec: specName,
          operation: 'ADDED' as DeltaOperation,
          description: `Add requirement: ${req.text}`,
          // Provide both single and plural forms for compatibility
          requirement: req,
          requirements: [req],
        });
      });
    }
    
    // Parse MODIFIED requirements
    const modifiedSection = this.findSection(sections, 'MODIFIED Requirements');
    if (modifiedSection) {
      const requirements = this.parseRequirements(modifiedSection);
      requirements.forEach(req => {
        deltas.push({
          spec: specName,
          operation: 'MODIFIED' as DeltaOperation,
          description: `Modify requirement: ${req.text}`,
          requirement: req,
          requirements: [req],
        });
      });
    }
    
    // Parse REMOVED requirements
    const removedSection = this.findSection(sections, 'REMOVED Requirements');
    if (removedSection) {
      const requirements = this.parseRequirements(removedSection);
      requirements.forEach(req => {
        deltas.push({
          spec: specName,
          operation: 'REMOVED' as DeltaOperation,
          description: `Remove requirement: ${req.text}`,
          requirement: req,
          requirements: [req],
        });
      });
    }
    
    // Parse RENAMED requirements
    const renamedSection = this.findSection(sections, 'RENAMED Requirements');
    if (renamedSection) {
      const renames = this.parseRenames(renamedSection.content);
      renames.forEach(rename => {
        deltas.push({
          spec: specName,
          operation: 'RENAMED' as DeltaOperation,
          description: `Rename requirement from "${rename.from}" to "${rename.to}"`,
          rename,
        });
      });
    }
    
    return deltas;
  }

  private parseRenames(content: string): Array<{ from: string; to: string }> {
    const renames: Array<{ from: string; to: string }> = [];
    const lines = ChangeParser.normalizeContent(content).split('\n');
    
    let currentRename: { from?: string; to?: string } = {};
    
    for (const line of lines) {
      const fromMatch = line.match(/^\s*-?\s*FROM:\s*`?###\s*Requirement:\s*(.+?)`?\s*$/);
      const toMatch = line.match(/^\s*-?\s*TO:\s*`?###\s*Requirement:\s*(.+?)`?\s*$/);
      
      if (fromMatch) {
        currentRename.from = fromMatch[1].trim();
      } else if (toMatch) {
        currentRename.to = toMatch[1].trim();
        
        if (currentRename.from && currentRename.to) {
          renames.push({
            from: currentRename.from,
            to: currentRename.to,
          });
          currentRename = {};
        }
      }
    }
    
    return renames;
  }

  private parseSectionsFromContent(content: string): Section[] {
    const normalizedContent = ChangeParser.normalizeContent(content);
    const lines = normalizedContent.split('\n');
    const sections: Section[] = [];
    const stack: Section[] = [];
    
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      const headerMatch = line.match(/^(#{1,6})\s+(.+)$/);
      
      if (headerMatch) {
        const level = headerMatch[1].length;
        const title = headerMatch[2].trim();
        const contentLines = this.getContentUntilNextHeaderFromLines(lines, i + 1, level);
        
        const section = {
          level,
          title,
          content: contentLines.join('\n').trim(),
          children: [],
        };

        while (stack.length > 0 && stack[stack.length - 1].level >= level) {
          stack.pop();
        }

        if (stack.length === 0) {
          sections.push(section);
        } else {
          stack[stack.length - 1].children.push(section);
        }
        
        stack.push(section);
      }
    }
    
    return sections;
  }

  private getContentUntilNextHeaderFromLines(lines: string[], startLine: number, currentLevel: number): string[] {
    const contentLines: string[] = [];
    
    for (let i = startLine; i < lines.length; i++) {
      const line = lines[i];
      const headerMatch = line.match(/^(#{1,6})\s+/);
      
      if (headerMatch && headerMatch[1].length <= currentLevel) {
        break;
      }
      
      contentLines.push(line);
    }
    
    return contentLines;
  }
}


================================================
FILE: src/core/parsers/markdown-parser.ts
================================================
import { Spec, Change, Requirement, Scenario, Delta, DeltaOperation } from '../schemas/index.js';

export interface Section {
  level: number;
  title: string;
  content: string;
  children: Section[];
}

export class MarkdownParser {
  private lines: string[];
  private currentLine: number;

  constructor(content: string) {
    const normalized = MarkdownParser.normalizeContent(content);
    this.lines = normalized.split('\n');
    this.currentLine = 0;
  }

  protected static normalizeContent(content: string): string {
    return content.replace(/\r\n?/g, '\n');
  }

  parseSpec(name: string): Spec {
    const sections = this.parseSections();
    const purpose = this.findSection(sections, 'Purpose')?.content || '';
    
    const requirementsSection = this.findSection(sections, 'Requirements');
    
    if (!purpose) {
      throw new Error('Spec must have a Purpose section');
    }
    
    if (!requirementsSection) {
      throw new Error('Spec must have a Requirements section');
    }

    const requirements = this.parseRequirements(requirementsSection);

    return {
      name,
      overview: purpose.trim(),
      requirements,
      metadata: {
        version: '1.0.0',
        format: 'openspec',
      },
    };
  }

  parseChange(name: string): Change {
    const sections = this.parseSections();
    const why = this.findSection(sections, 'Why')?.content || '';
    const whatChanges = this.findSection(sections, 'What Changes')?.content || '';
    
    if (!why) {
      throw new Error('Change must have a Why section');
    }
    
    if (!whatChanges) {
      throw new Error('Change must have a What Changes section');
    }

    const deltas = this.parseDeltas(whatChanges);

    return {
      name,
      why: why.trim(),
      whatChanges: whatChanges.trim(),
      deltas,
      metadata: {
        version: '1.0.0',
        format: 'openspec-change',
      },
    };
  }

  protected parseSections(): Section[] {
    const sections: Section[] = [];
    const stack: Section[] = [];
    
    for (let i = 0; i < this.lines.length; i++) {
      const line = this.lines[i];
      const headerMatch = line.match(/^(#{1,6})\s+(.+)$/);
      
      if (headerMatch) {
        const level = headerMatch[1].length;
        const title = headerMatch[2].trim();
        const content = this.getContentUntilNextHeader(i + 1, level);
        
        const section: Section = {
          level,
          title,
          content,
          children: [],
        };

        while (stack.length > 0 && stack[stack.length - 1].level >= level) {
          stack.pop();
        }

        if (stack.length === 0) {
          sections.push(section);
        } else {
          stack[stack.length - 1].children.push(section);
        }
        
        stack.push(section);
      }
    }
    
    return sections;
  }

  protected getContentUntilNextHeader(startLine: number, currentLevel: number): string {
    const contentLines: string[] = [];
    
    for (let i = startLine; i < this.lines.length; i++) {
      const line = this.lines[i];
      const headerMatch = line.match(/^(#{1,6})\s+/);
      
      if (headerMatch && headerMatch[1].length <= currentLevel) {
        break;
      }
      
      contentLines.push(line);
    }
    
    return contentLines.join('\n').trim();
  }

  protected findSection(sections: Section[], title: string): Section | undefined {
    for (const section of sections) {
      if (section.title.toLowerCase() === title.toLowerCase()) {
        return section;
      }
      const child = this.findSection(section.children, title);
      if (child) {
        return child;
      }
    }
    return undefined;
  }

  protected parseRequirements(section: Section): Requirement[] {
    const requirements: Requirement[] = [];
    
    for (const child of section.children) {
      // Extract requirement text from first non-empty content line, fall back to heading
      let text = child.title;
      
      // Get content before any child sections (scenarios)
      if (child.content.trim()) {
        // Split content into lines and find content before any child headers
        const lines = child.content.split('\n');
        const contentBeforeChildren: string[] = [];
        
        for (const line of lines) {
          // Stop at child headers (scenarios start with ####)
          if (line.trim().startsWith('#')) {
            break;
          }
          contentBeforeChildren.push(line);
        }
        
        // Find first non-empty line
        const directContent = contentBeforeChildren.join('\n').trim();
        if (directContent) {
          const firstLine = directContent.split('\n').find(l => l.trim());
          if (firstLine) {
            text = firstLine.trim();
          }
        }
      }
      
      const scenarios = this.parseScenarios(child);
      
      requirements.push({
        text,
        scenarios,
      });
    }
    
    return requirements;
  }

  protected parseScenarios(requirementSection: Section): Scenario[] {
    const scenarios: Scenario[] = [];
    
    for (const scenarioSection of requirementSection.children) {
      // Store the raw text content of the scenario section
      if (scenarioSection.content.trim()) {
        scenarios.push({
          rawText: scenarioSection.content
        });
      }
    }
    
    return scenarios;
  }


  protected parseDeltas(content: string): Delta[] {
    const deltas: Delta[] = [];
    const lines = content.split('\n');
    
    for (const line of lines) {
      // Match both formats: **spec:** and **spec**:
      const deltaMatch = line.match(/^\s*-\s*\*\*([^*:]+)(?::\*\*|\*\*:)\s*(.+)$/);
      if (deltaMatch) {
        const specName = deltaMatch[1].trim();
        const description = deltaMatch[2].trim();
        
        let operation: DeltaOperation = 'MODIFIED';
        const lowerDesc = description.toLowerCase();
        
        // Use word boundaries to avoid false matches (e.g., "address" matching "add")
        // Check RENAMED first since it's more specific than patterns containing "new"
        if (/\brename(s|d|ing)?\b/.test(lowerDesc) || /\brenamed\s+(to|from)\b/.test(lowerDesc)) {
          operation = 'RENAMED';
        } else if (/\badd(s|ed|ing)?\b/.test(lowerDesc) || /\bcreate(s|d|ing)?\b/.test(lowerDesc) || /\bnew\b/.test(lowerDesc)) {
          operation = 'ADDED';
        } else if (/\bremove(s|d|ing)?\b/.test(lowerDesc) || /\bdelete(s|d|ing)?\b/.test(lowerDesc)) {
          operation = 'REMOVED';
        }
        
        deltas.push({
          spec: specName,
          operation,
          description,
        });
      }
    }
    
    return deltas;
  }
}


================================================
FILE: src/core/parsers/requirement-blocks.ts
================================================
export interface RequirementBlock {
  headerLine: string; // e.g., '### Requirement: Something'
  name: string; // e.g., 'Something'
  raw: string; // full block including headerLine and following content
}

export interface RequirementsSectionParts {
  before: string;
  headerLine: string; // the '## Requirements' line
  preamble: string; // content between headerLine and first requirement block
  bodyBlocks: RequirementBlock[]; // parsed requirement blocks in order
  after: string;
}

export function normalizeRequirementName(name: string): string {
  return name.trim();
}

const REQUIREMENT_HEADER_REGEX = /^###\s*Requirement:\s*(.+)\s*$/;

/**
 * Extracts the Requirements section from a spec file and parses requirement blocks.
 */
export function extractRequirementsSection(content: string): RequirementsSectionParts {
  const normalized = normalizeLineEndings(content);
  const lines = normalized.split('\n');
  const reqHeaderIndex = lines.findIndex(l => /^##\s+Requirements\s*$/i.test(l));

  if (reqHeaderIndex === -1) {
    // No requirements section; create an empty one at the end
    const before = content.trimEnd();
    const headerLine = '## Requirements';
    return {
      before: before ? before + '\n\n' : '',
      headerLine,
      preamble: '',
      bodyBlocks: [],
      after: '\n',
    };
  }

  // Find end of this section: next line that starts with '## ' at same or higher level
  let endIndex = lines.length;
  for (let i = reqHeaderIndex + 1; i < lines.length; i++) {
    if (/^##\s+/.test(lines[i])) {
      endIndex = i;
      break;
    }
  }

  const before = lines.slice(0, reqHeaderIndex).join('\n');
  const headerLine = lines[reqHeaderIndex];
  const sectionBodyLines = lines.slice(reqHeaderIndex + 1, endIndex);

  // Parse requirement blocks within section body
  const blocks: RequirementBlock[] = [];
  let cursor = 0;
  let preambleLines: string[] = [];

  // Collect preamble lines until first requirement header
  while (cursor < sectionBodyLines.length && !/^###\s+Requirement:/.test(sectionBodyLines[cursor])) {
    preambleLines.push(sectionBodyLines[cursor]);
    cursor++;
  }

  while (cursor < sectionBodyLines.length) {
    const headerStart = cursor;
    const headerLineCandidate = sectionBodyLines[cursor];
    const headerMatch = headerLineCandidate.match(REQUIREMENT_HEADER_REGEX);
    if (!headerMatch) {
      // Not a requirement header; skip line defensively
      cursor++;
      continue;
    }
    const name = normalizeRequirementName(headerMatch[1]);
    cursor++;
    // Gather lines until next requirement header or end of section
    const bodyLines: string[] = [headerLineCandidate];
    while (cursor < sectionBodyLines.length && !/^###\s+Requirement:/.test(sectionBodyLines[cursor]) && !/^##\s+/.test(sectionBodyLines[cursor])) {
      bodyLines.push(sectionBodyLines[cursor]);
      cursor++;
    }
    const raw = bodyLines.join('\n').trimEnd();
    blocks.push({ headerLine: headerLineCandidate, name, raw });
  }

  const after = lines.slice(endIndex).join('\n');
  const preamble = preambleLines.join('\n').trimEnd();

  return {
    before: before.trimEnd() ? before + '\n' : before,
    headerLine,
    preamble,
    bodyBlocks: blocks,
    after: after.startsWith('\n') ? after : '\n' + after,
  };
}

export interface DeltaPlan {
  added: RequirementBlock[];
  modified: RequirementBlock[];
  removed: string[]; // requirement names
  renamed: Array<{ from: string; to: string }>;
  sectionPresence: {
    added: boolean;
    modified: boolean;
    removed: boolean;
    renamed: boolean;
  };
}

function normalizeLineEndings(content: string): string {
  return content.replace(/\r\n?/g, '\n');
}

/**
 * Parse a delta-formatted spec change file content into a DeltaPlan with raw blocks.
 */
export function parseDeltaSpec(content: string): DeltaPlan {
  const normalized = normalizeLineEndings(content);
  const sections = splitTopLevelSections(normalized);
  const addedLookup = getSectionCaseInsensitive(sections, 'ADDED Requirements');
  const modifiedLookup = getSectionCaseInsensitive(sections, 'MODIFIED Requirements');
  const removedLookup = getSectionCaseInsensitive(sections, 'REMOVED Requirements');
  const renamedLookup = getSectionCaseInsensitive(sections, 'RENAMED Requirements');
  const added = parseRequirementBlocksFromSection(addedLookup.body);
  const modified = parseRequirementBlocksFromSection(modifiedLookup.body);
  const removedNames = parseRemovedNames(removedLookup.body);
  const renamedPairs = parseRenamedPairs(renamedLookup.body);
  return {
    added,
    modified,
    removed: removedNames,
    renamed: renamedPairs,
    sectionPresence: {
      added: addedLookup.found,
      modified: modifiedLookup.found,
      removed: removedLookup.found,
      renamed: renamedLookup.found,
    },
  };
}

function splitTopLevelSections(content: string): Record<string, string> {
  const lines = content.split('\n');
  const result: Record<string, string> = {};
  const indices: Array<{ title: string; index: number; level: number }> = [];
  for (let i = 0; i < lines.length; i++) {
    const m = lines[i].match(/^(##)\s+(.+)$/);
    if (m) {
      const level = m[1].length; // only care for '##'
      indices.push({ title: m[2].trim(), index: i, level });
    }
  }
  for (let i = 0; i < indices.length; i++) {
    const current = indices[i];
    const next = indices[i + 1];
    const body = lines.slice(current.index + 1, next ? next.index : lines.length).join('\n');
    result[current.title] = body;
  }
  return result;
}

function getSectionCaseInsensitive(sections: Record<string, string>, desired: string): { body: string; found: boolean } {
  const target = desired.toLowerCase();
  for (const [title, body] of Object.entries(sections)) {
    if (title.toLowerCase() === target) return { body, found: true };
  }
  return { body: '', found: false };
}

function parseRequirementBlocksFromSection(sectionBody: string): RequirementBlock[] {
  if (!sectionBody) return [];
  const lines = normalizeLineEndings(sectionBody).split('\n');
  const blocks: RequirementBlock[] = [];
  let i = 0;
  while (i < lines.length) {
    // Seek next requirement header
    while (i < lines.length && !/^###\s+Requirement:/.test(lines[i])) i++;
    if (i >= lines.length) break;
    const headerLine = lines[i];
    const m = headerLine.match(REQUIREMENT_HEADER_REGEX);
    if (!m) { i++; continue; }
    const name = normalizeRequirementName(m[1]);
    const buf: string[] = [headerLine];
    i++;
    while (i < lines.length && !/^###\s+Requirement:/.test(lines[i]) && !/^##\s+/.test(lines[i])) {
      buf.push(lines[i]);
      i++;
    }
    blocks.push({ headerLine, name, raw: buf.join('\n').trimEnd() });
  }
  return blocks;
}

function parseRemovedNames(sectionBody: string): string[] {
  if (!sectionBody) return [];
  const names: string[] = [];
  const lines = normalizeLineEndings(sectionBody).split('\n');
  for (const line of lines) {
    const m = line.match(REQUIREMENT_HEADER_REGEX);
    if (m) {
      names.push(normalizeRequirementName(m[1]));
      continue;
    }
    // Also support bullet list of headers
    const bullet = line.match(/^\s*-\s*`?###\s*Requirement:\s*(.+?)`?\s*$/);
    if (bullet) {
      names.push(normalizeRequirementName(bullet[1]));
    }
  }
  return names;
}

function parseRenamedPairs(sectionBody: string): Array<{ from: string; to: string }> {
  if (!sectionBody) return [];
  const pairs: Array<{ from: string; to: string }> = [];
  const lines = normalizeLineEndings(sectionBody).split('\n');
  let current: { from?: string; to?: string } = {};
  for (const line of lines) {
    const fromMatch = line.match(/^\s*-?\s*FROM:\s*`?###\s*Requirement:\s*(.+?)`?\s*$/);
    const toMatch = line.match(/^\s*-?\s*TO:\s*`?###\s*Requirement:\s*(.+?)`?\s*$/);
    if (fromMatch) {
      current.from = normalizeRequirementName(fromMatch[1]);
    } else if (toMatch) {
      current.to = normalizeRequirementName(toMatch[1]);
      if (current.from && current.to) {
        pairs.push({ from: current.from, to: current.to });
        current = {};
      }
    }
  }
  return pairs;
}



================================================
FILE: src/core/schemas/base.schema.ts
================================================
import { z } from 'zod';
import { VALIDATION_MESSAGES } from '../validation/constants.js';

export const ScenarioSchema = z.object({
  rawText: z.string().min(1, VALIDATION_MESSAGES.SCENARIO_EMPTY),
});

export const RequirementSchema = z.object({
  text: z.string()
    .min(1, VALIDATION_MESSAGES.REQUIREMENT_EMPTY)
    .refine(
      (text) => text.includes('SHALL') || text.includes('MUST'),
      VALIDATION_MESSAGES.REQUIREMENT_NO_SHALL
    ),
  scenarios: z.array(ScenarioSchema)
    .min(1, VALIDATION_MESSAGES.REQUIREMENT_NO_SCENARIOS),
});

export type Scenario = z.infer<typeof ScenarioSchema>;
export type Requirement = z.infer<typeof RequirementSchema>;


================================================
FILE: src/core/schemas/change.schema.ts
================================================
import { z } from 'zod';
import { RequirementSchema } from './base.schema.js';
import { 
  MIN_WHY_SECTION_LENGTH,
  MAX_WHY_SECTION_LENGTH,
  MAX_DELTAS_PER_CHANGE,
  VALIDATION_MESSAGES 
} from '../validation/constants.js';

export const DeltaOperationType = z.enum(['ADDED', 'MODIFIED', 'REMOVED', 'RENAMED']);

export const DeltaSchema = z.object({
  spec: z.string().min(1, VALIDATION_MESSAGES.DELTA_SPEC_EMPTY),
  operation: DeltaOperationType,
  description: z.string().min(1, VALIDATION_MESSAGES.DELTA_DESCRIPTION_EMPTY),
  requirement: RequirementSchema.optional(),
  requirements: z.array(RequirementSchema).optional(),
  rename: z.object({
    from: z.string(),
    to: z.string(),
  }).optional(),
});

export const ChangeSchema = z.object({
  name: z.string().min(1, VALIDATION_MESSAGES.CHANGE_NAME_EMPTY),
  why: z.string()
    .min(MIN_WHY_SECTION_LENGTH, VALIDATION_MESSAGES.CHANGE_WHY_TOO_SHORT)
    .max(MAX_WHY_SECTION_LENGTH, VALIDATION_MESSAGES.CHANGE_WHY_TOO_LONG),
  whatChanges: z.string().min(1, VALIDATION_MESSAGES.CHANGE_WHAT_EMPTY),
  deltas: z.array(DeltaSchema)
    .min(1, VALIDATION_MESSAGES.CHANGE_NO_DELTAS)
    .max(MAX_DELTAS_PER_CHANGE, VALIDATION_MESSAGES.CHANGE_TOO_MANY_DELTAS),
  metadata: z.object({
    version: z.string().default('1.0.0'),
    format: z.literal('openspec-change'),
    sourcePath: z.string().optional(),
  }).optional(),
});

export type DeltaOperation = z.infer<typeof DeltaOperationType>;
export type Delta = z.infer<typeof DeltaSchema>;
export type Change = z.infer<typeof ChangeSchema>;


================================================
FILE: src/core/schemas/index.ts
================================================
export {
  ScenarioSchema,
  RequirementSchema,
  type Scenario,
  type Requirement,
} from './base.schema.js';

export {
  SpecSchema,
  type Spec,
} from './spec.schema.js';

export {
  DeltaOperationType,
  DeltaSchema,
  ChangeSchema,
  type DeltaOperation,
  type Delta,
  type Change,
} from './change.schema.js';


================================================
FILE: src/core/schemas/spec.schema.ts
================================================
import { z } from 'zod';
import { RequirementSchema } from './base.schema.js';
import { VALIDATION_MESSAGES } from '../validation/constants.js';

export const SpecSchema = z.object({
  name: z.string().min(1, VALIDATION_MESSAGES.SPEC_NAME_EMPTY),
  overview: z.string().min(1, VALIDATION_MESSAGES.SPEC_PURPOSE_EMPTY),
  requirements: z.array(RequirementSchema)
    .min(1, VALIDATION_MESSAGES.SPEC_NO_REQUIREMENTS),
  metadata: z.object({
    version: z.string().default('1.0.0'),
    format: z.literal('openspec'),
    sourcePath: z.string().optional(),
  }).optional(),
});

export type Spec = z.infer<typeof SpecSchema>;


================================================
FILE: src/core/styles/palette.ts
================================================
import chalk from 'chalk';

export const PALETTE = {
  white: chalk.hex('#f4f4f4'),
  lightGray: chalk.hex('#c8c8c8'),
  midGray: chalk.hex('#8a8a8a'),
  darkGray: chalk.hex('#4a4a4a')
};



================================================
FILE: src/core/templates/agents-root-stub.ts
================================================
export const agentsRootStubTemplate = `# OpenSpec Instructions

These instructions are for AI assistants working in this project.

Always open \`@/openspec/AGENTS.md\` when the request:
- Mentions planning or proposals (words like proposal, spec, change, plan)
- Introduces new capabilities, breaking changes, architecture shifts, or big performance/security work
- Sounds ambiguous and you need the authoritative spec before coding

Use \`@/openspec/AGENTS.md\` to learn:
- How to create and apply change proposals
- Spec format and conventions
- Project structure and guidelines

Keep this managed block so 'openspec update' can refresh the instructions.
`;



================================================
FILE: src/core/templates/agents-template.ts
================================================
export const agentsTemplate = `# OpenSpec Instructions

Instructions for AI coding assistants using OpenSpec for spec-driven development.

## TL;DR Quick Checklist

- Search existing work: \`openspec spec list --long\`, \`openspec list\` (use \`rg\` only for full-text search)
- Decide scope: new capability vs modify existing capability
- Pick a unique \`change-id\`: kebab-case, verb-led (\`add-\`, \`update-\`, \`remove-\`, \`refactor-\`)
- Scaffold: \`proposal.md\`, \`tasks.md\`, \`design.md\` (only if needed), and delta specs per affected capability
- Write deltas: use \`## ADDED|MODIFIED|REMOVED|RENAMED Requirements\`; include at least one \`#### Scenario:\` per requirement
- Validate: \`openspec validate [change-id] --strict --no-interactive\` and fix issues
- Request approval: Do not start implementation until proposal is approved

## Three-Stage Workflow

### Stage 1: Creating Changes
Create proposal when you need to:
- Add features or functionality
- Make breaking changes (API, schema)
- Change architecture or patterns  
- Optimize performance (changes behavior)
- Update security patterns

Triggers (examples):
- "Help me create a change proposal"
- "Help me plan a change"
- "Help me create a proposal"
- "I want to create a spec proposal"
- "I want to create a spec"

Loose matching guidance:
- Contains one of: \`proposal\`, \`change\`, \`spec\`
- With one of: \`create\`, \`plan\`, \`make\`, \`start\`, \`help\`

Skip proposal for:
- Bug fixes (restore intended behavior)
- Typos, formatting, comments
- Dependency updates (non-breaking)
- Configuration changes
- Tests for existing behavior

**Workflow**
1. Review \`openspec/project.md\`, \`openspec list\`, and \`openspec list --specs\` to understand current context.
2. Choose a unique verb-led \`change-id\` and scaffold \`proposal.md\`, \`tasks.md\`, optional \`design.md\`, and spec deltas under \`openspec/changes/<id>/\`.
3. Draft spec deltas using \`## ADDED|MODIFIED|REMOVED Requirements\` with at least one \`#### Scenario:\` per requirement.
4. Run \`openspec validate <id> --strict --no-interactive\` and resolve any issues before sharing the proposal.

### Stage 2: Implementing Changes
Track these steps as TODOs and complete them one by one.
1. **Read proposal.md** - Understand what's being built
2. **Read design.md** (if exists) - Review technical decisions
3. **Read tasks.md** - Get implementation checklist
4. **Implement tasks sequentially** - Complete in order
5. **Confirm completion** - Ensure every item in \`tasks.md\` is finished before updating statuses
6. **Update checklist** - After all work is done, set every task to \`- [x]\` so the list reflects reality
7. **Approval gate** - Do not start implementation until the proposal is reviewed and approved

### Stage 3: Archiving Changes
After deployment, create separate PR to:
- Move \`changes/[name]/\` â†’ \`changes/archive/YYYY-MM-DD-[name]/\`
- Update \`specs/\` if capabilities changed
- Use \`openspec archive <change-id> --skip-specs --yes\` for tooling-only changes (always pass the change ID explicitly)
- Run \`openspec validate --strict --no-interactive\` to confirm the archived change passes checks

## Before Any Task

**Context Checklist:**
- [ ] Read relevant specs in \`specs/[capability]/spec.md\`
- [ ] Check pending changes in \`changes/\` for conflicts
- [ ] Read \`openspec/project.md\` for conventions
- [ ] Run \`openspec list\` to see active changes
- [ ] Run \`openspec list --specs\` to see existing capabilities

**Before Creating Specs:**
- Always check if capability already exists
- Prefer modifying existing specs over creating duplicates
- Use \`openspec show [spec]\` to review current state
- If request is ambiguous, ask 1â€“2 clarifying questions before scaffolding

### Search Guidance
- Enumerate specs: \`openspec spec list --long\` (or \`--json\` for scripts)
- Enumerate changes: \`openspec list\` (or \`openspec change list --json\` - deprecated but available)
- Show details:
  - Spec: \`openspec show <spec-id> --type spec\` (use \`--json\` for filters)
  - Change: \`openspec show <change-id> --json --deltas-only\`
- Full-text search (use ripgrep): \`rg -n "Requirement:|Scenario:" openspec/specs\`

## Quick Start

### CLI Commands

\`\`\`bash
# Essential commands
openspec list                  # List active changes
openspec list --specs          # List specifications
openspec show [item]           # Display change or spec
openspec validate [item]       # Validate changes or specs
openspec archive <change-id> [--yes|-y]   # Archive after deployment (add --yes for non-interactive runs)

# Project management
openspec init [path]           # Initialize OpenSpec
openspec update [path]         # Update instruction files

# Interactive mode
openspec show                  # Prompts for selection
openspec validate              # Bulk validation mode

# Debugging
openspec show [change] --json --deltas-only
openspec validate [change] --strict --no-interactive
\`\`\`

### Command Flags

- \`--json\` - Machine-readable output
- \`--type change|spec\` - Disambiguate items
- \`--strict\` - Comprehensive validation
- \`--no-interactive\` - Disable prompts
- \`--skip-specs\` - Archive without spec updates
- \`--yes\`/\`-y\` - Skip confirmation prompts (non-interactive archive)

## Directory Structure

\`\`\`
openspec/
â”œâ”€â”€ project.md              # Project conventions
â”œâ”€â”€ specs/                  # Current truth - what IS built
â”‚   â””â”€â”€ [capability]/       # Single focused capability
â”‚       â”œâ”€â”€ spec.md         # Requirements and scenarios
â”‚       â””â”€â”€ design.md       # Technical patterns
â”œâ”€â”€ changes/                # Proposals - what SHOULD change
â”‚   â”œâ”€â”€ [change-name]/
â”‚   â”‚   â”œâ”€â”€ proposal.md     # Why, what, impact
â”‚   â”‚   â”œâ”€â”€ tasks.md        # Implementation checklist
â”‚   â”‚   â”œâ”€â”€ design.md       # Technical decisions (optional; see criteria)
â”‚   â”‚   â””â”€â”€ specs/          # Delta changes
â”‚   â”‚       â””â”€â”€ [capability]/
â”‚   â”‚           â””â”€â”€ spec.md # ADDED/MODIFIED/REMOVED
â”‚   â””â”€â”€ archive/            # Completed changes
\`\`\`

## Creating Change Proposals

### Decision Tree

\`\`\`
New request?
â”œâ”€ Bug fix restoring spec behavior? â†’ Fix directly
â”œâ”€ Typo/format/comment? â†’ Fix directly  
â”œâ”€ New feature/capability? â†’ Create proposal
â”œâ”€ Breaking change? â†’ Create proposal
â”œâ”€ Architecture change? â†’ Create proposal
â””â”€ Unclear? â†’ Create proposal (safer)
\`\`\`

### Proposal Structure

1. **Create directory:** \`changes/[change-id]/\` (kebab-case, verb-led, unique)

2. **Write proposal.md:**
\`\`\`markdown
# Change: [Brief description of change]

## Why
[1-2 sentences on problem/opportunity]

## What Changes
- [Bullet list of changes]
- [Mark breaking changes with **BREAKING**]

## Impact
- Affected specs: [list capabilities]
- Affected code: [key files/systems]
\`\`\`

3. **Create spec deltas:** \`specs/[capability]/spec.md\`
\`\`\`markdown
## ADDED Requirements
### Requirement: New Feature
The system SHALL provide...

#### Scenario: Success case
- **WHEN** user performs action
- **THEN** expected result

## MODIFIED Requirements
### Requirement: Existing Feature
[Complete modified requirement]

## REMOVED Requirements
### Requirement: Old Feature
**Reason**: [Why removing]
**Migration**: [How to handle]
\`\`\`
If multiple capabilities are affected, create multiple delta files under \`changes/[change-id]/specs/<capability>/spec.md\`â€”one per capability.

4. **Create tasks.md:**
\`\`\`markdown
## 1. Implementation
- [ ] 1.1 Create database schema
- [ ] 1.2 Implement API endpoint
- [ ] 1.3 Add frontend component
- [ ] 1.4 Write tests
\`\`\`

5. **Create design.md when needed:**
Create \`design.md\` if any of the following apply; otherwise omit it:
- Cross-cutting change (multiple services/modules) or a new architectural pattern
- New external dependency or significant data model changes
- Security, performance, or migration complexity
- Ambiguity that benefits from technical decisions before coding

Minimal \`design.md\` skeleton:
\`\`\`markdown
## Context
[Background, constraints, stakeholders]

## Goals / Non-Goals
- Goals: [...]
- Non-Goals: [...]

## Decisions
- Decision: [What and why]
- Alternatives considered: [Options + rationale]

## Risks / Trade-offs
- [Risk] â†’ Mitigation

## Migration Plan
[Steps, rollback]

## Open Questions
- [...]
\`\`\`

## Spec File Format

### Critical: Scenario Formatting

**CORRECT** (use #### headers):
\`\`\`markdown
#### Scenario: User login success
- **WHEN** valid credentials provided
- **THEN** return JWT token
\`\`\`

**WRONG** (don't use bullets or bold):
\`\`\`markdown
- **Scenario: User login**  âŒ
**Scenario**: User login     âŒ
### Scenario: User login      âŒ
\`\`\`

Every requirement MUST have at least one scenario.

### Requirement Wording
- Use SHALL/MUST for normative requirements (avoid should/may unless intentionally non-normative)

### Delta Operations

- \`## ADDED Requirements\` - New capabilities
- \`## MODIFIED Requirements\` - Changed behavior
- \`## REMOVED Requirements\` - Deprecated features
- \`## RENAMED Requirements\` - Name changes

Headers matched with \`trim(header)\` - whitespace ignored.

#### When to use ADDED vs MODIFIED
- ADDED: Introduces a new capability or sub-capability that can stand alone as a requirement. Prefer ADDED when the change is orthogonal (e.g., adding "Slash Command Configuration") rather than altering the semantics of an existing requirement.
- MODIFIED: Changes the behavior, scope, or acceptance criteria of an existing requirement. Always paste the full, updated requirement content (header + all scenarios). The archiver will replace the entire requirement with what you provide here; partial deltas will drop previous details.
- RENAMED: Use when only the name changes. If you also change behavior, use RENAMED (name) plus MODIFIED (content) referencing the new name.

Common pitfall: Using MODIFIED to add a new concern without including the previous text. This causes loss of detail at archive time. If you arenâ€™t explicitly changing the existing requirement, add a new requirement under ADDED instead.

Authoring a MODIFIED requirement correctly:
1) Locate the existing requirement in \`openspec/specs/<capability>/spec.md\`.
2) Copy the entire requirement block (from \`### Requirement: ...\` through its scenarios).
3) Paste it under \`## MODIFIED Requirements\` and edit to reflect the new behavior.
4) Ensure the header text matches exactly (whitespace-insensitive) and keep at least one \`#### Scenario:\`.

Example for RENAMED:
\`\`\`markdown
## RENAMED Requirements
- FROM: \`### Requirement: Login\`
- TO: \`### Requirement: User Authentication\`
\`\`\`

## Troubleshooting

### Common Errors

**"Change must have at least one delta"**
- Check \`changes/[name]/specs/\` exists with .md files
- Verify files have operation prefixes (## ADDED Requirements)

**"Requirement must have at least one scenario"**
- Check scenarios use \`#### Scenario:\` format (4 hashtags)
- Don't use bullet points or bold for scenario headers

**Silent scenario parsing failures**
- Exact format required: \`#### Scenario: Name\`
- Debug with: \`openspec show [change] --json --deltas-only\`

### Validation Tips

\`\`\`bash
# Always use strict mode for comprehensive checks
openspec validate [change] --strict --no-interactive

# Debug delta parsing
openspec show [change] --json | jq '.deltas'

# Check specific requirement
openspec show [spec] --json -r 1
\`\`\`

## Happy Path Script

\`\`\`bash
# 1) Explore current state
openspec spec list --long
openspec list
# Optional full-text search:
# rg -n "Requirement:|Scenario:" openspec/specs
# rg -n "^#|Requirement:" openspec/changes

# 2) Choose change id and scaffold
CHANGE=add-two-factor-auth
mkdir -p openspec/changes/$CHANGE/{specs/auth}
printf "## Why\\n...\\n\\n## What Changes\\n- ...\\n\\n## Impact\\n- ...\\n" > openspec/changes/$CHANGE/proposal.md
printf "## 1. Implementation\\n- [ ] 1.1 ...\\n" > openspec/changes/$CHANGE/tasks.md

# 3) Add deltas (example)
cat > openspec/changes/$CHANGE/specs/auth/spec.md << 'EOF'
## ADDED Requirements
### Requirement: Two-Factor Authentication
Users MUST provide a second factor during login.

#### Scenario: OTP required
- **WHEN** valid credentials are provided
- **THEN** an OTP challenge is required
EOF

# 4) Validate
openspec validate $CHANGE --strict --no-interactive
\`\`\`

## Multi-Capability Example

\`\`\`
openspec/changes/add-2fa-notify/
â”œâ”€â”€ proposal.md
â”œâ”€â”€ tasks.md
â””â”€â”€ specs/
    â”œâ”€â”€ auth/
    â”‚   â””â”€â”€ spec.md   # ADDED: Two-Factor Authentication
    â””â”€â”€ notifications/
        â””â”€â”€ spec.md   # ADDED: OTP email notification
\`\`\`

auth/spec.md
\`\`\`markdown
## ADDED Requirements
### Requirement: Two-Factor Authentication
...
\`\`\`

notifications/spec.md
\`\`\`markdown
## ADDED Requirements
### Requirement: OTP Email Notification
...
\`\`\`

## Best Practices

### Simplicity First
- Default to <100 lines of new code
- Single-file implementations until proven insufficient
- Avoid frameworks without clear justification
- Choose boring, proven patterns

### Complexity Triggers
Only add complexity with:
- Performance data showing current solution too slow
- Concrete scale requirements (>1000 users, >100MB data)
- Multiple proven use cases requiring abstraction

### Clear References
- Use \`file.ts:42\` format for code locations
- Reference specs as \`specs/auth/spec.md\`
- Link related changes and PRs

### Capability Naming
- Use verb-noun: \`user-auth\`, \`payment-capture\`
- Single purpose per capability
- 10-minute understandability rule
- Split if description needs "AND"

### Change ID Naming
- Use kebab-case, short and descriptive: \`add-two-factor-auth\`
- Prefer verb-led prefixes: \`add-\`, \`update-\`, \`remove-\`, \`refactor-\`
- Ensure uniqueness; if taken, append \`-2\`, \`-3\`, etc.

## Tool Selection Guide

| Task | Tool | Why |
|------|------|-----|
| Find files by pattern | Glob | Fast pattern matching |
| Search code content | Grep | Optimized regex search |
| Read specific files | Read | Direct file access |
| Explore unknown scope | Task | Multi-step investigation |

## Error Recovery

### Change Conflicts
1. Run \`openspec list\` to see active changes
2. Check for overlapping specs
3. Coordinate with change owners
4. Consider combining proposals

### Validation Failures
1. Run with \`--strict\` flag
2. Check JSON output for details
3. Verify spec file format
4. Ensure scenarios properly formatted

### Missing Context
1. Read project.md first
2. Check related specs
3. Review recent archives
4. Ask for clarification

## Quick Reference

### Stage Indicators
- \`changes/\` - Proposed, not yet built
- \`specs/\` - Built and deployed
- \`archive/\` - Completed changes

### File Purposes
- \`proposal.md\` - Why and what
- \`tasks.md\` - Implementation steps
- \`design.md\` - Technical decisions
- \`spec.md\` - Requirements and behavior

### CLI Essentials
\`\`\`bash
openspec list              # What's in progress?
openspec show [item]       # View details
openspec validate --strict --no-interactive  # Is it correct?
openspec archive <change-id> [--yes|-y]  # Mark complete (add --yes for automation)
\`\`\`

Remember: Specs are truth. Changes are proposals. Keep them in sync.
`;



================================================
FILE: src/core/templates/claude-template.ts
================================================
export { agentsRootStubTemplate as claudeTemplate } from './agents-root-stub.js';



================================================
FILE: src/core/templates/cline-template.ts
================================================
export { agentsRootStubTemplate as clineTemplate } from './agents-root-stub.js';



================================================
FILE: src/core/templates/costrict-template.ts
================================================
export { agentsRootStubTemplate as costrictTemplate } from './agents-root-stub.js';



================================================
FILE: src/core/templates/index.ts
================================================
import { agentsTemplate } from './agents-template.js';
import { projectTemplate, ProjectContext } from './project-template.js';
import { claudeTemplate } from './claude-template.js';
import { clineTemplate } from './cline-template.js';
import { costrictTemplate } from './costrict-template.js';
import { agentsRootStubTemplate } from './agents-root-stub.js';
import { getSlashCommandBody, SlashCommandId } from './slash-command-templates.js';

export interface Template {
  path: string;
  content: string | ((context: ProjectContext) => string);
}

export class TemplateManager {
  static getTemplates(context: ProjectContext = {}): Template[] {
    return [
      {
        path: 'AGENTS.md',
        content: agentsTemplate
      },
      {
        path: 'project.md',
        content: projectTemplate(context)
      }
    ];
  }

  static getClaudeTemplate(): string {
    return claudeTemplate;
  }

  static getClineTemplate(): string {
    return clineTemplate;
  }

  static getCostrictTemplate(): string {
    return costrictTemplate;
  }

  static getAgentsStandardTemplate(): string {
    return agentsRootStubTemplate;
  }

  static getSlashCommandBody(id: SlashCommandId): string {
    return getSlashCommandBody(id);
  }
}

export { ProjectContext } from './project-template.js';
export type { SlashCommandId } from './slash-command-templates.js';



================================================
FILE: src/core/templates/project-template.ts
================================================
export interface ProjectContext {
  projectName?: string;
  description?: string;
  techStack?: string[];
  conventions?: string;
}

export const projectTemplate = (context: ProjectContext = {}) => `# ${context.projectName || 'Project'} Context

## Purpose
${context.description || '[Describe your project\'s purpose and goals]'}

## Tech Stack
${context.techStack?.length ? context.techStack.map(tech => `- ${tech}`).join('\n') : '- [List your primary technologies]\n- [e.g., TypeScript, React, Node.js]'}

## Project Conventions

### Code Style
[Describe your code style preferences, formatting rules, and naming conventions]

### Architecture Patterns
[Document your architectural decisions and patterns]

### Testing Strategy
[Explain your testing approach and requirements]

### Git Workflow
[Describe your branching strategy and commit conventions]

## Domain Context
[Add domain-specific knowledge that AI assistants need to understand]

## Important Constraints
[List any technical, business, or regulatory constraints]

## External Dependencies
[Document key external services, APIs, or systems]
`;


================================================
FILE: src/core/templates/slash-command-templates.ts
================================================
export type SlashCommandId = 'proposal' | 'apply' | 'archive';

const baseGuardrails = `**Guardrails**
- Favor straightforward, minimal implementations first and add complexity only when it is requested or clearly required.
- Keep changes tightly scoped to the requested outcome.
- Refer to \`openspec/AGENTS.md\` (located inside the \`openspec/\` directoryâ€”run \`ls openspec\` or \`openspec update\` if you don't see it) if you need additional OpenSpec conventions or clarifications.`;

const proposalGuardrails = `${baseGuardrails}\n- Identify any vague or ambiguous details and ask the necessary follow-up questions before editing files.
- Do not write any code during the proposal stage. Only create design documents (proposal.md, tasks.md, design.md, and spec deltas). Implementation happens in the apply stage after approval.`;

const proposalSteps = `**Steps**
1. Review \`openspec/project.md\`, run \`openspec list\` and \`openspec list --specs\`, and inspect related code or docs (e.g., via \`rg\`/\`ls\`) to ground the proposal in current behaviour; note any gaps that require clarification.
2. Choose a unique verb-led \`change-id\` and scaffold \`proposal.md\`, \`tasks.md\`, and \`design.md\` (when needed) under \`openspec/changes/<id>/\`.
3. Map the change into concrete capabilities or requirements, breaking multi-scope efforts into distinct spec deltas with clear relationships and sequencing.
4. Capture architectural reasoning in \`design.md\` when the solution spans multiple systems, introduces new patterns, or demands trade-off discussion before committing to specs.
5. Draft spec deltas in \`changes/<id>/specs/<capability>/spec.md\` (one folder per capability) using \`## ADDED|MODIFIED|REMOVED Requirements\` with at least one \`#### Scenario:\` per requirement and cross-reference related capabilities when relevant.
6. Draft \`tasks.md\` as an ordered list of small, verifiable work items that deliver user-visible progress, include validation (tests, tooling), and highlight dependencies or parallelizable work.
7. Validate with \`openspec validate <id> --strict --no-interactive\` and resolve every issue before sharing the proposal.`;


const proposalReferences = `**Reference**
- Use \`openspec show <id> --json --deltas-only\` or \`openspec show <spec> --type spec\` to inspect details when validation fails.
- Search existing requirements with \`rg -n "Requirement:|Scenario:" openspec/specs\` before writing new ones.
- Explore the codebase with \`rg <keyword>\`, \`ls\`, or direct file reads so proposals align with current implementation realities.`;

const applySteps = `**Steps**
Track these steps as TODOs and complete them one by one.
1. Read \`changes/<id>/proposal.md\`, \`design.md\` (if present), and \`tasks.md\` to confirm scope and acceptance criteria.
2. Work through tasks sequentially, keeping edits minimal and focused on the requested change.
3. Confirm completion before updating statusesâ€”make sure every item in \`tasks.md\` is finished.
4. Update the checklist after all work is done so each task is marked \`- [x]\` and reflects reality.
5. Reference \`openspec list\` or \`openspec show <item>\` when additional context is required.`;

const applyReferences = `**Reference**
- Use \`openspec show <id> --json --deltas-only\` if you need additional context from the proposal while implementing.`;

const archiveSteps = `**Steps**
1. Determine the change ID to archive:
   - If this prompt already includes a specific change ID (for example inside a \`<ChangeId>\` block populated by slash-command arguments), use that value after trimming whitespace.
   - If the conversation references a change loosely (for example by title or summary), run \`openspec list\` to surface likely IDs, share the relevant candidates, and confirm which one the user intends.
   - Otherwise, review the conversation, run \`openspec list\`, and ask the user which change to archive; wait for a confirmed change ID before proceeding.
   - If you still cannot identify a single change ID, stop and tell the user you cannot archive anything yet.
2. Validate the change ID by running \`openspec list\` (or \`openspec show <id>\`) and stop if the change is missing, already archived, or otherwise not ready to archive.
3. Run \`openspec archive <id> --yes\` so the CLI moves the change and applies spec updates without prompts (use \`--skip-specs\` only for tooling-only work).
4. Review the command output to confirm the target specs were updated and the change landed in \`changes/archive/\`.
5. Validate with \`openspec validate --strict --no-interactive\` and inspect with \`openspec show <id>\` if anything looks off.`;

const archiveReferences = `**Reference**
- Use \`openspec list\` to confirm change IDs before archiving.
- Inspect refreshed specs with \`openspec list --specs\` and address any validation issues before handing off.`;

export const slashCommandBodies: Record<SlashCommandId, string> = {
  proposal: [proposalGuardrails, proposalSteps, proposalReferences].join('\n\n'),
  apply: [baseGuardrails, applySteps, applyReferences].join('\n\n'),
  archive: [baseGuardrails, archiveSteps, archiveReferences].join('\n\n')
};

export function getSlashCommandBody(id: SlashCommandId): string {
  return slashCommandBodies[id];
}



================================================
FILE: src/core/validation/constants.ts
================================================
/**
 * Validation threshold constants
 */

// Minimum character lengths
export const MIN_WHY_SECTION_LENGTH = 50;
export const MIN_PURPOSE_LENGTH = 50;

// Maximum character/item limits
export const MAX_WHY_SECTION_LENGTH = 1000;
export const MAX_REQUIREMENT_TEXT_LENGTH = 500;
export const MAX_DELTAS_PER_CHANGE = 10;

// Validation messages
export const VALIDATION_MESSAGES = {
  // Required content
  SCENARIO_EMPTY: 'Scenario text cannot be empty',
  REQUIREMENT_EMPTY: 'Requirement text cannot be empty',
  REQUIREMENT_NO_SHALL: 'Requirement must contain SHALL or MUST keyword',
  REQUIREMENT_NO_SCENARIOS: 'Requirement must have at least one scenario',
  SPEC_NAME_EMPTY: 'Spec name cannot be empty',
  SPEC_PURPOSE_EMPTY: 'Purpose section cannot be empty',
  SPEC_NO_REQUIREMENTS: 'Spec must have at least one requirement',
  CHANGE_NAME_EMPTY: 'Change name cannot be empty',
  CHANGE_WHY_TOO_SHORT: `Why section must be at least ${MIN_WHY_SECTION_LENGTH} characters`,
  CHANGE_WHY_TOO_LONG: `Why section should not exceed ${MAX_WHY_SECTION_LENGTH} characters`,
  CHANGE_WHAT_EMPTY: 'What Changes section cannot be empty',
  CHANGE_NO_DELTAS: 'Change must have at least one delta',
  CHANGE_TOO_MANY_DELTAS: `Consider splitting changes with more than ${MAX_DELTAS_PER_CHANGE} deltas`,
  DELTA_SPEC_EMPTY: 'Spec name cannot be empty',
  DELTA_DESCRIPTION_EMPTY: 'Delta description cannot be empty',
  
  // Warnings
  PURPOSE_TOO_BRIEF: `Purpose section is too brief (less than ${MIN_PURPOSE_LENGTH} characters)`,
  REQUIREMENT_TOO_LONG: `Requirement text is very long (>${MAX_REQUIREMENT_TEXT_LENGTH} characters). Consider breaking it down.`,
  DELTA_DESCRIPTION_TOO_BRIEF: 'Delta description is too brief',
  DELTA_MISSING_REQUIREMENTS: 'Delta should include requirements',
  
  // Guidance snippets (appended to primary messages for remediation)
  GUIDE_NO_DELTAS:
    'No deltas found. Ensure your change has a specs/ directory with capability folders (e.g. specs/http-server/spec.md) containing .md files that use delta headers (## ADDED/MODIFIED/REMOVED/RENAMED Requirements) and that each requirement includes at least one "#### Scenario:" block. Tip: run "openspec change show <change-id> --json --deltas-only" to inspect parsed deltas.',
  GUIDE_MISSING_SPEC_SECTIONS:
    'Missing required sections. Expected headers: "## Purpose" and "## Requirements". Example:\n## Purpose\n[brief purpose]\n\n## Requirements\n### Requirement: Clear requirement statement\nUsers SHALL ...\n\n#### Scenario: Descriptive name\n- **WHEN** ...\n- **THEN** ...',
  GUIDE_MISSING_CHANGE_SECTIONS:
    'Missing required sections. Expected headers: "## Why" and "## What Changes". Ensure deltas are documented in specs/ using delta headers.',
  GUIDE_SCENARIO_FORMAT:
    'Scenarios must use level-4 headers. Convert bullet lists into:\n#### Scenario: Short name\n- **WHEN** ...\n- **THEN** ...\n- **AND** ...',
} as const;



================================================
FILE: src/core/validation/types.ts
================================================
export type ValidationLevel = 'ERROR' | 'WARNING' | 'INFO';

export interface ValidationIssue {
  level: ValidationLevel;
  path: string;
  message: string;
  line?: number;
  column?: number;
}

export interface ValidationReport {
  valid: boolean;
  issues: ValidationIssue[];
  summary: {
    errors: number;
    warnings: number;
    info: number;
  };
}


================================================
FILE: src/core/validation/validator.ts
================================================
import { z, ZodError } from 'zod';
import { readFileSync, promises as fs } from 'fs';
import path from 'path';
import { SpecSchema, ChangeSchema, Spec, Change } from '../schemas/index.js';
import { MarkdownParser } from '../parsers/markdown-parser.js';
import { ChangeParser } from '../parsers/change-parser.js';
import { ValidationReport, ValidationIssue, ValidationLevel } from './types.js';
import {
  MIN_PURPOSE_LENGTH,
  MAX_REQUIREMENT_TEXT_LENGTH,
  VALIDATION_MESSAGES
} from './constants.js';
import { parseDeltaSpec, normalizeRequirementName } from '../parsers/requirement-blocks.js';
import { FileSystemUtils } from '../../utils/file-system.js';

export class Validator {
  private strictMode: boolean;

  constructor(strictMode: boolean = false) {
    this.strictMode = strictMode;
  }

  async validateSpec(filePath: string): Promise<ValidationReport> {
    const issues: ValidationIssue[] = [];
    const specName = this.extractNameFromPath(filePath);
    try {
      const content = readFileSync(filePath, 'utf-8');
      const parser = new MarkdownParser(content);
      
      const spec = parser.parseSpec(specName);
      
      const result = SpecSchema.safeParse(spec);
      
      if (!result.success) {
        issues.push(...this.convertZodErrors(result.error));
      }
      
      issues.push(...this.applySpecRules(spec, content));
      
    } catch (error) {
      const baseMessage = error instanceof Error ? error.message : 'Unknown error';
      const enriched = this.enrichTopLevelError(specName, baseMessage);
      issues.push({
        level: 'ERROR',
        path: 'file',
        message: enriched,
      });
    }
    
    return this.createReport(issues);
  }

  /**
   * Validate spec content from a string (used for pre-write validation of rebuilt specs)
   */
  async validateSpecContent(specName: string, content: string): Promise<ValidationReport> {
    const issues: ValidationIssue[] = [];
    try {
      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec(specName);
      const result = SpecSchema.safeParse(spec);
      if (!result.success) {
        issues.push(...this.convertZodErrors(result.error));
      }
      issues.push(...this.applySpecRules(spec, content));
    } catch (error) {
      const baseMessage = error instanceof Error ? error.message : 'Unknown error';
      const enriched = this.enrichTopLevelError(specName, baseMessage);
      issues.push({ level: 'ERROR', path: 'file', message: enriched });
    }
    return this.createReport(issues);
  }

  async validateChange(filePath: string): Promise<ValidationReport> {
    const issues: ValidationIssue[] = [];
    const changeName = this.extractNameFromPath(filePath);
    try {
      const content = readFileSync(filePath, 'utf-8');
      const changeDir = path.dirname(filePath);
      const parser = new ChangeParser(content, changeDir);
      
      const change = await parser.parseChangeWithDeltas(changeName);
      
      const result = ChangeSchema.safeParse(change);
      
      if (!result.success) {
        issues.push(...this.convertZodErrors(result.error));
      }
      
      issues.push(...this.applyChangeRules(change, content));
      
    } catch (error) {
      const baseMessage = error instanceof Error ? error.message : 'Unknown error';
      const enriched = this.enrichTopLevelError(changeName, baseMessage);
      issues.push({
        level: 'ERROR',
        path: 'file',
        message: enriched,
      });
    }
    
    return this.createReport(issues);
  }

  /**
   * Validate delta-formatted spec files under a change directory.
   * Enforces:
   * - At least one delta across all files
   * - ADDED/MODIFIED: each requirement has SHALL/MUST and at least one scenario
   * - REMOVED: names only; no scenario/description required
   * - RENAMED: pairs well-formed
   * - No duplicates within sections; no cross-section conflicts per spec
   */
  async validateChangeDeltaSpecs(changeDir: string): Promise<ValidationReport> {
    const issues: ValidationIssue[] = [];
    const specsDir = path.join(changeDir, 'specs');
    let totalDeltas = 0;
    const missingHeaderSpecs: string[] = [];
    const emptySectionSpecs: Array<{ path: string; sections: string[] }> = [];

    try {
      const entries = await fs.readdir(specsDir, { withFileTypes: true });
      for (const entry of entries) {
        if (!entry.isDirectory()) continue;
        const specName = entry.name;
        const specFile = path.join(specsDir, specName, 'spec.md');
        let content: string | undefined;
        try {
          content = await fs.readFile(specFile, 'utf-8');
        } catch {
          continue;
        }

        const plan = parseDeltaSpec(content);
        const entryPath = `${specName}/spec.md`;
        const sectionNames: string[] = [];
        if (plan.sectionPresence.added) sectionNames.push('## ADDED Requirements');
        if (plan.sectionPresence.modified) sectionNames.push('## MODIFIED Requirements');
        if (plan.sectionPresence.removed) sectionNames.push('## REMOVED Requirements');
        if (plan.sectionPresence.renamed) sectionNames.push('## RENAMED Requirements');
        const hasSections = sectionNames.length > 0;
        const hasEntries = plan.added.length + plan.modified.length + plan.removed.length + plan.renamed.length > 0;
        if (!hasEntries) {
          if (hasSections) emptySectionSpecs.push({ path: entryPath, sections: sectionNames });
          else missingHeaderSpecs.push(entryPath);
        }

        const addedNames = new Set<string>();
        const modifiedNames = new Set<string>();
        const removedNames = new Set<string>();
        const renamedFrom = new Set<string>();
        const renamedTo = new Set<string>();

        // Validate ADDED
        for (const block of plan.added) {
          const key = normalizeRequirementName(block.name);
          totalDeltas++;
          if (addedNames.has(key)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Duplicate requirement in ADDED: "${block.name}"` });
          } else {
            addedNames.add(key);
          }
          const requirementText = this.extractRequirementText(block.raw);
          if (!requirementText) {
            issues.push({ level: 'ERROR', path: entryPath, message: `ADDED "${block.name}" is missing requirement text` });
          } else if (!this.containsShallOrMust(requirementText)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `ADDED "${block.name}" must contain SHALL or MUST` });
          }
          const scenarioCount = this.countScenarios(block.raw);
          if (scenarioCount < 1) {
            issues.push({ level: 'ERROR', path: entryPath, message: `ADDED "${block.name}" must include at least one scenario` });
          }
        }

        // Validate MODIFIED
        for (const block of plan.modified) {
          const key = normalizeRequirementName(block.name);
          totalDeltas++;
          if (modifiedNames.has(key)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Duplicate requirement in MODIFIED: "${block.name}"` });
          } else {
            modifiedNames.add(key);
          }
          const requirementText = this.extractRequirementText(block.raw);
          if (!requirementText) {
            issues.push({ level: 'ERROR', path: entryPath, message: `MODIFIED "${block.name}" is missing requirement text` });
          } else if (!this.containsShallOrMust(requirementText)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `MODIFIED "${block.name}" must contain SHALL or MUST` });
          }
          const scenarioCount = this.countScenarios(block.raw);
          if (scenarioCount < 1) {
            issues.push({ level: 'ERROR', path: entryPath, message: `MODIFIED "${block.name}" must include at least one scenario` });
          }
        }

        // Validate REMOVED (names only)
        for (const name of plan.removed) {
          const key = normalizeRequirementName(name);
          totalDeltas++;
          if (removedNames.has(key)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Duplicate requirement in REMOVED: "${name}"` });
          } else {
            removedNames.add(key);
          }
        }

        // Validate RENAMED pairs
        for (const { from, to } of plan.renamed) {
          const fromKey = normalizeRequirementName(from);
          const toKey = normalizeRequirementName(to);
          totalDeltas++;
          if (renamedFrom.has(fromKey)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Duplicate FROM in RENAMED: "${from}"` });
          } else {
            renamedFrom.add(fromKey);
          }
          if (renamedTo.has(toKey)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Duplicate TO in RENAMED: "${to}"` });
          } else {
            renamedTo.add(toKey);
          }
        }

        // Cross-section conflicts (within the same spec file)
        for (const n of modifiedNames) {
          if (removedNames.has(n)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Requirement present in both MODIFIED and REMOVED: "${n}"` });
          }
          if (addedNames.has(n)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Requirement present in both MODIFIED and ADDED: "${n}"` });
          }
        }
        for (const n of addedNames) {
          if (removedNames.has(n)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `Requirement present in both ADDED and REMOVED: "${n}"` });
          }
        }
        for (const { from, to } of plan.renamed) {
          const fromKey = normalizeRequirementName(from);
          const toKey = normalizeRequirementName(to);
          if (modifiedNames.has(fromKey)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `MODIFIED references old name from RENAMED. Use new header for "${to}"` });
          }
          if (addedNames.has(toKey)) {
            issues.push({ level: 'ERROR', path: entryPath, message: `RENAMED TO collides with ADDED for "${to}"` });
          }
        }
      }
    } catch {
      // If no specs dir, treat as no deltas
    }

    for (const { path: specPath, sections } of emptySectionSpecs) {
      issues.push({
        level: 'ERROR',
        path: specPath,
        message: `Delta sections ${this.formatSectionList(sections)} were found, but no requirement entries parsed. Ensure each section includes at least one "### Requirement:" block (REMOVED may use bullet list syntax).`,
      });
    }
    for (const path of missingHeaderSpecs) {
      issues.push({
        level: 'ERROR',
        path,
        message: 'No delta sections found. Add headers such as "## ADDED Requirements" or move non-delta notes outside specs/.',
      });
    }

    if (totalDeltas === 0) {
      issues.push({ level: 'ERROR', path: 'file', message: this.enrichTopLevelError('change', VALIDATION_MESSAGES.CHANGE_NO_DELTAS) });
    }

    return this.createReport(issues);
  }

  private convertZodErrors(error: ZodError): ValidationIssue[] {
    return error.issues.map(err => {
      let message = err.message;
      if (message === VALIDATION_MESSAGES.CHANGE_NO_DELTAS) {
        message = `${message}. ${VALIDATION_MESSAGES.GUIDE_NO_DELTAS}`;
      }
      return {
        level: 'ERROR' as ValidationLevel,
        path: err.path.join('.'),
        message,
      };
    });
  }

  private applySpecRules(spec: Spec, content: string): ValidationIssue[] {
    const issues: ValidationIssue[] = [];
    
    if (spec.overview.length < MIN_PURPOSE_LENGTH) {
      issues.push({
        level: 'WARNING',
        path: 'overview',
        message: VALIDATION_MESSAGES.PURPOSE_TOO_BRIEF,
      });
    }
    
    spec.requirements.forEach((req, index) => {
      if (req.text.length > MAX_REQUIREMENT_TEXT_LENGTH) {
        issues.push({
          level: 'INFO',
          path: `requirements[${index}]`,
          message: VALIDATION_MESSAGES.REQUIREMENT_TOO_LONG,
        });
      }
      
      if (req.scenarios.length === 0) {
        issues.push({
          level: 'WARNING',
          path: `requirements[${index}].scenarios`,
          message: `${VALIDATION_MESSAGES.REQUIREMENT_NO_SCENARIOS}. ${VALIDATION_MESSAGES.GUIDE_SCENARIO_FORMAT}`,
        });
      }
    });
    
    return issues;
  }

  private applyChangeRules(change: Change, content: string): ValidationIssue[] {
    const issues: ValidationIssue[] = [];
    
    const MIN_DELTA_DESCRIPTION_LENGTH = 10;
    
    change.deltas.forEach((delta, index) => {
      if (!delta.description || delta.description.length < MIN_DELTA_DESCRIPTION_LENGTH) {
        issues.push({
          level: 'WARNING',
          path: `deltas[${index}].description`,
          message: VALIDATION_MESSAGES.DELTA_DESCRIPTION_TOO_BRIEF,
        });
      }
      
      if ((delta.operation === 'ADDED' || delta.operation === 'MODIFIED') && 
          (!delta.requirements || delta.requirements.length === 0)) {
        issues.push({
          level: 'WARNING',
          path: `deltas[${index}].requirements`,
          message: `${delta.operation} ${VALIDATION_MESSAGES.DELTA_MISSING_REQUIREMENTS}`,
        });
      }
    });
    
    return issues;
  }

  private enrichTopLevelError(itemId: string, baseMessage: string): string {
    const msg = baseMessage.trim();
    if (msg === VALIDATION_MESSAGES.CHANGE_NO_DELTAS) {
      return `${msg}. ${VALIDATION_MESSAGES.GUIDE_NO_DELTAS}`;
    }
    if (msg.includes('Spec must have a Purpose section') || msg.includes('Spec must have a Requirements section')) {
      return `${msg}. ${VALIDATION_MESSAGES.GUIDE_MISSING_SPEC_SECTIONS}`;
    }
    if (msg.includes('Change must have a Why section') || msg.includes('Change must have a What Changes section')) {
      return `${msg}. ${VALIDATION_MESSAGES.GUIDE_MISSING_CHANGE_SECTIONS}`;
    }
    return msg;
  }

  private extractNameFromPath(filePath: string): string {
    const normalizedPath = FileSystemUtils.toPosixPath(filePath);
    const parts = normalizedPath.split('/');
    
    // Look for the directory name after 'specs' or 'changes'
    for (let i = parts.length - 1; i >= 0; i--) {
      if (parts[i] === 'specs' || parts[i] === 'changes') {
        if (i < parts.length - 1) {
          return parts[i + 1];
        }
      }
    }
    
    // Fallback to filename without extension if not in expected structure
    const fileName = parts[parts.length - 1] ?? '';
    const dotIndex = fileName.lastIndexOf('.');
    return dotIndex > 0 ? fileName.slice(0, dotIndex) : fileName;
  }

  private createReport(issues: ValidationIssue[]): ValidationReport {
    const errors = issues.filter(i => i.level === 'ERROR').length;
    const warnings = issues.filter(i => i.level === 'WARNING').length;
    const info = issues.filter(i => i.level === 'INFO').length;
    
    const valid = this.strictMode 
      ? errors === 0 && warnings === 0
      : errors === 0;
    
    return {
      valid,
      issues,
      summary: {
        errors,
        warnings,
        info,
      },
    };
  }

  isValid(report: ValidationReport): boolean {
    return report.valid;
  }

  private extractRequirementText(blockRaw: string): string | undefined {
    const lines = blockRaw.split('\n');
    // Skip header line (index 0)
    let i = 1;

    // Find the first substantial text line, skipping metadata and blank lines
    for (; i < lines.length; i++) {
      const line = lines[i];

      // Stop at scenario headers
      if (/^####\s+/.test(line)) break;

      const trimmed = line.trim();

      // Skip blank lines
      if (trimmed.length === 0) continue;

      // Skip metadata lines (lines starting with ** like **ID**, **Priority**, etc.)
      if (/^\*\*[^*]+\*\*:/.test(trimmed)) continue;

      // Found first non-metadata, non-blank line - this is the requirement text
      return trimmed;
    }

    // No requirement text found
    return undefined;
  }

  private containsShallOrMust(text: string): boolean {
    return /\b(SHALL|MUST)\b/.test(text);
  }

  private countScenarios(blockRaw: string): number {
    const matches = blockRaw.match(/^####\s+/gm);
    return matches ? matches.length : 0;
  }

  private formatSectionList(sections: string[]): string {
    if (sections.length === 0) return '';
    if (sections.length === 1) return sections[0];
    const head = sections.slice(0, -1);
    const last = sections[sections.length - 1];
    return `${head.join(', ')} and ${last}`;
  }
}



================================================
FILE: src/prompts/searchable-multi-select.ts
================================================
import chalk from 'chalk';

interface Choice {
  name: string;
  value: string;
  description?: string;
  configured?: boolean;
  configuredLabel?: string;
  preSelected?: boolean;
}

interface Config {
  message: string;
  choices: Choice[];
  pageSize?: number;
  validate?: (selected: string[]) => boolean | string;
}

/**
 * Create the searchable multi-select prompt.
 * Uses dynamic import to prevent pre-commit hook hangs (see #367).
 */
async function createSearchableMultiSelect(): Promise<
  (config: Config) => Promise<string[]>
> {
  const {
    createPrompt,
    useState,
    useKeypress,
    useMemo,
    usePrefix,
    isEnterKey,
    isBackspaceKey,
    isUpKey,
    isDownKey,
  } = await import('@inquirer/core');

  return createPrompt((config: Config, done: (value: string[]) => void): string => {
    const { message, choices, pageSize = 15, validate } = config;

    const [searchText, setSearchText] = useState('');
    const [selectedValues, setSelectedValues] = useState<string[]>(
      () => choices.filter(c => c.preSelected).map(c => c.value)
    );
    const [cursor, setCursor] = useState(0);
    const [status, setStatus] = useState<'idle' | 'done'>('idle');
    const [error, setError] = useState<string | null>(null);

    const prefix = usePrefix({ status });

    // Filter choices by search
    const filteredChoices = useMemo(() => {
      if (!searchText.trim()) return choices;
      const term = searchText.toLowerCase();
      return choices.filter(
        (c) =>
          c.name.toLowerCase().includes(term) ||
          c.value.toLowerCase().includes(term)
      );
    }, [searchText, choices]);

    const selectedSet = useMemo(() => new Set(selectedValues), [selectedValues]);
    const choiceMap = useMemo(
      () => new Map(choices.map((c) => [c.value, c])),
      [choices]
    );

    useKeypress((key) => {
      if (status === 'done') return;

      // Tab to confirm
      if (key.name === 'tab') {
        if (validate) {
          const result = validate(selectedValues);
          if (result !== true) {
            setError(typeof result === 'string' ? result : 'Invalid');
            return;
          }
        }
        setStatus('done');
        done(selectedValues);
        return;
      }

      // Enter to add item
      if (isEnterKey(key)) {
        const choice = filteredChoices[cursor];
        if (choice && !selectedSet.has(choice.value)) {
          setSelectedValues([...selectedValues, choice.value]);
          setSearchText('');
          setCursor(0);
        }
        return;
      }

      // Backspace to remove or delete search char
      if (isBackspaceKey(key)) {
        if (searchText === '' && selectedValues.length > 0) {
          setSelectedValues(selectedValues.slice(0, -1));
        } else {
          setSearchText(searchText.slice(0, -1));
          setCursor(0);
        }
        return;
      }

      // Navigation
      if (isUpKey(key)) {
        setCursor(Math.max(0, cursor - 1));
        return;
      }
      if (isDownKey(key)) {
        setCursor(Math.min(filteredChoices.length - 1, cursor + 1));
        return;
      }

      // Character input - handle printable characters
      if (key.name && key.name.length === 1 && !key.ctrl) {
        setSearchText(searchText + key.name);
        setCursor(0);
      }
    });

    // Render done state
    if (status === 'done') {
      const names = selectedValues
        .map((v) => choiceMap.get(v)?.name ?? v)
        .join(', ');
      return `${prefix} ${chalk.bold(message)} ${chalk.cyan(names || '(none)')}`;
    }

    // Render active state
    const lines: string[] = [];
    lines.push(`${prefix} ${chalk.bold(message)}`);

    // Selected chips
    const chips =
      selectedValues.length > 0
        ? selectedValues
            .map((v) => chalk.bgCyan.black(` ${choiceMap.get(v)?.name} `))
            .join(' ')
        : chalk.dim('(none selected)');
    lines.push(`  Selected: ${chips}`);

    // Search box
    lines.push(
      `  Search: ${chalk.yellow('[')}${searchText || chalk.dim('type to filter')}${chalk.yellow(']')}`
    );

    // Instructions
    lines.push(
      `  ${chalk.cyan('â†‘â†“')} navigate â€¢ ${chalk.cyan('Enter')} add â€¢ ${chalk.cyan('Backspace')} remove â€¢ ${chalk.cyan('Tab')} confirm`
    );

    // List
    if (filteredChoices.length === 0) {
      lines.push(chalk.yellow('  No matches'));
    } else {
      // Calculate pagination
      const startIndex = Math.max(
        0,
        Math.min(cursor - Math.floor(pageSize / 2), filteredChoices.length - pageSize)
      );
      const endIndex = Math.min(startIndex + pageSize, filteredChoices.length);
      const visibleChoices = filteredChoices.slice(startIndex, endIndex);

      for (let i = 0; i < visibleChoices.length; i++) {
        const item = visibleChoices[i];
        const actualIndex = startIndex + i;
        const isActive = actualIndex === cursor;
        const selected = selectedSet.has(item.value);
        const icon = selected ? chalk.green('â—‰') : chalk.dim('â—‹');
        const arrow = isActive ? chalk.cyan('â€º') : ' ';
        const name = isActive ? chalk.cyan(item.name) : item.name;
        const isRefresh = selected && item.configured;
        const suffix = selected
          ? chalk.dim(isRefresh ? ' (refresh)' : ' (selected)')
          : '';
        lines.push(`  ${arrow} ${icon} ${name}${suffix}`);
      }

      // Show pagination indicator if needed
      if (filteredChoices.length > pageSize) {
        const currentPage = Math.floor(cursor / pageSize) + 1;
        const totalPages = Math.ceil(filteredChoices.length / pageSize);
        lines.push(chalk.dim(`  (${currentPage}/${totalPages})`));
      }
    }

    if (error) lines.push(chalk.red(`  ${error}`));
    return lines.join('\n');
  });
}

/**
 * A searchable multi-select prompt with visible search box,
 * selected items display, and intuitive keyboard navigation.
 *
 * - Type to filter choices
 * - â†‘â†“ to navigate
 * - Enter to add highlighted item
 * - Backspace to remove last selected item (or delete search char)
 * - Tab to confirm selections
 */
export async function searchableMultiSelect(config: Config): Promise<string[]> {
  const prompt = await createSearchableMultiSelect();
  return prompt(config);
}

export default searchableMultiSelect;



================================================
FILE: src/telemetry/config.ts
================================================
/**
 * Global configuration for telemetry state.
 * Stores anonymous ID and notice-seen flag in ~/.config/openspec/config.json
 */
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';

export interface TelemetryConfig {
  anonymousId?: string;
  noticeSeen?: boolean;
}

export interface GlobalConfig {
  telemetry?: TelemetryConfig;
  [key: string]: unknown; // Preserve other fields
}

/**
 * Get the path to the global config file.
 * Uses ~/.config/openspec/config.json on all platforms.
 */
export function getConfigPath(): string {
  const configDir = path.join(os.homedir(), '.config', 'openspec');
  return path.join(configDir, 'config.json');
}

/**
 * Read the global config file.
 * Returns an empty object if the file doesn't exist.
 */
export async function readConfig(): Promise<GlobalConfig> {
  const configPath = getConfigPath();
  try {
    const content = await fs.readFile(configPath, 'utf-8');
    return JSON.parse(content) as GlobalConfig;
  } catch (error: unknown) {
    if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
      return {};
    }
    // If parse fails or other error, return empty config
    return {};
  }
}

/**
 * Write to the global config file.
 * Preserves existing fields and merges in new values.
 */
export async function writeConfig(updates: Partial<GlobalConfig>): Promise<void> {
  const configPath = getConfigPath();
  const configDir = path.dirname(configPath);

  // Ensure directory exists
  await fs.mkdir(configDir, { recursive: true });

  // Read existing config and merge
  const existing = await readConfig();
  const merged = { ...existing, ...updates };

  // Deep merge for telemetry object
  if (updates.telemetry && existing.telemetry) {
    merged.telemetry = { ...existing.telemetry, ...updates.telemetry };
  }

  await fs.writeFile(configPath, JSON.stringify(merged, null, 2) + '\n');
}

/**
 * Get the telemetry config section.
 */
export async function getTelemetryConfig(): Promise<TelemetryConfig> {
  const config = await readConfig();
  return config.telemetry ?? {};
}

/**
 * Update the telemetry config section.
 */
export async function updateTelemetryConfig(updates: Partial<TelemetryConfig>): Promise<void> {
  const existing = await getTelemetryConfig();
  await writeConfig({
    telemetry: { ...existing, ...updates },
  });
}



================================================
FILE: src/telemetry/index.ts
================================================
/**
 * Telemetry module for anonymous usage analytics.
 *
 * Privacy-first design:
 * - Only tracks command name and version
 * - No arguments, file paths, or content
 * - Opt-out via OPENSPEC_TELEMETRY=0 or DO_NOT_TRACK=1
 * - Auto-disabled in CI environments
 * - Anonymous ID is a random UUID with no relation to the user
 */
import { PostHog } from 'posthog-node';
import { randomUUID } from 'crypto';
import { getTelemetryConfig, updateTelemetryConfig } from './config.js';

// PostHog API key - public key for client-side analytics
// This is safe to embed as it only allows sending events, not reading data
const POSTHOG_API_KEY = 'phc_Hthu8YvaIJ9QaFKyTG4TbVwkbd5ktcAFzVTKeMmoW2g';
// Using reverse proxy to avoid ad blockers and keep traffic on our domain
const POSTHOG_HOST = 'https://edge.openspec.dev';

let posthogClient: PostHog | null = null;
let anonymousId: string | null = null;

/**
 * Check if telemetry is enabled.
 *
 * Disabled when:
 * - OPENSPEC_TELEMETRY=0
 * - DO_NOT_TRACK=1
 * - CI=true (any CI environment)
 */
export function isTelemetryEnabled(): boolean {
  // Check explicit opt-out
  if (process.env.OPENSPEC_TELEMETRY === '0') {
    return false;
  }

  // Respect DO_NOT_TRACK standard
  if (process.env.DO_NOT_TRACK === '1') {
    return false;
  }

  // Auto-disable in CI environments
  if (process.env.CI === 'true') {
    return false;
  }

  return true;
}

/**
 * Get or create the anonymous user ID.
 * Lazily generates a UUID on first call and persists it.
 */
export async function getOrCreateAnonymousId(): Promise<string> {
  // Return cached value if available
  if (anonymousId) {
    return anonymousId;
  }

  // Try to load from config
  const config = await getTelemetryConfig();
  if (config.anonymousId) {
    anonymousId = config.anonymousId;
    return anonymousId;
  }

  // Generate new UUID and persist
  anonymousId = randomUUID();
  await updateTelemetryConfig({ anonymousId });
  return anonymousId;
}

/**
 * Get the PostHog client instance.
 * Creates it on first call with CLI-optimized settings.
 */
function getClient(): PostHog {
  if (!posthogClient) {
    posthogClient = new PostHog(POSTHOG_API_KEY, {
      host: POSTHOG_HOST,
      flushAt: 1, // Send immediately, don't batch
      flushInterval: 0, // No timer-based flushing
    });
  }
  return posthogClient;
}

/**
 * Track a command execution.
 *
 * @param commandName - The command name (e.g., 'init', 'change:apply')
 * @param version - The OpenSpec version
 */
export async function trackCommand(commandName: string, version: string): Promise<void> {
  if (!isTelemetryEnabled()) {
    return;
  }

  try {
    const userId = await getOrCreateAnonymousId();
    const client = getClient();

    client.capture({
      distinctId: userId,
      event: 'command_executed',
      properties: {
        command: commandName,
        version: version,
        surface: 'cli',
        $ip: null, // Explicitly disable IP tracking
      },
    });
  } catch {
    // Silent failure - telemetry should never break CLI
  }
}

/**
 * Show first-run telemetry notice if not already seen.
 */
export async function maybeShowTelemetryNotice(): Promise<void> {
  if (!isTelemetryEnabled()) {
    return;
  }

  try {
    const config = await getTelemetryConfig();
    if (config.noticeSeen) {
      return;
    }

    // Display notice
    console.log(
      'Note: OpenSpec collects anonymous usage stats. Opt out: OPENSPEC_TELEMETRY=0'
    );

    // Mark as seen
    await updateTelemetryConfig({ noticeSeen: true });
  } catch {
    // Silent failure - telemetry should never break CLI
  }
}

/**
 * Shutdown the PostHog client and flush pending events.
 * Call this before CLI exit.
 */
export async function shutdown(): Promise<void> {
  if (!posthogClient) {
    return;
  }

  try {
    await posthogClient.shutdown();
  } catch {
    // Silent failure - telemetry should never break CLI exit
  } finally {
    posthogClient = null;
  }
}



================================================
FILE: src/ui/ascii-patterns.ts
================================================
/**
 * ASCII art animation patterns for the welcome screen.
 * OpenSpec logo animation - diamond/rhombus shape with hollow center "O".
 */

// Detect if full Unicode is supported
const supportsUnicode =
  process.platform !== 'win32' ||
  !!process.env.WT_SESSION || // Windows Terminal
  !!process.env.TERM_PROGRAM; // Modern terminal

// Character set based on Unicode support
// Block characters for pixel-art aesthetic
const CHARS = supportsUnicode
  ? { full: 'â–ˆâ–ˆ', dim: 'â–‘â–‘', empty: '  ' }
  : { full: '##', dim: '++', empty: '  ' };

const _ = CHARS.empty;
const F = CHARS.full;
const D = CHARS.dim;

/**
 * Welcome animation frames - OpenSpec logo building from center
 * 7 rows Ã— 6 columns diamond with hollow center "O"
 * Center bar is 2 cols Ã— 3 rows (rows 3,4,5 cols 3,4)
 * Each frame is an array of strings (lines of ASCII art)
 * Grid: 6 cols Ã— 2 chars = 12 chars wide
 */
export const WELCOME_ANIMATION = {
  interval: 120,
  frames: [
    // Frame 1: Empty
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
    ],
    // Frame 2: Center blocks appear (dim) - 2x3 center bar
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${D}${D}${_}${_}`,
      `${_}${_}${_}${_}${D}${D}${_}${_}`,
      `${_}${_}${_}${_}${D}${D}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
    ],
    // Frame 3: Center blocks solidify
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
    ],
    // Frame 4: Top and bottom points appear
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${D}${D}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${_}${_}${_}${_}`,
      `${_}${_}${_}${_}${D}${D}${_}${_}`,
    ],
    // Frame 5: Inner ring forming
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${D}${_}${_}${D}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${D}${_}${_}${D}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
    ],
    // Frame 6: Outer ring appearing
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${F}${_}${_}${F}${_}`,
      `${_}${_}${D}${_}${F}${F}${_}${D}`,
      `${_}${_}${D}${_}${F}${F}${_}${D}`,
      `${_}${_}${D}${_}${F}${F}${_}${D}`,
      `${_}${_}${_}${F}${_}${_}${F}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
    ],
    // Frame 7: Full logo
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${F}${_}${_}${F}${_}`,
      `${_}${_}${F}${_}${F}${F}${_}${F}`,
      `${_}${_}${F}${_}${F}${F}${_}${F}`,
      `${_}${_}${F}${_}${F}${F}${_}${F}`,
      `${_}${_}${_}${F}${_}${_}${F}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
    ],
    // Frame 8: Hold complete logo
    [
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 1
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 2
      `${_}${_}${_}${_}${_}${_}${_}${_}`, // padding row 3
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
      `${_}${_}${_}${F}${_}${_}${F}${_}`,
      `${_}${_}${F}${_}${F}${F}${_}${F}`,
      `${_}${_}${F}${_}${F}${F}${_}${F}`,
      `${_}${_}${F}${_}${F}${F}${_}${F}`,
      `${_}${_}${_}${F}${_}${_}${F}${_}`,
      `${_}${_}${_}${_}${F}${F}${_}${_}`,
    ],
  ],
};



================================================
FILE: src/ui/welcome-screen.ts
================================================
/**
 * Animated welcome screen for the experimental artifact workflow setup.
 * Shows side-by-side layout with animated ASCII art on left and welcome text on right.
 */

import chalk from 'chalk';
import { WELCOME_ANIMATION } from './ascii-patterns.js';

// Minimum terminal width for side-by-side layout
const MIN_WIDTH = 60;

// Width of the ASCII art column (with padding)
const ART_COLUMN_WIDTH = 24;

/**
 * Welcome text content (right column)
 */
function getWelcomeText(): string[] {
  return [
    chalk.white.bold('Welcome to OpenSpec'),
    chalk.dim('Experimental Artifact Workflow'),
    '',
    chalk.white('This setup will configure:'),
    chalk.dim('  â€¢ Agent Skills for AI tools'),
    chalk.dim('  â€¢ /opsx:* slash commands'),
    '',
    chalk.white('Quick start after setup:'),
    `  ${chalk.yellow('/opsx:new')}      ${chalk.dim('Create a change')}`,
    `  ${chalk.yellow('/opsx:continue')} ${chalk.dim('Next artifact')}`,
    `  ${chalk.yellow('/opsx:apply')}    ${chalk.dim('Implement tasks')}`,
    '',
    chalk.cyan('Press Enter to select tools...'),
  ];
}

/**
 * Renders a single frame with side-by-side layout
 */
function renderFrame(artLines: string[], textLines: string[]): string {
  const maxLines = Math.max(artLines.length, textLines.length);
  const lines: string[] = [];

  for (let i = 0; i < maxLines; i++) {
    const artLine = artLines[i] || '';
    const textLine = textLines[i] || '';

    // Pad the art column to fixed width
    const paddedArt = artLine.padEnd(ART_COLUMN_WIDTH);

    // Color the ASCII art with cyan for visual appeal
    const coloredArt = chalk.cyan(paddedArt);

    // Clear line before writing to prevent residual characters
    lines.push(`\x1b[2K${coloredArt}${textLine}`);
  }

  return lines.join('\n');
}

/**
 * Checks if the terminal supports animation
 */
function canAnimate(): boolean {
  // Must be TTY
  if (!process.stdout.isTTY) return false;

  // Respect NO_COLOR
  if (process.env.NO_COLOR) return false;

  // Check terminal width
  const columns = process.stdout.columns || 80;
  if (columns < MIN_WIDTH) return false;

  return true;
}

/**
 * Wait for Enter key press
 */
function waitForEnter(): Promise<void> {
  return new Promise((resolve) => {
    const { stdin } = process;

    // Handle non-TTY gracefully
    if (!stdin.isTTY) {
      resolve();
      return;
    }

    const wasRaw = stdin.isRaw;
    stdin.setRawMode(true);
    stdin.resume();

    const onData = (data: Buffer): void => {
      const char = data.toString();

      // Enter key or Ctrl+C
      if (char === '\r' || char === '\n' || char === '\u0003') {
        stdin.removeListener('data', onData);
        stdin.setRawMode(wasRaw);
        stdin.pause();

        // Handle Ctrl+C
        if (char === '\u0003') {
          process.stdout.write('\n');
          process.exit(0);
        }

        resolve();
      }
    };

    stdin.on('data', onData);
  });
}

/**
 * Shows the animated welcome screen.
 * Returns when user presses Enter.
 */
export async function showWelcomeScreen(): Promise<void> {
  const textLines = getWelcomeText();

  if (!canAnimate()) {
    // Fallback: show static welcome
    const frame = WELCOME_ANIMATION.frames[3]; // Peak frame
    process.stdout.write('\n' + renderFrame(frame, textLines) + '\n\n');
    return;
  }

  let frameIndex = 0;
  let running = true;
  let isFirstRender = true;

  // Content height for cursor movement between frames
  const numContentLines = Math.max(WELCOME_ANIMATION.frames[0].length, textLines.length);
  const frameHeight = numContentLines + 1; // internal newlines (11) + trailing newlines (2) = 13

  // Total height including initial newline (for cleanup)
  const totalHeight = frameHeight + 1; // 14

  // Initial render
  process.stdout.write('\n');

  // Animation loop
  const interval = setInterval(() => {
    if (!running) return;

    const frame = WELCOME_ANIMATION.frames[frameIndex];

    // Move cursor up to overwrite previous frame (always after first render)
    if (!isFirstRender) {
      process.stdout.write(`\x1b[${frameHeight}A`);
    }
    isFirstRender = false;

    // Render current frame
    process.stdout.write(renderFrame(frame, textLines) + '\n\n');

    // Advance to next frame
    frameIndex = (frameIndex + 1) % WELCOME_ANIMATION.frames.length;
  }, WELCOME_ANIMATION.interval);

  // Wait for Enter
  await waitForEnter();

  // Stop animation
  running = false;
  clearInterval(interval);

  // Clear the welcome screen and move on
  process.stdout.write(`\x1b[${totalHeight}A`);
  for (let i = 0; i < totalHeight; i++) {
    process.stdout.write('\x1b[2K\n'); // Clear line
  }
  process.stdout.write(`\x1b[${totalHeight}A`); // Move back up
}



================================================
FILE: src/utils/change-metadata.ts
================================================
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as yaml from 'yaml';
import { ChangeMetadataSchema, type ChangeMetadata } from '../core/artifact-graph/types.js';
import { listSchemas } from '../core/artifact-graph/resolver.js';
import { readProjectConfig } from '../core/project-config.js';

const METADATA_FILENAME = '.openspec.yaml';

/**
 * Error thrown when change metadata validation fails.
 */
export class ChangeMetadataError extends Error {
  constructor(
    message: string,
    public readonly metadataPath: string,
    public readonly cause?: Error
  ) {
    super(message);
    this.name = 'ChangeMetadataError';
  }
}

/**
 * Validates that a schema name is valid (exists in available schemas).
 *
 * @param schemaName - The schema name to validate
 * @param projectRoot - Optional project root for project-local schema resolution
 * @returns The validated schema name
 * @throws Error if schema is not found
 */
export function validateSchemaName(
  schemaName: string,
  projectRoot?: string
): string {
  const availableSchemas = listSchemas(projectRoot);
  if (!availableSchemas.includes(schemaName)) {
    throw new Error(
      `Unknown schema '${schemaName}'. Available: ${availableSchemas.join(', ')}`
    );
  }
  return schemaName;
}

/**
 * Writes change metadata to .openspec.yaml in the change directory.
 *
 * @param changeDir - The path to the change directory
 * @param metadata - The metadata to write
 * @param projectRoot - Optional project root for project-local schema resolution
 * @throws ChangeMetadataError if validation fails or write fails
 */
export function writeChangeMetadata(
  changeDir: string,
  metadata: ChangeMetadata,
  projectRoot?: string
): void {
  const metaPath = path.join(changeDir, METADATA_FILENAME);

  // Validate schema exists
  validateSchemaName(metadata.schema, projectRoot);

  // Validate with Zod
  const parseResult = ChangeMetadataSchema.safeParse(metadata);
  if (!parseResult.success) {
    throw new ChangeMetadataError(
      `Invalid metadata: ${parseResult.error.message}`,
      metaPath
    );
  }

  // Write YAML file
  const content = yaml.stringify(parseResult.data);
  try {
    fs.writeFileSync(metaPath, content, 'utf-8');
  } catch (err) {
    const ioError = err instanceof Error ? err : new Error(String(err));
    throw new ChangeMetadataError(
      `Failed to write metadata: ${ioError.message}`,
      metaPath,
      ioError
    );
  }
}

/**
 * Reads change metadata from .openspec.yaml in the change directory.
 *
 * @param changeDir - The path to the change directory
 * @param projectRoot - Optional project root for project-local schema resolution
 * @returns The validated metadata, or null if no metadata file exists
 * @throws ChangeMetadataError if the file exists but is invalid
 */
export function readChangeMetadata(
  changeDir: string,
  projectRoot?: string
): ChangeMetadata | null {
  const metaPath = path.join(changeDir, METADATA_FILENAME);

  if (!fs.existsSync(metaPath)) {
    return null;
  }

  let content: string;
  try {
    content = fs.readFileSync(metaPath, 'utf-8');
  } catch (err) {
    const ioError = err instanceof Error ? err : new Error(String(err));
    throw new ChangeMetadataError(
      `Failed to read metadata: ${ioError.message}`,
      metaPath,
      ioError
    );
  }

  let parsed: unknown;
  try {
    parsed = yaml.parse(content);
  } catch (err) {
    const parseError = err instanceof Error ? err : new Error(String(err));
    throw new ChangeMetadataError(
      `Invalid YAML in metadata file: ${parseError.message}`,
      metaPath,
      parseError
    );
  }

  // Validate with Zod
  const parseResult = ChangeMetadataSchema.safeParse(parsed);
  if (!parseResult.success) {
    throw new ChangeMetadataError(
      `Invalid metadata: ${parseResult.error.message}`,
      metaPath
    );
  }

  // Validate that the schema exists
  const availableSchemas = listSchemas(projectRoot);
  if (!availableSchemas.includes(parseResult.data.schema)) {
    throw new ChangeMetadataError(
      `Unknown schema '${parseResult.data.schema}'. Available: ${availableSchemas.join(', ')}`,
      metaPath
    );
  }

  return parseResult.data;
}

/**
 * Resolves the schema for a change, with explicit override taking precedence.
 *
 * Resolution order:
 * 1. Explicit schema (if provided)
 * 2. Schema from .openspec.yaml metadata (if exists)
 * 3. Schema from openspec/config.yaml (if exists)
 * 4. Default 'spec-driven'
 *
 * @param changeDir - The path to the change directory
 * @param explicitSchema - Optional explicit schema override
 * @returns The resolved schema name
 */
export function resolveSchemaForChange(
  changeDir: string,
  explicitSchema?: string
): string {
  // Derive project root from changeDir (changeDir is typically projectRoot/openspec/changes/change-name)
  const projectRoot = path.resolve(changeDir, '../../..');

  // 1. Explicit override wins
  if (explicitSchema) {
    return explicitSchema;
  }

  // 2. Try reading from metadata
  try {
    const metadata = readChangeMetadata(changeDir, projectRoot);
    if (metadata?.schema) {
      return metadata.schema;
    }
  } catch {
    // If metadata read fails, continue to next option
  }

  // 3. Try reading from project config
  try {
    const config = readProjectConfig(projectRoot);
    if (config?.schema) {
      return config.schema;
    }
  } catch {
    // If config read fails, fall back to default
  }

  // 4. Default
  return 'spec-driven';
}



================================================
FILE: src/utils/change-utils.ts
================================================
import path from 'path';
import { FileSystemUtils } from './file-system.js';
import { writeChangeMetadata, validateSchemaName } from './change-metadata.js';
import { readProjectConfig } from '../core/project-config.js';

const DEFAULT_SCHEMA = 'spec-driven';

/**
 * Options for creating a change.
 */
export interface CreateChangeOptions {
  /** The workflow schema to use (default: 'spec-driven') */
  schema?: string;
}

/**
 * Result of creating a change.
 */
export interface CreateChangeResult {
  /** The schema that was actually used (resolved from options, config, or default) */
  schema: string;
}

/**
 * Result of validating a change name.
 */
export interface ValidationResult {
  valid: boolean;
  error?: string;
}

/**
 * Validates that a change name follows kebab-case conventions.
 *
 * Valid names:
 * - Start with a lowercase letter
 * - Contain only lowercase letters, numbers, and hyphens
 * - Do not start or end with a hyphen
 * - Do not contain consecutive hyphens
 *
 * @param name - The change name to validate
 * @returns Validation result with `valid: true` or `valid: false` with an error message
 *
 * @example
 * validateChangeName('add-auth') // { valid: true }
 * validateChangeName('Add-Auth') // { valid: false, error: '...' }
 */
export function validateChangeName(name: string): ValidationResult {
  // Pattern: starts with lowercase letter, followed by lowercase letters/numbers,
  // optionally followed by hyphen + lowercase letters/numbers (repeatable)
  const kebabCasePattern = /^[a-z][a-z0-9]*(-[a-z0-9]+)*$/;

  if (!name) {
    return { valid: false, error: 'Change name cannot be empty' };
  }

  if (!kebabCasePattern.test(name)) {
    // Provide specific error messages for common mistakes
    if (/[A-Z]/.test(name)) {
      return { valid: false, error: 'Change name must be lowercase (use kebab-case)' };
    }
    if (/\s/.test(name)) {
      return { valid: false, error: 'Change name cannot contain spaces (use hyphens instead)' };
    }
    if (/_/.test(name)) {
      return { valid: false, error: 'Change name cannot contain underscores (use hyphens instead)' };
    }
    if (name.startsWith('-')) {
      return { valid: false, error: 'Change name cannot start with a hyphen' };
    }
    if (name.endsWith('-')) {
      return { valid: false, error: 'Change name cannot end with a hyphen' };
    }
    if (/--/.test(name)) {
      return { valid: false, error: 'Change name cannot contain consecutive hyphens' };
    }
    if (/[^a-z0-9-]/.test(name)) {
      return { valid: false, error: 'Change name can only contain lowercase letters, numbers, and hyphens' };
    }
    if (/^[0-9]/.test(name)) {
      return { valid: false, error: 'Change name must start with a letter' };
    }

    return { valid: false, error: 'Change name must follow kebab-case convention (e.g., add-auth, refactor-db)' };
  }

  return { valid: true };
}

/**
 * Creates a new change directory with metadata file.
 *
 * @param projectRoot - The root directory of the project (where `openspec/` lives)
 * @param name - The change name (must be valid kebab-case)
 * @param options - Optional settings for the change
 * @throws Error if the change name is invalid
 * @throws Error if the schema name is invalid
 * @throws Error if the change directory already exists
 *
 * @returns Result containing the resolved schema name
 *
 * @example
 * // Creates openspec/changes/add-auth/ with default schema
 * const result = await createChange('/path/to/project', 'add-auth')
 * console.log(result.schema) // 'spec-driven' or value from config
 *
 * @example
 * // Creates openspec/changes/add-auth/ with TDD schema
 * const result = await createChange('/path/to/project', 'add-auth', { schema: 'tdd' })
 * console.log(result.schema) // 'tdd'
 */
export async function createChange(
  projectRoot: string,
  name: string,
  options: CreateChangeOptions = {}
): Promise<CreateChangeResult> {
  // Validate the name first
  const validation = validateChangeName(name);
  if (!validation.valid) {
    throw new Error(validation.error);
  }

  // Determine schema: explicit option â†’ project config â†’ hardcoded default
  let schemaName: string;
  if (options.schema) {
    schemaName = options.schema;
  } else {
    // Try to read from project config
    try {
      const config = readProjectConfig(projectRoot);
      schemaName = config?.schema ?? DEFAULT_SCHEMA;
    } catch {
      // If config read fails, use default
      schemaName = DEFAULT_SCHEMA;
    }
  }

  // Validate the resolved schema
  validateSchemaName(schemaName, projectRoot);

  // Build the change directory path
  const changeDir = path.join(projectRoot, 'openspec', 'changes', name);

  // Check if change already exists
  if (await FileSystemUtils.directoryExists(changeDir)) {
    throw new Error(`Change '${name}' already exists at ${changeDir}`);
  }

  // Create the directory (including parent directories if needed)
  await FileSystemUtils.createDirectory(changeDir);

  // Write metadata file with schema and creation date
  const today = new Date().toISOString().split('T')[0];
  writeChangeMetadata(changeDir, {
    schema: schemaName,
    created: today,
  }, projectRoot);

  return { schema: schemaName };
}



================================================
FILE: src/utils/file-system.ts
================================================
import { promises as fs, constants as fsConstants } from 'fs';
import path from 'path';

function isMarkerOnOwnLine(content: string, markerIndex: number, markerLength: number): boolean {
  let leftIndex = markerIndex - 1;
  while (leftIndex >= 0 && content[leftIndex] !== '\n') {
    const char = content[leftIndex];
    if (char !== ' ' && char !== '\t' && char !== '\r') {
      return false;
    }
    leftIndex--;
  }

  let rightIndex = markerIndex + markerLength;
  while (rightIndex < content.length && content[rightIndex] !== '\n') {
    const char = content[rightIndex];
    if (char !== ' ' && char !== '\t' && char !== '\r') {
      return false;
    }
    rightIndex++;
  }

  return true;
}

function findMarkerIndex(
  content: string,
  marker: string,
  fromIndex = 0
): number {
  let currentIndex = content.indexOf(marker, fromIndex);

  while (currentIndex !== -1) {
    if (isMarkerOnOwnLine(content, currentIndex, marker.length)) {
      return currentIndex;
    }

    currentIndex = content.indexOf(marker, currentIndex + marker.length);
  }

  return -1;
}

export class FileSystemUtils {
  /**
   * Converts a path to use forward slashes (POSIX style).
   * Essential for cross-platform compatibility with glob libraries like fast-glob.
   */
  static toPosixPath(p: string): string {
    return p.replace(/\\/g, '/');
  }

  private static isWindowsBasePath(basePath: string): boolean {
    return /^[A-Za-z]:[\\/]/.test(basePath) || basePath.startsWith('\\');
  }

  private static normalizeSegments(segments: string[]): string[] {
    return segments
      .flatMap((segment) => segment.split(/[\\/]+/u))
      .filter((part) => part.length > 0);
  }

  static joinPath(basePath: string, ...segments: string[]): string {
    const normalizedSegments = this.normalizeSegments(segments);

    if (this.isWindowsBasePath(basePath)) {
      const normalizedBasePath = path.win32.normalize(basePath);
      return normalizedSegments.length
        ? path.win32.join(normalizedBasePath, ...normalizedSegments)
        : normalizedBasePath;
    }

    const posixBasePath = basePath.replace(/\\/g, '/');

    return normalizedSegments.length
      ? path.posix.join(posixBasePath, ...normalizedSegments)
      : path.posix.normalize(posixBasePath);
  }

  static async createDirectory(dirPath: string): Promise<void> {
    await fs.mkdir(dirPath, { recursive: true });
  }

  static async fileExists(filePath: string): Promise<boolean> {
    try {
      await fs.access(filePath);
      return true;
    } catch (error: any) {
      if (error.code !== 'ENOENT') {
        console.debug(`Unable to check if file exists at ${filePath}: ${error.message}`);
      }
      return false;
    }
  }

  /**
   * Finds the first existing parent directory by walking up the directory tree.
   * @param dirPath Starting directory path
   * @returns The first existing directory path, or null if root is reached without finding one
   */
  private static async findFirstExistingDirectory(dirPath: string): Promise<string | null> {
    let currentDir = dirPath;

    while (true) {
      try {
        const stats = await fs.stat(currentDir);
        if (stats.isDirectory()) {
          return currentDir;
        }
        // Path component exists but is not a directory (edge case)
        console.debug(`Path component ${currentDir} exists but is not a directory`);
        return null;
      } catch (error: any) {
        if (error.code === 'ENOENT') {
          // Directory doesn't exist, move up one level
          const parentDir = path.dirname(currentDir);
          if (parentDir === currentDir) {
            // Reached filesystem root without finding existing directory
            return null;
          }
          currentDir = parentDir;
        } else {
          // Unexpected error (permissions, I/O error, etc.)
          console.debug(`Error checking directory ${currentDir}: ${error.message}`);
          return null;
        }
      }
    }
  }

  static async canWriteFile(filePath: string): Promise<boolean> {
    try {
      const stats = await fs.stat(filePath);

      if (!stats.isFile()) {
        return true;
      }

      // On Windows, stats.mode doesn't reliably indicate write permissions.
      // Use fs.access with W_OK to check actual write permissions cross-platform.
      try {
        await fs.access(filePath, fsConstants.W_OK);
        return true;
      } catch {
        return false;
      }
    } catch (error: any) {
      if (error.code === 'ENOENT') {
        // File doesn't exist - find first existing parent directory and check its permissions
        const parentDir = path.dirname(filePath);
        const existingDir = await this.findFirstExistingDirectory(parentDir);

        if (existingDir === null) {
          // No existing parent directory found (edge case)
          return false;
        }

        // Check if the existing parent directory is writable
        try {
          await fs.access(existingDir, fsConstants.W_OK);
          return true;
        } catch {
          return false;
        }
      }

      console.debug(`Unable to determine write permissions for ${filePath}: ${error.message}`);
      return false;
    }
  }

  static async directoryExists(dirPath: string): Promise<boolean> {
    try {
      const stats = await fs.stat(dirPath);
      return stats.isDirectory();
    } catch (error: any) {
      if (error.code !== 'ENOENT') {
        console.debug(`Unable to check if directory exists at ${dirPath}: ${error.message}`);
      }
      return false;
    }
  }

  static async writeFile(filePath: string, content: string): Promise<void> {
    const dir = path.dirname(filePath);
    await this.createDirectory(dir);
    await fs.writeFile(filePath, content, 'utf-8');
  }

  static async readFile(filePath: string): Promise<string> {
    return await fs.readFile(filePath, 'utf-8');
  }

  static async updateFileWithMarkers(
    filePath: string,
    content: string,
    startMarker: string,
    endMarker: string
  ): Promise<void> {
    let existingContent = '';
    
    if (await this.fileExists(filePath)) {
      existingContent = await this.readFile(filePath);
      
      const startIndex = findMarkerIndex(existingContent, startMarker);
      const endIndex = startIndex !== -1
        ? findMarkerIndex(existingContent, endMarker, startIndex + startMarker.length)
        : findMarkerIndex(existingContent, endMarker);

      if (startIndex !== -1 && endIndex !== -1) {
        if (endIndex < startIndex) {
          throw new Error(
            `Invalid marker state in ${filePath}. End marker appears before start marker.`
          );
        }

        const before = existingContent.substring(0, startIndex);
        const after = existingContent.substring(endIndex + endMarker.length);
        existingContent = before + startMarker + '\n' + content + '\n' + endMarker + after;
      } else if (startIndex === -1 && endIndex === -1) {
        existingContent = startMarker + '\n' + content + '\n' + endMarker + '\n\n' + existingContent;
      } else {
        throw new Error(`Invalid marker state in ${filePath}. Found start: ${startIndex !== -1}, Found end: ${endIndex !== -1}`);
      }
    } else {
      existingContent = startMarker + '\n' + content + '\n' + endMarker;
    }
    
    await this.writeFile(filePath, existingContent);
  }

  static async ensureWritePermissions(dirPath: string): Promise<boolean> {
    try {
      // If directory doesn't exist, check parent directory permissions
      if (!await this.directoryExists(dirPath)) {
        const parentDir = path.dirname(dirPath);
        if (!await this.directoryExists(parentDir)) {
          await this.createDirectory(parentDir);
        }
        return await this.ensureWritePermissions(parentDir);
      }
      
      const testFile = path.join(dirPath, '.openspec-test-' + Date.now());
      await fs.writeFile(testFile, '');
      await fs.unlink(testFile);
      return true;
    } catch (error: any) {
      console.debug(`Insufficient permissions to write to ${dirPath}: ${error.message}`);
      return false;
    }
  }
}



================================================
FILE: src/utils/index.ts
================================================
// Shared utilities
export { validateChangeName, createChange } from './change-utils.js';
export type { ValidationResult, CreateChangeOptions } from './change-utils.js';

// Change metadata utilities
export {
  readChangeMetadata,
  writeChangeMetadata,
  resolveSchemaForChange,
  validateSchemaName,
  ChangeMetadataError,
} from './change-metadata.js';


================================================
FILE: src/utils/interactive.ts
================================================
export type InteractiveOptions = {
  /**
   * Explicit "disable prompts" flag passed by internal callers.
   */
  noInteractive?: boolean;
  /**
   * Commander-style negated option: `--no-interactive` sets this to false.
   */
  interactive?: boolean;
};

/**
 * Resolves whether non-interactive mode is requested.
 * Handles both explicit `noInteractive: true` and Commander.js style `interactive: false`.
 * Use this helper instead of manually checking options.noInteractive to avoid bugs.
 */
export function resolveNoInteractive(value?: boolean | InteractiveOptions): boolean {
  if (typeof value === 'boolean') return value;
  return value?.noInteractive === true || value?.interactive === false;
}

export function isInteractive(value?: boolean | InteractiveOptions): boolean {
  if (resolveNoInteractive(value)) return false;
  if (process.env.OPEN_SPEC_INTERACTIVE === '0') return false;
  // Respect the standard CI environment variable (set by GitHub Actions, GitLab CI, Travis, etc.)
  if ('CI' in process.env) return false;
  return !!process.stdin.isTTY;
}




================================================
FILE: src/utils/item-discovery.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';

export async function getActiveChangeIds(root: string = process.cwd()): Promise<string[]> {
  const changesPath = path.join(root, 'openspec', 'changes');
  try {
    const entries = await fs.readdir(changesPath, { withFileTypes: true });
    const result: string[] = [];
    for (const entry of entries) {
      if (!entry.isDirectory() || entry.name.startsWith('.') || entry.name === 'archive') continue;
      const proposalPath = path.join(changesPath, entry.name, 'proposal.md');
      try {
        await fs.access(proposalPath);
        result.push(entry.name);
      } catch {
        // skip directories without proposal.md
      }
    }
    return result.sort();
  } catch {
    return [];
  }
}

export async function getSpecIds(root: string = process.cwd()): Promise<string[]> {
  const specsPath = path.join(root, 'openspec', 'specs');
  const result: string[] = [];
  try {
    const entries = await fs.readdir(specsPath, { withFileTypes: true });
    for (const entry of entries) {
      if (!entry.isDirectory() || entry.name.startsWith('.')) continue;
      const specFile = path.join(specsPath, entry.name, 'spec.md');
      try {
        await fs.access(specFile);
        result.push(entry.name);
      } catch {
        // ignore
      }
    }
  } catch {
    // ignore
  }
  return result.sort();
}

export async function getArchivedChangeIds(root: string = process.cwd()): Promise<string[]> {
  const archivePath = path.join(root, 'openspec', 'changes', 'archive');
  try {
    const entries = await fs.readdir(archivePath, { withFileTypes: true });
    const result: string[] = [];
    for (const entry of entries) {
      if (!entry.isDirectory() || entry.name.startsWith('.')) continue;
      const proposalPath = path.join(archivePath, entry.name, 'proposal.md');
      try {
        await fs.access(proposalPath);
        result.push(entry.name);
      } catch {
        // skip directories without proposal.md
      }
    }
    return result.sort();
  } catch {
    return [];
  }
}




================================================
FILE: src/utils/match.ts
================================================
export function nearestMatches(input: string, candidates: string[], max: number = 5): string[] {
  const scored = candidates.map(candidate => ({ candidate, distance: levenshtein(input, candidate) }));
  scored.sort((a, b) => a.distance - b.distance);
  return scored.slice(0, max).map(s => s.candidate);
}

export function levenshtein(a: string, b: string): number {
  const m = a.length;
  const n = b.length;
  const dp: number[][] = Array.from({ length: m + 1 }, () => Array(n + 1).fill(0));
  for (let i = 0; i <= m; i++) dp[i][0] = i;
  for (let j = 0; j <= n; j++) dp[0][j] = j;
  for (let i = 1; i <= m; i++) {
    for (let j = 1; j <= n; j++) {
      const cost = a[i - 1] === b[j - 1] ? 0 : 1;
      dp[i][j] = Math.min(
        dp[i - 1][j] + 1,
        dp[i][j - 1] + 1,
        dp[i - 1][j - 1] + cost
      );
    }
  }
  return dp[m][n];
}





================================================
FILE: src/utils/shell-detection.ts
================================================
/**
 * Supported shell types for completion generation
 */
export type SupportedShell = 'zsh' | 'bash' | 'fish' | 'powershell';

/**
 * Result of shell detection
 */
export interface ShellDetectionResult {
  /** The detected shell if supported, otherwise undefined */
  shell: SupportedShell | undefined;
  /** The raw shell name detected (even if unsupported), or undefined if nothing detected */
  detected: string | undefined;
}

/**
 * Detects the current user's shell based on environment variables
 *
 * @returns Detection result with supported shell and raw detected name
 */
export function detectShell(): ShellDetectionResult {
  // Try SHELL environment variable first (Unix-like systems)
  const shellPath = process.env.SHELL;

  if (shellPath) {
    const shellName = shellPath.toLowerCase();

    if (shellName.includes('zsh')) {
      return { shell: 'zsh', detected: 'zsh' };
    }
    if (shellName.includes('bash')) {
      return { shell: 'bash', detected: 'bash' };
    }
    if (shellName.includes('fish')) {
      return { shell: 'fish', detected: 'fish' };
    }

    // Shell detected but not supported
    // Extract shell name from path (e.g., /bin/tcsh -> tcsh)
    const match = shellPath.match(/\/([^/]+)$/);
    const detectedName = match ? match[1] : shellPath;
    return { shell: undefined, detected: detectedName };
  }

  // Check for PowerShell on Windows
  // PSModulePath is a reliable PowerShell-specific environment variable
  if (process.env.PSModulePath || process.platform === 'win32') {
    const comspec = process.env.COMSPEC?.toLowerCase();

    // If PSModulePath exists, we're definitely in PowerShell
    if (process.env.PSModulePath) {
      return { shell: 'powershell', detected: 'powershell' };
    }

    // On Windows without PSModulePath, we might be in cmd.exe
    if (comspec?.includes('cmd.exe')) {
      return { shell: undefined, detected: 'cmd.exe' };
    }
  }

  return { shell: undefined, detected: undefined };
}



================================================
FILE: src/utils/task-progress.ts
================================================
import { promises as fs } from 'fs';
import path from 'path';

const TASK_PATTERN = /^[-*]\s+\[[\sx]\]/i;
const COMPLETED_TASK_PATTERN = /^[-*]\s+\[x\]/i;

export interface TaskProgress {
  total: number;
  completed: number;
}

export function countTasksFromContent(content: string): TaskProgress {
  const lines = content.split('\n');
  let total = 0;
  let completed = 0;
  for (const line of lines) {
    if (line.match(TASK_PATTERN)) {
      total++;
      if (line.match(COMPLETED_TASK_PATTERN)) {
        completed++;
      }
    }
  }
  return { total, completed };
}

export async function getTaskProgressForChange(changesDir: string, changeName: string): Promise<TaskProgress> {
  const tasksPath = path.join(changesDir, changeName, 'tasks.md');
  try {
    const content = await fs.readFile(tasksPath, 'utf-8');
    return countTasksFromContent(content);
  } catch {
    return { total: 0, completed: 0 };
  }
}

export function formatTaskStatus(progress: TaskProgress): string {
  if (progress.total === 0) return 'No tasks';
  if (progress.completed === progress.total) return 'âœ“ Complete';
  return `${progress.completed}/${progress.total} tasks`;
}





================================================
FILE: test/cli-e2e/basic.test.ts
================================================
import { afterAll, describe, it, expect } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { tmpdir } from 'os';
import { runCLI, cliProjectRoot } from '../helpers/run-cli.js';
import { AI_TOOLS } from '../../src/core/config.js';

async function fileExists(filePath: string): Promise<boolean> {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}

const tempRoots: string[] = [];

async function prepareFixture(fixtureName: string): Promise<string> {
  const base = await fs.mkdtemp(path.join(tmpdir(), 'openspec-cli-e2e-'));
  tempRoots.push(base);
  const projectDir = path.join(base, 'project');
  await fs.mkdir(projectDir, { recursive: true });
  const fixtureDir = path.join(cliProjectRoot, 'test', 'fixtures', fixtureName);
  await fs.cp(fixtureDir, projectDir, { recursive: true });
  return projectDir;
}

afterAll(async () => {
  await Promise.all(tempRoots.map((dir) => fs.rm(dir, { recursive: true, force: true })));
});

describe('openspec CLI e2e basics', () => {
  it('shows help output', async () => {
    const result = await runCLI(['--help']);
    expect(result.exitCode).toBe(0);
    expect(result.stdout).toContain('Usage: openspec');
    expect(result.stderr).toBe('');

  });

  it('shows dynamic tool ids in init help', async () => {
    const result = await runCLI(['init', '--help']);
    expect(result.exitCode).toBe(0);

    const expectedTools = AI_TOOLS.filter((tool) => tool.available)
      .map((tool) => tool.value)
      .join(', ');
    const normalizedOutput = result.stdout.replace(/\s+/g, ' ').trim();
    expect(normalizedOutput).toContain(
      `Use "all", "none", or a comma-separated list of: ${expectedTools}`
    );
  });

  it('reports the package version', async () => {
    const pkgRaw = await fs.readFile(path.join(cliProjectRoot, 'package.json'), 'utf-8');
    const pkg = JSON.parse(pkgRaw);
    const result = await runCLI(['--version']);
    expect(result.exitCode).toBe(0);
    expect(result.stdout.trim()).toBe(pkg.version);
  });

  it('validates the tmp-init fixture with --all --json', async () => {
    const projectDir = await prepareFixture('tmp-init');
    const result = await runCLI(['validate', '--all', '--json'], { cwd: projectDir });
    expect(result.exitCode).toBe(0);
    const output = result.stdout.trim();
    expect(output).not.toBe('');
    const json = JSON.parse(output);
    expect(json.summary?.totals?.failed).toBe(0);
    expect(json.items.some((item: any) => item.id === 'c1' && item.type === 'change')).toBe(true);
  });

  it('returns an error for unknown items in the fixture', async () => {
    const projectDir = await prepareFixture('tmp-init');
    const result = await runCLI(['validate', 'does-not-exist'], { cwd: projectDir });
    expect(result.exitCode).toBe(1);
    expect(result.stderr).toContain("Unknown item 'does-not-exist'");
  });

  describe('init command non-interactive options', () => {
    it('initializes with --tools all option', async () => {
      const projectDir = await prepareFixture('tmp-init');
      const emptyProjectDir = path.join(projectDir, '..', 'empty-project');
      await fs.mkdir(emptyProjectDir, { recursive: true });

      const codexHome = path.join(emptyProjectDir, '.codex');
      const result = await runCLI(['init', '--tools', 'all'], {
        cwd: emptyProjectDir,
        env: { CODEX_HOME: codexHome },
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Tool summary:');

      // Check that tool configurations were created
      const claudePath = path.join(emptyProjectDir, 'CLAUDE.md');
      const cursorProposal = path.join(emptyProjectDir, '.cursor/commands/openspec-proposal.md');
      expect(await fileExists(claudePath)).toBe(true);
      expect(await fileExists(cursorProposal)).toBe(true);
    });

    it('initializes with --tools list option', async () => {
      const projectDir = await prepareFixture('tmp-init');
      const emptyProjectDir = path.join(projectDir, '..', 'empty-project');
      await fs.mkdir(emptyProjectDir, { recursive: true });

      const result = await runCLI(['init', '--tools', 'claude'], { cwd: emptyProjectDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Tool summary:');

      const claudePath = path.join(emptyProjectDir, 'CLAUDE.md');
      const cursorProposal = path.join(emptyProjectDir, '.cursor/commands/openspec-proposal.md');
      expect(await fileExists(claudePath)).toBe(true);
      expect(await fileExists(cursorProposal)).toBe(false); // Not selected
    });

    it('initializes with --tools none option', async () => {
      const projectDir = await prepareFixture('tmp-init');
      const emptyProjectDir = path.join(projectDir, '..', 'empty-project');
      await fs.mkdir(emptyProjectDir, { recursive: true });

      const result = await runCLI(['init', '--tools', 'none'], { cwd: emptyProjectDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Tool summary:');

      const claudePath = path.join(emptyProjectDir, 'CLAUDE.md');
      const cursorProposal = path.join(emptyProjectDir, '.cursor/commands/openspec-proposal.md');
      const rootAgentsPath = path.join(emptyProjectDir, 'AGENTS.md');

      expect(await fileExists(rootAgentsPath)).toBe(true);
      expect(await fileExists(claudePath)).toBe(false);
      expect(await fileExists(cursorProposal)).toBe(false);
    });

    it('returns error for invalid tool names', async () => {
      const projectDir = await prepareFixture('tmp-init');
      const emptyProjectDir = path.join(projectDir, '..', 'empty-project');
      await fs.mkdir(emptyProjectDir, { recursive: true });

      const result = await runCLI(['init', '--tools', 'invalid-tool'], { cwd: emptyProjectDir });
      expect(result.exitCode).toBe(1);
      expect(result.stderr).toContain('Invalid tool(s): invalid-tool');
      expect(result.stderr).toContain('Available values:');
    });

    it('returns error when combining reserved keywords with explicit ids', async () => {
      const projectDir = await prepareFixture('tmp-init');
      const emptyProjectDir = path.join(projectDir, '..', 'empty-project');
      await fs.mkdir(emptyProjectDir, { recursive: true });

      const result = await runCLI(['init', '--tools', 'all,claude'], { cwd: emptyProjectDir });
      expect(result.exitCode).toBe(1);
      expect(result.stderr).toContain('Cannot combine reserved values "all" or "none" with specific tool IDs');
    });
  });
});



================================================
FILE: test/commands/artifact-workflow.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { runCLI } from '../helpers/run-cli.js';

describe('artifact-workflow CLI commands', () => {
  let tempDir: string;
  let changesDir: string;

  beforeEach(async () => {
    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'openspec-artifact-workflow-'));
    changesDir = path.join(tempDir, 'openspec', 'changes');
    await fs.mkdir(changesDir, { recursive: true });
  });

  afterEach(async () => {
    if (tempDir) {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  /**
   * Gets combined output from CLI result (ora outputs to stdout).
   */
  function getOutput(result: { stdout: string; stderr: string }): string {
    return result.stdout + result.stderr;
  }

  /**
   * Normalizes path separators to forward slashes for cross-platform assertions.
   */
  function normalizePaths(str: string): string {
    return str.replace(/\\/g, '/');
  }

  /**
   * Creates a test change with the specified artifacts completed.
   * Note: An "active" change requires at least a proposal.md file to be detected.
   * If no artifacts are specified, we create an empty proposal to make it detectable.
   */
  async function createTestChange(
    changeName: string,
    artifacts: ('proposal' | 'design' | 'specs' | 'tasks')[] = []
  ): Promise<string> {
    const changeDir = path.join(changesDir, changeName);
    await fs.mkdir(changeDir, { recursive: true });

    // Always create proposal.md for the change to be detected as active
    // Content varies based on whether 'proposal' is in artifacts list
    const proposalContent = artifacts.includes('proposal')
      ? '## Why\nTest proposal content that is long enough.\n\n## What Changes\n- **test:** Something'
      : '## Why\nMinimal proposal.\n\n## What Changes\n- **test:** Placeholder';
    await fs.writeFile(path.join(changeDir, 'proposal.md'), proposalContent);

    if (artifacts.includes('design')) {
      await fs.writeFile(path.join(changeDir, 'design.md'), '# Design\n\nTechnical design.');
    }

    if (artifacts.includes('specs')) {
      // specs artifact uses glob pattern "specs/*.md" - files directly in specs/ directory
      const specsDir = path.join(changeDir, 'specs');
      await fs.mkdir(specsDir, { recursive: true });
      await fs.writeFile(path.join(specsDir, 'test-spec.md'), '## Purpose\nTest spec.');
    }

    if (artifacts.includes('tasks')) {
      await fs.writeFile(path.join(changeDir, 'tasks.md'), '## Tasks\n- [ ] Task 1');
    }

    return changeDir;
  }

  describe('status command', () => {
    it('shows status for scaffolded change without proposal.md', async () => {
      // Create empty change directory (no proposal.md)
      const changeDir = path.join(changesDir, 'scaffolded-change');
      await fs.mkdir(changeDir, { recursive: true });

      const result = await runCLI(['status', '--change', 'scaffolded-change'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('scaffolded-change');
      expect(result.stdout).toContain('0/4 artifacts complete');
    });

    it('shows status for a change with proposal only', async () => {
      // createTestChange always creates proposal.md, so this has 1 artifact complete
      await createTestChange('minimal-change');

      const result = await runCLI(['status', '--change', 'minimal-change'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('minimal-change');
      expect(result.stdout).toContain('spec-driven');
      expect(result.stdout).toContain('1/4 artifacts complete');
    });

    it('shows status for a change with proposal and design', async () => {
      await createTestChange('partial-change', ['proposal', 'design']);

      const result = await runCLI(['status', '--change', 'partial-change'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('2/4 artifacts complete');
      expect(result.stdout).toContain('[x]');
    });

    it('outputs JSON when --json flag is used', async () => {
      await createTestChange('json-change', ['proposal', 'design']);

      const result = await runCLI(['status', '--change', 'json-change', '--json'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      expect(json.changeName).toBe('json-change');
      expect(json.schemaName).toBe('spec-driven');
      expect(json.isComplete).toBe(false);
      expect(Array.isArray(json.artifacts)).toBe(true);
      expect(json.artifacts).toHaveLength(4);

      const proposalArtifact = json.artifacts.find((a: any) => a.id === 'proposal');
      expect(proposalArtifact.status).toBe('done');
    });

    it('shows complete status when all artifacts are done', async () => {
      await createTestChange('complete-change', ['proposal', 'design', 'specs', 'tasks']);

      const result = await runCLI(['status', '--change', 'complete-change'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('4/4 artifacts complete');
      expect(result.stdout).toContain('All artifacts complete!');
    });

    it('errors when --change is missing and lists available changes', async () => {
      await createTestChange('some-change');

      const result = await runCLI(['status'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('Missing required option --change');
      expect(output).toContain('some-change');
    });

    it('errors for unknown change name and lists available changes', async () => {
      await createTestChange('existing-change');

      const result = await runCLI(['status', '--change', 'nonexistent'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain("Change 'nonexistent' not found");
      expect(output).toContain('existing-change');
    });

    it('supports --schema option', async () => {
      await createTestChange('tdd-change');

      const result = await runCLI(['status', '--change', 'tdd-change', '--schema', 'tdd'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('tdd');
    });

    it('errors for unknown schema', async () => {
      await createTestChange('test-change');

      const result = await runCLI(['status', '--change', 'test-change', '--schema', 'unknown'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain("Schema 'unknown' not found");
    });

    it('rejects path traversal in change name', async () => {
      const result = await runCLI(['status', '--change', '../foo'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('Invalid change name');
    });

    it('rejects absolute path in change name', async () => {
      const result = await runCLI(['status', '--change', '/etc/passwd'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('Invalid change name');
    });

    it('rejects slashes in change name', async () => {
      const result = await runCLI(['status', '--change', 'foo/bar'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('Invalid change name');
    });
  });

  describe('instructions command', () => {
    it('shows instructions for proposal on scaffolded change', async () => {
      // Create empty change directory (no proposal.md)
      const changeDir = path.join(changesDir, 'scaffolded-change');
      await fs.mkdir(changeDir, { recursive: true });

      const result = await runCLI(['instructions', 'proposal', '--change', 'scaffolded-change'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('<artifact id="proposal"');
      expect(result.stdout).toContain('proposal.md');
      expect(result.stdout).toContain('<template>');
    });

    it('shows instructions for design artifact', async () => {
      await createTestChange('instr-change');

      const result = await runCLI(['instructions', 'design', '--change', 'instr-change'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('<artifact id="design"');
      expect(result.stdout).toContain('design.md');
      expect(result.stdout).toContain('<template>');
    });

    it('shows blocked warning for artifact with unmet dependencies', async () => {
      // tasks depends on design and specs, which are not done yet
      await createTestChange('blocked-change');

      const result = await runCLI(['instructions', 'tasks', '--change', 'blocked-change'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('<warning>');
      expect(result.stdout).toContain('status="missing"');
    });

    it('outputs JSON for instructions', async () => {
      await createTestChange('json-instr', ['proposal']);

      const result = await runCLI(['instructions', 'design', '--change', 'json-instr', '--json'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      expect(json.artifactId).toBe('design');
      expect(json.outputPath).toContain('design.md');
      expect(typeof json.template).toBe('string');
      expect(Array.isArray(json.dependencies)).toBe(true);
    });

    it('errors when artifact argument is missing', async () => {
      await createTestChange('test-change');

      const result = await runCLI(['instructions', '--change', 'test-change'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('Missing required argument <artifact>');
      expect(output).toContain('Valid artifacts');
    });

    it('errors for unknown artifact', async () => {
      await createTestChange('test-change');

      const result = await runCLI(['instructions', 'unknown-artifact', '--change', 'test-change'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain("Artifact 'unknown-artifact' not found");
      expect(output).toContain('Valid artifacts');
    });
  });

  describe('templates command', () => {
    it('shows template paths for default schema', async () => {
      const result = await runCLI(['templates'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Schema: spec-driven');
      expect(result.stdout).toContain('proposal:');
      expect(result.stdout).toContain('design:');
      expect(result.stdout).toContain('specs:');
      expect(result.stdout).toContain('tasks:');
    });

    it('shows template paths for custom schema', async () => {
      const result = await runCLI(['templates', '--schema', 'tdd'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Schema: tdd');
      expect(result.stdout).toContain('spec:');
      expect(result.stdout).toContain('tests:');
    });

    it('outputs JSON mapping of templates', async () => {
      const result = await runCLI(['templates', '--json'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      expect(json.proposal).toBeDefined();
      expect(json.proposal.path).toContain('proposal.md');
      expect(json.proposal.source).toBe('package');
    });

    it('errors for unknown schema', async () => {
      const result = await runCLI(['templates', '--schema', 'nonexistent'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain("Schema 'nonexistent' not found");
    });
  });

  describe('new change command', () => {
    it('creates a new change directory', async () => {
      const result = await runCLI(['new', 'change', 'my-new-feature'], { cwd: tempDir });
      expect(result.exitCode).toBe(0);
      const output = getOutput(result);
      expect(output).toContain("Created change 'my-new-feature'");

      const changeDir = path.join(changesDir, 'my-new-feature');
      const stat = await fs.stat(changeDir);
      expect(stat.isDirectory()).toBe(true);
    });

    it('creates README.md when --description is provided', async () => {
      const result = await runCLI(
        ['new', 'change', 'described-feature', '--description', 'This is a test feature'],
        { cwd: tempDir }
      );
      expect(result.exitCode).toBe(0);

      const readmePath = path.join(changesDir, 'described-feature', 'README.md');
      const content = await fs.readFile(readmePath, 'utf-8');
      expect(content).toContain('described-feature');
      expect(content).toContain('This is a test feature');
    });

    it('errors for invalid change name with spaces', async () => {
      const result = await runCLI(['new', 'change', 'invalid name'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('Error');
    });

    it('errors for duplicate change name', async () => {
      await createTestChange('existing-change');

      const result = await runCLI(['new', 'change', 'existing-change'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('exists');
    });

    it('errors when name argument is missing', async () => {
      const result = await runCLI(['new', 'change'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
    });
  });

  describe('instructions apply command', () => {
    it('shows apply instructions for spec-driven schema with tasks', async () => {
      await createTestChange('apply-change', ['proposal', 'design', 'specs', 'tasks']);

      const result = await runCLI(['instructions', 'apply', '--change', 'apply-change'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('## Apply: apply-change');
      expect(result.stdout).toContain('Schema: spec-driven');
      expect(result.stdout).toContain('### Context Files');
      expect(result.stdout).toContain('### Instruction');
    });

    it('shows blocked state when required artifacts are missing', async () => {
      // Only create proposal - missing tasks (required by spec-driven apply block)
      await createTestChange('blocked-apply', ['proposal']);

      const result = await runCLI(['instructions', 'apply', '--change', 'blocked-apply'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Blocked');
      expect(result.stdout).toContain('Missing artifacts: tasks');
    });

    it('outputs JSON for apply instructions', async () => {
      await createTestChange('json-apply', ['proposal', 'design', 'specs', 'tasks']);

      const result = await runCLI(
        ['instructions', 'apply', '--change', 'json-apply', '--json'],
        { cwd: tempDir }
      );
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      expect(json.changeName).toBe('json-apply');
      expect(json.schemaName).toBe('spec-driven');
      expect(json.state).toBe('ready');
      expect(json.contextFiles).toBeDefined();
      expect(typeof json.contextFiles).toBe('object');
    });

    it('shows schema instruction from apply block', async () => {
      await createTestChange('instr-apply', ['proposal', 'design', 'specs', 'tasks']);

      const result = await runCLI(['instructions', 'apply', '--change', 'instr-apply'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      // Should show the instruction from spec-driven schema apply block
      expect(result.stdout).toContain('work through pending tasks');
    });

    it('shows all_done state when all tasks are complete', async () => {
      const changeDir = await createTestChange('done-apply', [
        'proposal',
        'design',
        'specs',
        'tasks',
      ]);
      // Overwrite tasks with all completed
      await fs.writeFile(
        path.join(changeDir, 'tasks.md'),
        '## Tasks\n- [x] Task 1\n- [x] Task 2'
      );

      const result = await runCLI(['instructions', 'apply', '--change', 'done-apply'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('complete âœ“');
      expect(result.stdout).toContain('ready to be archived');
    });

    it('uses tdd schema apply configuration', async () => {
      // Create a TDD-style change with spec and tests
      const changeDir = path.join(changesDir, 'tdd-apply');
      await fs.mkdir(changeDir, { recursive: true });
      await fs.writeFile(path.join(changeDir, 'spec.md'), '## Feature\nTest spec.');
      const testsDir = path.join(changeDir, 'tests');
      await fs.mkdir(testsDir, { recursive: true });
      await fs.writeFile(path.join(testsDir, 'test.test.ts'), 'test("works", () => {})');

      const result = await runCLI(
        ['instructions', 'apply', '--change', 'tdd-apply', '--schema', 'tdd'],
        { cwd: tempDir }
      );
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('Schema: tdd');
      // TDD schema has no task tracking, so should show schema instruction
      expect(result.stdout).toContain('Run tests to see failures');
    });

    it('spec-driven schema uses apply block configuration', async () => {
      // Verify that spec-driven schema uses its apply block (requires: [tasks])
      await createTestChange('apply-config-test', ['proposal', 'design', 'specs', 'tasks']);

      const result = await runCLI(
        ['instructions', 'apply', '--change', 'apply-config-test', '--json'],
        { cwd: tempDir }
      );
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      // spec-driven schema has apply block with requires: [tasks], so should be ready
      expect(json.schemaName).toBe('spec-driven');
      expect(json.state).toBe('ready');
    });

    it('fallback: requires all artifacts when schema has no apply block', async () => {
      // Create a minimal schema without an apply block in user schemas dir
      const userDataDir = path.join(tempDir, 'user-data');
      const noApplySchemaDir = path.join(userDataDir, 'openspec', 'schemas', 'no-apply');
      const templatesDir = path.join(noApplySchemaDir, 'templates');
      await fs.mkdir(templatesDir, { recursive: true });

      // Minimal schema with 2 artifacts, no apply block
      const schemaContent = `
name: no-apply
version: 1
description: Test schema without apply block
artifacts:
  - id: first
    generates: first.md
    description: First artifact
    template: first.md
    requires: []
  - id: second
    generates: second.md
    description: Second artifact
    template: second.md
    requires: [first]
`;
      await fs.writeFile(path.join(noApplySchemaDir, 'schema.yaml'), schemaContent);
      await fs.writeFile(path.join(templatesDir, 'first.md'), '# First\n');
      await fs.writeFile(path.join(templatesDir, 'second.md'), '# Second\n');

      // Create a change with only the first artifact (missing second)
      const changeDir = path.join(changesDir, 'no-apply-test');
      await fs.mkdir(changeDir, { recursive: true });
      await fs.writeFile(path.join(changeDir, 'first.md'), '# First artifact content');

      // Run with XDG_DATA_HOME pointing to our temp user data dir
      const result = await runCLI(
        ['instructions', 'apply', '--change', 'no-apply-test', '--schema', 'no-apply', '--json'],
        {
          cwd: tempDir,
          env: { XDG_DATA_HOME: userDataDir },
        }
      );
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      // Without apply block, fallback requires ALL artifacts - second is missing
      expect(json.schemaName).toBe('no-apply');
      expect(json.state).toBe('blocked');
      expect(json.missingArtifacts).toContain('second');
    });

    it('fallback: ready when all artifacts exist for schema without apply block', async () => {
      // Create a minimal schema without an apply block
      const userDataDir = path.join(tempDir, 'user-data-2');
      const noApplySchemaDir = path.join(userDataDir, 'openspec', 'schemas', 'no-apply-full');
      const templatesDir = path.join(noApplySchemaDir, 'templates');
      await fs.mkdir(templatesDir, { recursive: true });

      const schemaContent = `
name: no-apply-full
version: 1
description: Test schema without apply block
artifacts:
  - id: only
    generates: only.md
    description: Only artifact
    template: only.md
    requires: []
`;
      await fs.writeFile(path.join(noApplySchemaDir, 'schema.yaml'), schemaContent);
      await fs.writeFile(path.join(templatesDir, 'only.md'), '# Only\n');

      // Create a change with the artifact present
      const changeDir = path.join(changesDir, 'no-apply-full-test');
      await fs.mkdir(changeDir, { recursive: true });
      await fs.writeFile(path.join(changeDir, 'only.md'), '# Content');

      const result = await runCLI(
        ['instructions', 'apply', '--change', 'no-apply-full-test', '--schema', 'no-apply-full', '--json'],
        {
          cwd: tempDir,
          env: { XDG_DATA_HOME: userDataDir },
        }
      );
      expect(result.exitCode).toBe(0);

      const json = JSON.parse(result.stdout);
      // All artifacts exist, should be ready with default instruction
      expect(json.schemaName).toBe('no-apply-full');
      expect(json.state).toBe('ready');
      expect(json.instruction).toContain('All required artifacts complete');
    });
  });

  describe('help text', () => {
    it('marks status command as experimental in help', async () => {
      const result = await runCLI(['status', '--help']);
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('[Experimental]');
    });

    it('marks instructions command as experimental in help', async () => {
      const result = await runCLI(['instructions', '--help']);
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('[Experimental]');
    });

    it('marks templates command as experimental in help', async () => {
      const result = await runCLI(['templates', '--help']);
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('[Experimental]');
    });

    it('marks new command as experimental in help', async () => {
      const result = await runCLI(['new', '--help']);
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('[Experimental]');
    });
  });

  describe('experimental command', () => {
    it('requires --tool flag', async () => {
      const result = await runCLI(['experimental'], { cwd: tempDir });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('--tool');
    });

    it('errors for unknown tool', async () => {
      const result = await runCLI(['experimental', '--tool', 'unknown-tool'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain("Unknown tool 'unknown-tool'");
    });

    it('errors for tool without skillsDir', async () => {
      // Using 'agents' which doesn't have skillsDir configured
      const result = await runCLI(['experimental', '--tool', 'agents'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(1);
      const output = getOutput(result);
      expect(output).toContain('does not support skill generation');
    });

    it('creates skills for Claude tool', async () => {
      const result = await runCLI(['experimental', '--tool', 'claude'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      const output = normalizePaths(getOutput(result));
      expect(output).toContain('Claude Code');
      expect(output).toContain('.claude/');

      // Verify skill files were created
      const skillFile = path.join(tempDir, '.claude', 'skills', 'openspec-explore', 'SKILL.md');
      const stat = await fs.stat(skillFile);
      expect(stat.isFile()).toBe(true);
    });

    it('creates skills for Cursor tool', async () => {
      const result = await runCLI(['experimental', '--tool', 'cursor'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      const output = normalizePaths(getOutput(result));
      expect(output).toContain('Cursor');
      expect(output).toContain('.cursor/');

      // Verify skill files were created
      const skillFile = path.join(tempDir, '.cursor', 'skills', 'openspec-explore', 'SKILL.md');
      const stat = await fs.stat(skillFile);
      expect(stat.isFile()).toBe(true);

      // Verify commands were created with Cursor format
      const commandFile = path.join(tempDir, '.cursor', 'commands', 'opsx-explore.md');
      const content = await fs.readFile(commandFile, 'utf-8');
      expect(content).toContain('name: /opsx-explore');
    });

    it('creates skills for Windsurf tool', async () => {
      const result = await runCLI(['experimental', '--tool', 'windsurf'], {
        cwd: tempDir,
      });
      expect(result.exitCode).toBe(0);
      const output = normalizePaths(getOutput(result));
      expect(output).toContain('Windsurf');
      expect(output).toContain('.windsurf/');

      // Verify skill files were created
      const skillFile = path.join(tempDir, '.windsurf', 'skills', 'openspec-explore', 'SKILL.md');
      const stat = await fs.stat(skillFile);
      expect(stat.isFile()).toBe(true);
    });
  });

  describe('project config integration', () => {
    describe('new change uses config schema', () => {
      it('creates change with schema from project config', async () => {
        // Create project config with tdd schema
        // Note: changesDir is already at tempDir/openspec/changes (created in beforeEach)
        await fs.writeFile(
          path.join(tempDir, 'openspec', 'config.yaml'),
          'schema: tdd\n'
        );

        // Create a new change without specifying schema
        const result = await runCLI(['new', 'change', 'test-change'], { cwd: tempDir, timeoutMs: 30000 });
        expect(result.exitCode).toBe(0);

        // Verify the change was created with tdd schema
        const metadataPath = path.join(changesDir, 'test-change', '.openspec.yaml');
        const metadata = await fs.readFile(metadataPath, 'utf-8');
        expect(metadata).toContain('schema: tdd');
      }, 60000);

      it('CLI schema overrides config schema', async () => {
        // Create project config with tdd schema
        // Note: openspec directory already exists (from changesDir creation in beforeEach)
        await fs.writeFile(
          path.join(tempDir, 'openspec', 'config.yaml'),
          'schema: tdd\n'
        );

        // Create change with explicit schema
        const result = await runCLI(
          ['new', 'change', 'override-test', '--schema', 'spec-driven'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(result.exitCode).toBe(0);

        // Verify the change uses the CLI-specified schema
        const metadataPath = path.join(changesDir, 'override-test', '.openspec.yaml');
        const metadata = await fs.readFile(metadataPath, 'utf-8');
        expect(metadata).toContain('schema: spec-driven');
      }, 60000);
    });

    describe('instructions command with config', () => {
      it('injects context and rules from config into instructions', async () => {
        // Create project config with context and rules
        // Note: openspec directory already exists (from changesDir creation in beforeEach)
        await fs.writeFile(
          path.join(tempDir, 'openspec', 'config.yaml'),
          `schema: spec-driven
context: |
  Tech stack: TypeScript, React
  API style: RESTful
rules:
  proposal:
    - Include rollback plan
    - Identify affected teams
`
        );

        // Create a test change
        await createTestChange('config-test');

        // Get instructions for proposal
        const result = await runCLI(
          ['instructions', 'proposal', '--change', 'config-test'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(result.exitCode).toBe(0);

        // Verify context is injected
        expect(result.stdout).toContain('Tech stack: TypeScript, React');
        expect(result.stdout).toContain('API style: RESTful');

        // Verify rules are injected for proposal
        expect(result.stdout).toContain('Include rollback plan');
        expect(result.stdout).toContain('Identify affected teams');
      }, 60000);

      it('does not inject rules for non-matching artifact', async () => {
        // Create project config with rules only for proposal
        // Note: openspec directory already exists (from changesDir creation in beforeEach)
        await fs.writeFile(
          path.join(tempDir, 'openspec', 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Include rollback plan
`
        );

        // Create a test change
        await createTestChange('non-matching-test');

        // Get instructions for design (not proposal)
        const result = await runCLI(
          ['instructions', 'design', '--change', 'non-matching-test'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(result.exitCode).toBe(0);

        // Verify rules are NOT injected for design
        expect(result.stdout).not.toContain('Include rollback plan');
      }, 60000);
    });

    describe('backwards compatibility', () => {
      it('existing changes work without config file', async () => {
        // Create change without any config file
        await createTestChange('no-config-change', ['proposal']);

        // Status command should work
        const statusResult = await runCLI(
          ['status', '--change', 'no-config-change'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(statusResult.exitCode).toBe(0);
        expect(statusResult.stdout).toContain('no-config-change');
        expect(statusResult.stdout).toContain('spec-driven'); // Default schema

        // Instructions command should work
        const instrResult = await runCLI(
          ['instructions', 'design', '--change', 'no-config-change'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(instrResult.exitCode).toBe(0);
        expect(instrResult.stdout).toContain('<artifact');
      }, 60000);

      it('changes with metadata work without config file', async () => {
        // Create change with explicit schema in metadata
        const changeDir = await createTestChange('metadata-only-change');
        await fs.writeFile(
          path.join(changeDir, '.openspec.yaml'),
          'schema: tdd\ncreated: "2025-01-05"\n'
        );

        // Status should use schema from metadata
        const result = await runCLI(
          ['status', '--change', 'metadata-only-change'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(result.exitCode).toBe(0);
        expect(result.stdout).toContain('tdd');
      }, 60000);
    });

    describe('config changes reflected immediately', () => {
      it('config changes are reflected without restart', async () => {
        // Create initial config
        // Note: openspec directory already exists (from changesDir creation in beforeEach)
        await fs.writeFile(
          path.join(tempDir, 'openspec', 'config.yaml'),
          `schema: spec-driven
context: Initial context
`
        );

        // Create a test change
        await createTestChange('immediate-test');

        // Get instructions - should have initial context
        const result1 = await runCLI(
          ['instructions', 'proposal', '--change', 'immediate-test'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(result1.exitCode).toBe(0);
        expect(result1.stdout).toContain('Initial context');

        // Update config
        await fs.writeFile(
          path.join(tempDir, 'openspec', 'config.yaml'),
          `schema: spec-driven
context: Updated context
`
        );

        // Get instructions again - should have updated context
        const result2 = await runCLI(
          ['instructions', 'proposal', '--change', 'immediate-test'],
          { cwd: tempDir, timeoutMs: 30000 }
        );
        expect(result2.exitCode).toBe(0);
        expect(result2.stdout).toContain('Updated context');
        expect(result2.stdout).not.toContain('Initial context');
      }, 60000);
    });
  });
});



================================================
FILE: test/commands/change.interactive-show.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

describe('change show (interactive behavior)', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-change-show-tmp');
  const changesDir = path.join(testDir, 'openspec', 'changes');
  const bin = path.join(projectRoot, 'bin', 'openspec.js');


  beforeEach(async () => {
    await fs.mkdir(changesDir, { recursive: true });
    const content = `# Change: Demo\n\n## Why\n\n## What Changes\n- x`;
    await fs.mkdir(path.join(changesDir, 'demo'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'demo', 'proposal.md'), content, 'utf-8');
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('prints list hint and exits non-zero when no arg and non-interactive', () => {
    const originalCwd = process.cwd();
    const originalEnv = { ...process.env };
    try {
      process.chdir(testDir);
      process.env.OPEN_SPEC_INTERACTIVE = '0';
      let err: any;
      try {
        execSync(`node ${bin} change show`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      expect(err.stderr.toString()).toContain('Available IDs:');
      expect(err.stderr.toString()).toContain('openspec change list');
    } finally {
      process.chdir(originalCwd);
      process.env = originalEnv;
    }
  });
});





================================================
FILE: test/commands/change.interactive-validate.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

// Note: We cannot truly simulate TTY prompts in this test runner easily.
// Instead, we verify non-interactive fallback behavior and basic invocation.

describe('change validate (interactive behavior)', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-change-validate-tmp');
  const changesDir = path.join(testDir, 'openspec', 'changes');
  const bin = path.join(projectRoot, 'bin', 'openspec.js');


  beforeEach(async () => {
    await fs.mkdir(changesDir, { recursive: true });
    const content = `# Change: Demo\n\n## Why\nBecause reasons that are sufficiently long.\n\n## What Changes\n- **spec-x:** Add something`;
    await fs.mkdir(path.join(changesDir, 'demo'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'demo', 'proposal.md'), content, 'utf-8');
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('prints list hint and exits non-zero when no arg and non-interactive', () => {
    const originalCwd = process.cwd();
    const originalEnv = { ...process.env };
    try {
      process.chdir(testDir);
      process.env.OPEN_SPEC_INTERACTIVE = '0';
      let err: any;
      try {
        execSync(`node ${bin} change validate`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      expect(err.stderr.toString()).toContain('Available IDs:');
      expect(err.stderr.toString()).toContain('openspec change list');
    } finally {
      process.chdir(originalCwd);
      process.env = originalEnv;
    }
  });
});





================================================
FILE: test/commands/completion.test.ts
================================================
import { describe, it, expect, beforeEach, vi, afterEach } from 'vitest';
import { CompletionCommand } from '../../src/commands/completion.js';
import * as shellDetection from '../../src/utils/shell-detection.js';

// Mock the shell detection module
vi.mock('../../src/utils/shell-detection.js', () => ({
  detectShell: vi.fn(),
}));

// Mock the ZshInstaller
vi.mock('../../src/core/completions/installers/zsh-installer.js', () => ({
  ZshInstaller: vi.fn().mockImplementation(() => ({
    install: vi.fn().mockResolvedValue({
      success: true,
      installedPath: '/home/user/.oh-my-zsh/completions/_openspec',
      isOhMyZsh: true,
      message: 'Completion script installed successfully for Oh My Zsh',
      instructions: [
        'Completion script installed to Oh My Zsh completions directory.',
        'Restart your shell or run: exec zsh',
        'Completions should activate automatically.',
      ],
    }),
    uninstall: vi.fn().mockResolvedValue({
      success: true,
      message: 'Completion script removed from /home/user/.oh-my-zsh/completions/_openspec',
    }),
  })),
}));

describe('CompletionCommand', () => {
  let command: CompletionCommand;
  let consoleLogSpy: any;
  let consoleErrorSpy: any;

  beforeEach(() => {
    command = new CompletionCommand();
    consoleLogSpy = vi.spyOn(console, 'log').mockImplementation(() => {});
    consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
    process.exitCode = 0;
  });

  afterEach(() => {
    consoleLogSpy.mockRestore();
    consoleErrorSpy.mockRestore();
    vi.clearAllMocks();
  });

  describe('generate subcommand', () => {
    it('should generate Zsh completion script to stdout', async () => {
      await command.generate({ shell: 'zsh' });

      expect(consoleLogSpy).toHaveBeenCalled();
      const output = consoleLogSpy.mock.calls[0][0];
      expect(output).toContain('#compdef openspec');
      expect(output).toContain('_openspec() {');
    });

    it('should auto-detect Zsh shell when no shell specified', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: 'zsh', detected: 'zsh' });

      await command.generate({});

      expect(consoleLogSpy).toHaveBeenCalled();
      const output = consoleLogSpy.mock.calls[0][0];
      expect(output).toContain('#compdef openspec');
    });

    it('should show error when shell cannot be auto-detected', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: undefined, detected: undefined });

      await command.generate({});

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        'Error: Could not auto-detect shell. Please specify shell explicitly.'
      );
      expect(process.exitCode).toBe(1);
    });

    it('should show error for unsupported shell', async () => {
      await command.generate({ shell: 'tcsh' });

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        "Error: Shell 'tcsh' is not supported yet. Currently supported: zsh, bash, fish, powershell"
      );
      expect(process.exitCode).toBe(1);
    });

    it('should handle shell parameter case-insensitively', async () => {
      await command.generate({ shell: 'ZSH' });

      expect(consoleLogSpy).toHaveBeenCalled();
      const output = consoleLogSpy.mock.calls[0][0];
      expect(output).toContain('#compdef openspec');
    });
  });

  describe('install subcommand', () => {
    it('should install Zsh completion script', async () => {
      await command.install({ shell: 'zsh' });

      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Completion script installed successfully')
      );
      expect(process.exitCode).toBe(0);
    });

    it('should show verbose output when --verbose flag is provided', async () => {
      await command.install({ shell: 'zsh', verbose: true });

      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Installed to:')
      );
    });

    it('should auto-detect Zsh shell when no shell specified', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: 'zsh', detected: 'zsh' });

      await command.install({});

      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Completion script installed successfully')
      );
    });

    it('should show error when shell cannot be auto-detected', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: undefined, detected: undefined });

      await command.install({});

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        'Error: Could not auto-detect shell. Please specify shell explicitly.'
      );
      expect(process.exitCode).toBe(1);
    });

    it('should show error for unsupported shell', async () => {
      await command.install({ shell: 'tcsh' });

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        "Error: Shell 'tcsh' is not supported yet. Currently supported: zsh, bash, fish, powershell"
      );
      expect(process.exitCode).toBe(1);
    });

    it('should display installation instructions', async () => {
      await command.install({ shell: 'zsh' });

      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Restart your shell or run: exec zsh')
      );
    });
  });

  describe('uninstall subcommand', () => {
    it('should uninstall Zsh completion script', async () => {
      await command.uninstall({ shell: 'zsh', yes: true });

      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Completion script removed')
      );
      expect(process.exitCode).toBe(0);
    });

    it('should auto-detect Zsh shell when no shell specified', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: 'zsh', detected: 'zsh' });

      await command.uninstall({ yes: true });

      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Completion script removed')
      );
    });

    it('should show error when shell cannot be auto-detected', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: undefined, detected: undefined });

      await command.uninstall({ yes: true });

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        'Error: Could not auto-detect shell. Please specify shell explicitly.'
      );
      expect(process.exitCode).toBe(1);
    });

    it('should show error for unsupported shell', async () => {
      await command.uninstall({ shell: 'tcsh', yes: true });

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        "Error: Shell 'tcsh' is not supported yet. Currently supported: zsh, bash, fish, powershell"
      );
      expect(process.exitCode).toBe(1);
    });
  });

  describe('error handling', () => {
    it('should handle installation failures gracefully', async () => {
      const { ZshInstaller } = await import('../../src/core/completions/installers/zsh-installer.js');
      vi.mocked(ZshInstaller).mockImplementationOnce(() => ({
        install: vi.fn().mockResolvedValue({
          success: false,
          isOhMyZsh: false,
          message: 'Permission denied',
        }),
        uninstall: vi.fn(),
        isInstalled: vi.fn(),
        getInstallationInfo: vi.fn(),
        isOhMyZshInstalled: vi.fn(),
        getInstallationPath: vi.fn(),
        backupExistingFile: vi.fn(),
      } as any));

      const cmd = new CompletionCommand();
      await cmd.install({ shell: 'zsh' });

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        expect.stringContaining('Permission denied')
      );
      expect(process.exitCode).toBe(1);
    });

    it('should handle uninstallation failures gracefully', async () => {
      const { ZshInstaller } = await import('../../src/core/completions/installers/zsh-installer.js');
      vi.mocked(ZshInstaller).mockImplementationOnce(() => ({
        install: vi.fn(),
        uninstall: vi.fn().mockResolvedValue({
          success: false,
          message: 'Completion script is not installed',
        }),
        isInstalled: vi.fn(),
        getInstallationInfo: vi.fn(),
        isOhMyZshInstalled: vi.fn(),
        getInstallationPath: vi.fn(),
        backupExistingFile: vi.fn(),
      } as any));

      const cmd = new CompletionCommand();
      await cmd.uninstall({ shell: 'zsh', yes: true });

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        expect.stringContaining('Completion script is not installed')
      );
      expect(process.exitCode).toBe(1);
    });
  });

  describe('shell detection integration', () => {
    it('should show appropriate error when detected shell is unsupported', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: undefined, detected: 'tcsh' });

      await command.generate({});

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        "Error: Shell 'tcsh' is not supported yet. Currently supported: zsh, bash, fish, powershell"
      );
      expect(process.exitCode).toBe(1);
    });

    it('should respect explicit shell parameter over auto-detection', async () => {
      vi.mocked(shellDetection.detectShell).mockReturnValue({ shell: undefined, detected: 'bash' });

      await command.generate({ shell: 'zsh' });

      expect(consoleLogSpy).toHaveBeenCalled();
      const output = consoleLogSpy.mock.calls[0][0];
      expect(output).toContain('#compdef openspec');
    });
  });
});



================================================
FILE: test/commands/config.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';

describe('config command integration', () => {
  // These tests use real file system operations with XDG_CONFIG_HOME override
  let tempDir: string;
  let originalEnv: NodeJS.ProcessEnv;
  let consoleErrorSpy: ReturnType<typeof vi.spyOn>;

  beforeEach(() => {
    // Create unique temp directory for each test
    tempDir = path.join(os.tmpdir(), `openspec-config-test-${Date.now()}-${Math.random().toString(36).slice(2)}`);
    fs.mkdirSync(tempDir, { recursive: true });

    // Save original env and set XDG_CONFIG_HOME
    originalEnv = { ...process.env };
    process.env.XDG_CONFIG_HOME = tempDir;

    // Spy on console.error
    consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
  });

  afterEach(() => {
    // Restore original env
    process.env = originalEnv;

    // Clean up temp directory
    fs.rmSync(tempDir, { recursive: true, force: true });

    // Restore spies
    consoleErrorSpy.mockRestore();

    // Reset module cache to pick up new XDG_CONFIG_HOME
    vi.resetModules();
  });

  it('should use XDG_CONFIG_HOME for config path', async () => {
    const { getGlobalConfigPath } = await import('../../src/core/global-config.js');
    const configPath = getGlobalConfigPath();
    expect(configPath).toBe(path.join(tempDir, 'openspec', 'config.json'));
  });

  it('should save and load config correctly', async () => {
    const { getGlobalConfig, saveGlobalConfig } = await import('../../src/core/global-config.js');

    saveGlobalConfig({ featureFlags: { test: true } });
    const config = getGlobalConfig();
    expect(config.featureFlags).toEqual({ test: true });
  });

  it('should return defaults when config file does not exist', async () => {
    const { getGlobalConfig, getGlobalConfigPath } = await import('../../src/core/global-config.js');

    const configPath = getGlobalConfigPath();
    // Make sure config doesn't exist
    if (fs.existsSync(configPath)) {
      fs.unlinkSync(configPath);
    }

    const config = getGlobalConfig();
    expect(config.featureFlags).toEqual({});
  });

  it('should preserve unknown fields', async () => {
    const { getGlobalConfig, getGlobalConfigDir } = await import('../../src/core/global-config.js');

    const configDir = getGlobalConfigDir();
    fs.mkdirSync(configDir, { recursive: true });
    fs.writeFileSync(path.join(configDir, 'config.json'), JSON.stringify({
      featureFlags: {},
      customField: 'preserved',
    }));

    const config = getGlobalConfig();
    expect((config as Record<string, unknown>).customField).toBe('preserved');
  });

  it('should handle invalid JSON gracefully', async () => {
    const { getGlobalConfig, getGlobalConfigDir } = await import('../../src/core/global-config.js');

    const configDir = getGlobalConfigDir();
    fs.mkdirSync(configDir, { recursive: true });
    fs.writeFileSync(path.join(configDir, 'config.json'), '{ invalid json }');

    const config = getGlobalConfig();
    // Should return defaults
    expect(config.featureFlags).toEqual({});
    expect(consoleErrorSpy).toHaveBeenCalledWith(expect.stringContaining('Invalid JSON'));
  });
});

describe('config command shell completion registry', () => {
  it('should have config command in registry', async () => {
    const { COMMAND_REGISTRY } = await import('../../src/core/completions/command-registry.js');

    const configCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'config');
    expect(configCmd).toBeDefined();
    expect(configCmd?.description).toBe('View and modify global OpenSpec configuration');
  });

  it('should have all config subcommands in registry', async () => {
    const { COMMAND_REGISTRY } = await import('../../src/core/completions/command-registry.js');

    const configCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'config');
    const subcommandNames = configCmd?.subcommands?.map((s) => s.name) ?? [];

    expect(subcommandNames).toContain('path');
    expect(subcommandNames).toContain('list');
    expect(subcommandNames).toContain('get');
    expect(subcommandNames).toContain('set');
    expect(subcommandNames).toContain('unset');
    expect(subcommandNames).toContain('reset');
    expect(subcommandNames).toContain('edit');
  });

  it('should have --json flag on list subcommand', async () => {
    const { COMMAND_REGISTRY } = await import('../../src/core/completions/command-registry.js');

    const configCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'config');
    const listCmd = configCmd?.subcommands?.find((s) => s.name === 'list');
    const flagNames = listCmd?.flags?.map((f) => f.name) ?? [];

    expect(flagNames).toContain('json');
  });

  it('should have --string flag on set subcommand', async () => {
    const { COMMAND_REGISTRY } = await import('../../src/core/completions/command-registry.js');

    const configCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'config');
    const setCmd = configCmd?.subcommands?.find((s) => s.name === 'set');
    const flagNames = setCmd?.flags?.map((f) => f.name) ?? [];

    expect(flagNames).toContain('string');
    expect(flagNames).toContain('allow-unknown');
  });

  it('should have --all and -y flags on reset subcommand', async () => {
    const { COMMAND_REGISTRY } = await import('../../src/core/completions/command-registry.js');

    const configCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'config');
    const resetCmd = configCmd?.subcommands?.find((s) => s.name === 'reset');
    const flagNames = resetCmd?.flags?.map((f) => f.name) ?? [];

    expect(flagNames).toContain('all');
    expect(flagNames).toContain('yes');
  });

  it('should have --scope flag on config command', async () => {
    const { COMMAND_REGISTRY } = await import('../../src/core/completions/command-registry.js');

    const configCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'config');
    const flagNames = configCmd?.flags?.map((f) => f.name) ?? [];

    expect(flagNames).toContain('scope');
  });
});

describe('config key validation', () => {
  it('rejects unknown top-level keys', async () => {
    const { validateConfigKeyPath } = await import('../../src/core/config-schema.js');
    expect(validateConfigKeyPath('unknownKey').valid).toBe(false);
  });

  it('allows feature flag keys', async () => {
    const { validateConfigKeyPath } = await import('../../src/core/config-schema.js');
    expect(validateConfigKeyPath('featureFlags.someFlag').valid).toBe(true);
  });

  it('rejects deeply nested feature flag keys', async () => {
    const { validateConfigKeyPath } = await import('../../src/core/config-schema.js');
    expect(validateConfigKeyPath('featureFlags.someFlag.extra').valid).toBe(false);
  });
});



================================================
FILE: test/commands/feedback.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { FeedbackCommand } from '../../src/commands/feedback.js';
import { execSync, execFileSync } from 'child_process';

// Mock child_process functions
vi.mock('child_process', () => ({
  execSync: vi.fn(),
  execFileSync: vi.fn(),
}));

describe('FeedbackCommand', () => {
  let feedbackCommand: FeedbackCommand;
  let consoleLogSpy: any;
  let consoleErrorSpy: any;
  let processExitSpy: any;
  const mockExecSync = execSync as unknown as ReturnType<typeof vi.fn>;
  const mockExecFileSync = execFileSync as unknown as ReturnType<typeof vi.fn>;

  beforeEach(() => {
    feedbackCommand = new FeedbackCommand();
    consoleLogSpy = vi.spyOn(console, 'log').mockImplementation(() => {});
    consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
    processExitSpy = vi.spyOn(process, 'exit').mockImplementation((code?: string | number | null) => {
      throw new Error(`process.exit(${code})`);
    });
    vi.clearAllMocks();
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  describe('gh CLI availability check', () => {
    it('should use which command on Unix/macOS platforms', async () => {
      // Mock platform as darwin
      const originalPlatform = process.platform;
      Object.defineProperty(process, 'platform', { value: 'darwin' });

      mockExecSync.mockImplementation((cmd: string) => {
        if (cmd === 'which gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue('https://github.com/Fission-AI/OpenSpec/issues/123\n');

      await feedbackCommand.execute('Test');

      // Verify 'which gh' was called
      expect(mockExecSync).toHaveBeenCalledWith('which gh', expect.any(Object));

      // Restore original platform
      Object.defineProperty(process, 'platform', { value: originalPlatform });
    });

    it('should use where command on Windows platform', async () => {
      // Mock platform as win32
      const originalPlatform = process.platform;
      Object.defineProperty(process, 'platform', { value: 'win32' });

      mockExecSync.mockImplementation((cmd: string) => {
        if (cmd === 'where gh') {
          return Buffer.from('C:\\Program Files\\GitHub CLI\\gh.exe');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue('https://github.com/Fission-AI/OpenSpec/issues/123\n');

      await feedbackCommand.execute('Test');

      // Verify 'where gh' was called
      expect(mockExecSync).toHaveBeenCalledWith('where gh', expect.any(Object));

      // Restore original platform
      Object.defineProperty(process, 'platform', { value: originalPlatform });
    });

    it('should handle missing gh CLI with fallback', async () => {
      // Simulate gh not installed
      mockExecSync.mockImplementation((cmd: string) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          throw new Error('Command not found');
        }
      });

      try {
        await feedbackCommand.execute('Test feedback');
      } catch (error: any) {
        // Should exit with code 0 (successful fallback)
        expect(error.message).toBe('process.exit(0)');
      }

      // Should display warning
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('GitHub CLI not found')
      );

      // Should show formatted feedback
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('--- FORMATTED FEEDBACK ---')
      );

      // Should show manual submission URL
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('https://github.com/Fission-AI/OpenSpec/issues/new')
      );
    });

    it('should handle unauthenticated gh CLI with fallback', async () => {
      // Simulate gh installed but not authenticated
      mockExecSync.mockImplementation((cmd: string) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          throw new Error('Not authenticated');
        }
      });

      try {
        await feedbackCommand.execute('Test feedback');
      } catch (error: any) {
        // Should exit with code 0 (successful fallback)
        expect(error.message).toBe('process.exit(0)');
      }

      // Should display warning
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('GitHub authentication required')
      );

      // Should show auth instructions
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('To auto-submit in the future: gh auth login')
      );

      // Should show formatted feedback
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('--- FORMATTED FEEDBACK ---')
      );
    });
  });

  describe('successful feedback submission', () => {
    it('should submit feedback via gh CLI when authenticated', async () => {
      const issueUrl = 'https://github.com/Fission-AI/OpenSpec/issues/123';

      // Simulate gh installed and authenticated
      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue(`${issueUrl}\n`);

      await feedbackCommand.execute('Great tool!');

      // Should call gh with correct arguments using execFileSync
      expect(mockExecFileSync).toHaveBeenCalledWith(
        'gh',
        [
          'issue',
          'create',
          '--repo',
          'Fission-AI/OpenSpec',
          '--title',
          'Feedback: Great tool!',
          '--body',
          expect.stringContaining('Submitted via OpenSpec CLI'),
          '--label',
          'feedback',
        ],
        expect.objectContaining({
          encoding: 'utf-8',
          stdio: 'pipe',
        })
      );

      // Should display success message
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Feedback submitted successfully')
      );

      // Should display issue URL
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining(issueUrl)
      );
    });

    it('should include --body flag when body is provided', async () => {
      const issueUrl = 'https://github.com/Fission-AI/OpenSpec/issues/124';

      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue(`${issueUrl}\n`);

      await feedbackCommand.execute('Title here', { body: 'Detailed description' });

      // Verify body is included in the arguments
      expect(mockExecFileSync).toHaveBeenCalledWith(
        'gh',
        expect.arrayContaining([
          '--body',
          expect.stringContaining('Detailed description'),
        ]),
        expect.any(Object)
      );
    });

    it('should format title with "Feedback:" prefix', async () => {
      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue('https://github.com/Fission-AI/OpenSpec/issues/125\n');

      await feedbackCommand.execute('Test message');

      // Verify title has "Feedback:" prefix
      expect(mockExecFileSync).toHaveBeenCalledWith(
        'gh',
        expect.arrayContaining([
          '--title',
          'Feedback: Test message',
        ]),
        expect.any(Object)
      );
    });

    it('should include metadata in issue body', async () => {
      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue('https://github.com/Fission-AI/OpenSpec/issues/126\n');

      await feedbackCommand.execute('Test', { body: 'Body text' });

      // Verify metadata is included in body
      expect(mockExecFileSync).toHaveBeenCalledWith(
        'gh',
        expect.arrayContaining([
          '--body',
          expect.stringMatching(/Submitted via OpenSpec CLI[\s\S]*Version:[\s\S]*Platform:[\s\S]*Timestamp:/),
        ]),
        expect.any(Object)
      );
    });

    it('should add feedback label to the issue', async () => {
      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue('https://github.com/Fission-AI/OpenSpec/issues/127\n');

      await feedbackCommand.execute('Test');

      // Verify feedback label is added
      expect(mockExecFileSync).toHaveBeenCalledWith(
        'gh',
        expect.arrayContaining([
          '--label',
          'feedback',
        ]),
        expect.any(Object)
      );
    });
  });

  describe('error handling', () => {
    it('should handle gh CLI execution failure', async () => {
      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      // Mock execFileSync to throw error
      mockExecFileSync.mockImplementation(() => {
        const error: any = new Error('Network error');
        error.status = 1;
        error.stderr = Buffer.from('Error: Network connectivity issue');
        throw error;
      });

      try {
        await feedbackCommand.execute('Test');
      } catch (error: any) {
        // Should exit with the same code as gh CLI
        expect(error.message).toBe('process.exit(1)');
      }

      // Should display the error from gh CLI
      expect(consoleErrorSpy).toHaveBeenCalledWith(
        expect.stringContaining('Network connectivity issue')
      );
    });

    it('should handle quotes in title and body without escaping (no shell injection)', async () => {
      mockExecSync.mockImplementation((cmd: string, options?: any) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          return Buffer.from('/usr/local/bin/gh');
        }
        if (cmd === 'gh auth status') {
          return Buffer.from('Logged in');
        }
        return '';
      });

      mockExecFileSync.mockReturnValue('https://github.com/Fission-AI/OpenSpec/issues/128\n');

      await feedbackCommand.execute('Test with "quotes"', {
        body: 'Body with "quotes"',
      });

      // Verify quotes are passed as-is (no escaping needed with execFileSync)
      expect(mockExecFileSync).toHaveBeenCalledWith(
        'gh',
        expect.arrayContaining([
          '--title',
          'Feedback: Test with "quotes"',
          '--body',
          expect.stringContaining('Body with "quotes"'),
        ]),
        expect.any(Object)
      );
    });
  });

  describe('formatted feedback output', () => {
    it('should display formatted feedback with proper structure', async () => {
      mockExecSync.mockImplementation((cmd: string) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          throw new Error('Command not found');
        }
      });

      try {
        await feedbackCommand.execute('Test message', { body: 'Test body' });
      } catch (error: any) {
        // Expected to exit
      }

      // Verify formatted output structure
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('--- FORMATTED FEEDBACK ---')
      );
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Title: Feedback: Test message')
      );
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('Labels: feedback')
      );
      expect(consoleLogSpy).toHaveBeenCalledWith(
        expect.stringContaining('--- END FEEDBACK ---')
      );
    });

    it('should generate correct manual submission URL', async () => {
      mockExecSync.mockImplementation((cmd: string) => {
        if (cmd === 'which gh' || cmd === 'where gh') {
          throw new Error('Command not found');
        }
      });

      try {
        await feedbackCommand.execute('Test');
      } catch (error: any) {
        // Expected to exit
      }

      // Verify URL is shown
      const urlCall = consoleLogSpy.mock.calls.find((call: any[]) =>
        call[0]?.includes('https://github.com/Fission-AI/OpenSpec/issues/new')
      );
      expect(urlCall).toBeDefined();

      // Verify URL has proper parameters
      const url = urlCall?.[0];
      expect(url).toContain('title=');
      expect(url).toContain('body=');
      expect(url).toContain('labels=feedback');
    });
  });
});



================================================
FILE: test/commands/schema.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';

describe('schema command', () => {
  let tempDir: string;
  let originalCwd: string;
  let originalEnv: NodeJS.ProcessEnv;
  let consoleLogSpy: ReturnType<typeof vi.spyOn>;
  let consoleErrorSpy: ReturnType<typeof vi.spyOn>;

  beforeEach(() => {
    // Create unique temp directory for each test
    tempDir = path.join(
      os.tmpdir(),
      `openspec-schema-test-${Date.now()}-${Math.random().toString(36).slice(2)}`
    );
    fs.mkdirSync(tempDir, { recursive: true });

    // Create openspec directory structure
    fs.mkdirSync(path.join(tempDir, 'openspec', 'schemas'), { recursive: true });

    // Save original cwd and env
    originalCwd = process.cwd();
    originalEnv = { ...process.env };

    // Change to temp directory
    process.chdir(tempDir);

    // Set XDG paths to temp to avoid polluting user directories
    process.env.XDG_DATA_HOME = path.join(tempDir, 'xdg-data');
    process.env.XDG_CONFIG_HOME = path.join(tempDir, 'xdg-config');

    // Spy on console
    consoleLogSpy = vi.spyOn(console, 'log').mockImplementation(() => {});
    consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
  });

  afterEach(() => {
    // Restore cwd and env
    process.chdir(originalCwd);
    process.env = originalEnv;

    // Clean up temp directory
    fs.rmSync(tempDir, { recursive: true, force: true });

    // Restore spies
    consoleLogSpy.mockRestore();
    consoleErrorSpy.mockRestore();

    // Reset module cache
    vi.resetModules();
  });

  describe('schema which', () => {
    it('should show schema resolution from package', async () => {
      const { getSchemaDir, listSchemas } = await import(
        '../../src/core/artifact-graph/resolver.js'
      );

      // Verify spec-driven exists in package
      const schemas = listSchemas(tempDir);
      expect(schemas).toContain('spec-driven');

      const schemaDir = getSchemaDir('spec-driven', tempDir);
      expect(schemaDir).not.toBeNull();
      expect(schemaDir).toContain('schemas');
    });

    it('should detect project schema shadowing package', async () => {
      // Create a project-local spec-driven schema
      const projectSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        `name: spec-driven
version: 1
description: Custom spec-driven
artifacts:
  - id: proposal
    generates: proposal.md
    description: Proposal
    template: proposal.md
`
      );
      fs.writeFileSync(path.join(projectSchemaDir, 'proposal.md'), '# Proposal');

      const { getSchemaDir } = await import('../../src/core/artifact-graph/resolver.js');

      // Should resolve to project
      const schemaDir = getSchemaDir('spec-driven', tempDir);
      expect(schemaDir).toBe(projectSchemaDir);
    });

    it('should list all schemas with --all flag', async () => {
      const { listSchemas } = await import('../../src/core/artifact-graph/resolver.js');

      const schemas = listSchemas(tempDir);
      expect(schemas.length).toBeGreaterThan(0);
      expect(schemas).toContain('spec-driven');
    });
  });

  describe('schema validate', () => {
    it('should validate a valid schema', async () => {
      // Create a valid project schema
      const schemaDir = path.join(tempDir, 'openspec', 'schemas', 'test-schema');
      fs.mkdirSync(schemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(schemaDir, 'schema.yaml'),
        `name: test-schema
version: 1
description: Test schema
artifacts:
  - id: proposal
    generates: proposal.md
    description: Proposal
    template: proposal.md
`
      );
      fs.writeFileSync(path.join(schemaDir, 'proposal.md'), '# Proposal Template');

      const { parseSchema } = await import('../../src/core/artifact-graph/schema.js');
      const content = fs.readFileSync(path.join(schemaDir, 'schema.yaml'), 'utf-8');
      const schema = parseSchema(content);

      expect(schema.name).toBe('test-schema');
      expect(schema.artifacts).toHaveLength(1);
    });

    it('should detect missing template file', async () => {
      const schemaDir = path.join(tempDir, 'openspec', 'schemas', 'bad-schema');
      fs.mkdirSync(schemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(schemaDir, 'schema.yaml'),
        `name: bad-schema
version: 1
description: Bad schema
artifacts:
  - id: proposal
    generates: proposal.md
    description: Proposal
    template: missing-template.md
`
      );

      // Template file doesn't exist, validation should report this
      const templatePath = path.join(schemaDir, 'missing-template.md');
      expect(fs.existsSync(templatePath)).toBe(false);
    });

    it('should detect circular dependencies', async () => {
      const { parseSchema, SchemaValidationError } = await import(
        '../../src/core/artifact-graph/schema.js'
      );

      const content = `name: circular-schema
version: 1
description: Schema with circular deps
artifacts:
  - id: a
    generates: a.md
    description: A
    template: a.md
    requires:
      - b
  - id: b
    generates: b.md
    description: B
    template: b.md
    requires:
      - a
`;

      expect(() => parseSchema(content)).toThrow(SchemaValidationError);
      expect(() => parseSchema(content)).toThrow(/[Cc]yclic/);
    });

    it('should detect unknown dependency reference', async () => {
      const { parseSchema, SchemaValidationError } = await import(
        '../../src/core/artifact-graph/schema.js'
      );

      const content = `name: bad-ref-schema
version: 1
description: Schema with bad ref
artifacts:
  - id: a
    generates: a.md
    description: A
    template: a.md
    requires:
      - nonexistent
`;

      expect(() => parseSchema(content)).toThrow(SchemaValidationError);
      expect(() => parseSchema(content)).toThrow(/nonexistent/);
    });
  });

  describe('schema fork', () => {
    it('should copy schema to project directory', async () => {
      const { getSchemaDir } = await import('../../src/core/artifact-graph/resolver.js');

      // Get the package spec-driven schema
      const sourceDir = getSchemaDir('spec-driven', tempDir);
      expect(sourceDir).not.toBeNull();

      // Copy manually to simulate fork
      const destDir = path.join(tempDir, 'openspec', 'schemas', 'my-custom');
      fs.mkdirSync(destDir, { recursive: true });

      // Copy files
      const files = fs.readdirSync(sourceDir!);
      for (const file of files) {
        const srcPath = path.join(sourceDir!, file);
        const destPath = path.join(destDir, file);
        const stat = fs.statSync(srcPath);

        if (stat.isFile()) {
          fs.copyFileSync(srcPath, destPath);
        }
      }

      // Verify destination exists
      expect(fs.existsSync(path.join(destDir, 'schema.yaml'))).toBe(true);
    });

    it('should reject invalid schema names', () => {
      // Test kebab-case validation
      const isValidSchemaName = (name: string): boolean => {
        return /^[a-z][a-z0-9]*(-[a-z0-9]+)*$/.test(name);
      };

      expect(isValidSchemaName('my-schema')).toBe(true);
      expect(isValidSchemaName('my-schema-v2')).toBe(true);
      expect(isValidSchemaName('schema123')).toBe(true);
      expect(isValidSchemaName('My Schema')).toBe(false);
      expect(isValidSchemaName('my_schema')).toBe(false);
      expect(isValidSchemaName('MySchema')).toBe(false);
      expect(isValidSchemaName('-my-schema')).toBe(false);
      expect(isValidSchemaName('123schema')).toBe(false);
    });
  });

  describe('schema init', () => {
    it('should create schema directory with schema.yaml', async () => {
      const schemaDir = path.join(tempDir, 'openspec', 'schemas', 'new-schema');
      fs.mkdirSync(schemaDir, { recursive: true });

      const { stringify: stringifyYaml } = await import('yaml');

      const schema = {
        name: 'new-schema',
        version: 1,
        description: 'A new schema',
        artifacts: [
          {
            id: 'proposal',
            generates: 'proposal.md',
            description: 'Proposal',
            template: 'proposal.md',
            requires: [],
          },
        ],
      };

      fs.writeFileSync(path.join(schemaDir, 'schema.yaml'), stringifyYaml(schema));
      fs.writeFileSync(path.join(schemaDir, 'proposal.md'), '# Proposal');

      // Verify
      expect(fs.existsSync(path.join(schemaDir, 'schema.yaml'))).toBe(true);
      expect(fs.existsSync(path.join(schemaDir, 'proposal.md'))).toBe(true);
    });

    it('should validate schema name format', () => {
      const isValidSchemaName = (name: string): boolean => {
        return /^[a-z][a-z0-9]*(-[a-z0-9]+)*$/.test(name);
      };

      expect(isValidSchemaName('valid-name')).toBe(true);
      expect(isValidSchemaName('Invalid Name')).toBe(false);
    });

    it('should set up artifact dependencies correctly', async () => {
      const { parseSchema } = await import('../../src/core/artifact-graph/schema.js');

      // Create schema with standard artifact chain
      const content = `name: test-workflow
version: 1
description: Test workflow
artifacts:
  - id: proposal
    generates: proposal.md
    description: Proposal
    template: proposal.md
  - id: specs
    generates: specs/**/*.md
    description: Specs
    template: specs/spec.md
    requires:
      - proposal
  - id: design
    generates: design.md
    description: Design
    template: design.md
    requires:
      - specs
  - id: tasks
    generates: tasks.md
    description: Tasks
    template: tasks.md
    requires:
      - design
`;

      const schema = parseSchema(content);
      expect(schema.artifacts[0].requires).toEqual([]);
      expect(schema.artifacts[1].requires).toEqual(['proposal']);
      expect(schema.artifacts[2].requires).toEqual(['specs']);
      expect(schema.artifacts[3].requires).toEqual(['design']);
    });
  });

  describe('JSON output format', () => {
    it('should output valid JSON for schema which', async () => {
      const { listSchemas } = await import('../../src/core/artifact-graph/resolver.js');

      const schemas = listSchemas(tempDir);
      const jsonOutput = JSON.stringify(schemas);

      expect(() => JSON.parse(jsonOutput)).not.toThrow();
    });

    it('should include expected fields in validation JSON', () => {
      const validationResult = {
        valid: true,
        name: 'test-schema',
        path: '/path/to/schema',
        issues: [],
      };

      const json = JSON.stringify(validationResult);
      const parsed = JSON.parse(json);

      expect(parsed).toHaveProperty('valid');
      expect(parsed).toHaveProperty('name');
      expect(parsed).toHaveProperty('path');
      expect(parsed).toHaveProperty('issues');
    });

    it('should include expected fields in fork JSON', () => {
      const forkResult = {
        forked: true,
        source: 'spec-driven',
        sourcePath: '/path/to/source',
        sourceLocation: 'package',
        destination: 'my-custom',
        destinationPath: '/path/to/dest',
      };

      const json = JSON.stringify(forkResult);
      const parsed = JSON.parse(json);

      expect(parsed).toHaveProperty('forked');
      expect(parsed).toHaveProperty('source');
      expect(parsed).toHaveProperty('sourceLocation');
      expect(parsed).toHaveProperty('destination');
    });

    it('should include expected fields in init JSON', () => {
      const initResult = {
        created: true,
        path: '/path/to/schema',
        schema: 'new-schema',
        artifacts: ['proposal', 'specs'],
        setAsDefault: false,
      };

      const json = JSON.stringify(initResult);
      const parsed = JSON.parse(json);

      expect(parsed).toHaveProperty('created');
      expect(parsed).toHaveProperty('path');
      expect(parsed).toHaveProperty('schema');
      expect(parsed).toHaveProperty('artifacts');
    });
  });
});

describe('schema command shell completion registry', () => {
  it('should have schema command in registry', async () => {
    const { COMMAND_REGISTRY } = await import(
      '../../src/core/completions/command-registry.js'
    );

    const schemaCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'schema');
    expect(schemaCmd).toBeDefined();
    expect(schemaCmd?.description).toBe('Manage workflow schemas');
  });

  it('should have all schema subcommands in registry', async () => {
    const { COMMAND_REGISTRY } = await import(
      '../../src/core/completions/command-registry.js'
    );

    const schemaCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'schema');
    const subcommandNames = schemaCmd?.subcommands?.map((s) => s.name) ?? [];

    expect(subcommandNames).toContain('which');
    expect(subcommandNames).toContain('validate');
    expect(subcommandNames).toContain('fork');
    expect(subcommandNames).toContain('init');
  });

  it('should have --json flag on all subcommands', async () => {
    const { COMMAND_REGISTRY } = await import(
      '../../src/core/completions/command-registry.js'
    );

    const schemaCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'schema');
    const subcommands = schemaCmd?.subcommands ?? [];

    for (const subcmd of subcommands) {
      const flagNames = subcmd.flags?.map((f) => f.name) ?? [];
      expect(flagNames).toContain('json');
    }
  });

  it('should have --all flag on which subcommand', async () => {
    const { COMMAND_REGISTRY } = await import(
      '../../src/core/completions/command-registry.js'
    );

    const schemaCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'schema');
    const whichCmd = schemaCmd?.subcommands?.find((s) => s.name === 'which');
    const flagNames = whichCmd?.flags?.map((f) => f.name) ?? [];

    expect(flagNames).toContain('all');
  });

  it('should have --verbose flag on validate subcommand', async () => {
    const { COMMAND_REGISTRY } = await import(
      '../../src/core/completions/command-registry.js'
    );

    const schemaCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'schema');
    const validateCmd = schemaCmd?.subcommands?.find((s) => s.name === 'validate');
    const flagNames = validateCmd?.flags?.map((f) => f.name) ?? [];

    expect(flagNames).toContain('verbose');
  });

  it('should have --force flag on fork and init subcommands', async () => {
    const { COMMAND_REGISTRY } = await import(
      '../../src/core/completions/command-registry.js'
    );

    const schemaCmd = COMMAND_REGISTRY.find((cmd) => cmd.name === 'schema');
    const forkCmd = schemaCmd?.subcommands?.find((s) => s.name === 'fork');
    const initCmd = schemaCmd?.subcommands?.find((s) => s.name === 'init');

    expect(forkCmd?.flags?.map((f) => f.name)).toContain('force');
    expect(initCmd?.flags?.map((f) => f.name)).toContain('force');
  });
});



================================================
FILE: test/commands/show.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

describe('top-level show command', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-show-command-tmp');
  const changesDir = path.join(testDir, 'openspec', 'changes');
  const specsDir = path.join(testDir, 'openspec', 'specs');
  const openspecBin = path.join(projectRoot, 'bin', 'openspec.js');


  beforeEach(async () => {
    await fs.mkdir(changesDir, { recursive: true });
    await fs.mkdir(specsDir, { recursive: true });

    const changeContent = `# Change: Demo\n\n## Why\nBecause reasons.\n\n## What Changes\n- **auth:** Add requirement\n`;
    await fs.mkdir(path.join(changesDir, 'demo'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'demo', 'proposal.md'), changeContent, 'utf-8');

    const specContent = `## Purpose\nAuth spec.\n\n## Requirements\n\n### Requirement: User Authentication\nText\n`;
    await fs.mkdir(path.join(specsDir, 'auth'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 'auth', 'spec.md'), specContent, 'utf-8');
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('prints hint and non-zero exit when no args and non-interactive', () => {
    const originalCwd = process.cwd();
    const originalEnv = { ...process.env };
    try {
      process.chdir(testDir);
      process.env.OPEN_SPEC_INTERACTIVE = '0';
      let err: any;
      try {
        execSync(`node ${openspecBin} show`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      const stderr = err.stderr.toString();
      expect(stderr).toContain('Nothing to show.');
      expect(stderr).toContain('openspec show <item>');
      expect(stderr).toContain('openspec change show');
      expect(stderr).toContain('openspec spec show');
    } finally {
      process.chdir(originalCwd);
      process.env = originalEnv;
    }
  });

  it('auto-detects change id and supports --json', () => {
    const originalCwd = process.cwd();
    try {
      process.chdir(testDir);
      const output = execSync(`node ${openspecBin} show demo --json`, { encoding: 'utf-8' });
      const json = JSON.parse(output);
      expect(json.id).toBe('demo');
      expect(Array.isArray(json.deltas)).toBe(true);
    } finally {
      process.chdir(originalCwd);
    }
  });

  it('auto-detects spec id and supports spec-only flags', () => {
    const originalCwd = process.cwd();
    try {
      process.chdir(testDir);
      const output = execSync(`node ${openspecBin} show auth --json --requirements`, { encoding: 'utf-8' });
      const json = JSON.parse(output);
      expect(json.id).toBe('auth');
      expect(Array.isArray(json.requirements)).toBe(true);
    } finally {
      process.chdir(originalCwd);
    }
  });

  it('handles ambiguity and suggests --type', async () => {
    // create matching spec and change named 'foo'
    await fs.mkdir(path.join(changesDir, 'foo'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'foo', 'proposal.md'), '# Change: Foo\n\n## Why\n\n## What Changes\n', 'utf-8');
    await fs.mkdir(path.join(specsDir, 'foo'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 'foo', 'spec.md'), '## Purpose\n\n## Requirements\n\n### Requirement: R\nX', 'utf-8');

    const originalCwd = process.cwd();
    try {
      process.chdir(testDir);
      let err: any;
      try {
        execSync(`node ${openspecBin} show foo`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      const stderr = err.stderr.toString();
      expect(stderr).toContain('Ambiguous item');
      expect(stderr).toContain('--type change|spec');
    } finally {
      process.chdir(originalCwd);
    }
  });

  it('prints nearest matches when not found', () => {
    const originalCwd = process.cwd();
    try {
      process.chdir(testDir);
      let err: any;
      try {
        execSync(`node ${openspecBin} show unknown-item`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      const stderr = err.stderr.toString();
      expect(stderr).toContain("Unknown item 'unknown-item'");
      expect(stderr).toContain('Did you mean:');
    } finally {
      process.chdir(originalCwd);
    }
  });
});





================================================
FILE: test/commands/spec.interactive-show.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

describe('spec show (interactive behavior)', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-spec-show-tmp');
  const specsDir = path.join(testDir, 'openspec', 'specs');
  const bin = path.join(projectRoot, 'bin', 'openspec.js');


  beforeEach(async () => {
    await fs.mkdir(specsDir, { recursive: true });
    const content = `## Purpose\nX\n\n## Requirements\n\n### Requirement: R\nText`;
    await fs.mkdir(path.join(specsDir, 's1'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 's1', 'spec.md'), content, 'utf-8');
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('errors when no arg and non-interactive', () => {
    const originalCwd = process.cwd();
    const originalEnv = { ...process.env };
    try {
      process.chdir(testDir);
      process.env.OPEN_SPEC_INTERACTIVE = '0';
      let err: any;
      try {
        execSync(`node ${bin} spec show`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      expect(err.stderr.toString()).toContain('Missing required argument <spec-id>');
    } finally {
      process.chdir(originalCwd);
      process.env = originalEnv;
    }
  });
});





================================================
FILE: test/commands/spec.interactive-validate.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

describe('spec validate (interactive behavior)', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-spec-validate-tmp');
  const specsDir = path.join(testDir, 'openspec', 'specs');
  const bin = path.join(projectRoot, 'bin', 'openspec.js');


  beforeEach(async () => {
    await fs.mkdir(specsDir, { recursive: true });
    const content = `## Purpose\nValid spec for interactive test.\n\n## Requirements\n\n### Requirement: X\nText`;
    await fs.mkdir(path.join(specsDir, 's1'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 's1', 'spec.md'), content, 'utf-8');
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('errors when no arg and non-interactive', () => {
    const originalCwd = process.cwd();
    const originalEnv = { ...process.env };
    try {
      process.chdir(testDir);
      process.env.OPEN_SPEC_INTERACTIVE = '0';
      let err: any;
      try {
        execSync(`node ${bin} spec validate`, { encoding: 'utf-8' });
      } catch (e) { err = e; }
      expect(err).toBeDefined();
      expect(err.status).not.toBe(0);
      expect(err.stderr.toString()).toContain('Missing required argument <spec-id>');
    } finally {
      process.chdir(originalCwd);
      process.env = originalEnv;
    }
  });
});





================================================
FILE: test/commands/spec.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

describe('spec command', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-spec-command-tmp');
  const specsDir = path.join(testDir, 'openspec', 'specs');
  const openspecBin = path.join(projectRoot, 'bin', 'openspec.js');
  
  
  beforeEach(async () => {
    await fs.mkdir(specsDir, { recursive: true });
    
    // Create test spec files
    const testSpec = `## Purpose
This is a test specification for the authentication system.

## Requirements

### Requirement: User Authentication
The system SHALL provide secure user authentication

#### Scenario: Successful login
- **GIVEN** a user with valid credentials
- **WHEN** they submit the login form  
- **THEN** they are authenticated

### Requirement: Password Reset
The system SHALL allow users to reset their password

#### Scenario: Reset via email
- **GIVEN** a user with a registered email
- **WHEN** they request a password reset
- **THEN** they receive a reset link`;

    await fs.mkdir(path.join(specsDir, 'auth'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 'auth', 'spec.md'), testSpec);
    
    const testSpec2 = `## Purpose
This specification defines the payment processing system.

## Requirements

### Requirement: Process Payments
The system SHALL process credit card payments securely`;

    await fs.mkdir(path.join(specsDir, 'payment'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 'payment', 'spec.md'), testSpec2);
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('spec show', () => {
    it('should display spec in text format', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec show auth`, {
          encoding: 'utf-8'
        });
        
        // Raw passthrough should match spec.md content
        const raw = execSync(`cat ${path.join(specsDir, 'auth', 'spec.md')}`, { encoding: 'utf-8' });
        expect(output.trim()).toBe(raw.trim());
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should output spec as JSON with --json flag', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec show auth --json`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.id).toBe('auth');
        expect(json.title).toBe('auth');
        expect(json.overview).toContain('test specification');
        expect(json.requirements).toHaveLength(2);
        expect(json.metadata.format).toBe('openspec');
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should filter to show only requirements with --requirements flag (JSON only)', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec show auth --json --requirements`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.requirements).toHaveLength(2);
        // Scenarios should be excluded when --requirements is used
        expect(json.requirements.every((r: any) => Array.isArray(r.scenarios) && r.scenarios.length === 0)).toBe(true);
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should exclude scenarios with --no-scenarios flag (JSON only)', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec show auth --json --no-scenarios`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.requirements).toHaveLength(2);
        expect(json.requirements.every((r: any) => Array.isArray(r.scenarios) && r.scenarios.length === 0)).toBe(true);
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should show specific requirement with -r flag (JSON only)', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec show auth --json -r 1`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.requirements).toHaveLength(1);
        expect(json.requirements[0].text).toContain('The system SHALL provide secure user authentication');
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should return JSON with filtered requirements', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec show auth --json --no-scenarios`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.requirements).toHaveLength(2);
        expect(json.requirements[0].scenarios).toHaveLength(0);
      } finally {
        process.chdir(originalCwd);
      }
    });
  });

  describe('spec list', () => {
    it('should list all available specs (IDs only by default)', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec list`, {
          encoding: 'utf-8'
        });
        
        expect(output).toContain('auth');
        expect(output).toContain('payment');
        // Default should not include counts or teasers
        expect(output).not.toMatch(/Requirements:\s*\d+/);
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should output spec list as JSON with --json flag', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec list --json`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json).toHaveLength(2);
        expect(json.find((s: any) => s.id === 'auth')).toBeDefined();
        expect(json.find((s: any) => s.id === 'payment')).toBeDefined();
        expect(json[0].requirementCount).toBeDefined();
      } finally {
        process.chdir(originalCwd);
      }
    });
  });

  describe('spec validate', () => {
    it('should validate a valid spec', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec validate auth`, {
          encoding: 'utf-8'
        });
        
        expect(output).toContain("Specification 'auth' is valid");
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should output validation report as JSON with --json flag', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec validate auth --json`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.valid).toBeDefined();
        expect(json.issues).toBeDefined();
        expect(json.summary).toBeDefined();
        expect(json.summary.errors).toBeDefined();
        expect(json.summary.warnings).toBeDefined();
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should validate with strict mode', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec validate auth --strict --json`, {
          encoding: 'utf-8'
        });
        
        const json = JSON.parse(output);
        expect(json.valid).toBeDefined();
        // In strict mode, warnings also affect validity
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should detect invalid spec structure', async () => {
      const invalidSpec = `## Purpose

## Requirements
This section has no actual requirements`;

      await fs.mkdir(path.join(specsDir, 'invalid'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'invalid', 'spec.md'), invalidSpec);

      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        
        // This should exit with non-zero code
        let exitCode = 0;
        try {
          execSync(`node ${openspecBin} spec validate invalid`, {
            encoding: 'utf-8'
          });
        } catch (error: any) {
          exitCode = error.status;
        }
        
        expect(exitCode).not.toBe(0);
      } finally {
        process.chdir(originalCwd);
      }
    });
  });

  describe('error handling', () => {
    it('should handle non-existent spec gracefully', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        
        let error: any;
        try {
          execSync(`node ${openspecBin} spec show nonexistent`, {
            encoding: 'utf-8'
          });
        } catch (e) {
          error = e;
        }
        
        expect(error).toBeDefined();
        expect(error.status).not.toBe(0);
        expect(error.stderr.toString()).toContain('not found');
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should handle missing specs directory gracefully', async () => {
      await fs.rm(specsDir, { recursive: true, force: true });
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} spec list`, { encoding: 'utf-8' });
        expect(output.trim()).toBe('No items found');
      } finally {
        process.chdir(originalCwd);
      }
    });

    it('should honor --no-color (no ANSI escapes)', () => {
      const originalCwd = process.cwd();
      try {
        process.chdir(testDir);
        const output = execSync(`node ${openspecBin} --no-color spec list --long`, { encoding: 'utf-8' });
        // Basic ANSI escape pattern
        const hasAnsi = /\u001b\[[0-9;]*m/.test(output);
        expect(hasAnsi).toBe(false);
      } finally {
        process.chdir(originalCwd);
      }
    });
  });
});


================================================
FILE: test/commands/validate.enriched-output.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { execSync } from 'child_process';

describe('validate command enriched human output', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-validate-enriched-tmp');
  const changesDir = path.join(testDir, 'openspec', 'changes');
  const bin = path.join(projectRoot, 'bin', 'openspec.js');


  beforeEach(async () => {
    await fs.mkdir(changesDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('prints Next steps footer and guidance on invalid change', () => {
    const changeContent = `# Test Change\n\n## Why\nThis is a sufficiently long explanation to pass the why length requirement for validation purposes.\n\n## What Changes\nThere are changes proposed, but no delta specs provided yet.`;
    const changeId = 'c-next-steps';
    const changePath = path.join(changesDir, changeId);
    execSync(`mkdir -p ${changePath}`);
    execSync(`bash -lc "cat > ${path.join(changePath, 'proposal.md')} <<'EOF'\n${changeContent}\nEOF"`);

    const originalCwd = process.cwd();
    try {
      process.chdir(testDir);
      let code = 0;
      let stderr = '';
      try {
        execSync(`node ${bin} change validate ${changeId}`, { encoding: 'utf-8', stdio: 'pipe' });
      } catch (e: any) {
        code = e?.status ?? 1;
        stderr = e?.stderr?.toString?.() ?? '';
      }
      expect(code).not.toBe(0);
      expect(stderr).toContain('has issues');
      expect(stderr).toContain('Next steps:');
      expect(stderr).toContain('openspec change show');
    } finally {
      process.chdir(originalCwd);
    }
  });
});





================================================
FILE: test/commands/validate.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { runCLI } from '../helpers/run-cli.js';

describe('top-level validate command', () => {
  const projectRoot = process.cwd();
  const testDir = path.join(projectRoot, 'test-validate-command-tmp');
  const changesDir = path.join(testDir, 'openspec', 'changes');
  const specsDir = path.join(testDir, 'openspec', 'specs');

  beforeEach(async () => {
    await fs.mkdir(changesDir, { recursive: true });
    await fs.mkdir(specsDir, { recursive: true });

    // Create a valid spec
    const specContent = [
      '## Purpose',
      'This spec ensures the validation harness exercises a deterministic alpha module for automated tests.',
      '',
      '## Requirements',
      '',
      '### Requirement: Alpha module SHALL produce deterministic output',
      'The alpha module SHALL produce a deterministic response for validation.',
      '',
      '#### Scenario: Deterministic alpha run',
      '- **GIVEN** a configured alpha module',
      '- **WHEN** the module runs the default flow',
      '- **THEN** the output matches the expected fixture result',
    ].join('\n');
    await fs.mkdir(path.join(specsDir, 'alpha'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 'alpha', 'spec.md'), specContent, 'utf-8');

    // Create a simple change with bullets (parser supports this)
    const changeContent = `# Test Change\n\n## Why\nBecause reasons that are sufficiently long for validation.\n\n## What Changes\n- **alpha:** Add something`;
    await fs.mkdir(path.join(changesDir, 'c1'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'c1', 'proposal.md'), changeContent, 'utf-8');
    const deltaContent = [
      '## ADDED Requirements',
      '### Requirement: Validator SHALL support alpha change deltas',
      'The validator SHALL accept deltas provided by the test harness.',
      '',
      '#### Scenario: Apply alpha delta',
      '- **GIVEN** the test change delta',
      '- **WHEN** openspec validate runs',
      '- **THEN** the validator reports the change as valid',
    ].join('\n');
    const c1DeltaDir = path.join(changesDir, 'c1', 'specs', 'alpha');
    await fs.mkdir(c1DeltaDir, { recursive: true });
    await fs.writeFile(path.join(c1DeltaDir, 'spec.md'), deltaContent, 'utf-8');

    // Duplicate name for ambiguity test
    await fs.mkdir(path.join(changesDir, 'dup'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'dup', 'proposal.md'), changeContent, 'utf-8');
    const dupDeltaDir = path.join(changesDir, 'dup', 'specs', 'dup');
    await fs.mkdir(dupDeltaDir, { recursive: true });
    await fs.writeFile(path.join(dupDeltaDir, 'spec.md'), deltaContent, 'utf-8');
    await fs.mkdir(path.join(specsDir, 'dup'), { recursive: true });
    await fs.writeFile(path.join(specsDir, 'dup', 'spec.md'), specContent, 'utf-8');
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('prints a helpful hint when no args in non-interactive mode', async () => {
    const result = await runCLI(['validate'], { cwd: testDir });
    expect(result.exitCode).toBe(1);
    expect(result.stderr).toContain('Nothing to validate. Try one of:');
  });

  it('validates all with --all and outputs JSON summary', async () => {
    const result = await runCLI(['validate', '--all', '--json'], { cwd: testDir });
    expect(result.exitCode).toBe(0);
    const output = result.stdout.trim();
    expect(output).not.toBe('');
    const json = JSON.parse(output);
    expect(Array.isArray(json.items)).toBe(true);
    expect(json.summary?.totals?.items).toBeDefined();
    expect(json.version).toBe('1.0');
  });

  it('validates only specs with --specs and respects --concurrency', async () => {
    const result = await runCLI(['validate', '--specs', '--json', '--concurrency', '1'], { cwd: testDir });
    expect(result.exitCode).toBe(0);
    const output = result.stdout.trim();
    expect(output).not.toBe('');
    const json = JSON.parse(output);
    expect(json.items.every((i: any) => i.type === 'spec')).toBe(true);
  });

  it('errors on ambiguous item names and suggests type override', async () => {
    const result = await runCLI(['validate', 'dup'], { cwd: testDir });
    expect(result.exitCode).toBe(1);
    expect(result.stderr).toContain('Ambiguous item');
  });

  it('accepts change proposals saved with CRLF line endings', async () => {
    const changeId = 'crlf-change';
    const toCrlf = (segments: string[]) => segments.join('\n').replace(/\n/g, '\r\n');

    const crlfContent = toCrlf([
      '# CRLF Proposal',
      '',
      '## Why',
      'This change verifies validation works with Windows line endings.',
      '',
      '## What Changes',
      '- **alpha:** Ensure validation passes on CRLF files',
    ]);

    await fs.mkdir(path.join(changesDir, changeId), { recursive: true });
    await fs.writeFile(path.join(changesDir, changeId, 'proposal.md'), crlfContent, 'utf-8');

    const deltaContent = toCrlf([
      '## ADDED Requirements',
      '### Requirement: Parser SHALL accept CRLF change proposals',
      'The parser SHALL accept CRLF change proposals without manual edits.',
      '',
      '#### Scenario: Validate CRLF change',
      '- **GIVEN** a change proposal saved with CRLF line endings',
      '- **WHEN** a developer runs openspec validate on the proposal',
      '- **THEN** validation succeeds without section errors',
    ]);

    const deltaDir = path.join(changesDir, changeId, 'specs', 'alpha');
    await fs.mkdir(deltaDir, { recursive: true });
    await fs.writeFile(path.join(deltaDir, 'spec.md'), deltaContent, 'utf-8');

    const result = await runCLI(['validate', changeId], { cwd: testDir });
    expect(result.exitCode).toBe(0);
  });

  it('respects --no-interactive flag passed via CLI', async () => {
    // This test ensures Commander.js --no-interactive flag is correctly parsed
    // and passed to the validate command. The flag sets options.interactive = false
    // (not options.noInteractive = true) due to Commander.js convention.
    const result = await runCLI(['validate', '--specs', '--no-interactive'], {
      cwd: testDir,
      // Don't set OPEN_SPEC_INTERACTIVE to ensure we're testing the flag itself
      env: { ...process.env, OPEN_SPEC_INTERACTIVE: undefined },
    });
    expect(result.exitCode).toBe(0);
    // Should complete without hanging and without prompts
    expect(result.stderr).not.toContain('What would you like to validate?');
  });
});



================================================
FILE: test/core/archive.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { ArchiveCommand } from '../../src/core/archive.js';
import { Validator } from '../../src/core/validation/validator.js';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';

// Mock @inquirer/prompts
vi.mock('@inquirer/prompts', () => ({
  select: vi.fn(),
  confirm: vi.fn()
}));

describe('ArchiveCommand', () => {
  let tempDir: string;
  let archiveCommand: ArchiveCommand;
  const originalConsoleLog = console.log;

  beforeEach(async () => {
    // Create temp directory
    tempDir = path.join(os.tmpdir(), `openspec-archive-test-${Date.now()}`);
    await fs.mkdir(tempDir, { recursive: true });
    
    // Change to temp directory
    process.chdir(tempDir);
    
    // Create OpenSpec structure
    const openspecDir = path.join(tempDir, 'openspec');
    await fs.mkdir(path.join(openspecDir, 'changes'), { recursive: true });
    await fs.mkdir(path.join(openspecDir, 'specs'), { recursive: true });
    await fs.mkdir(path.join(openspecDir, 'changes', 'archive'), { recursive: true });
    
    // Suppress console.log during tests
    console.log = vi.fn();
    
    archiveCommand = new ArchiveCommand();
  });

  afterEach(async () => {
    // Restore console.log
    console.log = originalConsoleLog;
    
    // Clear mocks
    vi.clearAllMocks();
    
    // Clean up temp directory
    try {
      await fs.rm(tempDir, { recursive: true, force: true });
    } catch (error) {
      // Ignore cleanup errors
    }
  });

  describe('execute', () => {
    it('should archive a change successfully', async () => {
      // Create a test change
      const changeName = 'test-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Create tasks.md with completed tasks
      const tasksContent = '- [x] Task 1\n- [x] Task 2';
      await fs.writeFile(path.join(changeDir, 'tasks.md'), tasksContent);
      
      // Execute archive with --yes flag
      await archiveCommand.execute(changeName, { yes: true });
      
      // Check that change was moved to archive
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      
      expect(archives.length).toBe(1);
      expect(archives[0]).toMatch(new RegExp(`\\d{4}-\\d{2}-\\d{2}-${changeName}`));
      
      // Verify original change directory no longer exists
      await expect(fs.access(changeDir)).rejects.toThrow();
    });

    it('should warn about incomplete tasks', async () => {
      const changeName = 'incomplete-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Create tasks.md with incomplete tasks
      const tasksContent = '- [x] Task 1\n- [ ] Task 2\n- [ ] Task 3';
      await fs.writeFile(path.join(changeDir, 'tasks.md'), tasksContent);
      
      // Execute archive with --yes flag
      await archiveCommand.execute(changeName, { yes: true });
      
      // Verify warning was logged
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('Warning: 2 incomplete task(s) found')
      );
    });

    it('should update specs when archiving (delta-based ADDED) and include change name in skeleton', async () => {
      const changeName = 'spec-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'test-capability');
      await fs.mkdir(changeSpecDir, { recursive: true });
      
      // Create delta-based change spec (ADDED requirement)
      const specContent = `# Test Capability Spec - Changes

## ADDED Requirements

### Requirement: The system SHALL provide test capability

#### Scenario: Basic test
Given a test condition
When an action occurs
Then expected result happens`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), specContent);
      
      // Execute archive with --yes flag and skip validation for speed
      await archiveCommand.execute(changeName, { yes: true, noValidate: true });
      
      // Verify spec was created from skeleton and ADDED requirement applied
      const mainSpecPath = path.join(tempDir, 'openspec', 'specs', 'test-capability', 'spec.md');
      const updatedContent = await fs.readFile(mainSpecPath, 'utf-8');
      expect(updatedContent).toContain('# test-capability Specification');
      expect(updatedContent).toContain('## Purpose');
      expect(updatedContent).toContain(`created by archiving change ${changeName}`);
      expect(updatedContent).toContain('## Requirements');
      expect(updatedContent).toContain('### Requirement: The system SHALL provide test capability');
      expect(updatedContent).toContain('#### Scenario: Basic test');
    });

    it('should allow REMOVED requirements when creating new spec file (issue #403)', async () => {
      const changeName = 'new-spec-with-removed';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'gift-card');
      await fs.mkdir(changeSpecDir, { recursive: true });
      
      // Create delta spec with both ADDED and REMOVED requirements
      // This simulates refactoring where old fields are removed and new ones are added
      const specContent = `# Gift Card - Changes

## ADDED Requirements

### Requirement: Logo and Background Color
The system SHALL support logo and backgroundColor fields for gift cards.

#### Scenario: Display gift card with logo
- **WHEN** a gift card is displayed
- **THEN** it shows the logo and backgroundColor

## REMOVED Requirements

### Requirement: Image Field
### Requirement: Thumbnail Field`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), specContent);
      
      // Execute archive - should succeed with warning about REMOVED requirements
      await archiveCommand.execute(changeName, { yes: true, noValidate: true });
      
      // Verify warning was logged about REMOVED requirements being ignored
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('Warning: gift-card - 2 REMOVED requirement(s) ignored for new spec (nothing to remove).')
      );
      
      // Verify spec was created with only ADDED requirements
      const mainSpecPath = path.join(tempDir, 'openspec', 'specs', 'gift-card', 'spec.md');
      const updatedContent = await fs.readFile(mainSpecPath, 'utf-8');
      expect(updatedContent).toContain('# gift-card Specification');
      expect(updatedContent).toContain('### Requirement: Logo and Background Color');
      expect(updatedContent).toContain('#### Scenario: Display gift card with logo');
      // REMOVED requirements should not be in the final spec
      expect(updatedContent).not.toContain('### Requirement: Image Field');
      expect(updatedContent).not.toContain('### Requirement: Thumbnail Field');
      
      // Verify change was archived successfully
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.length).toBeGreaterThan(0);
      expect(archives.some(a => a.includes(changeName))).toBe(true);
    });

    it('should still error on MODIFIED when creating new spec file', async () => {
      const changeName = 'new-spec-with-modified';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'new-capability');
      await fs.mkdir(changeSpecDir, { recursive: true });
      
      // Create delta spec with MODIFIED requirement (should fail for new spec)
      const specContent = `# New Capability - Changes

## ADDED Requirements

### Requirement: New Feature
New feature description.

## MODIFIED Requirements

### Requirement: Existing Feature
Modified content.`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), specContent);
      
      // Execute archive - should abort with error message (not throw, but log and return)
      await archiveCommand.execute(changeName, { yes: true, noValidate: true });
      
      // Verify error message mentions MODIFIED not allowed for new specs
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('new-capability: target spec does not exist; only ADDED requirements are allowed for new specs. MODIFIED and RENAMED operations require an existing spec.')
      );
      expect(console.log).toHaveBeenCalledWith('Aborted. No files were changed.');
      
      // Verify spec was NOT created
      const mainSpecPath = path.join(tempDir, 'openspec', 'specs', 'new-capability', 'spec.md');
      await expect(fs.access(mainSpecPath)).rejects.toThrow();
      
      // Verify change was NOT archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.some(a => a.includes(changeName))).toBe(false);
    });

    it('should still error on RENAMED when creating new spec file', async () => {
      const changeName = 'new-spec-with-renamed';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'another-capability');
      await fs.mkdir(changeSpecDir, { recursive: true });
      
      // Create delta spec with RENAMED requirement (should fail for new spec)
      const specContent = `# Another Capability - Changes

## ADDED Requirements

### Requirement: New Feature
New feature description.

## RENAMED Requirements
- FROM: \`### Requirement: Old Name\`
- TO: \`### Requirement: New Name\``;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), specContent);
      
      // Execute archive - should abort with error message (not throw, but log and return)
      await archiveCommand.execute(changeName, { yes: true, noValidate: true });
      
      // Verify error message mentions RENAMED not allowed for new specs
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('another-capability: target spec does not exist; only ADDED requirements are allowed for new specs. MODIFIED and RENAMED operations require an existing spec.')
      );
      expect(console.log).toHaveBeenCalledWith('Aborted. No files were changed.');
      
      // Verify spec was NOT created
      const mainSpecPath = path.join(tempDir, 'openspec', 'specs', 'another-capability', 'spec.md');
      await expect(fs.access(mainSpecPath)).rejects.toThrow();
      
      // Verify change was NOT archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.some(a => a.includes(changeName))).toBe(false);
    });

    it('should throw error if change does not exist', async () => {
      await expect(
        archiveCommand.execute('non-existent-change', { yes: true })
      ).rejects.toThrow("Change 'non-existent-change' not found.");
    });

    it('should throw error if archive already exists', async () => {
      const changeName = 'duplicate-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Create existing archive with same date
      const date = new Date().toISOString().split('T')[0];
      const archivePath = path.join(tempDir, 'openspec', 'changes', 'archive', `${date}-${changeName}`);
      await fs.mkdir(archivePath, { recursive: true });
      
      // Try to archive
      await expect(
        archiveCommand.execute(changeName, { yes: true })
      ).rejects.toThrow(`Archive '${date}-${changeName}' already exists.`);
    });

    it('should handle changes without tasks.md', async () => {
      const changeName = 'no-tasks-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Execute archive without tasks.md
      await archiveCommand.execute(changeName, { yes: true });
      
      // Should complete without warnings
      expect(console.log).not.toHaveBeenCalledWith(
        expect.stringContaining('incomplete task(s)')
      );
      
      // Verify change was archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.length).toBe(1);
    });

    it('should handle changes without specs', async () => {
      const changeName = 'no-specs-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Execute archive without specs
      await archiveCommand.execute(changeName, { yes: true });
      
      // Should complete without spec updates
      expect(console.log).not.toHaveBeenCalledWith(
        expect.stringContaining('Specs to update')
      );
      
      // Verify change was archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.length).toBe(1);
    });

    it('should skip spec updates when --skip-specs flag is used', async () => {
      const changeName = 'skip-specs-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'test-capability');
      await fs.mkdir(changeSpecDir, { recursive: true });
      
      // Create spec in change
      const specContent = '# Test Capability Spec\n\nTest content';
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), specContent);
      
      // Execute archive with --skip-specs flag and noValidate to skip validation
      await archiveCommand.execute(changeName, { yes: true, skipSpecs: true, noValidate: true });
      
      // Verify skip message was logged
      expect(console.log).toHaveBeenCalledWith(
        'Skipping spec updates (--skip-specs flag provided).'
      );
      
      // Verify spec was NOT copied to main specs
      const mainSpecPath = path.join(tempDir, 'openspec', 'specs', 'test-capability', 'spec.md');
      await expect(fs.access(mainSpecPath)).rejects.toThrow();
      
      // Verify change was still archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.length).toBe(1);
      expect(archives[0]).toMatch(new RegExp(`\\d{4}-\\d{2}-\\d{2}-${changeName}`));
    });

    it('should skip validation when commander sets validate to false (--no-validate)', async () => {
      const changeName = 'skip-validation-flag';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'unstable-capability');
      await fs.mkdir(changeSpecDir, { recursive: true });

      const deltaSpec = `# Unstable Capability

## ADDED Requirements

### Requirement: Logging Feature
**ID**: REQ-LOG-001

The system will log all events.

#### Scenario: Event recorded
- **WHEN** an event occurs
- **THEN** it is captured`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), deltaSpec);
      await fs.writeFile(path.join(changeDir, 'tasks.md'), '- [x] Task 1\n');

      const deltaSpy = vi.spyOn(Validator.prototype, 'validateChangeDeltaSpecs');
      const specContentSpy = vi.spyOn(Validator.prototype, 'validateSpecContent');

      try {
        await archiveCommand.execute(changeName, { yes: true, skipSpecs: true, validate: false });

        expect(deltaSpy).not.toHaveBeenCalled();
        expect(specContentSpy).not.toHaveBeenCalled();

        const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
        const archives = await fs.readdir(archiveDir);
        expect(archives.length).toBe(1);
        expect(archives[0]).toMatch(new RegExp(`\\d{4}-\\d{2}-\\d{2}-${changeName}`));
      } finally {
        deltaSpy.mockRestore();
        specContentSpy.mockRestore();
      }
    });

    it('should proceed with archive when user declines spec updates', async () => {
      const { confirm } = await import('@inquirer/prompts');
      const mockConfirm = confirm as unknown as ReturnType<typeof vi.fn>;
      
      const changeName = 'decline-specs-feature';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'test-capability');
      await fs.mkdir(changeSpecDir, { recursive: true });
      
      // Create valid spec in change
      const specContent = `# Test Capability Spec

## Purpose
This is a test capability specification.

## Requirements

### The system SHALL provide test capability

#### Scenario: Basic test
Given a test condition
When an action occurs
Then expected result happens`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), specContent);
      
      // Mock confirm to return false (decline spec updates)
      mockConfirm.mockResolvedValueOnce(false);
      
      // Execute archive without --yes flag
      await archiveCommand.execute(changeName);
      
      // Verify user was prompted about specs
      expect(mockConfirm).toHaveBeenCalledWith({
        message: 'Proceed with spec updates?',
        default: true
      });
      
      // Verify skip message was logged
      expect(console.log).toHaveBeenCalledWith(
        'Skipping spec updates. Proceeding with archive.'
      );
      
      // Verify spec was NOT copied to main specs
      const mainSpecPath = path.join(tempDir, 'openspec', 'specs', 'test-capability', 'spec.md');
      await expect(fs.access(mainSpecPath)).rejects.toThrow();
      
      // Verify change was still archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives.length).toBe(1);
      expect(archives[0]).toMatch(new RegExp(`\\d{4}-\\d{2}-\\d{2}-${changeName}`));
    });

    it('should support header trim-only normalization for matching', async () => {
      const changeName = 'normalize-headers';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'alpha');
      await fs.mkdir(changeSpecDir, { recursive: true });

      // Create existing main spec with a requirement (no extra trailing spaces)
      const mainSpecDir = path.join(tempDir, 'openspec', 'specs', 'alpha');
      await fs.mkdir(mainSpecDir, { recursive: true });
      const mainContent = `# alpha Specification

## Purpose
Alpha purpose.

## Requirements

### Requirement: Important Rule
Some details.`;
      await fs.writeFile(path.join(mainSpecDir, 'spec.md'), mainContent);

      // Change attempts to modify the same requirement but with trailing spaces after the name
      const deltaContent = `# Alpha - Changes

## MODIFIED Requirements

### Requirement: Important Rule   
Updated details.`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), deltaContent);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });

      const updated = await fs.readFile(path.join(mainSpecDir, 'spec.md'), 'utf-8');
      expect(updated).toContain('### Requirement: Important Rule');
      expect(updated).toContain('Updated details.');
    });

    it('should apply operations in order: RENAMED â†’ REMOVED â†’ MODIFIED â†’ ADDED', async () => {
      const changeName = 'apply-order';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'beta');
      await fs.mkdir(changeSpecDir, { recursive: true });

      // Main spec with two requirements A and B
      const mainSpecDir = path.join(tempDir, 'openspec', 'specs', 'beta');
      await fs.mkdir(mainSpecDir, { recursive: true });
      const mainContent = `# beta Specification

## Purpose
Beta purpose.

## Requirements

### Requirement: A
content A

### Requirement: B
content B`;
      await fs.writeFile(path.join(mainSpecDir, 'spec.md'), mainContent);

      // Rename A->C, Remove B, Modify C, Add D
      const deltaContent = `# Beta - Changes

## RENAMED Requirements
- FROM: \`### Requirement: A\`
- TO: \`### Requirement: C\`

## REMOVED Requirements
### Requirement: B

## MODIFIED Requirements
### Requirement: C
updated C

## ADDED Requirements
### Requirement: D
content D`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), deltaContent);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });

      const updated = await fs.readFile(path.join(mainSpecDir, 'spec.md'), 'utf-8');
      expect(updated).toContain('### Requirement: C');
      expect(updated).toContain('updated C');
      expect(updated).toContain('### Requirement: D');
      expect(updated).not.toContain('### Requirement: A');
      expect(updated).not.toContain('### Requirement: B');
    });

    it('should abort with error when MODIFIED/REMOVED reference non-existent requirements', async () => {
      const changeName = 'validate-missing';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'gamma');
      await fs.mkdir(changeSpecDir, { recursive: true });

      // Main spec with no requirements
      const mainSpecDir = path.join(tempDir, 'openspec', 'specs', 'gamma');
      await fs.mkdir(mainSpecDir, { recursive: true });
      const mainContent = `# gamma Specification

## Purpose
Gamma purpose.

## Requirements`;
      await fs.writeFile(path.join(mainSpecDir, 'spec.md'), mainContent);

      // Delta tries to modify and remove non-existent requirement
      const deltaContent = `# Gamma - Changes

## MODIFIED Requirements
### Requirement: Missing
new text

## REMOVED Requirements
### Requirement: Another Missing`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), deltaContent);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });

      // Should not change the main spec and should not archive the change dir
      const still = await fs.readFile(path.join(mainSpecDir, 'spec.md'), 'utf-8');
      expect(still).toBe(mainContent);
      // Change dir should still exist since operation aborted
      await expect(fs.access(changeDir)).resolves.not.toThrow();
    });

    it('should require MODIFIED to reference the NEW header when a rename exists (error format)', async () => {
      const changeName = 'rename-modify-new-header';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const changeSpecDir = path.join(changeDir, 'specs', 'delta');
      await fs.mkdir(changeSpecDir, { recursive: true });

      // Main spec with Old
      const mainSpecDir = path.join(tempDir, 'openspec', 'specs', 'delta');
      await fs.mkdir(mainSpecDir, { recursive: true });
      const mainContent = `# delta Specification

## Purpose
Delta purpose.

## Requirements

### Requirement: Old
old body`;
      await fs.writeFile(path.join(mainSpecDir, 'spec.md'), mainContent);

      // Delta: rename Old->New, but MODIFIED references Old (should abort)
      const badDelta = `# Delta - Changes

## RENAMED Requirements
- FROM: \`### Requirement: Old\`
- TO: \`### Requirement: New\`

## MODIFIED Requirements
### Requirement: Old
new body`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), badDelta);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });
      const unchanged = await fs.readFile(path.join(mainSpecDir, 'spec.md'), 'utf-8');
      expect(unchanged).toBe(mainContent);
      // Assert error message format and abort notice
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('delta validation failed')
      );
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('Aborted. No files were changed.')
      );

      // Fix MODIFIED to reference New (should succeed)
      const goodDelta = `# Delta - Changes

## RENAMED Requirements
- FROM: \`### Requirement: Old\`
- TO: \`### Requirement: New\`

## MODIFIED Requirements
### Requirement: New
new body`;
      await fs.writeFile(path.join(changeSpecDir, 'spec.md'), goodDelta);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });
      const updated = await fs.readFile(path.join(mainSpecDir, 'spec.md'), 'utf-8');
      expect(updated).toContain('### Requirement: New');
      expect(updated).toContain('new body');
      expect(updated).not.toContain('### Requirement: Old');
    });

    it('should process multiple specs atomically (any failure aborts all)', async () => {
      const changeName = 'multi-spec-atomic';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const spec1Dir = path.join(changeDir, 'specs', 'epsilon');
      const spec2Dir = path.join(changeDir, 'specs', 'zeta');
      await fs.mkdir(spec1Dir, { recursive: true });
      await fs.mkdir(spec2Dir, { recursive: true });

      // Existing main specs
      const epsilonMain = path.join(tempDir, 'openspec', 'specs', 'epsilon', 'spec.md');
      await fs.mkdir(path.dirname(epsilonMain), { recursive: true });
      await fs.writeFile(epsilonMain, `# epsilon Specification

## Purpose
Epsilon purpose.

## Requirements

### Requirement: E1
e1`);

      const zetaMain = path.join(tempDir, 'openspec', 'specs', 'zeta', 'spec.md');
      await fs.mkdir(path.dirname(zetaMain), { recursive: true });
      await fs.writeFile(zetaMain, `# zeta Specification

## Purpose
Zeta purpose.

## Requirements

### Requirement: Z1
z1`);

      // Delta: epsilon is valid modification; zeta tries to remove non-existent -> should abort both
      await fs.writeFile(path.join(spec1Dir, 'spec.md'), `# Epsilon - Changes

## MODIFIED Requirements
### Requirement: E1
E1 updated`);

      await fs.writeFile(path.join(spec2Dir, 'spec.md'), `# Zeta - Changes

## REMOVED Requirements
### Requirement: Missing`);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });

      const e1 = await fs.readFile(epsilonMain, 'utf-8');
      const z1 = await fs.readFile(zetaMain, 'utf-8');
      expect(e1).toContain('### Requirement: E1');
      expect(e1).not.toContain('E1 updated');
      expect(z1).toContain('### Requirement: Z1');
      // changeDir should still exist
      await expect(fs.access(changeDir)).resolves.not.toThrow();
    });

    it('should display aggregated totals across multiple specs', async () => {
      const changeName = 'multi-spec-totals';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      const spec1Dir = path.join(changeDir, 'specs', 'omega');
      const spec2Dir = path.join(changeDir, 'specs', 'psi');
      await fs.mkdir(spec1Dir, { recursive: true });
      await fs.mkdir(spec2Dir, { recursive: true });

      // Existing main specs
      const omegaMain = path.join(tempDir, 'openspec', 'specs', 'omega', 'spec.md');
      await fs.mkdir(path.dirname(omegaMain), { recursive: true });
      await fs.writeFile(omegaMain, `# omega Specification\n\n## Purpose\nOmega purpose.\n\n## Requirements\n\n### Requirement: O1\no1`);

      const psiMain = path.join(tempDir, 'openspec', 'specs', 'psi', 'spec.md');
      await fs.mkdir(path.dirname(psiMain), { recursive: true });
      await fs.writeFile(psiMain, `# psi Specification\n\n## Purpose\nPsi purpose.\n\n## Requirements\n\n### Requirement: P1\np1`);

      // Deltas: omega add one, psi rename and modify -> totals: +1, ~1, -0, â†’1
      await fs.writeFile(path.join(spec1Dir, 'spec.md'), `# Omega - Changes\n\n## ADDED Requirements\n\n### Requirement: O2\nnew`);
      await fs.writeFile(path.join(spec2Dir, 'spec.md'), `# Psi - Changes\n\n## RENAMED Requirements\n- FROM: \`### Requirement: P1\`\n- TO: \`### Requirement: P2\`\n\n## MODIFIED Requirements\n### Requirement: P2\nupdated`);

      await archiveCommand.execute(changeName, { yes: true, noValidate: true });

      // Verify aggregated totals line was printed
      expect(console.log).toHaveBeenCalledWith(
        expect.stringContaining('Totals: + 1, ~ 1, - 0, â†’ 1')
      );
    });
  });

  describe('error handling', () => {
    it('should throw error when openspec directory does not exist', async () => {
      // Remove openspec directory
      await fs.rm(path.join(tempDir, 'openspec'), { recursive: true });
      
      await expect(
        archiveCommand.execute('any-change', { yes: true })
      ).rejects.toThrow("No OpenSpec changes directory found. Run 'openspec init' first.");
    });
  });

  describe('interactive mode', () => {
    it('should use select prompt for change selection', async () => {
      const { select } = await import('@inquirer/prompts');
      const mockSelect = select as unknown as ReturnType<typeof vi.fn>;
      
      // Create test changes
      const change1 = 'feature-a';
      const change2 = 'feature-b';
      await fs.mkdir(path.join(tempDir, 'openspec', 'changes', change1), { recursive: true });
      await fs.mkdir(path.join(tempDir, 'openspec', 'changes', change2), { recursive: true });
      
      // Mock select to return first change
      mockSelect.mockResolvedValueOnce(change1);
      
      // Execute without change name
      await archiveCommand.execute(undefined, { yes: true });
      
      // Verify select was called with correct options (values matter, names may include progress)
      expect(mockSelect).toHaveBeenCalledWith(expect.objectContaining({
        message: 'Select a change to archive',
        choices: expect.arrayContaining([
          expect.objectContaining({ value: change1 }),
          expect.objectContaining({ value: change2 })
        ])
      }));
      
      // Verify the selected change was archived
      const archiveDir = path.join(tempDir, 'openspec', 'changes', 'archive');
      const archives = await fs.readdir(archiveDir);
      expect(archives[0]).toContain(change1);
    });

    it('should use confirm prompt for task warnings', async () => {
      const { confirm } = await import('@inquirer/prompts');
      const mockConfirm = confirm as unknown as ReturnType<typeof vi.fn>;
      
      const changeName = 'incomplete-interactive';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Create tasks.md with incomplete tasks
      const tasksContent = '- [ ] Task 1';
      await fs.writeFile(path.join(changeDir, 'tasks.md'), tasksContent);
      
      // Mock confirm to return true (proceed)
      mockConfirm.mockResolvedValueOnce(true);
      
      // Execute without --yes flag
      await archiveCommand.execute(changeName);
      
      // Verify confirm was called
      expect(mockConfirm).toHaveBeenCalledWith({
        message: 'Warning: 1 incomplete task(s) found. Continue?',
        default: false
      });
    });

    it('should cancel when user declines task warning', async () => {
      const { confirm } = await import('@inquirer/prompts');
      const mockConfirm = confirm as unknown as ReturnType<typeof vi.fn>;
      
      const changeName = 'cancel-test';
      const changeDir = path.join(tempDir, 'openspec', 'changes', changeName);
      await fs.mkdir(changeDir, { recursive: true });
      
      // Create tasks.md with incomplete tasks
      const tasksContent = '- [ ] Task 1';
      await fs.writeFile(path.join(changeDir, 'tasks.md'), tasksContent);
      
      // Mock confirm to return false (cancel) for validation skip
      mockConfirm.mockResolvedValueOnce(false);
      // Mock another false for task warning
      mockConfirm.mockResolvedValueOnce(false);
      
      // Execute without --yes flag but skip validation to test task warning
      await archiveCommand.execute(changeName, { noValidate: true });
      
      // Verify archive was cancelled
      expect(console.log).toHaveBeenCalledWith('Archive cancelled.');
      
      // Verify change was not archived
      await expect(fs.access(changeDir)).resolves.not.toThrow();
    });
  });
});



================================================
FILE: test/core/config-schema.test.ts
================================================
import { describe, it, expect } from 'vitest';

import {
  getNestedValue,
  setNestedValue,
  deleteNestedValue,
  coerceValue,
  formatValueYaml,
  validateConfig,
  GlobalConfigSchema,
  DEFAULT_CONFIG,
} from '../../src/core/config-schema.js';

describe('config-schema', () => {
  describe('getNestedValue', () => {
    it('should get a top-level value', () => {
      const obj = { foo: 'bar' };
      expect(getNestedValue(obj, 'foo')).toBe('bar');
    });

    it('should get a nested value with dot notation', () => {
      const obj = { a: { b: { c: 'deep' } } };
      expect(getNestedValue(obj, 'a.b.c')).toBe('deep');
    });

    it('should return undefined for non-existent path', () => {
      const obj = { foo: 'bar' };
      expect(getNestedValue(obj, 'baz')).toBeUndefined();
    });

    it('should return undefined for non-existent nested path', () => {
      const obj = { a: { b: 'value' } };
      expect(getNestedValue(obj, 'a.b.c')).toBeUndefined();
    });

    it('should return undefined when traversing through null', () => {
      const obj = { a: null };
      expect(getNestedValue(obj as Record<string, unknown>, 'a.b')).toBeUndefined();
    });

    it('should return undefined when traversing through primitive', () => {
      const obj = { a: 'string' };
      expect(getNestedValue(obj, 'a.b')).toBeUndefined();
    });

    it('should get object values', () => {
      const obj = { a: { b: 'value' } };
      expect(getNestedValue(obj, 'a')).toEqual({ b: 'value' });
    });

    it('should handle array values', () => {
      const obj = { arr: [1, 2, 3] };
      expect(getNestedValue(obj, 'arr')).toEqual([1, 2, 3]);
    });
  });

  describe('setNestedValue', () => {
    it('should set a top-level value', () => {
      const obj: Record<string, unknown> = {};
      setNestedValue(obj, 'foo', 'bar');
      expect(obj.foo).toBe('bar');
    });

    it('should set a nested value', () => {
      const obj: Record<string, unknown> = {};
      setNestedValue(obj, 'a.b.c', 'deep');
      expect((obj.a as Record<string, unknown>).b).toEqual({ c: 'deep' });
    });

    it('should create intermediate objects', () => {
      const obj: Record<string, unknown> = {};
      setNestedValue(obj, 'x.y.z', 'value');
      expect(obj).toEqual({ x: { y: { z: 'value' } } });
    });

    it('should overwrite existing values', () => {
      const obj: Record<string, unknown> = { a: 'old' };
      setNestedValue(obj, 'a', 'new');
      expect(obj.a).toBe('new');
    });

    it('should overwrite primitive with object when setting nested path', () => {
      const obj: Record<string, unknown> = { a: 'string' };
      setNestedValue(obj, 'a.b', 'value');
      expect(obj.a).toEqual({ b: 'value' });
    });

    it('should preserve other keys when setting nested value', () => {
      const obj: Record<string, unknown> = { a: { existing: 'keep' } };
      setNestedValue(obj, 'a.new', 'added');
      expect(obj.a).toEqual({ existing: 'keep', new: 'added' });
    });
  });

  describe('deleteNestedValue', () => {
    it('should delete a top-level key', () => {
      const obj: Record<string, unknown> = { foo: 'bar', baz: 'qux' };
      const result = deleteNestedValue(obj, 'foo');
      expect(result).toBe(true);
      expect(obj).toEqual({ baz: 'qux' });
    });

    it('should delete a nested key', () => {
      const obj: Record<string, unknown> = { a: { b: 'value', c: 'keep' } };
      const result = deleteNestedValue(obj, 'a.b');
      expect(result).toBe(true);
      expect(obj.a).toEqual({ c: 'keep' });
    });

    it('should return false for non-existent key', () => {
      const obj: Record<string, unknown> = { foo: 'bar' };
      const result = deleteNestedValue(obj, 'baz');
      expect(result).toBe(false);
    });

    it('should return false for non-existent nested path', () => {
      const obj: Record<string, unknown> = { a: { b: 'value' } };
      const result = deleteNestedValue(obj, 'a.c');
      expect(result).toBe(false);
    });

    it('should return false when intermediate path does not exist', () => {
      const obj: Record<string, unknown> = { a: 'string' };
      const result = deleteNestedValue(obj, 'a.b.c');
      expect(result).toBe(false);
    });
  });

  describe('coerceValue', () => {
    it('should coerce "true" to boolean true', () => {
      expect(coerceValue('true')).toBe(true);
    });

    it('should coerce "false" to boolean false', () => {
      expect(coerceValue('false')).toBe(false);
    });

    it('should coerce integer string to number', () => {
      expect(coerceValue('42')).toBe(42);
    });

    it('should coerce float string to number', () => {
      expect(coerceValue('3.14')).toBe(3.14);
    });

    it('should coerce negative number string to number', () => {
      expect(coerceValue('-10')).toBe(-10);
    });

    it('should keep regular strings as strings', () => {
      expect(coerceValue('hello')).toBe('hello');
    });

    it('should keep strings that start with numbers but are not numbers', () => {
      expect(coerceValue('123abc')).toBe('123abc');
    });

    it('should keep empty string as string', () => {
      expect(coerceValue('')).toBe('');
    });

    it('should keep whitespace-only string as string', () => {
      expect(coerceValue('   ')).toBe('   ');
    });

    it('should force string when forceString is true', () => {
      expect(coerceValue('true', true)).toBe('true');
      expect(coerceValue('42', true)).toBe('42');
      expect(coerceValue('hello', true)).toBe('hello');
    });

    it('should not coerce Infinity to number (not finite)', () => {
      // Infinity is not a useful config value, so we keep it as string
      expect(coerceValue('Infinity')).toBe('Infinity');
    });

    it('should handle scientific notation', () => {
      expect(coerceValue('1e10')).toBe(1e10);
    });
  });

  describe('formatValueYaml', () => {
    it('should format null as "null"', () => {
      expect(formatValueYaml(null)).toBe('null');
    });

    it('should format undefined as "null"', () => {
      expect(formatValueYaml(undefined)).toBe('null');
    });

    it('should format boolean as string', () => {
      expect(formatValueYaml(true)).toBe('true');
      expect(formatValueYaml(false)).toBe('false');
    });

    it('should format number as string', () => {
      expect(formatValueYaml(42)).toBe('42');
      expect(formatValueYaml(3.14)).toBe('3.14');
    });

    it('should format string as-is', () => {
      expect(formatValueYaml('hello')).toBe('hello');
    });

    it('should format empty array as "[]"', () => {
      expect(formatValueYaml([])).toBe('[]');
    });

    it('should format empty object as "{}"', () => {
      expect(formatValueYaml({})).toBe('{}');
    });

    it('should format object with key-value pairs', () => {
      const result = formatValueYaml({ foo: 'bar' });
      expect(result).toBe('foo: bar');
    });

    it('should format nested objects with indentation', () => {
      const result = formatValueYaml({ a: { b: 'value' } });
      expect(result).toContain('a:');
      expect(result).toContain('b: value');
    });
  });

  describe('validateConfig', () => {
    it('should accept valid config with featureFlags', () => {
      const result = validateConfig({ featureFlags: { test: true } });
      expect(result.success).toBe(true);
    });

    it('should accept empty featureFlags', () => {
      const result = validateConfig({ featureFlags: {} });
      expect(result.success).toBe(true);
    });

    it('should accept config without featureFlags (uses default)', () => {
      const result = validateConfig({});
      expect(result.success).toBe(true);
    });

    it('should accept unknown fields (passthrough)', () => {
      const result = validateConfig({ featureFlags: {}, unknownField: 'value' });
      expect(result.success).toBe(true);
    });

    it('should accept unknown fields with various types', () => {
      const result = validateConfig({
        featureFlags: {},
        futureStringField: 'value',
        futureNumberField: 123,
        futureObjectField: { nested: 'data' },
      });
      expect(result.success).toBe(true);
    });

    it('should reject non-boolean values in featureFlags', () => {
      const result = validateConfig({ featureFlags: { test: 'string' } });
      expect(result.success).toBe(false);
      expect(result.error).toBeDefined();
    });

    it('should include path in error message for invalid featureFlags', () => {
      const result = validateConfig({ featureFlags: { someFlag: 'notABoolean' } });
      expect(result.success).toBe(false);
      expect(result.error).toContain('featureFlags');
    });

    it('should reject non-object featureFlags', () => {
      const result = validateConfig({ featureFlags: 'string' });
      expect(result.success).toBe(false);
    });

    it('should reject number values in featureFlags', () => {
      const result = validateConfig({ featureFlags: { flag: 123 } });
      expect(result.success).toBe(false);
    });
  });

  describe('config set simulation', () => {
    // These tests simulate the full config set flow: coerce value â†’ set nested â†’ validate

    it('should accept setting unknown top-level key (forward compatibility)', () => {
      const config: Record<string, unknown> = { featureFlags: {} };
      const value = coerceValue('123');
      setNestedValue(config, 'someFutureKey', value);

      const result = validateConfig(config);
      expect(result.success).toBe(true);
      expect(config.someFutureKey).toBe(123);
    });

    it('should reject setting non-boolean to featureFlags', () => {
      const config: Record<string, unknown> = { featureFlags: {} };
      const value = coerceValue('notABoolean'); // stays as string
      setNestedValue(config, 'featureFlags.someFlag', value);

      const result = validateConfig(config);
      expect(result.success).toBe(false);
      expect(result.error).toContain('featureFlags');
    });

    it('should accept setting boolean to featureFlags', () => {
      const config: Record<string, unknown> = { featureFlags: {} };
      const value = coerceValue('true'); // coerces to boolean
      setNestedValue(config, 'featureFlags.newFlag', value);

      const result = validateConfig(config);
      expect(result.success).toBe(true);
      expect((config.featureFlags as Record<string, unknown>).newFlag).toBe(true);
    });

    it('should create featureFlags object when setting nested flag', () => {
      const config: Record<string, unknown> = {};
      const value = coerceValue('false');
      setNestedValue(config, 'featureFlags.experimental', value);

      const result = validateConfig(config);
      expect(result.success).toBe(true);
      expect((config.featureFlags as Record<string, unknown>).experimental).toBe(false);
    });
  });

  describe('GlobalConfigSchema', () => {
    it('should parse valid config', () => {
      const result = GlobalConfigSchema.safeParse({ featureFlags: { test: true } });
      expect(result.success).toBe(true);
    });

    it('should provide defaults for missing featureFlags', () => {
      const result = GlobalConfigSchema.parse({});
      expect(result.featureFlags).toEqual({});
    });
  });

  describe('DEFAULT_CONFIG', () => {
    it('should have empty featureFlags', () => {
      expect(DEFAULT_CONFIG.featureFlags).toEqual({});
    });
  });
});



================================================
FILE: test/core/global-config.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';

import {
  getGlobalConfigDir,
  getGlobalConfigPath,
  getGlobalConfig,
  saveGlobalConfig,
  GLOBAL_CONFIG_DIR_NAME,
  GLOBAL_CONFIG_FILE_NAME
} from '../../src/core/global-config.js';

describe('global-config', () => {
  let tempDir: string;
  let originalEnv: NodeJS.ProcessEnv;
  let consoleErrorSpy: ReturnType<typeof vi.spyOn>;

  beforeEach(() => {
    // Create temp directory for tests
    tempDir = path.join(os.tmpdir(), `openspec-global-config-test-${Date.now()}`);
    fs.mkdirSync(tempDir, { recursive: true });

    // Save original env
    originalEnv = { ...process.env };

    // Spy on console.error for warning tests
    consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
  });

  afterEach(() => {
    // Restore original env
    process.env = originalEnv;

    // Clean up temp directory
    fs.rmSync(tempDir, { recursive: true, force: true });

    // Restore console.error
    consoleErrorSpy.mockRestore();
  });

  describe('constants', () => {
    it('should export correct directory name', () => {
      expect(GLOBAL_CONFIG_DIR_NAME).toBe('openspec');
    });

    it('should export correct file name', () => {
      expect(GLOBAL_CONFIG_FILE_NAME).toBe('config.json');
    });
  });

  describe('getGlobalConfigDir', () => {
    it('should use XDG_CONFIG_HOME when set', () => {
      process.env.XDG_CONFIG_HOME = tempDir;

      const result = getGlobalConfigDir();

      expect(result).toBe(path.join(tempDir, 'openspec'));
    });

    it('should fall back to ~/.config on Unix/macOS without XDG_CONFIG_HOME', () => {
      delete process.env.XDG_CONFIG_HOME;

      const result = getGlobalConfigDir();

      // On non-Windows, should use ~/.config/openspec
      if (os.platform() !== 'win32') {
        expect(result).toBe(path.join(os.homedir(), '.config', 'openspec'));
      }
    });

    it('should use APPDATA on Windows when XDG_CONFIG_HOME is not set', () => {
      // This test only makes sense conceptually - we can't change os.platform()
      // But we can verify the APPDATA logic by checking the code path
      if (os.platform() === 'win32') {
        delete process.env.XDG_CONFIG_HOME;
        const appData = process.env.APPDATA;
        if (appData) {
          const result = getGlobalConfigDir();
          expect(result).toBe(path.join(appData, 'openspec'));
        }
      }
    });
  });

  describe('getGlobalConfigPath', () => {
    it('should return path to config.json in config directory', () => {
      process.env.XDG_CONFIG_HOME = tempDir;

      const result = getGlobalConfigPath();

      expect(result).toBe(path.join(tempDir, 'openspec', 'config.json'));
    });
  });

  describe('getGlobalConfig', () => {
    it('should return defaults when config file does not exist', () => {
      process.env.XDG_CONFIG_HOME = tempDir;

      const config = getGlobalConfig();

      expect(config).toEqual({ featureFlags: {} });
    });

    it('should not create directory when reading non-existent config', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');

      getGlobalConfig();

      expect(fs.existsSync(configDir)).toBe(false);
    });

    it('should load valid config from file', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        featureFlags: { testFlag: true, anotherFlag: false }
      }));

      const config = getGlobalConfig();

      expect(config.featureFlags).toEqual({ testFlag: true, anotherFlag: false });
    });

    it('should return defaults for invalid JSON', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, '{ invalid json }');

      const config = getGlobalConfig();

      expect(config).toEqual({ featureFlags: {} });
    });

    it('should log warning for invalid JSON', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, '{ invalid json }');

      getGlobalConfig();

      expect(consoleErrorSpy).toHaveBeenCalledWith(
        expect.stringContaining('Invalid JSON')
      );
    });

    it('should preserve unknown fields from config file', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        featureFlags: { x: true },
        unknownField: 'preserved',
        futureOption: 123
      }));

      const config = getGlobalConfig();

      expect((config as any).unknownField).toBe('preserved');
      expect((config as any).futureOption).toBe(123);
    });

    it('should merge loaded config with defaults', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');
      const configPath = path.join(configDir, 'config.json');

      // Config with only some fields
      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        featureFlags: { customFlag: true }
      }));

      const config = getGlobalConfig();

      // Should have the custom flag
      expect(config.featureFlags?.customFlag).toBe(true);
    });
  });

  describe('saveGlobalConfig', () => {
    it('should create directory if it does not exist', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');

      saveGlobalConfig({ featureFlags: { test: true } });

      expect(fs.existsSync(configDir)).toBe(true);
    });

    it('should write config to file', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configPath = path.join(tempDir, 'openspec', 'config.json');

      saveGlobalConfig({ featureFlags: { myFlag: true } });

      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.featureFlags.myFlag).toBe(true);
    });

    it('should overwrite existing config file', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configDir = path.join(tempDir, 'openspec');
      const configPath = path.join(configDir, 'config.json');

      // Create initial config
      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({ featureFlags: { old: true } }));

      // Overwrite
      saveGlobalConfig({ featureFlags: { new: true } });

      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.featureFlags.new).toBe(true);
      expect(parsed.featureFlags.old).toBeUndefined();
    });

    it('should write formatted JSON with trailing newline', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const configPath = path.join(tempDir, 'openspec', 'config.json');

      saveGlobalConfig({ featureFlags: {} });

      const content = fs.readFileSync(configPath, 'utf-8');
      expect(content).toContain('\n');
      expect(content.endsWith('\n')).toBe(true);
    });

    it('should round-trip config correctly', () => {
      process.env.XDG_CONFIG_HOME = tempDir;
      const originalConfig = {
        featureFlags: { flag1: true, flag2: false }
      };

      saveGlobalConfig(originalConfig);
      const loadedConfig = getGlobalConfig();

      expect(loadedConfig.featureFlags).toEqual(originalConfig.featureFlags);
    });
  });
});



================================================
FILE: test/core/list.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { ListCommand } from '../../src/core/list.js';

describe('ListCommand', () => {
  let tempDir: string;
  let originalLog: typeof console.log;
  let logOutput: string[] = [];

  beforeEach(async () => {
    // Create temp directory
    tempDir = path.join(os.tmpdir(), `openspec-list-test-${Date.now()}`);
    await fs.mkdir(tempDir, { recursive: true });

    // Mock console.log to capture output
    originalLog = console.log;
    console.log = (...args: any[]) => {
      logOutput.push(args.join(' '));
    };
    logOutput = [];
  });

  afterEach(async () => {
    // Restore console.log
    console.log = originalLog;

    // Clean up temp directory
    await fs.rm(tempDir, { recursive: true, force: true });
  });

  describe('execute', () => {
    it('should handle missing openspec/changes directory', async () => {
      const listCommand = new ListCommand();
      
      await expect(listCommand.execute(tempDir, 'changes')).rejects.toThrow(
        "No OpenSpec changes directory found. Run 'openspec init' first."
      );
    });

    it('should handle empty changes directory', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir, 'changes');

      expect(logOutput).toEqual(['No active changes found.']);
    });

    it('should exclude archive directory', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      await fs.mkdir(path.join(changesDir, 'archive'), { recursive: true });
      await fs.mkdir(path.join(changesDir, 'my-change'), { recursive: true });
      
      // Create tasks.md with some tasks
      await fs.writeFile(
        path.join(changesDir, 'my-change', 'tasks.md'),
        '- [x] Task 1\n- [ ] Task 2\n'
      );

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir, 'changes');

      expect(logOutput).toContain('Changes:');
      expect(logOutput.some(line => line.includes('my-change'))).toBe(true);
      expect(logOutput.some(line => line.includes('archive'))).toBe(false);
    });

    it('should count tasks correctly', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      await fs.mkdir(path.join(changesDir, 'test-change'), { recursive: true });
      
      await fs.writeFile(
        path.join(changesDir, 'test-change', 'tasks.md'),
        `# Tasks
- [x] Completed task 1
- [x] Completed task 2
- [ ] Incomplete task 1
- [ ] Incomplete task 2
- [ ] Incomplete task 3
Regular text that should be ignored
`
      );

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir, 'changes');

      expect(logOutput.some(line => line.includes('2/5 tasks'))).toBe(true);
    });

    it('should show complete status for fully completed changes', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      await fs.mkdir(path.join(changesDir, 'completed-change'), { recursive: true });
      
      await fs.writeFile(
        path.join(changesDir, 'completed-change', 'tasks.md'),
        '- [x] Task 1\n- [x] Task 2\n- [x] Task 3\n'
      );

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir, 'changes');

      expect(logOutput.some(line => line.includes('âœ“ Complete'))).toBe(true);
    });

    it('should handle changes without tasks.md', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      await fs.mkdir(path.join(changesDir, 'no-tasks'), { recursive: true });

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir, 'changes');

      expect(logOutput.some(line => line.includes('no-tasks') && line.includes('No tasks'))).toBe(true);
    });

    it('should sort changes alphabetically when sort=name', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      await fs.mkdir(path.join(changesDir, 'zebra'), { recursive: true });
      await fs.mkdir(path.join(changesDir, 'alpha'), { recursive: true });
      await fs.mkdir(path.join(changesDir, 'middle'), { recursive: true });

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir, 'changes', { sort: 'name' });

      const changeLines = logOutput.filter(line =>
        line.includes('alpha') || line.includes('middle') || line.includes('zebra')
      );

      expect(changeLines[0]).toContain('alpha');
      expect(changeLines[1]).toContain('middle');
      expect(changeLines[2]).toContain('zebra');
    });

    it('should handle multiple changes with various states', async () => {
      const changesDir = path.join(tempDir, 'openspec', 'changes');
      
      // Complete change
      await fs.mkdir(path.join(changesDir, 'completed'), { recursive: true });
      await fs.writeFile(
        path.join(changesDir, 'completed', 'tasks.md'),
        '- [x] Task 1\n- [x] Task 2\n'
      );

      // Partial change
      await fs.mkdir(path.join(changesDir, 'partial'), { recursive: true });
      await fs.writeFile(
        path.join(changesDir, 'partial', 'tasks.md'),
        '- [x] Done\n- [ ] Not done\n- [ ] Also not done\n'
      );

      // No tasks
      await fs.mkdir(path.join(changesDir, 'no-tasks'), { recursive: true });

      const listCommand = new ListCommand();
      await listCommand.execute(tempDir);

      expect(logOutput).toContain('Changes:');
      expect(logOutput.some(line => line.includes('completed') && line.includes('âœ“ Complete'))).toBe(true);
      expect(logOutput.some(line => line.includes('partial') && line.includes('1/3 tasks'))).toBe(true);
      expect(logOutput.some(line => line.includes('no-tasks') && line.includes('No tasks'))).toBe(true);
    });
  });
});


================================================
FILE: test/core/project-config.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import {
  readProjectConfig,
  validateConfigRules,
  suggestSchemas,
} from '../../src/core/project-config.js';

describe('project-config', () => {
  let tempDir: string;
  let consoleWarnSpy: ReturnType<typeof vi.spyOn>;

  beforeEach(() => {
    tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'openspec-test-config-'));
    consoleWarnSpy = vi.spyOn(console, 'warn').mockImplementation(() => {});
  });

  afterEach(() => {
    fs.rmSync(tempDir, { recursive: true, force: true });
    consoleWarnSpy.mockRestore();
  });

  describe('readProjectConfig', () => {
    describe('resilient parsing', () => {
      it('should parse complete valid config', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  Tech stack: TypeScript, React
  API style: RESTful
rules:
  proposal:
    - Include rollback plan
    - Identify affected teams
  specs:
    - Use Given/When/Then format
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
          context: 'Tech stack: TypeScript, React\nAPI style: RESTful\n',
          rules: {
            proposal: ['Include rollback plan', 'Identify affected teams'],
            specs: ['Use Given/When/Then format'],
          },
        });
        expect(consoleWarnSpy).not.toHaveBeenCalled();
      });

      it('should parse minimal config with schema only', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(path.join(configDir, 'config.yaml'), 'schema: spec-driven\n');

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
        });
        expect(consoleWarnSpy).not.toHaveBeenCalled();
      });

      it('should return partial config when schema is invalid', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: ""
context: Valid context here
rules:
  proposal:
    - Valid rule
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          context: 'Valid context here',
          rules: {
            proposal: ['Valid rule'],
          },
        });
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining("Invalid 'schema' field")
        );
      });

      it('should return partial config when context is invalid', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: 123
rules:
  proposal:
    - Valid rule
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
          rules: {
            proposal: ['Valid rule'],
          },
        });
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining("Invalid 'context' field")
        );
      });

      it('should return partial config when rules is not an object', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: Valid context
rules: ["not", "an", "object"]
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
          context: 'Valid context',
        });
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining("Invalid 'rules' field")
        );
      });

      it('should handle rules: null without aborting config parsing', () => {
        // YAML `rules:` with no value parses to null
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: Valid context
rules:
`
        );

        const config = readProjectConfig(tempDir);

        // Should still parse schema and context despite null rules
        expect(config).toEqual({
          schema: 'spec-driven',
          context: 'Valid context',
        });
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining("Invalid 'rules' field")
        );
      });

      it('should filter out invalid rules for specific artifact', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Valid rule
  specs: "not an array"
  design:
    - Another valid rule
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
          rules: {
            proposal: ['Valid rule'],
            design: ['Another valid rule'],
          },
        });
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining("Rules for 'specs' must be an array of strings")
        );
      });

      it('should filter out empty string rules', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Valid rule
    - ""
    - Another valid rule
    - ""
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
          rules: {
            proposal: ['Valid rule', 'Another valid rule'],
          },
        });
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining("Some rules for 'proposal' are empty strings")
        );
      });

      it('should skip artifact if all rules are empty strings', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - ""
    - ""
  specs:
    - Valid rule
`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({
          schema: 'spec-driven',
          rules: {
            specs: ['Valid rule'],
          },
        });
      });

      it('should handle completely invalid YAML gracefully', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(path.join(configDir, 'config.yaml'), 'schema: [unclosed');

        const config = readProjectConfig(tempDir);

        expect(config).toBeNull();
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining('Failed to parse openspec/config.yaml'),
          expect.anything()
        );
      });

      it('should warn when config is not a YAML object', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(path.join(configDir, 'config.yaml'), '"just a string"');

        const config = readProjectConfig(tempDir);

        expect(config).toBeNull();
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining('not a valid YAML object')
        );
      });

      it('should handle empty config file', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(path.join(configDir, 'config.yaml'), '');

        const config = readProjectConfig(tempDir);

        expect(config).toBeNull();
      });
    });

    describe('context size limit enforcement', () => {
      it('should accept context under 50KB limit', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        const smallContext = 'a'.repeat(1000); // 1KB
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven\ncontext: "${smallContext}"\n`
        );

        const config = readProjectConfig(tempDir);

        expect(config?.context).toBe(smallContext);
        expect(consoleWarnSpy).not.toHaveBeenCalledWith(
          expect.stringContaining('Context too large')
        );
      });

      it('should reject context over 50KB limit', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        const largeContext = 'a'.repeat(51 * 1024); // 51KB
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven\ncontext: "${largeContext}"\n`
        );

        const config = readProjectConfig(tempDir);

        expect(config).toEqual({ schema: 'spec-driven' });
        expect(config?.context).toBeUndefined();
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining('Context too large (51.0KB, limit: 50KB)')
        );
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining('Ignoring context field')
        );
      });

      it('should handle context exactly at 50KB limit', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        const exactContext = 'a'.repeat(50 * 1024); // Exactly 50KB
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven\ncontext: "${exactContext}"\n`
        );

        const config = readProjectConfig(tempDir);

        expect(config?.context).toBe(exactContext);
        expect(consoleWarnSpy).not.toHaveBeenCalledWith(
          expect.stringContaining('Context too large')
        );
      });

      it('should handle multi-byte UTF-8 characters in size calculation', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        // Unicode snowman is 3 bytes in UTF-8
        const contextWithUnicode = 'â˜ƒ'.repeat(18000); // ~54KB in UTF-8 (18000 * 3 bytes)
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  ${contextWithUnicode}
`
        );

        const config = readProjectConfig(tempDir);

        expect(config?.context).toBeUndefined();
        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining('Context too large')
        );
      });
    });

    describe('.yml/.yaml precedence', () => {
      it('should prefer .yaml when both exist', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          'schema: spec-driven\ncontext: from yaml\n'
        );
        fs.writeFileSync(
          path.join(configDir, 'config.yml'),
          'schema: tdd\ncontext: from yml\n'
        );

        const config = readProjectConfig(tempDir);

        expect(config?.schema).toBe('spec-driven');
        expect(config?.context).toBe('from yaml');
      });

      it('should use .yml when .yaml does not exist', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yml'),
          'schema: tdd\ncontext: from yml\n'
        );

        const config = readProjectConfig(tempDir);

        expect(config?.schema).toBe('tdd');
        expect(config?.context).toBe('from yml');
      });

      it('should return null when neither .yaml nor .yml exist', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });

        const config = readProjectConfig(tempDir);

        expect(config).toBeNull();
        expect(consoleWarnSpy).not.toHaveBeenCalled();
      });

      it('should return null when openspec directory does not exist', () => {
        const config = readProjectConfig(tempDir);

        expect(config).toBeNull();
        expect(consoleWarnSpy).not.toHaveBeenCalled();
      });
    });

    describe('multi-line and special characters', () => {
      it('should preserve multi-line context', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  Line 1: Tech stack
  Line 2: API conventions
  Line 3: Testing approach
`
        );

        const config = readProjectConfig(tempDir);

        expect(config?.context).toBe(
          'Line 1: Tech stack\nLine 2: API conventions\nLine 3: Testing approach\n'
        );
      });

      it('should preserve special YAML characters in context', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  Special chars: : @ # $ % & * [ ] { }
  Quotes: "double" 'single'
  Symbols: < > | \\ /
`
        );

        const config = readProjectConfig(tempDir);

        expect(config?.context).toContain('Special chars: : @ # $ % & * [ ] { }');
        expect(config?.context).toContain('"double"');
        expect(config?.context).toContain("'single'");
        expect(config?.context).toContain('Symbols: < > | \\ /');
      });

      it('should preserve special characters in rule strings', () => {
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - "Use <template> tags in docs"
    - "Reference @mentions and #channels"
    - "Follow {variable} naming"
`
        );

        const config = readProjectConfig(tempDir);

        expect(config?.rules?.proposal).toEqual([
          'Use <template> tags in docs',
          'Reference @mentions and #channels',
          'Follow {variable} naming',
        ]);
      });
    });
  });

  describe('validateConfigRules', () => {
    it('should return no warnings for valid artifact IDs', () => {
      const rules = {
        proposal: ['Rule 1'],
        specs: ['Rule 2'],
        design: ['Rule 3'],
      };
      const validIds = new Set(['proposal', 'specs', 'design', 'tasks']);

      const warnings = validateConfigRules(rules, validIds, 'spec-driven');

      expect(warnings).toEqual([]);
    });

    it('should warn about unknown artifact IDs', () => {
      const rules = {
        proposal: ['Rule 1'],
        testplan: ['Rule 2'], // Invalid
        documentation: ['Rule 3'], // Invalid
      };
      const validIds = new Set(['proposal', 'specs', 'design', 'tasks']);

      const warnings = validateConfigRules(rules, validIds, 'spec-driven');

      expect(warnings).toHaveLength(2);
      expect(warnings[0]).toContain('Unknown artifact ID in rules: "testplan"');
      expect(warnings[0]).toContain('Valid IDs for schema "spec-driven": design, proposal, specs, tasks');
      expect(warnings[1]).toContain('Unknown artifact ID in rules: "documentation"');
    });

    it('should return warnings for all unknown artifact IDs', () => {
      const rules = {
        invalid1: ['Rule 1'],
        invalid2: ['Rule 2'],
        invalid3: ['Rule 3'],
      };
      const validIds = new Set(['proposal', 'specs']);

      const warnings = validateConfigRules(rules, validIds, 'spec-driven');

      expect(warnings).toHaveLength(3);
    });

    it('should handle empty rules object', () => {
      const rules = {};
      const validIds = new Set(['proposal', 'specs']);

      const warnings = validateConfigRules(rules, validIds, 'spec-driven');

      expect(warnings).toEqual([]);
    });
  });

  describe('suggestSchemas', () => {
    const availableSchemas = [
      { name: 'spec-driven', isBuiltIn: true },
      { name: 'tdd', isBuiltIn: true },
      { name: 'custom-workflow', isBuiltIn: false },
      { name: 'team-process', isBuiltIn: false },
    ];

    it('should suggest close matches using fuzzy matching', () => {
      const message = suggestSchemas('spec-drven', availableSchemas); // Missing 'i'

      expect(message).toContain("Schema 'spec-drven' not found");
      expect(message).toContain('Did you mean one of these?');
      expect(message).toContain('spec-driven (built-in)');
    });

    it('should suggest tdd for tdd typo', () => {
      const message = suggestSchemas('td', availableSchemas);

      expect(message).toContain('Did you mean one of these?');
      expect(message).toContain('tdd (built-in)');
    });

    it('should list all available schemas', () => {
      const message = suggestSchemas('nonexistent', availableSchemas);

      expect(message).toContain('Available schemas:');
      expect(message).toContain('Built-in: spec-driven, tdd');
      expect(message).toContain('Project-local: custom-workflow, team-process');
    });

    it('should handle case when no project-local schemas exist', () => {
      const builtInOnly = [
        { name: 'spec-driven', isBuiltIn: true },
        { name: 'tdd', isBuiltIn: true },
      ];
      const message = suggestSchemas('invalid', builtInOnly);

      expect(message).toContain('Built-in: spec-driven, tdd');
      expect(message).toContain('Project-local: (none found)');
    });

    it('should include fix instruction', () => {
      const message = suggestSchemas('wrong-schema', availableSchemas);

      expect(message).toContain(
        "Fix: Edit openspec/config.yaml and change 'schema: wrong-schema' to a valid schema name"
      );
    });

    it('should limit suggestions to top 3 matches', () => {
      const manySchemas = [
        { name: 'test-a', isBuiltIn: true },
        { name: 'test-b', isBuiltIn: true },
        { name: 'test-c', isBuiltIn: true },
        { name: 'test-d', isBuiltIn: true },
        { name: 'test-e', isBuiltIn: true },
      ];
      const message = suggestSchemas('test', manySchemas);

      // Should suggest at most 3
      const suggestionCount = (message.match(/test-/g) || []).length;
      expect(suggestionCount).toBeGreaterThanOrEqual(3);
      expect(suggestionCount).toBeLessThanOrEqual(3 + 5); // 3 in suggestions + 5 in "Available" list
    });

    it('should not suggest schemas with distance > 3', () => {
      const message = suggestSchemas('abcdefghijk', availableSchemas);

      // 'abcdefghijk' has large Levenshtein distance from all schemas
      expect(message).not.toContain('Did you mean');
      expect(message).toContain('Available schemas:');
    });
  });
});



================================================
FILE: test/core/validation.enriched-messages.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { Validator } from '../../src/core/validation/validator.js';

describe('Validator enriched messages', () => {
  const testDir = path.join(process.cwd(), 'test-validation-enriched-tmp');

  beforeEach(async () => {
    await fs.mkdir(testDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('adds guidance for no deltas in change', async () => {
    const changeContent = `# Test Change

## Why
This is a sufficiently long explanation to pass the why length requirement for validation purposes.

## What Changes
There are changes proposed, but no delta specs provided yet.`;
    const changePath = path.join(testDir, 'proposal.md');
    await fs.writeFile(changePath, changeContent);

    const validator = new Validator();
    const report = await validator.validateChange(changePath);
    expect(report.valid).toBe(false);
    const msg = report.issues.map(i => i.message).join('\n');
    expect(msg).toContain('Change must have at least one delta');
    expect(msg).toContain('Ensure your change has a specs/ directory');
    expect(msg).toContain('## ADDED/MODIFIED/REMOVED/RENAMED Requirements');
  });

  it('adds guidance when spec missing Purpose/Requirements', async () => {
    const specContent = `# Test Spec\n\n## Requirements\n\n### Requirement: Foo\nFoo SHALL ...\n\n#### Scenario: Bar\nWhen...`;
    const specPath = path.join(testDir, 'spec.md');
    await fs.writeFile(specPath, specContent);

    const validator = new Validator();
    const report = await validator.validateSpec(specPath);
    expect(report.valid).toBe(false);
    const msg = report.issues.map(i => i.message).join('\n');
    expect(msg).toContain('Spec must have a Purpose section');
    expect(msg).toContain('Expected headers: "## Purpose" and "## Requirements"');
  });

  it('warns with scenario conversion template when missing scenarios', async () => {
    const specContent = `# Test Spec

## Purpose
This is a sufficiently long purpose section to avoid warnings about brevity.

## Requirements

### Requirement: Foo SHALL be described
Text of requirement
`;
    const specPath = path.join(testDir, 'spec.md');
    await fs.writeFile(specPath, specContent);

    const validator = new Validator();
    const report = await validator.validateSpec(specPath);
    expect(report.valid).toBe(false);
    const warn = report.issues.find(i => i.path.includes('requirements[0].scenarios'));
    expect(warn?.message).toContain('Requirement must have at least one scenario');
    expect(warn?.message).toContain('Scenarios must use level-4 headers');
    expect(warn?.message).toContain('#### Scenario:');
  });
});





================================================
FILE: test/core/validation.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { Validator } from '../../src/core/validation/validator.js';
import { 
  ScenarioSchema, 
  RequirementSchema, 
  SpecSchema, 
  ChangeSchema,
  DeltaSchema 
} from '../../src/core/schemas/index.js';

describe('Validation Schemas', () => {
  describe('ScenarioSchema', () => {
    it('should validate a valid scenario', () => {
      const scenario = {
        rawText: 'Given a user is logged in\nWhen they click logout\nThen they are redirected to login page',
      };
      
      const result = ScenarioSchema.safeParse(scenario);
      expect(result.success).toBe(true);
    });

    it('should reject scenario with empty text', () => {
      const scenario = {
        rawText: '',
      };
      
      const result = ScenarioSchema.safeParse(scenario);
      expect(result.success).toBe(false);
      if (!result.success) {
        expect(result.error.issues[0].message).toBe('Scenario text cannot be empty');
      }
    });
  });

  describe('RequirementSchema', () => {
    it('should validate a valid requirement', () => {
      const requirement = {
        text: 'The system SHALL provide user authentication',
        scenarios: [
          {
            rawText: 'Given a user with valid credentials\nWhen they submit the login form\nThen they are authenticated',
          },
        ],
      };
      
      const result = RequirementSchema.safeParse(requirement);
      expect(result.success).toBe(true);
    });

    it('should reject requirement without SHALL or MUST', () => {
      const requirement = {
        text: 'The system provides user authentication',
        scenarios: [
          {
            rawText: 'Given a user\nWhen they login\nThen authenticated',
          },
        ],
      };
      
      const result = RequirementSchema.safeParse(requirement);
      expect(result.success).toBe(false);
      if (!result.success) {
        expect(result.error.issues[0].message).toBe('Requirement must contain SHALL or MUST keyword');
      }
    });

    it('should reject requirement without scenarios', () => {
      const requirement = {
        text: 'The system SHALL provide user authentication',
        scenarios: [],
      };
      
      const result = RequirementSchema.safeParse(requirement);
      expect(result.success).toBe(false);
      if (!result.success) {
        expect(result.error.issues[0].message).toBe('Requirement must have at least one scenario');
      }
    });
  });

  describe('SpecSchema', () => {
    it('should validate a valid spec', () => {
      const spec = {
        name: 'user-auth',
        overview: 'This spec defines user authentication requirements',
        requirements: [
          {
            text: 'The system SHALL provide user authentication',
            scenarios: [
              {
                rawText: 'Given a user with valid credentials\nWhen they submit the login form\nThen they are authenticated',
              },
            ],
          },
        ],
      };
      
      const result = SpecSchema.safeParse(spec);
      expect(result.success).toBe(true);
    });

    it('should reject spec without requirements', () => {
      const spec = {
        name: 'user-auth',
        overview: 'This spec defines user authentication requirements',
        requirements: [],
      };
      
      const result = SpecSchema.safeParse(spec);
      expect(result.success).toBe(false);
      if (!result.success) {
        expect(result.error.issues[0].message).toBe('Spec must have at least one requirement');
      }
    });
  });

  describe('ChangeSchema', () => {
    it('should validate a valid change', () => {
      const change = {
        name: 'add-user-auth',
        why: 'We need user authentication to secure the application and protect user data',
        whatChanges: 'Add authentication module with login and logout capabilities',
        deltas: [
          {
            spec: 'user-auth',
            operation: 'ADDED',
            description: 'Add new user authentication spec',
          },
        ],
      };
      
      const result = ChangeSchema.safeParse(change);
      expect(result.success).toBe(true);
    });

    it('should reject change with short why section', () => {
      const change = {
        name: 'add-user-auth',
        why: 'Need auth',
        whatChanges: 'Add authentication',
        deltas: [
          {
            spec: 'user-auth',
            operation: 'ADDED',
            description: 'Add auth',
          },
        ],
      };
      
      const result = ChangeSchema.safeParse(change);
      expect(result.success).toBe(false);
      if (!result.success) {
        expect(result.error.issues[0].message).toBe('Why section must be at least 50 characters');
      }
    });

    it('should warn about too many deltas', () => {
      const deltas = Array.from({ length: 11 }, (_, i) => ({
        spec: `spec-${i}`,
        operation: 'ADDED' as const,
        description: `Add spec ${i}`,
      }));
      
      const change = {
        name: 'massive-change',
        why: 'This is a massive change that affects many parts of the system',
        whatChanges: 'Update everything',
        deltas,
      };
      
      const result = ChangeSchema.safeParse(change);
      expect(result.success).toBe(false);
      if (!result.success) {
        expect(result.error.issues[0].message).toBe('Consider splitting changes with more than 10 deltas');
      }
    });
  });
});

describe('Validator', () => {
  const testDir = path.join(process.cwd(), 'test-validation-tmp');
  
  beforeEach(async () => {
    await fs.mkdir(testDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('validateSpec', () => {
    it('should validate a valid spec file', async () => {
      const specContent = `# User Authentication Spec

## Purpose
This specification defines the requirements for user authentication in the system.

## Requirements

### The system SHALL provide secure user authentication
The system SHALL provide secure user authentication mechanisms.

#### Scenario: Successful login
Given a user with valid credentials
When they submit the login form
Then they are authenticated and redirected to the dashboard

### The system SHALL handle invalid login attempts
The system SHALL gracefully handle incorrect credentials.

#### Scenario: Invalid credentials
Given a user with invalid credentials
When they submit the login form
Then they see an error message`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);
      
      const validator = new Validator();
      const report = await validator.validateSpec(specPath);
      
      expect(report.valid).toBe(true);
      expect(report.summary.errors).toBe(0);
    });

    it('should detect missing overview section', async () => {
      const specContent = `# User Authentication Spec

## Requirements

### The system SHALL provide secure user authentication

#### Scenario: Login
Given a user
When they login
Then authenticated`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);
      
      const validator = new Validator();
      const report = await validator.validateSpec(specPath);
      
      expect(report.valid).toBe(false);
      expect(report.summary.errors).toBeGreaterThan(0);
      expect(report.issues.some(i => i.message.includes('Purpose'))).toBe(true);
    });
  });

  describe('validateChange', () => {
    it('should validate a valid change file', async () => {
      const changeContent = `# Add User Authentication

## Why
We need to implement user authentication to secure the application and protect user data from unauthorized access.

## What Changes
- **user-auth:** Add new user authentication specification
- **api-endpoints:** Modify to include auth endpoints`;

      const changePath = path.join(testDir, 'change.md');
      await fs.writeFile(changePath, changeContent);
      
      const validator = new Validator();
      const report = await validator.validateChange(changePath);
      
      expect(report.valid).toBe(true);
      expect(report.summary.errors).toBe(0);
    });

    it('should detect missing why section', async () => {
      const changeContent = `# Add User Authentication

## What Changes
- **user-auth:** Add new user authentication specification`;

      const changePath = path.join(testDir, 'change.md');
      await fs.writeFile(changePath, changeContent);
      
      const validator = new Validator();
      const report = await validator.validateChange(changePath);
      
      expect(report.valid).toBe(false);
      expect(report.summary.errors).toBeGreaterThan(0);
      expect(report.issues.some(i => i.message.includes('Why'))).toBe(true);
    });
  });

  describe('strict mode', () => {
    it('should fail on warnings in strict mode', async () => {
      const specContent = `# Test Spec

## Purpose
Brief overview

## Requirements

### The system SHALL do something

#### Scenario: Test
Given test
When action
Then result`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);

      const validator = new Validator(true); // strict mode
      const report = await validator.validateSpec(specPath);

      expect(report.valid).toBe(false); // Should fail due to brief overview warning
    });

    it('should pass warnings in non-strict mode', async () => {
      const specContent = `# Test Spec

## Purpose
Brief overview

## Requirements

### The system SHALL do something

#### Scenario: Test
Given test
When action
Then result`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);

      const validator = new Validator(false); // non-strict mode
      const report = await validator.validateSpec(specPath);

      expect(report.valid).toBe(true); // Should pass despite warnings
      expect(report.summary.warnings).toBeGreaterThan(0);
    });
  });

  describe('validateChangeDeltaSpecs with metadata', () => {
    it('should validate requirement with metadata before SHALL/MUST text', async () => {
      const changeDir = path.join(testDir, 'test-change');
      const specsDir = path.join(changeDir, 'specs', 'test-spec');
      await fs.mkdir(specsDir, { recursive: true });

      const deltaSpec = `# Test Spec

## ADDED Requirements

### Requirement: Circuit Breaker State Management SHALL be implemented
**ID**: REQ-CB-001
**Priority**: P1 (High)

The system MUST implement a circuit breaker with three states.

#### Scenario: Normal operation
**Given** the circuit breaker is in CLOSED state
**When** a request is made
**Then** the request is executed normally`;

      const specPath = path.join(specsDir, 'spec.md');
      await fs.writeFile(specPath, deltaSpec);

      const validator = new Validator(true);
      const report = await validator.validateChangeDeltaSpecs(changeDir);

      expect(report.valid).toBe(true);
      expect(report.summary.errors).toBe(0);
    });

    it('should validate requirement with SHALL in text but not in header', async () => {
      const changeDir = path.join(testDir, 'test-change-2');
      const specsDir = path.join(changeDir, 'specs', 'test-spec');
      await fs.mkdir(specsDir, { recursive: true });

      const deltaSpec = `# Test Spec

## ADDED Requirements

### Requirement: Error Handling
**ID**: REQ-ERR-001
**Priority**: P2

The system SHALL handle all errors gracefully.

#### Scenario: Error occurs
**Given** an error condition
**When** an error occurs
**Then** the error is logged and user is notified`;

      const specPath = path.join(specsDir, 'spec.md');
      await fs.writeFile(specPath, deltaSpec);

      const validator = new Validator(true);
      const report = await validator.validateChangeDeltaSpecs(changeDir);

      expect(report.valid).toBe(true);
      expect(report.summary.errors).toBe(0);
    });

    it('should fail when requirement text lacks SHALL/MUST', async () => {
      const changeDir = path.join(testDir, 'test-change-3');
      const specsDir = path.join(changeDir, 'specs', 'test-spec');
      await fs.mkdir(specsDir, { recursive: true });

      const deltaSpec = `# Test Spec

## ADDED Requirements

### Requirement: Logging Feature
**ID**: REQ-LOG-001

The system will log all events.

#### Scenario: Event occurs
**Given** an event
**When** it occurs
**Then** it is logged`;

      const specPath = path.join(specsDir, 'spec.md');
      await fs.writeFile(specPath, deltaSpec);

      const validator = new Validator(true);
      const report = await validator.validateChangeDeltaSpecs(changeDir);

      expect(report.valid).toBe(false);
      expect(report.summary.errors).toBeGreaterThan(0);
      expect(report.issues.some(i => i.message.includes('must contain SHALL or MUST'))).toBe(true);
    });

    it('should handle requirements without metadata fields', async () => {
      const changeDir = path.join(testDir, 'test-change-4');
      const specsDir = path.join(changeDir, 'specs', 'test-spec');
      await fs.mkdir(specsDir, { recursive: true });

      const deltaSpec = `# Test Spec

## ADDED Requirements

### Requirement: Simple Feature
The system SHALL implement this feature.

#### Scenario: Basic usage
**Given** a condition
**When** an action occurs
**Then** a result happens`;

      const specPath = path.join(specsDir, 'spec.md');
      await fs.writeFile(specPath, deltaSpec);

      const validator = new Validator(true);
      const report = await validator.validateChangeDeltaSpecs(changeDir);

      expect(report.valid).toBe(true);
      expect(report.summary.errors).toBe(0);
    });

    it('should treat delta headers case-insensitively', async () => {
      const changeDir = path.join(testDir, 'test-change-mixed-case');
      const specsDir = path.join(changeDir, 'specs', 'test-spec');
      await fs.mkdir(specsDir, { recursive: true });

      const deltaSpec = `# Test Spec

## Added Requirements

### Requirement: Mixed Case Handling
The system MUST support mixed case delta headers.

#### Scenario: Case insensitive parsing
**Given** a delta file with mixed case headers
**When** validation runs
**Then** the delta is detected`;

      const specPath = path.join(specsDir, 'spec.md');
      await fs.writeFile(specPath, deltaSpec);

      const validator = new Validator(true);
      const report = await validator.validateChangeDeltaSpecs(changeDir);

      expect(report.valid).toBe(true);
      expect(report.summary.errors).toBe(0);
      expect(report.summary.warnings).toBe(0);
      expect(report.summary.info).toBe(0);
    });
  });
});



================================================
FILE: test/core/view.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { ViewCommand } from '../../src/core/view.js';

const stripAnsi = (input: string): string => input.replace(/\u001b\[[0-9;]*m/g, '');

describe('ViewCommand', () => {
  let tempDir: string;
  let originalLog: typeof console.log;
  let logOutput: string[] = [];

  beforeEach(async () => {
    tempDir = path.join(os.tmpdir(), `openspec-view-test-${Date.now()}`);
    await fs.mkdir(tempDir, { recursive: true });

    originalLog = console.log;
    console.log = (...args: any[]) => {
      logOutput.push(args.join(' '));
    };

    logOutput = [];
  });

  afterEach(async () => {
    console.log = originalLog;
    await fs.rm(tempDir, { recursive: true, force: true });
  });

  it('shows changes with no tasks in Draft section, not Completed', async () => {
    const changesDir = path.join(tempDir, 'openspec', 'changes');
    await fs.mkdir(changesDir, { recursive: true });

    // Empty change (no tasks.md) - should show in Draft
    await fs.mkdir(path.join(changesDir, 'empty-change'), { recursive: true });

    // Change with tasks.md but no tasks - should show in Draft
    await fs.mkdir(path.join(changesDir, 'no-tasks-change'), { recursive: true });
    await fs.writeFile(path.join(changesDir, 'no-tasks-change', 'tasks.md'), '# Tasks\n\nNo tasks yet.');

    // Change with all tasks complete - should show in Completed
    await fs.mkdir(path.join(changesDir, 'completed-change'), { recursive: true });
    await fs.writeFile(
      path.join(changesDir, 'completed-change', 'tasks.md'),
      '- [x] Done task\n'
    );

    const viewCommand = new ViewCommand();
    await viewCommand.execute(tempDir);

    const output = logOutput.map(stripAnsi).join('\n');

    // Draft section should contain empty and no-tasks changes
    expect(output).toContain('Draft Changes');
    expect(output).toContain('empty-change');
    expect(output).toContain('no-tasks-change');

    // Completed section should only contain changes with all tasks done
    expect(output).toContain('Completed Changes');
    expect(output).toContain('completed-change');

    // Verify empty-change and no-tasks-change are in Draft section (marked with â—‹)
    const draftLines = logOutput
      .map(stripAnsi)
      .filter((line) => line.includes('â—‹'));
    const draftNames = draftLines.map((line) => line.trim().replace('â—‹ ', ''));
    expect(draftNames).toContain('empty-change');
    expect(draftNames).toContain('no-tasks-change');

    // Verify completed-change is in Completed section (marked with âœ“)
    const completedLines = logOutput
      .map(stripAnsi)
      .filter((line) => line.includes('âœ“'));
    const completedNames = completedLines.map((line) => line.trim().replace('âœ“ ', ''));
    expect(completedNames).toContain('completed-change');
    expect(completedNames).not.toContain('empty-change');
    expect(completedNames).not.toContain('no-tasks-change');
  });

  it('sorts active changes by completion percentage ascending with deterministic tie-breakers', async () => {
    const changesDir = path.join(tempDir, 'openspec', 'changes');
    await fs.mkdir(changesDir, { recursive: true });

    await fs.mkdir(path.join(changesDir, 'gamma-change'), { recursive: true });
    await fs.writeFile(
      path.join(changesDir, 'gamma-change', 'tasks.md'),
      '- [x] Done\n- [x] Also done\n- [ ] Not done\n'
    );

    await fs.mkdir(path.join(changesDir, 'beta-change'), { recursive: true });
    await fs.writeFile(
      path.join(changesDir, 'beta-change', 'tasks.md'),
      '- [x] Task 1\n- [ ] Task 2\n'
    );

    await fs.mkdir(path.join(changesDir, 'delta-change'), { recursive: true });
    await fs.writeFile(
      path.join(changesDir, 'delta-change', 'tasks.md'),
      '- [x] Task 1\n- [ ] Task 2\n'
    );

    await fs.mkdir(path.join(changesDir, 'alpha-change'), { recursive: true });
    await fs.writeFile(
      path.join(changesDir, 'alpha-change', 'tasks.md'),
      '- [ ] Task 1\n- [ ] Task 2\n'
    );

    const viewCommand = new ViewCommand();
    await viewCommand.execute(tempDir);

    const activeLines = logOutput
      .map(stripAnsi)
      .filter(line => line.includes('â—‰'));

    const activeOrder = activeLines.map(line => {
      const afterBullet = line.split('â—‰')[1] ?? '';
      return afterBullet.split('[')[0]?.trim();
    });

    expect(activeOrder).toEqual([
      'alpha-change',
      'beta-change',
      'delta-change',
      'gamma-change'
    ]);
  });
});




================================================
FILE: test/core/artifact-graph/graph.test.ts
================================================
import { describe, it, expect } from 'vitest';
import { ArtifactGraph } from '../../../src/core/artifact-graph/graph.js';
import type { SchemaYaml } from '../../../src/core/artifact-graph/types.js';

describe('artifact-graph/graph', () => {
  const createSchema = (artifacts: SchemaYaml['artifacts']): SchemaYaml => ({
    name: 'test',
    version: 1,
    artifacts,
  });

  describe('fromSchema', () => {
    it('should create graph from schema object', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
      ]);

      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.getName()).toBe('test');
      expect(graph.getVersion()).toBe(1);
    });
  });

  describe('fromYamlContent', () => {
    it('should create graph from YAML string', () => {
      const yaml = `
name: my-workflow
version: 2
artifacts:
  - id: doc
    generates: doc.md
    description: Documentation
    template: templates/doc.md
`;
      const graph = ArtifactGraph.fromYamlContent(yaml);

      expect(graph.getName()).toBe('my-workflow');
      expect(graph.getVersion()).toBe(2);
      expect(graph.getArtifact('doc')).toBeDefined();
    });
  });

  describe('getArtifact', () => {
    it('should return artifact by ID', () => {
      const schema = createSchema([
        { id: 'proposal', generates: 'proposal.md', description: 'Proposal', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const artifact = graph.getArtifact('proposal');

      expect(artifact).toBeDefined();
      expect(artifact?.id).toBe('proposal');
      expect(artifact?.generates).toBe('proposal.md');
    });

    it('should return undefined for non-existent ID', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.getArtifact('nonexistent')).toBeUndefined();
    });
  });

  describe('getAllArtifacts', () => {
    it('should return all artifacts', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const artifacts = graph.getAllArtifacts();

      expect(artifacts).toHaveLength(3);
      expect(artifacts.map(a => a.id).sort()).toEqual(['A', 'B', 'C']);
    });
  });

  describe('getBuildOrder', () => {
    it('should return correct order for linear chain A â†’ B â†’ C', () => {
      const schema = createSchema([
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: ['B'] },
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const order = graph.getBuildOrder();

      expect(order).toEqual(['A', 'B', 'C']);
    });

    it('should handle diamond dependency correctly', () => {
      // A â†’ B, A â†’ C, B â†’ D, C â†’ D
      const schema = createSchema([
        { id: 'D', generates: 'd.md', description: 'D', template: 't.md', requires: ['B', 'C'] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: ['A'] },
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const order = graph.getBuildOrder();

      // A must come before B and C; D must come last
      expect(order.indexOf('A')).toBeLessThan(order.indexOf('B'));
      expect(order.indexOf('A')).toBeLessThan(order.indexOf('C'));
      expect(order.indexOf('B')).toBeLessThan(order.indexOf('D'));
      expect(order.indexOf('C')).toBeLessThan(order.indexOf('D'));
    });

    it('should return independent artifacts in stable sorted order', () => {
      const schema = createSchema([
        { id: 'Z', generates: 'z.md', description: 'Z', template: 't.md', requires: [] },
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'M', generates: 'm.md', description: 'M', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const order = graph.getBuildOrder();

      // All independent, should be sorted alphabetically for stability
      expect(order).toEqual(['A', 'M', 'Z']);
    });
  });

  describe('getNextArtifacts', () => {
    it('should return root artifacts when nothing completed', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const ready = graph.getNextArtifacts(new Set());

      expect(ready.sort()).toEqual(['A', 'C']);
    });

    it('should include artifact when all deps completed', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const ready = graph.getNextArtifacts(new Set(['A']));

      expect(ready).toEqual(['B']);
    });

    it('should not include completed artifacts', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const ready = graph.getNextArtifacts(new Set(['A', 'B']));

      expect(ready).toEqual([]);
    });

    it('should handle diamond dependency correctly', () => {
      // D requires B and C
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: ['A'] },
        { id: 'D', generates: 'd.md', description: 'D', template: 't.md', requires: ['B', 'C'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Only A completed - B and C ready, D not
      expect(graph.getNextArtifacts(new Set(['A'])).sort()).toEqual(['B', 'C']);

      // Only B completed (from deps) - C still needed for D
      expect(graph.getNextArtifacts(new Set(['A', 'B']))).toEqual(['C']);

      // Both B and C completed - D ready
      expect(graph.getNextArtifacts(new Set(['A', 'B', 'C']))).toEqual(['D']);
    });
  });

  describe('isComplete', () => {
    it('should return true when all artifacts completed', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.isComplete(new Set(['A', 'B']))).toBe(true);
    });

    it('should return false when some artifacts incomplete', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.isComplete(new Set(['A']))).toBe(false);
      expect(graph.isComplete(new Set())).toBe(false);
    });
  });

  describe('getBlocked', () => {
    it('should return empty object when nothing is blocked', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.getBlocked(new Set())).toEqual({});
    });

    it('should return artifact blocked by single dependency', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.getBlocked(new Set())).toEqual({ B: ['A'] });
    });

    it('should return artifact blocked by multiple dependencies', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: [] },
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: ['A', 'B'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Neither A nor B completed
      expect(graph.getBlocked(new Set())).toEqual({ C: ['A', 'B'] });
    });

    it('should only list unmet dependencies', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: [] },
        { id: 'C', generates: 'c.md', description: 'C', template: 't.md', requires: ['A', 'B'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // A completed, B not
      expect(graph.getBlocked(new Set(['A']))).toEqual({ C: ['B'] });
    });

    it('should not include completed artifacts', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
        { id: 'B', generates: 'b.md', description: 'B', template: 't.md', requires: ['A'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.getBlocked(new Set(['A', 'B']))).toEqual({});
    });
  });
});



================================================
FILE: test/core/artifact-graph/instruction-loader.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import {
  loadTemplate,
  loadChangeContext,
  generateInstructions,
  formatChangeStatus,
  TemplateLoadError,
} from '../../../src/core/artifact-graph/instruction-loader.js';

describe('instruction-loader', () => {
  describe('loadTemplate', () => {
    it('should load template from schema directory', () => {
      // Uses built-in spec-driven schema
      const template = loadTemplate('spec-driven', 'proposal.md');

      expect(template).toContain('## Why');
      expect(template).toContain('## What Changes');
    });

    it('should throw TemplateLoadError for non-existent template', () => {
      expect(() => loadTemplate('spec-driven', 'nonexistent.md')).toThrow(
        TemplateLoadError
      );
    });

    it('should throw TemplateLoadError for non-existent schema', () => {
      expect(() => loadTemplate('nonexistent-schema', 'proposal.md')).toThrow(
        TemplateLoadError
      );
    });

    it('should include template path in error', () => {
      try {
        loadTemplate('spec-driven', 'nonexistent.md');
        expect.fail('Should have thrown');
      } catch (err) {
        expect(err).toBeInstanceOf(TemplateLoadError);
        expect((err as TemplateLoadError).templatePath).toContain('nonexistent.md');
      }
    });
  });

  describe('loadChangeContext', () => {
    let tempDir: string;

    beforeEach(() => {
      tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'openspec-test-'));
    });

    afterEach(() => {
      fs.rmSync(tempDir, { recursive: true, force: true });
    });

    it('should load context with default schema', () => {
      const context = loadChangeContext(tempDir, 'my-change');

      expect(context.schemaName).toBe('spec-driven');
      expect(context.changeName).toBe('my-change');
      expect(context.graph.getName()).toBe('spec-driven');
      expect(context.completed.size).toBe(0);
    });

    it('should load context with custom schema', () => {
      const context = loadChangeContext(tempDir, 'my-change', 'tdd');

      expect(context.schemaName).toBe('tdd');
      expect(context.graph.getName()).toBe('tdd');
    });

    it('should detect completed artifacts', () => {
      // Create change directory with proposal.md
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });
      fs.writeFileSync(path.join(changeDir, 'proposal.md'), '# Proposal');

      const context = loadChangeContext(tempDir, 'my-change');

      expect(context.completed.has('proposal')).toBe(true);
    });

    it('should return empty completed set for non-existent change directory', () => {
      const context = loadChangeContext(tempDir, 'nonexistent-change');

      expect(context.completed.size).toBe(0);
    });

    it('should auto-detect schema from .openspec.yaml metadata', () => {
      // Create change directory with metadata file
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });
      fs.writeFileSync(path.join(changeDir, '.openspec.yaml'), 'schema: tdd\ncreated: "2025-01-05"\n');

      // Load without explicit schema - should detect from metadata
      const context = loadChangeContext(tempDir, 'my-change');

      expect(context.schemaName).toBe('tdd');
      expect(context.graph.getName()).toBe('tdd');
    });

    it('should use explicit schema over metadata schema', () => {
      // Create change directory with metadata file using tdd
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });
      fs.writeFileSync(path.join(changeDir, '.openspec.yaml'), 'schema: tdd\n');

      // Load with explicit schema - should override metadata
      const context = loadChangeContext(tempDir, 'my-change', 'spec-driven');

      expect(context.schemaName).toBe('spec-driven');
      expect(context.graph.getName()).toBe('spec-driven');
    });

    it('should fall back to default when no metadata and no explicit schema', () => {
      // Create change directory without metadata file
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });

      const context = loadChangeContext(tempDir, 'my-change');

      expect(context.schemaName).toBe('spec-driven');
    });
  });

  describe('generateInstructions', () => {
    let tempDir: string;

    beforeEach(() => {
      tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'openspec-test-'));
    });

    afterEach(() => {
      fs.rmSync(tempDir, { recursive: true, force: true });
    });

    it('should include artifact metadata', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const instructions = generateInstructions(context, 'proposal');

      expect(instructions.changeName).toBe('my-change');
      expect(instructions.artifactId).toBe('proposal');
      expect(instructions.schemaName).toBe('spec-driven');
      expect(instructions.outputPath).toBe('proposal.md');
    });

    it('should include template content', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const instructions = generateInstructions(context, 'proposal');

      expect(instructions.template).toContain('## Why');
    });

    it('should show dependencies with completion status', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const instructions = generateInstructions(context, 'specs');

      expect(instructions.dependencies).toHaveLength(1);
      expect(instructions.dependencies[0].id).toBe('proposal');
      expect(instructions.dependencies[0].done).toBe(false);
    });

    it('should mark completed dependencies as done', () => {
      // Create proposal
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });
      fs.writeFileSync(path.join(changeDir, 'proposal.md'), '# Proposal');

      const context = loadChangeContext(tempDir, 'my-change');
      const instructions = generateInstructions(context, 'specs');

      expect(instructions.dependencies[0].done).toBe(true);
    });

    it('should list artifacts unlocked by this one', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const instructions = generateInstructions(context, 'proposal');

      // proposal unlocks specs and design
      expect(instructions.unlocks).toContain('specs');
      expect(instructions.unlocks).toContain('design');
    });

    it('should have empty dependencies for root artifact', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const instructions = generateInstructions(context, 'proposal');

      expect(instructions.dependencies).toHaveLength(0);
    });

    it('should throw for non-existent artifact', () => {
      const context = loadChangeContext(tempDir, 'my-change');

      expect(() => generateInstructions(context, 'nonexistent')).toThrow(
        "Artifact 'nonexistent' not found"
      );
    });

    describe('project config integration', () => {
      it('should return context as separate field for all artifacts', () => {
        // Create project config
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  Tech stack: TypeScript, React
  API style: RESTful
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        // Context should be in separate field, not in template
        expect(instructions.context).toContain('Tech stack: TypeScript, React');
        expect(instructions.context).toContain('API style: RESTful');
        expect(instructions.template).not.toContain('Tech stack');
        expect(instructions.template).toContain('## Why'); // Actual template content
      });

      it('should return undefined context when config is absent', () => {
        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        expect(instructions.context).toBeUndefined();
        expect(instructions.rules).toBeUndefined();
        expect(instructions.template).toContain('## Why'); // Actual template content
      });

      it('should preserve multi-line context', () => {
        // Create project config with multi-line context
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  Line 1
  Line 2
  Line 3
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        expect(instructions.context).toContain('Line 1\nLine 2\nLine 3');
      });

      it('should preserve special characters in context', () => {
        // Create project config with special characters
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: |
  Special: < > & " ' @ # $ % [ ] { }
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        expect(instructions.context).toContain('Special: < > & " \' @ # $ % [ ] { }');
      });

      it('should return rules only for matching artifact', () => {
        // Create project config with rules
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Include rollback plan
    - Identify affected teams
  specs:
    - Use Given/When/Then format
`
        );

        const context = loadChangeContext(tempDir, 'my-change');

        // Check proposal artifact has its rules
        const proposalInstructions = generateInstructions(context, 'proposal', tempDir);
        expect(proposalInstructions.rules).toEqual(['Include rollback plan', 'Identify affected teams']);
        expect(proposalInstructions.template).not.toContain('rollback plan');

        // Check specs artifact has its rules
        const specsInstructions = generateInstructions(context, 'specs', tempDir);
        expect(specsInstructions.rules).toEqual(['Use Given/When/Then format']);
        expect(specsInstructions.template).not.toContain('Given/When/Then');
      });

      it('should return undefined rules for non-matching artifact', () => {
        // Create project config with rules only for proposal
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Include rollback plan
`
        );

        const context = loadChangeContext(tempDir, 'my-change');

        // Check design artifact (no rules configured) has undefined rules
        const designInstructions = generateInstructions(context, 'design', tempDir);
        expect(designInstructions.rules).toBeUndefined();
      });

      it('should return undefined rules when empty array', () => {
        // Create project config with empty rules array
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: Some context
rules:
  proposal: []
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        expect(instructions.context).toBe('Some context');
        expect(instructions.rules).toBeUndefined();
      });

      it('should keep context, rules, and template as separate fields', () => {
        // Create project config with both context and rules
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: Project context here
rules:
  proposal:
    - Rule 1
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        // All three should be separate
        expect(instructions.context).toBe('Project context here');
        expect(instructions.rules).toEqual(['Rule 1']);
        expect(instructions.template).toContain('## Why');
        // Template should not contain context or rules
        expect(instructions.template).not.toContain('Project context here');
        expect(instructions.template).not.toContain('Rule 1');
      });

      it('should handle context without rules', () => {
        // Create project config with only context
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
context: Project context only
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        expect(instructions.context).toBe('Project context only');
        expect(instructions.rules).toBeUndefined();
        expect(instructions.template).toContain('## Why');
      });

      it('should handle rules without context', () => {
        // Create project config with only rules
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Rule only
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal', tempDir);

        expect(instructions.context).toBeUndefined();
        expect(instructions.rules).toEqual(['Rule only']);
        expect(instructions.template).toContain('## Why');
      });

      it('should work without project root parameter', () => {
        const context = loadChangeContext(tempDir, 'my-change');
        const instructions = generateInstructions(context, 'proposal'); // No projectRoot

        expect(instructions.context).toBeUndefined();
        expect(instructions.rules).toBeUndefined();
        expect(instructions.template).toContain('## Why');
      });
    });

    describe('validation and warnings', () => {
      let consoleWarnSpy: ReturnType<typeof vi.spyOn>;

      beforeEach(() => {
        consoleWarnSpy = vi.spyOn(console, 'warn').mockImplementation(() => {});
      });

      afterEach(() => {
        consoleWarnSpy.mockRestore();
      });

      it('should warn about unknown artifact IDs in rules', () => {
        // Create project config with invalid artifact ID
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Valid rule
  invalid-artifact:
    - Invalid rule
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        generateInstructions(context, 'proposal', tempDir);

        expect(consoleWarnSpy).toHaveBeenCalledWith(
          expect.stringContaining('Unknown artifact ID in rules: "invalid-artifact"')
        );
      });

      it('should deduplicate validation warnings within session', () => {
        // Create a fresh temp directory to avoid cache pollution
        const freshTempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'openspec-test-'));

        try {
          // Create project config with a uniquely named invalid artifact ID
          const configDir = path.join(freshTempDir, 'openspec');
          fs.mkdirSync(configDir, { recursive: true });
          fs.writeFileSync(
            path.join(configDir, 'config.yaml'),
            `schema: spec-driven
rules:
  unique-invalid-artifact-${Date.now()}:
    - Invalid rule
`
          );

          const context = loadChangeContext(freshTempDir, 'my-change');

          // Call multiple times
          generateInstructions(context, 'proposal', freshTempDir);
          generateInstructions(context, 'specs', freshTempDir);
          generateInstructions(context, 'design', freshTempDir);

          // Warning should be shown only once (deduplication works)
          // Note: We may have gotten warnings from other tests, so check that
          // the count didn't increase by more than 1 from the first call
          const callCount = consoleWarnSpy.mock.calls.filter(call =>
            call[0]?.includes('Unknown artifact ID in rules')
          ).length;

          expect(callCount).toBeGreaterThanOrEqual(1);
        } finally {
          fs.rmSync(freshTempDir, { recursive: true, force: true });
        }
      });

      it('should not warn for valid artifact IDs', () => {
        // Create project config with valid artifact IDs
        const configDir = path.join(tempDir, 'openspec');
        fs.mkdirSync(configDir, { recursive: true });
        fs.writeFileSync(
          path.join(configDir, 'config.yaml'),
          `schema: spec-driven
rules:
  proposal:
    - Rule 1
  specs:
    - Rule 2
`
        );

        const context = loadChangeContext(tempDir, 'my-change');
        generateInstructions(context, 'proposal', tempDir);

        expect(consoleWarnSpy).not.toHaveBeenCalled();
      });
    });
  });

  describe('formatChangeStatus', () => {
    let tempDir: string;

    beforeEach(() => {
      tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'openspec-test-'));
    });

    afterEach(() => {
      fs.rmSync(tempDir, { recursive: true, force: true });
    });

    it('should show all artifacts as ready/blocked when nothing completed', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const status = formatChangeStatus(context);

      expect(status.changeName).toBe('my-change');
      expect(status.schemaName).toBe('spec-driven');
      expect(status.isComplete).toBe(false);

      // proposal has no deps, should be ready
      const proposal = status.artifacts.find(a => a.id === 'proposal');
      expect(proposal?.status).toBe('ready');

      // specs depends on proposal, should be blocked
      const specs = status.artifacts.find(a => a.id === 'specs');
      expect(specs?.status).toBe('blocked');
      expect(specs?.missingDeps).toContain('proposal');
    });

    it('should show completed artifacts as done', () => {
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });
      fs.writeFileSync(path.join(changeDir, 'proposal.md'), '# Proposal');

      const context = loadChangeContext(tempDir, 'my-change');
      const status = formatChangeStatus(context);

      const proposal = status.artifacts.find(a => a.id === 'proposal');
      expect(proposal?.status).toBe('done');

      // specs should now be ready
      const specs = status.artifacts.find(a => a.id === 'specs');
      expect(specs?.status).toBe('ready');
    });

    it('should include output paths for each artifact', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const status = formatChangeStatus(context);

      const proposal = status.artifacts.find(a => a.id === 'proposal');
      expect(proposal?.outputPath).toBe('proposal.md');

      const specs = status.artifacts.find(a => a.id === 'specs');
      expect(specs?.outputPath).toBe('specs/**/*.md');
    });

    it('should report isComplete true when all done', () => {
      const changeDir = path.join(tempDir, 'openspec', 'changes', 'my-change');
      fs.mkdirSync(changeDir, { recursive: true });
      fs.mkdirSync(path.join(changeDir, 'specs'), { recursive: true });

      // Create all required files for spec-driven schema
      fs.writeFileSync(path.join(changeDir, 'proposal.md'), '# Proposal');
      fs.writeFileSync(path.join(changeDir, 'specs', 'test.md'), '# Spec');
      fs.writeFileSync(path.join(changeDir, 'design.md'), '# Design');
      fs.writeFileSync(path.join(changeDir, 'tasks.md'), '# Tasks');

      const context = loadChangeContext(tempDir, 'my-change');
      const status = formatChangeStatus(context);

      expect(status.isComplete).toBe(true);
      expect(status.artifacts.every(a => a.status === 'done')).toBe(true);
    });

    it('should show blocked artifacts with missing dependencies', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const status = formatChangeStatus(context);

      // tasks requires specs and design
      const tasks = status.artifacts.find(a => a.id === 'tasks');
      expect(tasks?.status).toBe('blocked');
      expect(tasks?.missingDeps).toContain('specs');
      expect(tasks?.missingDeps).toContain('design');
    });

    it('should sort artifacts in build order', () => {
      const context = loadChangeContext(tempDir, 'my-change');
      const status = formatChangeStatus(context);

      const ids = status.artifacts.map(a => a.id);
      const proposalIdx = ids.indexOf('proposal');
      const specsIdx = ids.indexOf('specs');
      const tasksIdx = ids.indexOf('tasks');

      // proposal must come before specs, specs before tasks
      expect(proposalIdx).toBeLessThan(specsIdx);
      expect(specsIdx).toBeLessThan(tasksIdx);
    });
  });
});



================================================
FILE: test/core/artifact-graph/resolver.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import {
  resolveSchema,
  listSchemas,
  listSchemasWithInfo,
  SchemaLoadError,
  getSchemaDir,
  getPackageSchemasDir,
  getUserSchemasDir,
  getProjectSchemasDir,
} from '../../../src/core/artifact-graph/resolver.js';

describe('artifact-graph/resolver', () => {
  let tempDir: string;
  let originalEnv: NodeJS.ProcessEnv;

  beforeEach(() => {
    tempDir = path.join(os.tmpdir(), `openspec-resolver-test-${Date.now()}`);
    fs.mkdirSync(tempDir, { recursive: true });
    originalEnv = { ...process.env };
  });

  afterEach(() => {
    process.env = originalEnv;
    fs.rmSync(tempDir, { recursive: true, force: true });
  });

  describe('getPackageSchemasDir', () => {
    it('should return a valid path', () => {
      const schemasDir = getPackageSchemasDir();
      expect(typeof schemasDir).toBe('string');
      expect(schemasDir.length).toBeGreaterThan(0);
    });
  });

  describe('getUserSchemasDir', () => {
    it('should use XDG_DATA_HOME when set', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userDir = getUserSchemasDir();
      expect(userDir).toBe(path.join(tempDir, 'openspec', 'schemas'));
    });
  });

  describe('getSchemaDir', () => {
    it('should return null for non-existent schema', () => {
      const dir = getSchemaDir('nonexistent-schema');
      expect(dir).toBeNull();
    });

    it('should return package dir for built-in schema', () => {
      const dir = getSchemaDir('spec-driven');
      expect(dir).not.toBeNull();
      expect(dir).toContain('schemas');
      expect(dir).toContain('spec-driven');
    });

    it('should prefer user override directory', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        'name: custom\nversion: 1\nartifacts: []'
      );

      const dir = getSchemaDir('spec-driven');
      expect(dir).toBe(userSchemaDir);
    });
  });

  describe('resolveSchema', () => {
    it('should return built-in spec-driven schema', () => {
      const schema = resolveSchema('spec-driven');

      expect(schema.name).toBe('spec-driven');
      expect(schema.version).toBe(1);
      expect(schema.artifacts.length).toBeGreaterThan(0);
    });

    it('should return built-in tdd schema', () => {
      const schema = resolveSchema('tdd');

      expect(schema.name).toBe('tdd');
      expect(schema.version).toBe(1);
      expect(schema.artifacts.length).toBeGreaterThan(0);
    });

    it('should strip .yaml extension from name', () => {
      const schema1 = resolveSchema('spec-driven');
      const schema2 = resolveSchema('spec-driven.yaml');

      expect(schema1).toEqual(schema2);
    });

    it('should strip .yml extension from name', () => {
      const schema1 = resolveSchema('spec-driven');
      const schema2 = resolveSchema('spec-driven.yml');

      expect(schema1).toEqual(schema2);
    });

    it('should prefer user override over built-in', () => {
      // Set up global data dir
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });

      // Create a custom schema with same name as built-in
      const customSchema = `
name: custom-override
version: 99
artifacts:
  - id: custom
    generates: custom.md
    description: Custom artifact
    template: custom.md
`;
      fs.writeFileSync(path.join(userSchemaDir, 'schema.yaml'), customSchema);

      const schema = resolveSchema('spec-driven');

      expect(schema.name).toBe('custom-override');
      expect(schema.version).toBe(99);
    });

    it('should validate user override and throw on invalid schema', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });

      // Create an invalid schema (missing required fields)
      const invalidSchema = `
name: invalid
version: 1
artifacts:
  - id: broken
    # missing generates, description, template
`;
      fs.writeFileSync(path.join(userSchemaDir, 'schema.yaml'), invalidSchema);

      expect(() => resolveSchema('spec-driven')).toThrow(SchemaLoadError);
    });

    it('should include file path in validation error message', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });

      const invalidSchema = `
name: invalid
version: 1
artifacts:
  - id: broken
`;
      const schemaPath = path.join(userSchemaDir, 'schema.yaml');
      fs.writeFileSync(schemaPath, invalidSchema);

      try {
        resolveSchema('spec-driven');
        expect.fail('Should have thrown');
      } catch (e) {
        const error = e as SchemaLoadError;
        expect(error.message).toContain(schemaPath);
        expect(error.schemaPath).toBe(schemaPath);
        expect(error.cause).toBeDefined();
      }
    });

    it('should detect cycles in user override schemas', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });

      // Create a schema with cyclic dependencies
      const cyclicSchema = `
name: cyclic
version: 1
artifacts:
  - id: a
    generates: a.md
    description: A
    template: a.md
    requires: [b]
  - id: b
    generates: b.md
    description: B
    template: b.md
    requires: [a]
`;
      fs.writeFileSync(path.join(userSchemaDir, 'schema.yaml'), cyclicSchema);

      expect(() => resolveSchema('spec-driven')).toThrow(/Cyclic dependency/);
    });

    it('should detect invalid requires references in user override schemas', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });

      // Create a schema with invalid requires reference
      const invalidRefSchema = `
name: invalid-ref
version: 1
artifacts:
  - id: a
    generates: a.md
    description: A
    template: a.md
    requires: [nonexistent]
`;
      fs.writeFileSync(path.join(userSchemaDir, 'schema.yaml'), invalidRefSchema);

      expect(() => resolveSchema('spec-driven')).toThrow(/does not exist/);
    });

    it('should throw SchemaLoadError on YAML syntax errors', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });

      // Create malformed YAML
      const malformedYaml = `
name: bad
version: [[[invalid yaml
`;
      const schemaPath = path.join(userSchemaDir, 'schema.yaml');
      fs.writeFileSync(schemaPath, malformedYaml);

      try {
        resolveSchema('spec-driven');
        expect.fail('Should have thrown');
      } catch (e) {
        expect(e).toBeInstanceOf(SchemaLoadError);
        const error = e as SchemaLoadError;
        expect(error.message).toContain('Failed to parse');
        expect(error.message).toContain(schemaPath);
      }
    });

    it('should fall back to built-in when user override not found', () => {
      process.env.XDG_DATA_HOME = tempDir;
      // Don't create any user schemas

      const schema = resolveSchema('spec-driven');

      expect(schema.name).toBe('spec-driven');
      expect(schema.version).toBe(1);
    });

    it('should throw when schema not found', () => {
      expect(() => resolveSchema('nonexistent-schema')).toThrow(/not found/);
    });

    it('should list available schemas in error message', () => {
      try {
        resolveSchema('nonexistent');
        expect.fail('Should have thrown');
      } catch (e) {
        const error = e as Error;
        expect(error.message).toContain('spec-driven');
        expect(error.message).toContain('tdd');
      }
    });
  });

  describe('listSchemas', () => {
    it('should list built-in schemas', () => {
      const schemas = listSchemas();

      expect(schemas).toContain('spec-driven');
      expect(schemas).toContain('tdd');
    });

    it('should include user override schemas', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'custom-workflow');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(path.join(userSchemaDir, 'schema.yaml'), 'name: custom\nversion: 1\nartifacts: []');

      const schemas = listSchemas();

      expect(schemas).toContain('custom-workflow');
      expect(schemas).toContain('spec-driven');
    });

    it('should deduplicate schemas with same name', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      // Override spec-driven
      fs.writeFileSync(path.join(userSchemaDir, 'schema.yaml'), 'name: custom\nversion: 1\nartifacts: []');

      const schemas = listSchemas();

      // Should only appear once
      const count = schemas.filter(s => s === 'spec-driven').length;
      expect(count).toBe(1);
    });

    it('should return sorted list', () => {
      const schemas = listSchemas();

      const sorted = [...schemas].sort();
      expect(schemas).toEqual(sorted);
    });

    it('should only include directories with schema.yaml', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemasBase = path.join(tempDir, 'openspec', 'schemas');

      // Create a directory without schema.yaml
      const emptyDir = path.join(userSchemasBase, 'empty-dir');
      fs.mkdirSync(emptyDir, { recursive: true });

      // Create a valid schema directory
      const validDir = path.join(userSchemasBase, 'valid-schema');
      fs.mkdirSync(validDir, { recursive: true });
      fs.writeFileSync(path.join(validDir, 'schema.yaml'), 'name: valid\nversion: 1\nartifacts: []');

      const schemas = listSchemas();

      expect(schemas).toContain('valid-schema');
      expect(schemas).not.toContain('empty-dir');
    });
  });

  // =========================================================================
  // Project-local schema tests
  // =========================================================================

  describe('getProjectSchemasDir', () => {
    it('should return correct path', () => {
      const projectRoot = '/path/to/project';
      const schemasDir = getProjectSchemasDir(projectRoot);
      expect(schemasDir).toBe(path.join('/path/to/project', 'openspec', 'schemas'));
    });

    it('should work with relative-looking paths', () => {
      const schemasDir = getProjectSchemasDir('./my-project');
      expect(schemasDir).toBe(path.join('my-project', 'openspec', 'schemas'));
    });
  });

  describe('getSchemaDir with projectRoot', () => {
    it('should return null for non-existent project schema', () => {
      const dir = getSchemaDir('nonexistent-schema', tempDir);
      expect(dir).toBeNull();
    });

    it('should prefer project-local schema over user override', () => {
      // Set up user override
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'my-schema');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        'name: user-version\nversion: 1\nartifacts: []'
      );

      // Set up project-local schema
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'my-schema');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        'name: project-version\nversion: 2\nartifacts: []'
      );

      const dir = getSchemaDir('my-schema', projectRoot);
      expect(dir).toBe(projectSchemaDir);
    });

    it('should prefer project-local schema over package built-in', () => {
      // Set up project-local schema that overrides built-in
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'spec-driven');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        'name: project-spec-driven\nversion: 99\nartifacts: []\n'
      );

      const dir = getSchemaDir('spec-driven', projectRoot);
      expect(dir).toBe(projectSchemaDir);
    });

    it('should fall back to user override when no project-local schema', () => {
      // Set up user override only
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'user-only-schema');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        'name: user-only\nversion: 1\nartifacts: []'
      );

      const projectRoot = path.join(tempDir, 'project');
      fs.mkdirSync(projectRoot, { recursive: true });

      const dir = getSchemaDir('user-only-schema', projectRoot);
      expect(dir).toBe(userSchemaDir);
    });

    it('should fall back to package built-in when no project or user schema', () => {
      const projectRoot = path.join(tempDir, 'project');
      fs.mkdirSync(projectRoot, { recursive: true });

      const dir = getSchemaDir('spec-driven', projectRoot);
      expect(dir).not.toBeNull();
      // Should be package path, not project or user
      expect(dir).not.toContain(projectRoot);
    });

    it('should maintain backward compatibility when projectRoot not provided', () => {
      // Set up user override
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'my-schema');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        'name: user-version\nversion: 1\nartifacts: []'
      );

      // Set up project-local schema (should be ignored when projectRoot not provided)
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'my-schema');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        'name: project-version\nversion: 2\nartifacts: []'
      );

      // Without projectRoot, should get user version
      const dir = getSchemaDir('my-schema');
      expect(dir).toBe(userSchemaDir);
    });
  });

  describe('resolveSchema with projectRoot', () => {
    it('should resolve project-local schema', () => {
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'team-workflow');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        `name: team-workflow
version: 1
description: Team workflow
artifacts:
  - id: spec
    generates: spec.md
    description: Specification
    template: spec.md
`
      );

      const schema = resolveSchema('team-workflow', projectRoot);
      expect(schema.name).toBe('team-workflow');
      expect(schema.version).toBe(1);
    });

    it('should prefer project-local over user override when resolving', () => {
      // Set up user override
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'shared-schema');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        `name: user-version
version: 1
artifacts:
  - id: user-artifact
    generates: user.md
    description: User artifact
    template: user.md
`
      );

      // Set up project-local schema
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'shared-schema');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        `name: project-version
version: 2
artifacts:
  - id: project-artifact
    generates: project.md
    description: Project artifact
    template: project.md
`
      );

      const schema = resolveSchema('shared-schema', projectRoot);
      expect(schema.name).toBe('project-version');
      expect(schema.version).toBe(2);
    });
  });

  describe('listSchemas with projectRoot', () => {
    it('should include project-local schemas', () => {
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'team-workflow');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        'name: team-workflow\nversion: 1\nartifacts: []'
      );

      const schemas = listSchemas(projectRoot);
      expect(schemas).toContain('team-workflow');
      expect(schemas).toContain('spec-driven'); // built-in still included
    });

    it('should deduplicate project-local schema that shadows user override', () => {
      // Set up user override
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'my-schema');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        'name: user\nversion: 1\nartifacts: []'
      );

      // Set up project-local schema with same name
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'my-schema');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        'name: project\nversion: 2\nartifacts: []'
      );

      const schemas = listSchemas(projectRoot);
      const count = schemas.filter(s => s === 'my-schema').length;
      expect(count).toBe(1);
    });

    it('should maintain backward compatibility when projectRoot not provided', () => {
      // Set up project-local schema
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'project-only');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        'name: project-only\nversion: 1\nartifacts: []'
      );

      // Without projectRoot, project-only schema should not appear
      const schemas = listSchemas();
      expect(schemas).not.toContain('project-only');
    });
  });

  describe('listSchemasWithInfo with projectRoot', () => {
    it('should return source: project for project-local schemas', () => {
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'team-workflow');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        `name: team-workflow
version: 1
description: Team workflow
artifacts:
  - id: spec
    generates: spec.md
    description: Specification
    template: spec.md
`
      );

      const schemas = listSchemasWithInfo(projectRoot);
      const teamSchema = schemas.find(s => s.name === 'team-workflow');
      expect(teamSchema).toBeDefined();
      expect(teamSchema!.source).toBe('project');
    });

    it('should return source: package for built-in schemas', () => {
      const projectRoot = path.join(tempDir, 'project');
      fs.mkdirSync(projectRoot, { recursive: true });

      const schemas = listSchemasWithInfo(projectRoot);
      const specDriven = schemas.find(s => s.name === 'spec-driven');
      expect(specDriven).toBeDefined();
      expect(specDriven!.source).toBe('package');
    });

    it('should return source: user for user override schemas', () => {
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'user-custom');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        `name: user-custom
version: 1
description: User custom
artifacts:
  - id: artifact
    generates: artifact.md
    description: Artifact
    template: artifact.md
`
      );

      const projectRoot = path.join(tempDir, 'project');
      fs.mkdirSync(projectRoot, { recursive: true });

      const schemas = listSchemasWithInfo(projectRoot);
      const userSchema = schemas.find(s => s.name === 'user-custom');
      expect(userSchema).toBeDefined();
      expect(userSchema!.source).toBe('user');
    });

    it('should show project source when project-local shadows user override', () => {
      // Set up user override
      process.env.XDG_DATA_HOME = tempDir;
      const userSchemaDir = path.join(tempDir, 'openspec', 'schemas', 'shared');
      fs.mkdirSync(userSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(userSchemaDir, 'schema.yaml'),
        `name: user-shared
version: 1
description: User shared
artifacts:
  - id: a
    generates: a.md
    description: A
    template: a.md
`
      );

      // Set up project-local with same name
      const projectRoot = path.join(tempDir, 'project');
      const projectSchemaDir = path.join(projectRoot, 'openspec', 'schemas', 'shared');
      fs.mkdirSync(projectSchemaDir, { recursive: true });
      fs.writeFileSync(
        path.join(projectSchemaDir, 'schema.yaml'),
        `name: project-shared
version: 2
description: Project shared
artifacts:
  - id: b
    generates: b.md
    description: B
    template: b.md
`
      );

      const schemas = listSchemasWithInfo(projectRoot);
      const sharedSchema = schemas.find(s => s.name === 'shared');
      expect(sharedSchema).toBeDefined();
      expect(sharedSchema!.source).toBe('project');
      expect(sharedSchema!.description).toBe('Project shared'); // project version wins
    });
  });
});



================================================
FILE: test/core/artifact-graph/schema.test.ts
================================================
import { describe, it, expect } from 'vitest';
import { parseSchema, SchemaValidationError } from '../../../src/core/artifact-graph/schema.js';

describe('artifact-graph/schema', () => {
  describe('parseSchema', () => {
    it('should parse valid schema YAML', () => {
      const yaml = `
name: test-schema
version: 1
description: A test schema
artifacts:
  - id: proposal
    generates: proposal.md
    description: Initial proposal
    template: templates/proposal.md
    requires: []
  - id: design
    generates: design.md
    description: Design document
    template: templates/design.md
    requires:
      - proposal
`;
      const schema = parseSchema(yaml);

      expect(schema.name).toBe('test-schema');
      expect(schema.version).toBe(1);
      expect(schema.description).toBe('A test schema');
      expect(schema.artifacts).toHaveLength(2);
      expect(schema.artifacts[0].id).toBe('proposal');
      expect(schema.artifacts[1].requires).toEqual(['proposal']);
    });

    it('should throw on missing required fields', () => {
      const yaml = `
name: test-schema
version: 1
artifacts:
  - id: proposal
    description: Missing generates and template
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/generates/);
    });

    it('should throw on missing schema name', () => {
      const yaml = `
version: 1
artifacts:
  - id: proposal
    generates: proposal.md
    description: Test
    template: templates/proposal.md
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/name/);
    });

    it('should throw on invalid version (non-positive)', () => {
      const yaml = `
name: test
version: 0
artifacts:
  - id: proposal
    generates: proposal.md
    description: Test
    template: templates/proposal.md
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/positive/);
    });

    it('should throw on empty artifacts array', () => {
      const yaml = `
name: test
version: 1
artifacts: []
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/artifact/i);
    });

    it('should throw on duplicate artifact IDs', () => {
      const yaml = `
name: test
version: 1
artifacts:
  - id: proposal
    generates: proposal.md
    description: First
    template: templates/proposal.md
  - id: proposal
    generates: other.md
    description: Duplicate
    template: templates/other.md
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/Duplicate artifact ID: proposal/);
    });

    it('should throw on invalid requires reference', () => {
      const yaml = `
name: test
version: 1
artifacts:
  - id: design
    generates: design.md
    description: Design doc
    template: templates/design.md
    requires:
      - nonexistent
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/Invalid dependency reference.*nonexistent/);
    });

    it('should detect self-referencing cycle', () => {
      const yaml = `
name: test
version: 1
artifacts:
  - id: A
    generates: a.md
    description: Self reference
    template: templates/a.md
    requires:
      - A
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/Cyclic dependency detected/);
    });

    it('should detect simple A â†’ B â†’ A cycle', () => {
      const yaml = `
name: test
version: 1
artifacts:
  - id: A
    generates: a.md
    description: A
    template: templates/a.md
    requires:
      - B
  - id: B
    generates: b.md
    description: B
    template: templates/b.md
    requires:
      - A
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/Cyclic dependency detected/);
      expect(() => parseSchema(yaml)).toThrow(/â†’/);
    });

    it('should detect longer A â†’ B â†’ C â†’ A cycle and list all IDs', () => {
      const yaml = `
name: test
version: 1
artifacts:
  - id: A
    generates: a.md
    description: A
    template: templates/a.md
    requires:
      - C
  - id: B
    generates: b.md
    description: B
    template: templates/b.md
    requires:
      - A
  - id: C
    generates: c.md
    description: C
    template: templates/c.md
    requires:
      - B
`;
      expect(() => parseSchema(yaml)).toThrow(SchemaValidationError);
      expect(() => parseSchema(yaml)).toThrow(/Cyclic dependency detected/);
      // Should contain all three in the cycle path
      const error = (() => {
        try {
          parseSchema(yaml);
        } catch (e) {
          return e;
        }
      })() as Error;
      expect(error.message).toMatch(/A.*â†’.*B|B.*â†’.*C|C.*â†’.*A/);
    });

    it('should allow default empty requires array', () => {
      const yaml = `
name: test
version: 1
artifacts:
  - id: root
    generates: root.md
    description: Root artifact
    template: templates/root.md
`;
      const schema = parseSchema(yaml);
      expect(schema.artifacts[0].requires).toEqual([]);
    });
  });
});



================================================
FILE: test/core/artifact-graph/state.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import { detectCompleted } from '../../../src/core/artifact-graph/state.js';
import { ArtifactGraph } from '../../../src/core/artifact-graph/graph.js';
import type { SchemaYaml } from '../../../src/core/artifact-graph/types.js';

describe('artifact-graph/state', () => {
  let tempDir: string;

  const createSchema = (artifacts: SchemaYaml['artifacts']): SchemaYaml => ({
    name: 'test',
    version: 1,
    artifacts,
  });

  beforeEach(() => {
    tempDir = path.join(os.tmpdir(), `openspec-state-test-${Date.now()}`);
    fs.mkdirSync(tempDir, { recursive: true });
  });

  afterEach(() => {
    fs.rmSync(tempDir, { recursive: true, force: true });
  });

  describe('detectCompleted', () => {
    it('should return empty set when changeDir does not exist', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const completed = detectCompleted(graph, '/nonexistent/path');

      expect(completed.size).toBe(0);
    });

    it('should return empty set when changeDir is empty', () => {
      const schema = createSchema([
        { id: 'A', generates: 'a.md', description: 'A', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const completed = detectCompleted(graph, tempDir);

      expect(completed.size).toBe(0);
    });

    it('should mark artifact complete when file exists', () => {
      const schema = createSchema([
        { id: 'proposal', generates: 'proposal.md', description: 'Proposal', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Create the file
      fs.writeFileSync(path.join(tempDir, 'proposal.md'), 'content');

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('proposal')).toBe(true);
    });

    it('should not mark artifact complete when file does not exist', () => {
      const schema = createSchema([
        { id: 'proposal', generates: 'proposal.md', description: 'Proposal', template: 't.md', requires: [] },
        { id: 'design', generates: 'design.md', description: 'Design', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Only create proposal.md
      fs.writeFileSync(path.join(tempDir, 'proposal.md'), 'content');

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('proposal')).toBe(true);
      expect(completed.has('design')).toBe(false);
    });

    it('should handle nested paths', () => {
      const schema = createSchema([
        { id: 'nested', generates: 'docs/design.md', description: 'Nested', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Create nested directory and file
      fs.mkdirSync(path.join(tempDir, 'docs'), { recursive: true });
      fs.writeFileSync(path.join(tempDir, 'docs', 'design.md'), 'content');

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('nested')).toBe(true);
    });

    it('should detect glob pattern as complete when files exist', () => {
      const schema = createSchema([
        { id: 'specs', generates: 'specs/*.md', description: 'Specs', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Create specs directory with files
      fs.mkdirSync(path.join(tempDir, 'specs'), { recursive: true });
      fs.writeFileSync(path.join(tempDir, 'specs', 'feature-a.md'), 'content');
      fs.writeFileSync(path.join(tempDir, 'specs', 'feature-b.md'), 'content');

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('specs')).toBe(true);
    });

    it('should not mark glob pattern complete when directory is empty', () => {
      const schema = createSchema([
        { id: 'specs', generates: 'specs/*.md', description: 'Specs', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Create empty specs directory
      fs.mkdirSync(path.join(tempDir, 'specs'), { recursive: true });

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('specs')).toBe(false);
    });

    it('should not mark glob pattern complete when directory does not exist', () => {
      const schema = createSchema([
        { id: 'specs', generates: 'specs/*.md', description: 'Specs', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('specs')).toBe(false);
    });

    it('should not mark glob pattern complete when only non-matching files exist', () => {
      const schema = createSchema([
        { id: 'specs', generates: 'specs/*.md', description: 'Specs', template: 't.md', requires: [] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Create specs directory with non-matching files
      fs.mkdirSync(path.join(tempDir, 'specs'), { recursive: true });
      fs.writeFileSync(path.join(tempDir, 'specs', 'readme.txt'), 'content');

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('specs')).toBe(false);
    });

    it('should handle multiple artifacts with mixed completion', () => {
      const schema = createSchema([
        { id: 'proposal', generates: 'proposal.md', description: 'Proposal', template: 't.md', requires: [] },
        { id: 'specs', generates: 'specs/*.md', description: 'Specs', template: 't.md', requires: ['proposal'] },
        { id: 'design', generates: 'design.md', description: 'Design', template: 't.md', requires: ['proposal'] },
        { id: 'tasks', generates: 'tasks.md', description: 'Tasks', template: 't.md', requires: ['specs', 'design'] },
      ]);
      const graph = ArtifactGraph.fromSchema(schema);

      // Create some files
      fs.writeFileSync(path.join(tempDir, 'proposal.md'), 'content');
      fs.mkdirSync(path.join(tempDir, 'specs'), { recursive: true });
      fs.writeFileSync(path.join(tempDir, 'specs', 'auth.md'), 'content');
      // design.md and tasks.md do not exist

      const completed = detectCompleted(graph, tempDir);

      expect(completed.has('proposal')).toBe(true);
      expect(completed.has('specs')).toBe(true);
      expect(completed.has('design')).toBe(false);
      expect(completed.has('tasks')).toBe(false);
    });
  });
});



================================================
FILE: test/core/artifact-graph/workflow.integration.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import { resolveSchema } from '../../../src/core/artifact-graph/resolver.js';
import { ArtifactGraph } from '../../../src/core/artifact-graph/graph.js';
import { detectCompleted } from '../../../src/core/artifact-graph/state.js';
import type { BlockedArtifacts } from '../../../src/core/artifact-graph/types.js';

/**
 * Normalize BlockedArtifacts for comparison by sorting dependency arrays.
 * The order of unmet dependencies is not guaranteed, so we sort for stable assertions.
 */
function normalizeBlocked(blocked: BlockedArtifacts): BlockedArtifacts {
  const normalized: BlockedArtifacts = {};
  for (const [key, deps] of Object.entries(blocked)) {
    normalized[key] = [...deps].sort();
  }
  return normalized;
}

describe('artifact-graph workflow integration', () => {
  let tempDir: string;

  beforeEach(() => {
    // Use a unique temp directory for each test
    tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'openspec-workflow-test-'));
  });

  afterEach(() => {
    // Clean up temp directory after each test
    if (tempDir && fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }
  });

  describe('spec-driven workflow', () => {
    it('should progress through complete workflow', () => {
      // 1. Resolve the real built-in schema
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      // Verify schema structure
      expect(graph.getName()).toBe('spec-driven');
      expect(graph.getAllArtifacts()).toHaveLength(4);

      // 2. Initial state - nothing complete, only proposal is ready
      let completed = detectCompleted(graph, tempDir);
      expect(completed.size).toBe(0);
      expect(graph.getNextArtifacts(completed)).toEqual(['proposal']);
      expect(graph.isComplete(completed)).toBe(false);
      expect(normalizeBlocked(graph.getBlocked(completed))).toEqual({
        specs: ['proposal'],
        design: ['proposal'],
        tasks: ['design', 'specs'],
      });

      // 3. Create proposal.md - now specs and design become ready
      fs.writeFileSync(path.join(tempDir, 'proposal.md'), '# Proposal\n\nInitial proposal content.');
      completed = detectCompleted(graph, tempDir);
      expect(completed).toEqual(new Set(['proposal']));
      expect(graph.getNextArtifacts(completed).sort()).toEqual(['design', 'specs']);
      expect(normalizeBlocked(graph.getBlocked(completed))).toEqual({
        tasks: ['design', 'specs'],
      });

      // 4. Create design.md - specs still needed for tasks
      fs.writeFileSync(path.join(tempDir, 'design.md'), '# Design\n\nTechnical design content.');
      completed = detectCompleted(graph, tempDir);
      expect(completed).toEqual(new Set(['proposal', 'design']));
      expect(graph.getNextArtifacts(completed)).toEqual(['specs']);
      expect(graph.getBlocked(completed)).toEqual({
        tasks: ['specs'],
      });

      // 5. Create specs directory with a spec file - tasks becomes ready
      const specsDir = path.join(tempDir, 'specs');
      fs.mkdirSync(specsDir, { recursive: true });
      fs.writeFileSync(path.join(specsDir, 'feature-auth.md'), '# Auth Spec\n\nAuthentication specification.');
      completed = detectCompleted(graph, tempDir);
      expect(completed).toEqual(new Set(['proposal', 'design', 'specs']));
      expect(graph.getNextArtifacts(completed)).toEqual(['tasks']);
      expect(graph.getBlocked(completed)).toEqual({});

      // 6. Create tasks.md - workflow complete
      fs.writeFileSync(path.join(tempDir, 'tasks.md'), '# Tasks\n\n- [ ] Implement feature');
      completed = detectCompleted(graph, tempDir);
      expect(completed).toEqual(new Set(['proposal', 'design', 'specs', 'tasks']));
      expect(graph.getNextArtifacts(completed)).toEqual([]);
      expect(graph.isComplete(completed)).toBe(true);
      expect(graph.getBlocked(completed)).toEqual({});
    });

    it('should handle out-of-order file creation', () => {
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      // Create files in wrong order - design before proposal
      fs.writeFileSync(path.join(tempDir, 'design.md'), '# Design');

      let completed = detectCompleted(graph, tempDir);
      // design file exists but it's still marked complete (filesystem-based)
      expect(completed).toEqual(new Set(['design']));
      // proposal is still the only "ready" artifact since it has no deps
      expect(graph.getNextArtifacts(completed)).toEqual(['proposal']);

      // Now create proposal
      fs.writeFileSync(path.join(tempDir, 'proposal.md'), '# Proposal');
      completed = detectCompleted(graph, tempDir);
      expect(completed).toEqual(new Set(['proposal', 'design']));
      // specs is the only thing ready now (design already done)
      expect(graph.getNextArtifacts(completed)).toEqual(['specs']);
    });

    it('should handle multiple spec files in glob pattern', () => {
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      // Complete prerequisites
      fs.writeFileSync(path.join(tempDir, 'proposal.md'), '# Proposal');

      // Create specs directory with multiple files
      const specsDir = path.join(tempDir, 'specs');
      fs.mkdirSync(specsDir, { recursive: true });
      fs.writeFileSync(path.join(specsDir, 'auth.md'), '# Auth');
      fs.writeFileSync(path.join(specsDir, 'api.md'), '# API');
      fs.writeFileSync(path.join(specsDir, 'database.md'), '# Database');

      const completed = detectCompleted(graph, tempDir);
      expect(completed.has('specs')).toBe(true);
    });
  });

  describe('tdd workflow', () => {
    it('should progress through complete workflow', () => {
      const schema = resolveSchema('tdd');
      const graph = ArtifactGraph.fromSchema(schema);

      expect(graph.getName()).toBe('tdd');
      expect(graph.getBuildOrder()).toEqual(['spec', 'tests', 'implementation', 'docs']);

      // Initial state
      let completed = detectCompleted(graph, tempDir);
      expect(graph.getNextArtifacts(completed)).toEqual(['spec']);

      // Create spec
      fs.writeFileSync(path.join(tempDir, 'spec.md'), '# Feature Spec');
      completed = detectCompleted(graph, tempDir);
      expect(graph.getNextArtifacts(completed)).toEqual(['tests']);

      // Create tests directory with test file
      const testsDir = path.join(tempDir, 'tests');
      fs.mkdirSync(testsDir, { recursive: true });
      fs.writeFileSync(path.join(testsDir, 'feature.test.ts'), 'describe("feature", () => {});');
      completed = detectCompleted(graph, tempDir);
      expect(graph.getNextArtifacts(completed)).toEqual(['implementation']);

      // Create src directory with implementation
      const srcDir = path.join(tempDir, 'src');
      fs.mkdirSync(srcDir, { recursive: true });
      fs.writeFileSync(path.join(srcDir, 'feature.ts'), 'export function feature() {}');
      completed = detectCompleted(graph, tempDir);
      expect(graph.getNextArtifacts(completed)).toEqual(['docs']);

      // Create docs
      const docsDir = path.join(tempDir, 'docs');
      fs.mkdirSync(docsDir, { recursive: true });
      fs.writeFileSync(path.join(docsDir, 'feature.md'), '# Feature Documentation');
      completed = detectCompleted(graph, tempDir);
      expect(graph.isComplete(completed)).toBe(true);
    });
  });

  describe('build order consistency', () => {
    it('should return consistent build order across multiple calls', () => {
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      const order1 = graph.getBuildOrder();
      const order2 = graph.getBuildOrder();
      const order3 = graph.getBuildOrder();

      expect(order1).toEqual(order2);
      expect(order2).toEqual(order3);
    });
  });

  describe('empty and edge cases', () => {
    it('should handle empty change directory gracefully', () => {
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      // Directory exists but is empty
      const completed = detectCompleted(graph, tempDir);
      expect(completed.size).toBe(0);
      expect(graph.getNextArtifacts(completed)).toEqual(['proposal']);
    });

    it('should handle non-existent change directory', () => {
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      const nonExistentDir = path.join(tempDir, 'does-not-exist');
      const completed = detectCompleted(graph, nonExistentDir);
      expect(completed.size).toBe(0);
    });

    it('should not count non-matching files in glob directories', () => {
      const schema = resolveSchema('spec-driven');
      const graph = ArtifactGraph.fromSchema(schema);

      // Create specs directory with wrong file types
      const specsDir = path.join(tempDir, 'specs');
      fs.mkdirSync(specsDir, { recursive: true });
      fs.writeFileSync(path.join(specsDir, 'notes.txt'), 'not a markdown file');
      fs.writeFileSync(path.join(specsDir, 'data.json'), '{}');

      const completed = detectCompleted(graph, tempDir);
      expect(completed.has('specs')).toBe(false);
    });
  });
});



================================================
FILE: test/core/command-generation/adapters.test.ts
================================================
import { describe, it, expect } from 'vitest';
import path from 'path';
import { amazonQAdapter } from '../../../src/core/command-generation/adapters/amazon-q.js';
import { antigravityAdapter } from '../../../src/core/command-generation/adapters/antigravity.js';
import { auggieAdapter } from '../../../src/core/command-generation/adapters/auggie.js';
import { claudeAdapter } from '../../../src/core/command-generation/adapters/claude.js';
import { clineAdapter } from '../../../src/core/command-generation/adapters/cline.js';
import { codexAdapter } from '../../../src/core/command-generation/adapters/codex.js';
import { codebuddyAdapter } from '../../../src/core/command-generation/adapters/codebuddy.js';
import { continueAdapter } from '../../../src/core/command-generation/adapters/continue.js';
import { costrictAdapter } from '../../../src/core/command-generation/adapters/costrict.js';
import { crushAdapter } from '../../../src/core/command-generation/adapters/crush.js';
import { cursorAdapter } from '../../../src/core/command-generation/adapters/cursor.js';
import { factoryAdapter } from '../../../src/core/command-generation/adapters/factory.js';
import { geminiAdapter } from '../../../src/core/command-generation/adapters/gemini.js';
import { githubCopilotAdapter } from '../../../src/core/command-generation/adapters/github-copilot.js';
import { iflowAdapter } from '../../../src/core/command-generation/adapters/iflow.js';
import { kilocodeAdapter } from '../../../src/core/command-generation/adapters/kilocode.js';
import { opencodeAdapter } from '../../../src/core/command-generation/adapters/opencode.js';
import { qoderAdapter } from '../../../src/core/command-generation/adapters/qoder.js';
import { qwenAdapter } from '../../../src/core/command-generation/adapters/qwen.js';
import { roocodeAdapter } from '../../../src/core/command-generation/adapters/roocode.js';
import { windsurfAdapter } from '../../../src/core/command-generation/adapters/windsurf.js';
import type { CommandContent } from '../../../src/core/command-generation/types.js';

describe('command-generation/adapters', () => {
  const sampleContent: CommandContent = {
    id: 'explore',
    name: 'OpenSpec Explore',
    description: 'Enter explore mode for thinking',
    category: 'Workflow',
    tags: ['workflow', 'explore', 'experimental'],
    body: 'This is the command body.\n\nWith multiple lines.',
  };

  describe('claudeAdapter', () => {
    it('should have correct toolId', () => {
      expect(claudeAdapter.toolId).toBe('claude');
    });

    it('should generate correct file path', () => {
      const filePath = claudeAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.claude', 'commands', 'opsx', 'explore.md'));
    });

    it('should generate correct file path for different command IDs', () => {
      expect(claudeAdapter.getFilePath('new')).toBe(path.join('.claude', 'commands', 'opsx', 'new.md'));
      expect(claudeAdapter.getFilePath('bulk-archive')).toBe(path.join('.claude', 'commands', 'opsx', 'bulk-archive.md'));
    });

    it('should format file with correct YAML frontmatter', () => {
      const output = claudeAdapter.formatFile(sampleContent);

      expect(output).toContain('---\n');
      expect(output).toContain('name: OpenSpec Explore');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('category: Workflow');
      expect(output).toContain('tags: [workflow, explore, experimental]');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.\n\nWith multiple lines.');
    });

    it('should handle empty tags', () => {
      const contentNoTags: CommandContent = { ...sampleContent, tags: [] };
      const output = claudeAdapter.formatFile(contentNoTags);
      expect(output).toContain('tags: []');
    });
  });

  describe('cursorAdapter', () => {
    it('should have correct toolId', () => {
      expect(cursorAdapter.toolId).toBe('cursor');
    });

    it('should generate correct file path with opsx- prefix', () => {
      const filePath = cursorAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.cursor', 'commands', 'opsx-explore.md'));
    });

    it('should generate correct file paths for different commands', () => {
      expect(cursorAdapter.getFilePath('new')).toBe(path.join('.cursor', 'commands', 'opsx-new.md'));
      expect(cursorAdapter.getFilePath('bulk-archive')).toBe(path.join('.cursor', 'commands', 'opsx-bulk-archive.md'));
    });

    it('should format file with Cursor-specific frontmatter', () => {
      const output = cursorAdapter.formatFile(sampleContent);

      expect(output).toContain('---\n');
      expect(output).toContain('name: /opsx-explore');
      expect(output).toContain('id: opsx-explore');
      expect(output).toContain('category: Workflow');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });

    it('should not include tags in Cursor format', () => {
      const output = cursorAdapter.formatFile(sampleContent);
      expect(output).not.toContain('tags:');
    });
  });

  describe('windsurfAdapter', () => {
    it('should have correct toolId', () => {
      expect(windsurfAdapter.toolId).toBe('windsurf');
    });

    it('should generate correct file path', () => {
      const filePath = windsurfAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.windsurf', 'commands', 'opsx', 'explore.md'));
    });

    it('should format file similar to Claude format', () => {
      const output = windsurfAdapter.formatFile(sampleContent);

      expect(output).toContain('---\n');
      expect(output).toContain('name: OpenSpec Explore');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('category: Workflow');
      expect(output).toContain('tags: [workflow, explore, experimental]');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('amazonQAdapter', () => {
    it('should have correct toolId', () => {
      expect(amazonQAdapter.toolId).toBe('amazon-q');
    });

    it('should generate correct file path', () => {
      const filePath = amazonQAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.amazonq', 'prompts', 'opsx-explore.md'));
    });

    it('should format file with description frontmatter', () => {
      const output = amazonQAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('antigravityAdapter', () => {
    it('should have correct toolId', () => {
      expect(antigravityAdapter.toolId).toBe('antigravity');
    });

    it('should generate correct file path', () => {
      const filePath = antigravityAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.agent', 'workflows', 'opsx-explore.md'));
    });

    it('should format file with description frontmatter', () => {
      const output = antigravityAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('auggieAdapter', () => {
    it('should have correct toolId', () => {
      expect(auggieAdapter.toolId).toBe('auggie');
    });

    it('should generate correct file path', () => {
      const filePath = auggieAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.augment', 'commands', 'opsx-explore.md'));
    });

    it('should format file with description and argument-hint', () => {
      const output = auggieAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('argument-hint: command arguments');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('clineAdapter', () => {
    it('should have correct toolId', () => {
      expect(clineAdapter.toolId).toBe('cline');
    });

    it('should generate correct file path', () => {
      const filePath = clineAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.clinerules', 'workflows', 'opsx-explore.md'));
    });

    it('should format file with markdown header (no YAML frontmatter)', () => {
      const output = clineAdapter.formatFile(sampleContent);
      expect(output).toContain('# OpenSpec Explore');
      expect(output).toContain('Enter explore mode for thinking');
      expect(output).toContain('This is the command body.');
      expect(output).not.toContain('---');
    });
  });

  describe('codexAdapter', () => {
    it('should have correct toolId', () => {
      expect(codexAdapter.toolId).toBe('codex');
    });

    it('should generate correct file path', () => {
      const filePath = codexAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.codex', 'prompts', 'opsx-explore.md'));
    });

    it('should format file with description and argument-hint', () => {
      const output = codexAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('argument-hint: command arguments');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('codebuddyAdapter', () => {
    it('should have correct toolId', () => {
      expect(codebuddyAdapter.toolId).toBe('codebuddy');
    });

    it('should generate correct file path with nested opsx folder', () => {
      const filePath = codebuddyAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.codebuddy', 'commands', 'opsx', 'explore.md'));
    });

    it('should format file with name, description, and argument-hint', () => {
      const output = codebuddyAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('name: OpenSpec Explore');
      expect(output).toContain('description: "Enter explore mode for thinking"');
      expect(output).toContain('argument-hint: "[command arguments]"');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('continueAdapter', () => {
    it('should have correct toolId', () => {
      expect(continueAdapter.toolId).toBe('continue');
    });

    it('should generate correct file path with .prompt extension', () => {
      const filePath = continueAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.continue', 'prompts', 'opsx-explore.prompt'));
    });

    it('should format file with name, description, and invokable', () => {
      const output = continueAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('name: opsx-explore');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('invokable: true');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('costrictAdapter', () => {
    it('should have correct toolId', () => {
      expect(costrictAdapter.toolId).toBe('costrict');
    });

    it('should generate correct file path', () => {
      const filePath = costrictAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.cospec', 'openspec', 'commands', 'opsx-explore.md'));
    });

    it('should format file with description and argument-hint', () => {
      const output = costrictAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: "Enter explore mode for thinking"');
      expect(output).toContain('argument-hint: command arguments');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('crushAdapter', () => {
    it('should have correct toolId', () => {
      expect(crushAdapter.toolId).toBe('crush');
    });

    it('should generate correct file path with nested opsx folder', () => {
      const filePath = crushAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.crush', 'commands', 'opsx', 'explore.md'));
    });

    it('should format file with name, description, category, and tags', () => {
      const output = crushAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('name: OpenSpec Explore');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('category: Workflow');
      expect(output).toContain('tags: [workflow, explore, experimental]');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('factoryAdapter', () => {
    it('should have correct toolId', () => {
      expect(factoryAdapter.toolId).toBe('factory');
    });

    it('should generate correct file path', () => {
      const filePath = factoryAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.factory', 'commands', 'opsx-explore.md'));
    });

    it('should format file with description and argument-hint', () => {
      const output = factoryAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('argument-hint: command arguments');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('geminiAdapter', () => {
    it('should have correct toolId', () => {
      expect(geminiAdapter.toolId).toBe('gemini');
    });

    it('should generate correct file path with .toml extension', () => {
      const filePath = geminiAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.gemini', 'commands', 'opsx', 'explore.toml'));
    });

    it('should format file in TOML format', () => {
      const output = geminiAdapter.formatFile(sampleContent);
      expect(output).toContain('description = "Enter explore mode for thinking"');
      expect(output).toContain('prompt = """');
      expect(output).toContain('This is the command body.');
      expect(output).toContain('"""');
    });
  });

  describe('githubCopilotAdapter', () => {
    it('should have correct toolId', () => {
      expect(githubCopilotAdapter.toolId).toBe('github-copilot');
    });

    it('should generate correct file path with .prompt.md extension', () => {
      const filePath = githubCopilotAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.github', 'prompts', 'opsx-explore.prompt.md'));
    });

    it('should format file with description frontmatter', () => {
      const output = githubCopilotAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('iflowAdapter', () => {
    it('should have correct toolId', () => {
      expect(iflowAdapter.toolId).toBe('iflow');
    });

    it('should generate correct file path', () => {
      const filePath = iflowAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.iflow', 'commands', 'opsx-explore.md'));
    });

    it('should format file with name, id, category, and description', () => {
      const output = iflowAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('name: /opsx-explore');
      expect(output).toContain('id: opsx-explore');
      expect(output).toContain('category: Workflow');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('kilocodeAdapter', () => {
    it('should have correct toolId', () => {
      expect(kilocodeAdapter.toolId).toBe('kilocode');
    });

    it('should generate correct file path', () => {
      const filePath = kilocodeAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.kilocode', 'workflows', 'opsx-explore.md'));
    });

    it('should format file without frontmatter', () => {
      const output = kilocodeAdapter.formatFile(sampleContent);
      expect(output).not.toContain('---');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('opencodeAdapter', () => {
    it('should have correct toolId', () => {
      expect(opencodeAdapter.toolId).toBe('opencode');
    });

    it('should generate correct file path', () => {
      const filePath = opencodeAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.opencode', 'command', 'opsx-explore.md'));
    });

    it('should format file with description frontmatter', () => {
      const output = opencodeAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('qoderAdapter', () => {
    it('should have correct toolId', () => {
      expect(qoderAdapter.toolId).toBe('qoder');
    });

    it('should generate correct file path with nested opsx folder', () => {
      const filePath = qoderAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.qoder', 'commands', 'opsx', 'explore.md'));
    });

    it('should format file with name, description, category, and tags', () => {
      const output = qoderAdapter.formatFile(sampleContent);
      expect(output).toContain('---\n');
      expect(output).toContain('name: OpenSpec Explore');
      expect(output).toContain('description: Enter explore mode for thinking');
      expect(output).toContain('category: Workflow');
      expect(output).toContain('tags: [workflow, explore, experimental]');
      expect(output).toContain('---\n\n');
      expect(output).toContain('This is the command body.');
    });
  });

  describe('qwenAdapter', () => {
    it('should have correct toolId', () => {
      expect(qwenAdapter.toolId).toBe('qwen');
    });

    it('should generate correct file path with .toml extension', () => {
      const filePath = qwenAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.qwen', 'commands', 'opsx-explore.toml'));
    });

    it('should format file in TOML format', () => {
      const output = qwenAdapter.formatFile(sampleContent);
      expect(output).toContain('description = "Enter explore mode for thinking"');
      expect(output).toContain('prompt = """');
      expect(output).toContain('This is the command body.');
      expect(output).toContain('"""');
    });
  });

  describe('roocodeAdapter', () => {
    it('should have correct toolId', () => {
      expect(roocodeAdapter.toolId).toBe('roocode');
    });

    it('should generate correct file path', () => {
      const filePath = roocodeAdapter.getFilePath('explore');
      expect(filePath).toBe(path.join('.roo', 'commands', 'opsx-explore.md'));
    });

    it('should format file with markdown header (no YAML frontmatter)', () => {
      const output = roocodeAdapter.formatFile(sampleContent);
      expect(output).toContain('# OpenSpec Explore');
      expect(output).toContain('Enter explore mode for thinking');
      expect(output).toContain('This is the command body.');
      expect(output).not.toContain('---');
    });
  });

  describe('cross-platform path handling', () => {
    it('Claude adapter uses path.join for paths', () => {
      // path.join handles platform-specific separators
      const filePath = claudeAdapter.getFilePath('test');
      // On any platform, path.join returns the correct separator
      expect(filePath.split(path.sep)).toEqual(['.claude', 'commands', 'opsx', 'test.md']);
    });

    it('Cursor adapter uses path.join for paths', () => {
      const filePath = cursorAdapter.getFilePath('test');
      expect(filePath.split(path.sep)).toEqual(['.cursor', 'commands', 'opsx-test.md']);
    });

    it('Windsurf adapter uses path.join for paths', () => {
      const filePath = windsurfAdapter.getFilePath('test');
      expect(filePath.split(path.sep)).toEqual(['.windsurf', 'commands', 'opsx', 'test.md']);
    });

    it('All adapters use path.join for paths', () => {
      // Verify all adapters produce valid paths
      const adapters = [
        amazonQAdapter, antigravityAdapter, auggieAdapter, clineAdapter,
        codexAdapter, codebuddyAdapter, continueAdapter, costrictAdapter,
        crushAdapter, factoryAdapter, geminiAdapter, githubCopilotAdapter,
        iflowAdapter, kilocodeAdapter, opencodeAdapter, qoderAdapter,
        qwenAdapter, roocodeAdapter
      ];
      for (const adapter of adapters) {
        const filePath = adapter.getFilePath('test');
        expect(filePath.length).toBeGreaterThan(0);
        expect(filePath.includes(path.sep) || filePath.includes('.')).toBe(true);
      }
    });
  });
});



================================================
FILE: test/core/command-generation/generator.test.ts
================================================
import { describe, it, expect } from 'vitest';
import { generateCommand, generateCommands } from '../../../src/core/command-generation/generator.js';
import { claudeAdapter } from '../../../src/core/command-generation/adapters/claude.js';
import { cursorAdapter } from '../../../src/core/command-generation/adapters/cursor.js';
import type { CommandContent, ToolCommandAdapter } from '../../../src/core/command-generation/types.js';

describe('command-generation/generator', () => {
  const sampleContent: CommandContent = {
    id: 'explore',
    name: 'OpenSpec Explore',
    description: 'Enter explore mode',
    category: 'Workflow',
    tags: ['workflow'],
    body: 'Command body here.',
  };

  describe('generateCommand', () => {
    it('should generate command with path and content using Claude adapter', () => {
      const result = generateCommand(sampleContent, claudeAdapter);

      expect(result.path).toContain('.claude');
      expect(result.path).toContain('explore.md');
      expect(result.fileContent).toContain('name: OpenSpec Explore');
      expect(result.fileContent).toContain('Command body here.');
    });

    it('should generate command with path and content using Cursor adapter', () => {
      const result = generateCommand(sampleContent, cursorAdapter);

      expect(result.path).toContain('.cursor');
      expect(result.path).toContain('opsx-explore.md');
      expect(result.fileContent).toContain('name: /opsx-explore');
      expect(result.fileContent).toContain('id: opsx-explore');
      expect(result.fileContent).toContain('Command body here.');
    });

    it('should use command id for path', () => {
      const content: CommandContent = { ...sampleContent, id: 'custom-cmd' };
      const result = generateCommand(content, claudeAdapter);

      expect(result.path).toContain('custom-cmd.md');
    });

    it('should work with custom adapter', () => {
      const customAdapter: ToolCommandAdapter = {
        toolId: 'custom',
        getFilePath: (id) => `.custom/${id}.txt`,
        formatFile: (content) => `# ${content.name}\n\n${content.body}`,
      };

      const result = generateCommand(sampleContent, customAdapter);

      expect(result.path).toBe('.custom/explore.txt');
      expect(result.fileContent).toBe('# OpenSpec Explore\n\nCommand body here.');
    });
  });

  describe('generateCommands', () => {
    it('should generate multiple commands', () => {
      const contents: CommandContent[] = [
        { ...sampleContent, id: 'explore', name: 'Explore' },
        { ...sampleContent, id: 'new', name: 'New' },
        { ...sampleContent, id: 'apply', name: 'Apply' },
      ];

      const results = generateCommands(contents, claudeAdapter);

      expect(results).toHaveLength(3);
      expect(results[0].path).toContain('explore.md');
      expect(results[1].path).toContain('new.md');
      expect(results[2].path).toContain('apply.md');
    });

    it('should return empty array for empty input', () => {
      const results = generateCommands([], claudeAdapter);
      expect(results).toEqual([]);
    });

    it('should preserve order of input', () => {
      const contents: CommandContent[] = [
        { ...sampleContent, id: 'c', name: 'C' },
        { ...sampleContent, id: 'a', name: 'A' },
        { ...sampleContent, id: 'b', name: 'B' },
      ];

      const results = generateCommands(contents, claudeAdapter);

      expect(results[0].path).toContain('c.md');
      expect(results[1].path).toContain('a.md');
      expect(results[2].path).toContain('b.md');
    });

    it('should generate each command independently', () => {
      const contents: CommandContent[] = [
        { id: 'a', name: 'A', description: 'DA', category: 'C1', tags: ['t1'], body: 'B1' },
        { id: 'b', name: 'B', description: 'DB', category: 'C2', tags: ['t2'], body: 'B2' },
      ];

      const results = generateCommands(contents, claudeAdapter);

      expect(results[0].fileContent).toContain('name: A');
      expect(results[0].fileContent).toContain('B1');
      expect(results[0].fileContent).not.toContain('name: B');

      expect(results[1].fileContent).toContain('name: B');
      expect(results[1].fileContent).toContain('B2');
      expect(results[1].fileContent).not.toContain('name: A');
    });
  });
});



================================================
FILE: test/core/command-generation/registry.test.ts
================================================
import { describe, it, expect } from 'vitest';
import { CommandAdapterRegistry } from '../../../src/core/command-generation/registry.js';

describe('command-generation/registry', () => {
  describe('get', () => {
    it('should return Claude adapter for "claude"', () => {
      const adapter = CommandAdapterRegistry.get('claude');
      expect(adapter).toBeDefined();
      expect(adapter?.toolId).toBe('claude');
    });

    it('should return Cursor adapter for "cursor"', () => {
      const adapter = CommandAdapterRegistry.get('cursor');
      expect(adapter).toBeDefined();
      expect(adapter?.toolId).toBe('cursor');
    });

    it('should return Windsurf adapter for "windsurf"', () => {
      const adapter = CommandAdapterRegistry.get('windsurf');
      expect(adapter).toBeDefined();
      expect(adapter?.toolId).toBe('windsurf');
    });

    it('should return undefined for unregistered tool', () => {
      const adapter = CommandAdapterRegistry.get('unknown-tool');
      expect(adapter).toBeUndefined();
    });

    it('should return undefined for empty string', () => {
      const adapter = CommandAdapterRegistry.get('');
      expect(adapter).toBeUndefined();
    });
  });

  describe('getAll', () => {
    it('should return array of all registered adapters', () => {
      const adapters = CommandAdapterRegistry.getAll();
      expect(Array.isArray(adapters)).toBe(true);
      expect(adapters.length).toBeGreaterThanOrEqual(3); // At least Claude, Cursor, Windsurf
    });

    it('should include Claude, Cursor, and Windsurf adapters', () => {
      const adapters = CommandAdapterRegistry.getAll();
      const toolIds = adapters.map((a) => a.toolId);

      expect(toolIds).toContain('claude');
      expect(toolIds).toContain('cursor');
      expect(toolIds).toContain('windsurf');
    });
  });

  describe('has', () => {
    it('should return true for registered tools', () => {
      expect(CommandAdapterRegistry.has('claude')).toBe(true);
      expect(CommandAdapterRegistry.has('cursor')).toBe(true);
      expect(CommandAdapterRegistry.has('windsurf')).toBe(true);
    });

    it('should return false for unregistered tools', () => {
      expect(CommandAdapterRegistry.has('unknown')).toBe(false);
      expect(CommandAdapterRegistry.has('')).toBe(false);
    });
  });

  describe('adapter functionality', () => {
    it('registered adapters should have working getFilePath', () => {
      const claudeAdapter = CommandAdapterRegistry.get('claude');
      const cursorAdapter = CommandAdapterRegistry.get('cursor');
      const windsurfAdapter = CommandAdapterRegistry.get('windsurf');

      expect(claudeAdapter?.getFilePath('test')).toContain('.claude');
      expect(cursorAdapter?.getFilePath('test')).toContain('.cursor');
      expect(windsurfAdapter?.getFilePath('test')).toContain('.windsurf');
    });

    it('registered adapters should have working formatFile', () => {
      const content = {
        id: 'test',
        name: 'Test',
        description: 'Test desc',
        category: 'Test',
        tags: ['tag1'],
        body: 'Body content',
      };

      // Tools that don't use YAML frontmatter (markdown headers or TOML or plain)
      const noYamlFrontmatter = ['cline', 'kilocode', 'roocode', 'gemini', 'qwen'];

      const adapters = CommandAdapterRegistry.getAll();
      for (const adapter of adapters) {
        const output = adapter.formatFile(content);
        // All adapters should include the body content
        expect(output).toContain('Body content');
        // Only check for YAML frontmatter for tools that use it
        if (!noYamlFrontmatter.includes(adapter.toolId)) {
          expect(output).toContain('---');
        }
      }
    });
  });
});



================================================
FILE: test/core/command-generation/types.test.ts
================================================
import { describe, it, expect } from 'vitest';
import type { CommandContent, ToolCommandAdapter, GeneratedCommand } from '../../../src/core/command-generation/types.js';

describe('command-generation/types', () => {
  describe('CommandContent interface', () => {
    it('should allow creating valid command content', () => {
      const content: CommandContent = {
        id: 'explore',
        name: 'OpenSpec Explore',
        description: 'Enter explore mode for thinking',
        category: 'Workflow',
        tags: ['workflow', 'explore'],
        body: 'This is the command body content.',
      };

      expect(content.id).toBe('explore');
      expect(content.name).toBe('OpenSpec Explore');
      expect(content.description).toBe('Enter explore mode for thinking');
      expect(content.category).toBe('Workflow');
      expect(content.tags).toEqual(['workflow', 'explore']);
      expect(content.body).toBe('This is the command body content.');
    });

    it('should allow empty tags array', () => {
      const content: CommandContent = {
        id: 'test',
        name: 'Test',
        description: 'Test command',
        category: 'Test',
        tags: [],
        body: 'Body',
      };

      expect(content.tags).toEqual([]);
    });
  });

  describe('ToolCommandAdapter interface contract', () => {
    it('should implement adapter with getFilePath and formatFile', () => {
      const mockAdapter: ToolCommandAdapter = {
        toolId: 'test-tool',
        getFilePath(commandId: string): string {
          return `.test/${commandId}.md`;
        },
        formatFile(content: CommandContent): string {
          return `---\nname: ${content.name}\n---\n\n${content.body}\n`;
        },
      };

      expect(mockAdapter.toolId).toBe('test-tool');
      expect(mockAdapter.getFilePath('explore')).toBe('.test/explore.md');

      const content: CommandContent = {
        id: 'test',
        name: 'Test Command',
        description: 'Desc',
        category: 'Cat',
        tags: [],
        body: 'Body content',
      };

      const formatted = mockAdapter.formatFile(content);
      expect(formatted).toContain('name: Test Command');
      expect(formatted).toContain('Body content');
    });
  });

  describe('GeneratedCommand interface', () => {
    it('should represent generated command output', () => {
      const generated: GeneratedCommand = {
        path: '.claude/commands/opsx/explore.md',
        fileContent: '---\nname: Test\n---\n\nBody\n',
      };

      expect(generated.path).toBe('.claude/commands/opsx/explore.md');
      expect(generated.fileContent).toContain('name: Test');
    });
  });
});



================================================
FILE: test/core/commands/change-command.list.test.ts
================================================
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { ChangeCommand } from '../../../src/commands/change.js';
import path from 'path';
import { promises as fs } from 'fs';
import os from 'os';

describe('ChangeCommand.list', () => {
  let cmd: ChangeCommand;
  let tempRoot: string;
  let originalCwd: string;

  beforeAll(async () => {
    cmd = new ChangeCommand();
    originalCwd = process.cwd();
    tempRoot = path.join(os.tmpdir(), `openspec-change-command-list-${Date.now()}`);
    const changeDir = path.join(tempRoot, 'openspec', 'changes', 'demo');
    await fs.mkdir(changeDir, { recursive: true });
    const proposal = `# Change: Demo\n\n## Why\nTest list.\n\n## What Changes\n- **auth:** Add requirement`;
    await fs.writeFile(path.join(changeDir, 'proposal.md'), proposal, 'utf-8');
    await fs.writeFile(path.join(changeDir, 'tasks.md'), '- [x] Task 1\n- [ ] Task 2\n', 'utf-8');
    process.chdir(tempRoot);
  });

  afterAll(async () => {
    process.chdir(originalCwd);
    await fs.rm(tempRoot, { recursive: true, force: true });
  });

  it('returns JSON with expected shape', async () => {
    // Capture console output
    const logs: string[] = [];
    const origLog = console.log;
    try {
      console.log = (msg?: any, ...args: any[]) => {
        logs.push([msg, ...args].filter(Boolean).join(' '));
      };

      await cmd.list({ json: true });

      const output = logs.join('\n');
      const parsed = JSON.parse(output);
      expect(Array.isArray(parsed)).toBe(true);
      if (parsed.length > 0) {
        const item = parsed[0];
        expect(item).toHaveProperty('id');
        expect(item).toHaveProperty('title');
        expect(item).toHaveProperty('deltaCount');
        expect(item).toHaveProperty('taskStatus');
        expect(item.taskStatus).toHaveProperty('total');
        expect(item.taskStatus).toHaveProperty('completed');
      }
    } finally {
      console.log = origLog;
    }
  });

  it('prints IDs by default and details with --long', async () => {
    const logs: string[] = [];
    const origLog = console.log;
    try {
      console.log = (msg?: any, ...args: any[]) => {
        logs.push([msg, ...args].filter(Boolean).join(' '));
      };
      await cmd.list({});
      const idsOnly = logs.join('\n');
      expect(idsOnly).toMatch(/\w+/);
      logs.length = 0;
      await cmd.list({ long: true });
      const longOut = logs.join('\n');
      expect(longOut).toMatch(/:\s/);
      expect(longOut).toMatch(/\[deltas\s\d+\]/);
    } finally {
      console.log = origLog;
    }
  });
});



================================================
FILE: test/core/commands/change-command.show-validate.test.ts
================================================
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { ChangeCommand } from '../../../src/commands/change.js';
import path from 'path';
import { promises as fs } from 'fs';
import os from 'os';

describe('ChangeCommand.show/validate', () => {
  let cmd: ChangeCommand;
  let changeName: string;
  let tempRoot: string;
  let originalCwd: string;

  beforeAll(async () => {
    cmd = new ChangeCommand();
    originalCwd = process.cwd();
    tempRoot = path.join(os.tmpdir(), `openspec-change-command-${Date.now()}`);
    const changesDir = path.join(tempRoot, 'openspec', 'changes', 'sample-change');
    await fs.mkdir(changesDir, { recursive: true });
    const proposal = `# Change: Sample Change\n\n## Why\nConsistency in tests.\n\n## What Changes\n- **auth:** Add requirement`;
    await fs.writeFile(path.join(changesDir, 'proposal.md'), proposal, 'utf-8');
    process.chdir(tempRoot);
    changeName = 'sample-change';
  });

  afterAll(async () => {
    process.chdir(originalCwd);
    await fs.rm(tempRoot, { recursive: true, force: true });
  });

  it('show --json prints JSON including deltas', async () => {
    const logs: string[] = [];
    const origLog = console.log;
    try {
      console.log = (msg?: any, ...args: any[]) => {
        logs.push([msg, ...args].filter(Boolean).join(' '));
      };

      await cmd.show(changeName, { json: true });

      const output = logs.join('\n');
      const parsed = JSON.parse(output);
      expect(parsed).toHaveProperty('deltas');
      expect(Array.isArray(parsed.deltas)).toBe(true);
    } finally {
      console.log = origLog;
    }
  });

  it('error when no change specified: prints available IDs', async () => {
    const logsErr: string[] = [];
    const origErr = console.error;
    try {
      console.error = (msg?: any, ...args: any[]) => {
        logsErr.push([msg, ...args].filter(Boolean).join(' '));
      };
      await cmd.show(undefined as unknown as string, { json: false } as any);
      // Should have set exit code and printed hint
      expect(process.exitCode).toBe(1);
      const errOut = logsErr.join('\n');
      expect(errOut).toMatch(/No change specified/);
      expect(errOut).toMatch(/Available IDs/);
    } finally {
      console.error = origErr;
      process.exitCode = 0;
    }
  });

  it('show --json --requirements-only returns minimal object with deltas (deprecated alias)', async () => {
    const logs: string[] = [];
    const origLog = console.log;
    try {
      console.log = (msg?: any, ...args: any[]) => {
        logs.push([msg, ...args].filter(Boolean).join(' '));
      };

      await cmd.show(changeName, { json: true, requirementsOnly: true });

      const output = logs.join('\n');
      const parsed = JSON.parse(output);
      expect(parsed).toHaveProperty('deltas');
      expect(Array.isArray(parsed.deltas)).toBe(true);
      if (parsed.deltas.length > 0) {
        expect(parsed.deltas[0]).toHaveProperty('spec');
        expect(parsed.deltas[0]).toHaveProperty('operation');
        expect(parsed.deltas[0]).toHaveProperty('description');
      }
    } finally {
      console.log = origLog;
    }
  });

  it('validate --strict --json returns a report with valid boolean', async () => {
    const logs: string[] = [];
    const origLog = console.log;
    try {
      console.log = (msg?: any, ...args: any[]) => {
        logs.push([msg, ...args].filter(Boolean).join(' '));
      };

      await cmd.validate(changeName, { strict: true, json: true });

      const output = logs.join('\n');
      const parsed = JSON.parse(output);
      expect(parsed).toHaveProperty('valid');
      expect(parsed).toHaveProperty('issues');
      expect(Array.isArray(parsed.issues)).toBe(true);
    } finally {
      console.log = origLog;
    }
  });
});



================================================
FILE: test/core/completions/completion-provider.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';
import { CompletionProvider } from '../../../src/core/completions/completion-provider.js';

describe('CompletionProvider', () => {
  let testDir: string;
  let provider: CompletionProvider;

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-test-${randomUUID()}`);
    await fs.mkdir(testDir, { recursive: true });
    provider = new CompletionProvider(2000, testDir);
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('getChangeIds', () => {
    it('should return empty array when no changes exist', async () => {
      const changeIds = await provider.getChangeIds();
      expect(changeIds).toEqual([]);
    });

    it('should return active change IDs', async () => {
      // Create openspec/changes directory structure
      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      // Create some changes
      await fs.mkdir(path.join(changesDir, 'change-1'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-1', 'proposal.md'), '# Change 1');

      await fs.mkdir(path.join(changesDir, 'change-2'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-2', 'proposal.md'), '# Change 2');

      const changeIds = await provider.getChangeIds();
      expect(changeIds).toEqual(['change-1', 'change-2']);
    });

    it('should exclude archive directory', async () => {
      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      // Create active change
      await fs.mkdir(path.join(changesDir, 'active-change'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'active-change', 'proposal.md'), '# Active');

      // Create archived change
      await fs.mkdir(path.join(changesDir, 'archive', 'old-change'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'archive', 'old-change', 'proposal.md'), '# Old');

      const changeIds = await provider.getChangeIds();
      expect(changeIds).toEqual(['active-change']);
    });

    it('should cache results for the TTL duration', async () => {
      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      await fs.mkdir(path.join(changesDir, 'change-1'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-1', 'proposal.md'), '# Change 1');

      // First call
      const firstResult = await provider.getChangeIds();
      expect(firstResult).toEqual(['change-1']);

      // Add another change
      await fs.mkdir(path.join(changesDir, 'change-2'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-2', 'proposal.md'), '# Change 2');

      // Second call should return cached result (still only change-1)
      const secondResult = await provider.getChangeIds();
      expect(secondResult).toEqual(['change-1']);
    });

    it('should refresh cache after TTL expires', async () => {
      // Use a very short TTL for testing
      const shortTTLProvider = new CompletionProvider(50, testDir);

      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      await fs.mkdir(path.join(changesDir, 'change-1'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-1', 'proposal.md'), '# Change 1');

      // First call
      const firstResult = await shortTTLProvider.getChangeIds();
      expect(firstResult).toEqual(['change-1']);

      // Add another change
      await fs.mkdir(path.join(changesDir, 'change-2'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-2', 'proposal.md'), '# Change 2');

      // Wait for cache to expire
      await new Promise(resolve => setTimeout(resolve, 60));

      // Should now see both changes
      const secondResult = await shortTTLProvider.getChangeIds();
      expect(secondResult).toEqual(['change-1', 'change-2']);
    });
  });

  describe('getSpecIds', () => {
    it('should return empty array when no specs exist', async () => {
      const specIds = await provider.getSpecIds();
      expect(specIds).toEqual([]);
    });

    it('should return spec IDs', async () => {
      const specsDir = path.join(testDir, 'openspec', 'specs');
      await fs.mkdir(specsDir, { recursive: true });

      // Create some specs
      await fs.mkdir(path.join(specsDir, 'spec-1'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'spec-1', 'spec.md'), '# Spec 1');

      await fs.mkdir(path.join(specsDir, 'spec-2'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'spec-2', 'spec.md'), '# Spec 2');

      const specIds = await provider.getSpecIds();
      expect(specIds).toEqual(['spec-1', 'spec-2']);
    });

    it('should cache results for the TTL duration', async () => {
      const specsDir = path.join(testDir, 'openspec', 'specs');
      await fs.mkdir(specsDir, { recursive: true });

      await fs.mkdir(path.join(specsDir, 'spec-1'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'spec-1', 'spec.md'), '# Spec 1');

      // First call
      const firstResult = await provider.getSpecIds();
      expect(firstResult).toEqual(['spec-1']);

      // Add another spec
      await fs.mkdir(path.join(specsDir, 'spec-2'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'spec-2', 'spec.md'), '# Spec 2');

      // Second call should return cached result
      const secondResult = await provider.getSpecIds();
      expect(secondResult).toEqual(['spec-1']);
    });

    it('should refresh cache after TTL expires', async () => {
      const shortTTLProvider = new CompletionProvider(50, testDir);

      const specsDir = path.join(testDir, 'openspec', 'specs');
      await fs.mkdir(specsDir, { recursive: true });

      await fs.mkdir(path.join(specsDir, 'spec-1'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'spec-1', 'spec.md'), '# Spec 1');

      const firstResult = await shortTTLProvider.getSpecIds();
      expect(firstResult).toEqual(['spec-1']);

      // Add another spec
      await fs.mkdir(path.join(specsDir, 'spec-2'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'spec-2', 'spec.md'), '# Spec 2');

      // Wait for cache to expire
      await new Promise(resolve => setTimeout(resolve, 60));

      const secondResult = await shortTTLProvider.getSpecIds();
      expect(secondResult).toEqual(['spec-1', 'spec-2']);
    });
  });

  describe('getAllIds', () => {
    it('should return both change and spec IDs', async () => {
      const changesDir = path.join(testDir, 'openspec', 'changes');
      const specsDir = path.join(testDir, 'openspec', 'specs');
      await fs.mkdir(changesDir, { recursive: true });
      await fs.mkdir(specsDir, { recursive: true });

      // Create a change
      await fs.mkdir(path.join(changesDir, 'my-change'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'my-change', 'proposal.md'), '# Change');

      // Create a spec
      await fs.mkdir(path.join(specsDir, 'my-spec'), { recursive: true });
      await fs.writeFile(path.join(specsDir, 'my-spec', 'spec.md'), '# Spec');

      const result = await provider.getAllIds();
      expect(result).toEqual({
        changeIds: ['my-change'],
        specIds: ['my-spec'],
      });
    });

    it('should return empty arrays when no items exist', async () => {
      const result = await provider.getAllIds();
      expect(result).toEqual({
        changeIds: [],
        specIds: [],
      });
    });
  });

  describe('clearCache', () => {
    it('should clear all cached data', async () => {
      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      await fs.mkdir(path.join(changesDir, 'change-1'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-1', 'proposal.md'), '# Change 1');

      // Populate cache
      await provider.getChangeIds();

      // Clear cache
      provider.clearCache();

      // Add new change
      await fs.mkdir(path.join(changesDir, 'change-2'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-2', 'proposal.md'), '# Change 2');

      // Should see new data immediately
      const result = await provider.getChangeIds();
      expect(result).toEqual(['change-1', 'change-2']);
    });
  });

  describe('getCacheStats', () => {
    it('should report invalid cache when empty', () => {
      const stats = provider.getCacheStats();
      expect(stats.changeCache.valid).toBe(false);
      expect(stats.specCache.valid).toBe(false);
      expect(stats.changeCache.age).toBeUndefined();
      expect(stats.specCache.age).toBeUndefined();
    });

    it('should report valid cache after data is fetched', async () => {
      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      await fs.mkdir(path.join(changesDir, 'change-1'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-1', 'proposal.md'), '# Change 1');

      await provider.getChangeIds();

      const stats = provider.getCacheStats();
      expect(stats.changeCache.valid).toBe(true);
      expect(stats.changeCache.age).toBeDefined();
      expect(stats.changeCache.age).toBeLessThan(100);
    });

    it('should report invalid cache after TTL expires', async () => {
      const shortTTLProvider = new CompletionProvider(50, testDir);

      const changesDir = path.join(testDir, 'openspec', 'changes');
      await fs.mkdir(changesDir, { recursive: true });

      await fs.mkdir(path.join(changesDir, 'change-1'), { recursive: true });
      await fs.writeFile(path.join(changesDir, 'change-1', 'proposal.md'), '# Change 1');

      await shortTTLProvider.getChangeIds();

      // Wait for cache to expire
      await new Promise(resolve => setTimeout(resolve, 60));

      const stats = shortTTLProvider.getCacheStats();
      expect(stats.changeCache.valid).toBe(false);
      expect(stats.changeCache.age).toBeGreaterThan(50);
    });
  });

  describe('constructor', () => {
    it('should use default TTL of 2000ms', async () => {
      const defaultProvider = new CompletionProvider();
      expect(defaultProvider).toBeDefined();
      // We can verify this behavior by checking cache stats after waiting
    });

    it('should accept custom TTL', async () => {
      const customProvider = new CompletionProvider(5000, testDir);
      expect(customProvider).toBeDefined();
    });

    it('should use process.cwd() as default project root', () => {
      const defaultProvider = new CompletionProvider();
      expect(defaultProvider).toBeDefined();
    });
  });
});



================================================
FILE: test/core/completions/generators/bash-generator.test.ts
================================================
import { describe, it, expect, beforeEach } from 'vitest';
import { BashGenerator } from '../../../../src/core/completions/generators/bash-generator.js';
import { CommandDefinition } from '../../../../src/core/completions/types.js';

describe('BashGenerator', () => {
  let generator: BashGenerator;

  beforeEach(() => {
    generator = new BashGenerator();
  });

  describe('interface compliance', () => {
    it('should have shell property set to "bash"', () => {
      expect(generator.shell).toBe('bash');
    });

    it('should implement generate method', () => {
      expect(typeof generator.generate).toBe('function');
    });
  });

  describe('generate', () => {
    it('should generate valid bash completion script with header', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('# Bash completion script for OpenSpec CLI');
      expect(script).toContain('_openspec_completion() {');
      expect(script).toContain('local cur prev words cword');
      expect(script).toContain('_init_completion -n : || return');
    });

    it('should include all commands in the command list', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [],
        },
        {
          name: 'show',
          description: 'Show a spec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('init');
      expect(script).toContain('validate');
      expect(script).toContain('show');
    });

    it('should handle commands with flags without short options', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'strict',
              description: 'Enable strict mode',
            },
            {
              name: 'json',
              description: 'Output as JSON',
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--strict');
      expect(script).toContain('--json');
    });

    it('should handle flags with short options', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show a spec',
          flags: [
            {
              name: 'requirement',
              short: 'r',
              description: 'Show specific requirement',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('-r');
      expect(script).toContain('--requirement');
    });

    it('should handle boolean flags vs value-taking flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'strict',
              description: 'Enable strict mode',
            },
            {
              name: 'output',
              description: 'Output file',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--strict');
      expect(script).toContain('--output');
    });

    it('should handle flags with enum values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'type',
              description: 'Specify item type',
              takesValue: true,
              values: ['change', 'spec'],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--type');
      expect(script).toContain('change');
      expect(script).toContain('spec');
    });

    it('should handle flags with takesValue but no specific values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'concurrency',
              description: 'Max concurrent validations',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--concurrency');
    });

    it('should handle commands with subcommands', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'change',
          description: 'Manage changes',
          flags: [],
          subcommands: [
            {
              name: 'show',
              description: 'Show a change',
              flags: [],
            },
            {
              name: 'list',
              description: 'List changes',
              flags: [],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('change)');
      expect(script).toContain('show');
      expect(script).toContain('list');
    });

    it('should offer parent flags when command has both flags and subcommands', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'config',
          description: 'Manage configuration',
          flags: [
            {
              name: 'scope',
              short: 's',
              description: 'Configuration scope',
            },
            {
              name: 'json',
              description: 'Output as JSON',
            },
          ],
          subcommands: [
            {
              name: 'set',
              description: 'Set a config value',
              flags: [],
            },
            {
              name: 'get',
              description: 'Get a config value',
              flags: [],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      // Should check for flag prefix before offering subcommands
      expect(script).toContain('if [[ "$cur" == -* ]]; then');
      // Should include parent command flags
      expect(script).toContain('-s');
      expect(script).toContain('--scope');
      expect(script).toContain('--json');
      // Should also include subcommands
      expect(script).toContain('set');
      expect(script).toContain('get');
    });

    it('should handle positional arguments for change-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'archive',
          description: 'Archive a change',
          acceptsPositional: true,
          positionalType: 'change-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_complete_changes');
    });

    it('should handle positional arguments for spec-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show-spec',
          description: 'Show a spec',
          acceptsPositional: true,
          positionalType: 'spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_complete_specs');
    });

    it('should handle positional arguments for change-or-spec-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show an item',
          acceptsPositional: true,
          positionalType: 'change-or-spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_complete_items');
    });

    it('should handle positional arguments for shell', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'generate',
          description: 'Generate completions',
          acceptsPositional: true,
          positionalType: 'shell',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('zsh');
      expect(script).toContain('bash');
      expect(script).toContain('fish');
      expect(script).toContain('powershell');
    });

    it('should handle positional arguments for paths', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          acceptsPositional: true,
          positionalType: 'path',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('compgen -f');
    });

    it('should generate dynamic completion helper for changes', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'archive',
          description: 'Archive a change',
          acceptsPositional: true,
          positionalType: 'change-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_complete_changes() {');
      expect(script).toContain('openspec __complete changes 2>/dev/null');
      expect(script).toContain('cut -f1');
      expect(script).toContain('COMPREPLY=');
    });

    it('should generate dynamic completion helper for specs', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show-spec',
          description: 'Show a spec',
          acceptsPositional: true,
          positionalType: 'spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_complete_specs() {');
      expect(script).toContain('openspec __complete specs 2>/dev/null');
      expect(script).toContain('cut -f1');
    });

    it('should generate dynamic completion helper for items (changes and specs)', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show an item',
          acceptsPositional: true,
          positionalType: 'change-or-spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_complete_items() {');
      expect(script).toContain('openspec __complete changes 2>/dev/null');
      expect(script).toContain('openspec __complete specs 2>/dev/null');
    });

    it('should handle complex nested subcommands with flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'spec',
          description: 'Manage specs',
          flags: [],
          subcommands: [
            {
              name: 'validate',
              description: 'Validate a spec',
              acceptsPositional: true,
              positionalType: 'spec-id',
              flags: [
                {
                  name: 'strict',
                  description: 'Enable strict mode',
                },
                {
                  name: 'json',
                  description: 'Output as JSON',
                },
              ],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('spec)');
      expect(script).toContain('validate');
      expect(script).toContain('--strict');
      expect(script).toContain('--json');
      expect(script).toContain('_openspec_complete_specs');
    });

    it('should generate script that ends with complete registration', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script.trim().endsWith('complete -F _openspec_completion openspec')).toBe(true);
    });

    it('should handle empty command list', () => {
      const commands: CommandDefinition[] = [];

      const script = generator.generate(commands);

      expect(script).toContain('# Bash completion script');
      expect(script).toContain('_openspec_completion() {');
      expect(script).toContain('complete -F _openspec_completion openspec');
    });

    it('should handle commands with no flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'view',
          description: 'Display dashboard',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('view)');
    });
  });

  describe('security - command injection prevention', () => {
    it('should escape command names with shell metacharacters', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: 'Test command',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Normal command name should be in the script
      expect(script).toContain('test');
    });

    it('should escape dollar signs in command names', () => {
      // This tests that if a command name somehow contained $, it would be escaped
      // In practice, command names are validated, but the escaping provides defense in depth
      const maliciousName = 'test$var';
      const commands: CommandDefinition[] = [
        {
          name: maliciousName,
          description: 'Test',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should escape the dollar sign
      expect(script).toContain('test\\$var');
    });

    it('should escape backticks in command names', () => {
      const maliciousName = 'test`cmd`';
      const commands: CommandDefinition[] = [
        {
          name: maliciousName,
          description: 'Test',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should escape backticks
      expect(script).toContain('\\`');
    });

    it('should escape double quotes in command names', () => {
      const maliciousName = 'test"quoted"';
      const commands: CommandDefinition[] = [
        {
          name: maliciousName,
          description: 'Test',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should escape double quotes
      expect(script).toContain('\\"');
    });

    it('should escape backslashes in command names', () => {
      const maliciousName = 'test\\path';
      const commands: CommandDefinition[] = [
        {
          name: maliciousName,
          description: 'Test',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should escape backslashes
      expect(script).toContain('\\\\');
    });

    it('should escape subcommand names with shell metacharacters', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'parent',
          description: 'Parent command',
          flags: [],
          subcommands: [
            {
              name: 'sub$cmd',
              description: 'Subcommand with metacharacter',
              flags: [],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      // Should escape metacharacters in subcommand names
      expect(script).toContain('sub\\$cmd');
    });
  });
});



================================================
FILE: test/core/completions/generators/fish-generator.test.ts
================================================
import { describe, it, expect, beforeEach } from 'vitest';
import { FishGenerator } from '../../../../src/core/completions/generators/fish-generator.js';
import { CommandDefinition } from '../../../../src/core/completions/types.js';

describe('FishGenerator', () => {
  let generator: FishGenerator;

  beforeEach(() => {
    generator = new FishGenerator();
  });

  describe('interface compliance', () => {
    it('should have shell property set to "fish"', () => {
      expect(generator.shell).toBe('fish');
    });

    it('should implement generate method', () => {
      expect(typeof generator.generate).toBe('function');
    });
  });

  describe('generate', () => {
    it('should generate valid fish completion script with header', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('# Fish completion script for OpenSpec CLI');
      expect(script).toContain('function __fish_openspec');
    });

    it('should generate helper functions for Fish', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('function __fish_openspec_using_subcommand');
      expect(script).toContain('function __fish_openspec_no_subcommand');
      expect(script).toContain('commandline -opc');
    });

    it('should include all commands with descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [],
        },
        {
          name: 'show',
          description: 'Show a spec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("complete -c openspec");
      expect(script).toContain("-a 'init'");
      expect(script).toContain("'Initialize OpenSpec'");
      expect(script).toContain("-a 'validate'");
      expect(script).toContain("'Validate specs'");
      expect(script).toContain("-a 'show'");
      expect(script).toContain("'Show a spec'");
    });

    it('should handle commands with flags without short options', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'strict',
              description: 'Enable strict mode',
            },
            {
              name: 'json',
              description: 'Output as JSON',
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("-l strict");
      expect(script).toContain("'Enable strict mode'");
      expect(script).toContain("-l json");
      expect(script).toContain("'Output as JSON'");
    });

    it('should handle flags with short options', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show a spec',
          flags: [
            {
              name: 'requirement',
              short: 'r',
              description: 'Show specific requirement',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("-s r");
      expect(script).toContain("-l requirement");
      expect(script).toContain("'Show specific requirement'");
      expect(script).toContain("-r");
    });

    it('should use -r flag for flags that require values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'output',
              description: 'Output file',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("-l output");
      expect(script).toContain("-r");
    });

    it('should not use -r flag for boolean flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'strict',
              description: 'Enable strict mode',
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      const lines = script.split('\n');
      const strictLine = lines.find(line => line.includes('-l strict'));

      expect(strictLine).toBeDefined();
      expect(strictLine).not.toContain(' -r');
    });

    it('should handle flags with enum values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'type',
              description: 'Specify item type',
              takesValue: true,
              values: ['change', 'spec'],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("-l type");
      expect(script).toContain("change");
      expect(script).toContain("spec");
    });

    it('should handle commands with subcommands', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'change',
          description: 'Manage changes',
          flags: [],
          subcommands: [
            {
              name: 'show',
              description: 'Show a change',
              flags: [],
            },
            {
              name: 'list',
              description: 'List changes',
              flags: [],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'change'");
      expect(script).toContain("'show'");
      expect(script).toContain("'list'");
      expect(script).toContain("__fish_openspec_using_subcommand change");
    });

    it('should handle positional arguments for change-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'archive',
          description: 'Archive a change',
          acceptsPositional: true,
          positionalType: 'change-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('__fish_openspec_changes');
    });

    it('should handle positional arguments for spec-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show-spec',
          description: 'Show a spec',
          acceptsPositional: true,
          positionalType: 'spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('__fish_openspec_specs');
    });

    it('should handle positional arguments for change-or-spec-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show an item',
          acceptsPositional: true,
          positionalType: 'change-or-spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('__fish_openspec_items');
    });

    it('should handle positional arguments for shell with inline values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'generate',
          description: 'Generate completions',
          acceptsPositional: true,
          positionalType: 'shell',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('zsh');
      expect(script).toContain('bash');
      expect(script).toContain('fish');
      expect(script).toContain('powershell');
    });

    it('should generate dynamic completion helper for changes', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'archive',
          description: 'Archive a change',
          acceptsPositional: true,
          positionalType: 'change-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('function __fish_openspec_changes');
      expect(script).toContain('openspec __complete changes 2>/dev/null');
      expect(script).toContain('while read -l id desc');
      expect(script).toContain('printf');
    });

    it('should generate dynamic completion helper for specs', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show-spec',
          description: 'Show a spec',
          acceptsPositional: true,
          positionalType: 'spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('function __fish_openspec_specs');
      expect(script).toContain('openspec __complete specs 2>/dev/null');
    });

    it('should generate dynamic completion helper for items', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show an item',
          acceptsPositional: true,
          positionalType: 'change-or-spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('function __fish_openspec_items');
      expect(script).toContain('__fish_openspec_changes');
      expect(script).toContain('__fish_openspec_specs');
    });

    it('should escape single quotes in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: "Test with 'quotes'",
          flags: [
            {
              name: 'flag',
              description: "Special chars: 'quotes'",
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("\\'quotes\\'");
    });

    it('should handle complex nested subcommands with flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'spec',
          description: 'Manage specs',
          flags: [],
          subcommands: [
            {
              name: 'validate',
              description: 'Validate a spec',
              acceptsPositional: true,
              positionalType: 'spec-id',
              flags: [
                {
                  name: 'strict',
                  description: 'Enable strict mode',
                },
                {
                  name: 'json',
                  description: 'Output as JSON',
                },
              ],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'spec'");
      expect(script).toContain("'validate'");
      expect(script).toContain("-l strict");
      expect(script).toContain("-l json");
      expect(script).toContain('__fish_openspec_specs');
    });

    it('should handle empty command list', () => {
      const commands: CommandDefinition[] = [];

      const script = generator.generate(commands);

      expect(script).toContain('# Fish completion script');
      expect(script).toContain('function __fish_openspec');
    });

    it('should handle commands with no flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'view',
          description: 'Display dashboard',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'view'");
      expect(script).toContain("'Display dashboard'");
    });
  });

  describe('security - command injection prevention', () => {
    it('should escape $() command substitution in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: 'Test command $(curl evil.com)',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should contain escaped dollar signs to prevent command substitution
      expect(script).toContain('\\$');
      // Should have backslash before $( to escape it
      expect(script).toMatch(/\\\$\(curl/);
    });

    it('should escape backticks in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: 'Test command `whoami`',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should not contain unescaped backticks
      expect(script).not.toMatch(/`whoami`/);
      // Should contain escaped version
      expect(script).toContain('\\`');
    });

    it('should escape dollar signs in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: 'Test with $variable',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should escape dollar signs
      expect(script).toContain('\\$');
    });

    it('should escape single quotes in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: "Test with 'quotes'",
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should escape single quotes
      expect(script).toContain("\\'");
    });

    it('should escape backslashes in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: 'Test with \\ backslash',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should contain escaped backslashes
      expect(script).toContain('\\\\');
    });

    it('should handle multiple shell metacharacters together', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: "Dangerous: $(rm -rf /) `cat /etc/passwd` $HOME 'quoted'",
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      // Should contain escaped versions of dangerous patterns
      expect(script).toContain('\\$');  // Escaped dollar signs
      expect(script).toContain('\\`');  // Escaped backticks
      expect(script).toContain("\\'");  // Escaped single quotes

      // The escaped patterns should be present (backslash before dangerous chars)
      expect(script).toMatch(/\\\$\(/);  // \$( instead of $(
      expect(script).toMatch(/\\\`cat/);  // \`cat instead of `cat
    });
  });
});



================================================
FILE: test/core/completions/generators/powershell-generator.test.ts
================================================
import { describe, it, expect, beforeEach } from 'vitest';
import { PowerShellGenerator } from '../../../../src/core/completions/generators/powershell-generator.js';
import { CommandDefinition } from '../../../../src/core/completions/types.js';

describe('PowerShellGenerator', () => {
	let generator: PowerShellGenerator;

	beforeEach(() => {
		generator = new PowerShellGenerator();
	});

	describe('interface compliance', () => {
		it('should have shell property set to "powershell"', () => {
			expect(generator.shell).toBe('powershell');
		});

		it('should implement generate method', () => {
			expect(typeof generator.generate).toBe('function');
		});
	});

	describe('generate', () => {
		it('should generate valid PowerShell completion script with header', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'init',
					description: 'Initialize OpenSpec',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('# PowerShell completion script for OpenSpec CLI');
			expect(script).toContain('$openspecCompleter = {');
			expect(script).toContain('Register-ArgumentCompleter');
		});

		it('should register argument completer for openspec command', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'init',
					description: 'Initialize OpenSpec',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('Register-ArgumentCompleter -CommandName openspec');
			expect(script).toContain('-ScriptBlock $openspecCompleter');
		});

		it('should include all commands with descriptions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'init',
					description: 'Initialize OpenSpec',
					flags: [],
				},
				{
					name: 'validate',
					description: 'Validate specs',
					flags: [],
				},
				{
					name: 'show',
					description: 'Show a spec',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('"init"');
			expect(script).toContain('Initialize OpenSpec');
			expect(script).toContain('"validate"');
			expect(script).toContain('Validate specs');
			expect(script).toContain('"show"');
			expect(script).toContain('Show a spec');
		});

		it('should use CompletionResult objects for completions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'init',
					description: 'Initialize OpenSpec',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('[System.Management.Automation.CompletionResult]::new(');
		});

		it('should handle commands with flags without short options', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'validate',
					description: 'Validate specs',
					flags: [
						{
							name: 'strict',
							description: 'Enable strict mode',
						},
						{
							name: 'json',
							description: 'Output as JSON',
						},
					],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('--strict');
			expect(script).toContain('Enable strict mode');
			expect(script).toContain('--json');
			expect(script).toContain('Output as JSON');
		});

		it('should handle flags with short options', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'show',
					description: 'Show a spec',
					flags: [
						{
							name: 'requirement',
							short: 'r',
							description: 'Show specific requirement',
							takesValue: true,
						},
					],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('-r');
			expect(script).toContain('--requirement');
			expect(script).toContain('Show specific requirement');
		});

		it('should handle boolean flags vs value-taking flags', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'validate',
					description: 'Validate specs',
					flags: [
						{
							name: 'strict',
							description: 'Enable strict mode',
						},
						{
							name: 'output',
							description: 'Output file',
							takesValue: true,
						},
					],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('--strict');
			expect(script).toContain('--output');
			expect(script).toContain('Enable strict mode');
			expect(script).toContain('Output file');
		});

		it('should handle flags with enum values', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'validate',
					description: 'Validate specs',
					flags: [
						{
							name: 'type',
							description: 'Specify item type',
							takesValue: true,
							values: ['change', 'spec'],
						},
					],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('--type');
			expect(script).toContain('change');
			expect(script).toContain('spec');
		});

		it('should handle commands with subcommands', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'change',
					description: 'Manage changes',
					flags: [],
					subcommands: [
						{
							name: 'show',
							description: 'Show a change',
							flags: [],
						},
						{
							name: 'list',
							description: 'List changes',
							flags: [],
						},
					],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('"change"');
			expect(script).toContain('"show"');
			expect(script).toContain('"list"');
			expect(script).toContain('Manage changes');
			expect(script).toContain('Show a change');
			expect(script).toContain('List changes');
		});

		it('should offer parent flags when command has both flags and subcommands', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'config',
					description: 'Manage configuration',
					flags: [
						{
							name: 'scope',
							short: 's',
							description: 'Configuration scope',
						},
						{
							name: 'json',
							description: 'Output as JSON',
						},
					],
					subcommands: [
						{
							name: 'set',
							description: 'Set a config value',
							flags: [],
						},
						{
							name: 'get',
							description: 'Get a config value',
							flags: [],
						},
					],
				},
			];

			const script = generator.generate(commands);

			// Should check for flag prefix before offering subcommands
			expect(script).toContain('if ($wordToComplete -like "-*")');
			// Should include parent command flags
			expect(script).toContain('-s');
			expect(script).toContain('--scope');
			expect(script).toContain('--json');
			// Should also include subcommands
			expect(script).toContain('"set"');
			expect(script).toContain('"get"');
		});

		it('should handle positional arguments for change-id', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'archive',
					description: 'Archive a change',
					acceptsPositional: true,
					positionalType: 'change-id',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('Get-OpenSpecChanges');
		});

		it('should handle positional arguments for spec-id', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'show-spec',
					description: 'Show a spec',
					acceptsPositional: true,
					positionalType: 'spec-id',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('Get-OpenSpecSpecs');
		});

		it('should handle positional arguments for change-or-spec-id', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'show',
					description: 'Show an item',
					acceptsPositional: true,
					positionalType: 'change-or-spec-id',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('Get-OpenSpecChanges');
			expect(script).toContain('Get-OpenSpecSpecs');
		});

		it('should handle positional arguments for shell with inline values', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'generate',
					description: 'Generate completions',
					acceptsPositional: true,
					positionalType: 'shell',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('zsh');
			expect(script).toContain('bash');
			expect(script).toContain('fish');
			expect(script).toContain('powershell');
		});

		it('should not include path completion helpers (PowerShell handles natively)', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'init',
					description: 'Initialize OpenSpec',
					acceptsPositional: true,
					positionalType: 'path',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			// PowerShell handles path completion natively, so we just check the command is present
			expect(script).toContain('"init"');
		});

		it('should generate dynamic completion helper for changes', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'archive',
					description: 'Archive a change',
					acceptsPositional: true,
					positionalType: 'change-id',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('function Get-OpenSpecChanges');
			expect(script).toContain('openspec __complete changes 2>$null');
			expect(script).toContain('-split');
		});

		it('should generate dynamic completion helper for specs', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'show-spec',
					description: 'Show a spec',
					acceptsPositional: true,
					positionalType: 'spec-id',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('function Get-OpenSpecSpecs');
			expect(script).toContain('openspec __complete specs 2>$null');
		});

		it('should escape double quotes in descriptions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'test',
					description: 'Test with "quotes"',
					flags: [
						{
							name: 'flag',
							description: 'Special chars: "quotes"',
						},
					],
				},
			];

			const script = generator.generate(commands);

			// PowerShell escapes double quotes by doubling them
			expect(script).toContain('""quotes""');
		});

		it('should handle complex nested subcommands with flags', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'spec',
					description: 'Manage specs',
					flags: [],
					subcommands: [
						{
							name: 'validate',
							description: 'Validate a spec',
							acceptsPositional: true,
							positionalType: 'spec-id',
							flags: [
								{
									name: 'strict',
									description: 'Enable strict mode',
								},
								{
									name: 'json',
									description: 'Output as JSON',
								},
							],
						},
					],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('"spec"');
			expect(script).toContain('"validate"');
			expect(script).toContain('--strict');
			expect(script).toContain('--json');
			expect(script).toContain('Get-OpenSpecSpecs');
		});

		it('should not emit trailing commas in @() arrays', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'config',
					description: 'Manage configuration',
					flags: [
						{
							name: 'scope',
							short: 's',
							description: 'Configuration scope',
						},
					],
					subcommands: [
						{
							name: 'get',
							description: 'Get a config value',
							flags: [],
						},
					],
				},
			];

			const script = generator.generate(commands);

			// PowerShell array literals (@(...)) can't have a trailing comma on the last element.
			expect(script).not.toMatch(/\},\s*\r?\n\s*\)/);
		});

		it('should handle empty command list', () => {
			const commands: CommandDefinition[] = [];

			const script = generator.generate(commands);

			expect(script).toContain('# PowerShell completion script');
			expect(script).toContain('$openspecCompleter = {');
			expect(script).toContain('Register-ArgumentCompleter');
		});

		it('should handle commands with no flags', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'view',
					description: 'Display dashboard',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('"view"');
			expect(script).toContain('Display dashboard');
		});

		it('should generate helper function that splits on tab character', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'archive',
					description: 'Archive a change',
					acceptsPositional: true,
					positionalType: 'change-id',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			expect(script).toContain('function Get-OpenSpecChanges');
			// PowerShell uses -split with \\t for tab character
			expect(script).toContain('-split');
			expect(script).toContain('[0]');
		});
	});

	describe('security - command injection prevention', () => {
		it('should escape $() subexpressions in descriptions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'test',
					description: 'Test command $(Get-Process)',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			// Should contain escaped version (backtick before $)
			expect(script).toContain('`$');
			// Should have backtick before $( to escape it
			expect(script).toMatch(/`\$\(Get-Process\)/);
		});

		it('should escape backticks in descriptions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'test',
					description: 'Test with `n newline escape',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			// Should escape backticks (PowerShell escape character)
			expect(script).toContain('``');
		});

		it('should escape dollar signs in descriptions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'test',
					description: 'Test with $env:PATH variable',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			// Should escape dollar signs
			expect(script).toContain('`$');
		});

		it('should escape double quotes in descriptions', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'test',
					description: 'Test with "quotes"',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			// Should escape double quotes (PowerShell string delimiter)
			expect(script).toContain('""');
		});

		it('should handle multiple PowerShell metacharacters together', () => {
			const commands: CommandDefinition[] = [
				{
					name: 'test',
					description: 'Dangerous: $(Remove-Item -Force) `n $env:HOME "quoted"',
					flags: [],
				},
			];

			const script = generator.generate(commands);

			// Should contain escaped versions of dangerous patterns
			expect(script).toContain('`$');  // Escaped dollar signs
			expect(script).toContain('``');  // Escaped backticks
			expect(script).toContain('""');  // Escaped double quotes

			// The escaped patterns should be present (backtick before $ and n)
			expect(script).toMatch(/`\$\(/);  // `$( instead of $(
			expect(script).toMatch(/``n/);     // ``n instead of `n
		});
	});
});



================================================
FILE: test/core/completions/generators/zsh-generator.test.ts
================================================
import { describe, it, expect } from 'vitest';
import { ZshGenerator } from '../../../../src/core/completions/generators/zsh-generator.js';
import { CommandDefinition } from '../../../../src/core/completions/types.js';

describe('ZshGenerator', () => {
  let generator: ZshGenerator;

  beforeEach(() => {
    generator = new ZshGenerator();
  });

  describe('interface compliance', () => {
    it('should have shell property set to "zsh"', () => {
      expect(generator.shell).toBe('zsh');
    });

    it('should implement generate method', () => {
      expect(typeof generator.generate).toBe('function');
    });
  });

  describe('generate', () => {
    it('should generate valid zsh completion script with header', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('#compdef openspec');
      expect(script).toContain('# Zsh completion script for OpenSpec CLI');
      expect(script).toContain('_openspec() {');
    });

    it('should include all commands in the command list', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [],
        },
        {
          name: 'show',
          description: 'Show a spec',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'init:Initialize OpenSpec'");
      expect(script).toContain("'validate:Validate specs'");
      expect(script).toContain("'show:Show a spec'");
    });

    it('should generate command completion functions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          flags: [],
        },
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_init() {');
      expect(script).toContain('_openspec_validate() {');
    });

    it('should handle commands with flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'strict',
              description: 'Enable strict mode',
            },
            {
              name: 'json',
              description: 'Output as JSON',
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--strict');
      expect(script).toContain('[Enable strict mode]');
      expect(script).toContain('--json');
      expect(script).toContain('[Output as JSON]');
    });

    it('should handle flags with short options', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show a spec',
          flags: [
            {
              name: 'requirement',
              short: 'r',
              description: 'Show specific requirement',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'(-r --requirement)'{-r,--requirement}'[Show specific requirement]:value:'");
      expect(script).toContain('[Show specific requirement]');
    });

    it('should handle flags that take values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'type',
              description: 'Specify item type',
              takesValue: true,
              values: ['change', 'spec'],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--type');
      expect(script).toContain('[Specify item type]');
      expect(script).toContain(':value:(change spec)');
    });

    it('should handle flags with takesValue but no specific values', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'validate',
          description: 'Validate specs',
          flags: [
            {
              name: 'concurrency',
              description: 'Max concurrent validations',
              takesValue: true,
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('--concurrency');
      expect(script).toContain('[Max concurrent validations]');
      expect(script).toContain(':value:');
    });

    it('should handle commands with subcommands', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'change',
          description: 'Manage changes',
          flags: [],
          subcommands: [
            {
              name: 'show',
              description: 'Show a change',
              flags: [],
            },
            {
              name: 'list',
              description: 'List changes',
              flags: [],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'show:Show a change'");
      expect(script).toContain("'list:List changes'");
      expect(script).toContain('_openspec_change_show() {');
      expect(script).toContain('_openspec_change_list() {');
    });

    it('should handle positional arguments for change-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'archive',
          description: 'Archive a change',
          acceptsPositional: true,
          positionalType: 'change-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'*: :_openspec_complete_changes'");
    });

    it('should handle positional arguments for spec-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show-spec',
          description: 'Show a spec',
          acceptsPositional: true,
          positionalType: 'spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'*: :_openspec_complete_specs'");
    });

    it('should handle positional arguments for change-or-spec-id', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'show',
          description: 'Show an item',
          acceptsPositional: true,
          positionalType: 'change-or-spec-id',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'*: :_openspec_complete_items'");
    });

    it('should handle positional arguments for paths', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize OpenSpec',
          acceptsPositional: true,
          positionalType: 'path',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("'*:path:_files'");
    });

    it('should escape special characters in descriptions', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'test',
          description: "Test with 'quotes' and [brackets] and back\\slash and colon:",
          flags: [
            {
              name: 'flag',
              description: "Special chars: 'quotes' [brackets] back\\slash colon:",
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain("\\'quotes\\'");
      expect(script).toContain('\\[brackets\\]');
      expect(script).toContain('\\\\slash');
      expect(script).toContain('\\:');
    });

    it('should sanitize command names with hyphens for function names', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'my-command',
          description: 'A hyphenated command',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_my_command() {');
    });

    it('should handle complex nested subcommands with flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'spec',
          description: 'Manage specs',
          flags: [],
          subcommands: [
            {
              name: 'validate',
              description: 'Validate a spec',
              acceptsPositional: true,
              positionalType: 'spec-id',
              flags: [
                {
                  name: 'strict',
                  description: 'Enable strict mode',
                },
                {
                  name: 'json',
                  description: 'Output as JSON',
                },
              ],
            },
          ],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_spec() {');
      expect(script).toContain('_openspec_spec_validate() {');
      expect(script).toContain('--strict');
      expect(script).toContain('--json');
      expect(script).toContain("'*: :_openspec_complete_specs'");
    });

    it('should generate script that ends with compdef registration', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'init',
          description: 'Initialize',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script.trim().endsWith('compdef _openspec openspec')).toBe(true);
    });

    it('should handle empty command list', () => {
      const commands: CommandDefinition[] = [];

      const script = generator.generate(commands);

      expect(script).toContain('#compdef openspec');
      expect(script).toContain('_openspec() {');
    });

    it('should handle commands with no flags', () => {
      const commands: CommandDefinition[] = [
        {
          name: 'view',
          description: 'Display dashboard',
          flags: [],
        },
      ];

      const script = generator.generate(commands);

      expect(script).toContain('_openspec_view() {');
      expect(script).toContain('_arguments');
    });
  });
});



================================================
FILE: test/core/completions/installers/bash-installer.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';
import { BashInstaller } from '../../../../src/core/completions/installers/bash-installer.js';

describe('BashInstaller', () => {
  let testHomeDir: string;
  let installer: BashInstaller;

  beforeEach(async () => {
    // Create a temporary home directory for testing
    testHomeDir = path.join(os.tmpdir(), `openspec-bash-test-${randomUUID()}`);
    await fs.mkdir(testHomeDir, { recursive: true });
    installer = new BashInstaller(testHomeDir);
  });

  afterEach(async () => {
    // Clean up test directory
    await fs.rm(testHomeDir, { recursive: true, force: true });
  });

  describe('getInstallationPath', () => {
    it('should return standard bash-completion path', async () => {
      const result = await installer.getInstallationPath();

      expect(result).toBe(path.join(testHomeDir, '.local', 'share', 'bash-completion', 'completions', 'openspec'));
    });
  });

  describe('backupExistingFile', () => {
    it('should return undefined when file does not exist', async () => {
      const nonExistentPath = path.join(testHomeDir, 'nonexistent.txt');
      const backupPath = await installer.backupExistingFile(nonExistentPath);

      expect(backupPath).toBeUndefined();
    });

    it('should create backup when file exists', async () => {
      const filePath = path.join(testHomeDir, 'test.txt');
      await fs.writeFile(filePath, 'original content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      expect(backupPath).toContain('.backup-');

      // Verify backup file exists and has correct content
      const backupContent = await fs.readFile(backupPath!, 'utf-8');
      expect(backupContent).toBe('original content');
    });

    it('should create backup with timestamp in filename', async () => {
      const filePath = path.join(testHomeDir, 'test.txt');
      await fs.writeFile(filePath, 'content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toMatch(/\.backup-\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}/);
    });
  });

  describe('install', () => {
    const testScript = '# Bash completion script for OpenSpec CLI\n_openspec_completion() {\n  echo "test"\n}\n';

    it('should install to bash-completion path', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.installedPath).toBe(path.join(testHomeDir, '.local', 'share', 'bash-completion', 'completions', 'openspec'));

      // Verify file was created with correct content
      const content = await fs.readFile(result.installedPath!, 'utf-8');
      expect(content).toBe(testScript);
    });

    it('should create necessary directories if they do not exist', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);

      // Verify directory structure was created
      const completionsDir = path.dirname(result.installedPath!);
      const stat = await fs.stat(completionsDir);
      expect(stat.isDirectory()).toBe(true);
    });

    it('should backup existing file before overwriting', async () => {
      const targetPath = path.join(testHomeDir, '.local', 'share', 'bash-completion', 'completions', 'openspec');
      await fs.mkdir(path.dirname(targetPath), { recursive: true });
      await fs.writeFile(targetPath, 'old script');

      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.backupPath).toBeDefined();
      expect(result.backupPath).toContain('.backup-');

      // Verify backup has old content
      const backupContent = await fs.readFile(result.backupPath!, 'utf-8');
      expect(backupContent).toBe('old script');

      // Verify new file has new content
      const newContent = await fs.readFile(targetPath, 'utf-8');
      expect(newContent).toBe(testScript);
    });

    it('should configure .bashrc when auto-config is enabled', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.bashrcConfigured).toBe(true);

      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const content = await fs.readFile(bashrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain('OpenSpec shell completions configuration');
    });

    it('should include instructions when auto-config is disabled', async () => {
      const originalEnv = process.env.OPENSPEC_NO_AUTO_CONFIG;
      process.env.OPENSPEC_NO_AUTO_CONFIG = '1';

      const result = await installer.install(testScript);

      expect(result.instructions).toBeDefined();
      expect(result.instructions!.join('\n')).toContain('.bashrc');
      expect(result.bashrcConfigured).toBe(false);

      // Restore env
      if (originalEnv === undefined) {
        delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      } else {
        process.env.OPENSPEC_NO_AUTO_CONFIG = originalEnv;
      }
    });

    it('should handle installation errors gracefully', async () => {
      // Create a temporary file and use its path as homeDir
      // This guarantees ENOTDIR when trying to create subdirectories (cross-platform)
      const blockingFile = path.join(testHomeDir, 'blocking-file');
      await fs.writeFile(blockingFile, 'blocking content');
      const invalidInstaller = new BashInstaller(blockingFile);

      const result = await invalidInstaller.install(testScript);

      expect(result.success).toBe(false);
      expect(result.message).toContain('Failed to install');
    });

    it('should detect already-installed completion with identical content', async () => {
      // First installation
      const firstResult = await installer.install(testScript);
      expect(firstResult.success).toBe(true);

      // Second installation with same script
      const secondResult = await installer.install(testScript);

      expect(secondResult.success).toBe(true);
      expect(secondResult.message).toContain('already installed');
      expect(secondResult.message).toContain('up to date');
      expect(secondResult.backupPath).toBeUndefined();
    });

    it('should update completion when content differs', async () => {
      // First installation
      const firstScript = '# Bash completion v1\n_openspec_completion() {\n  echo "version 1"\n}\n';
      const firstResult = await installer.install(firstScript);
      expect(firstResult.success).toBe(true);

      // Second installation with different script
      const secondScript = '# Bash completion v2\n_openspec_completion() {\n  echo "version 2"\n}\n';
      const secondResult = await installer.install(secondScript);

      expect(secondResult.success).toBe(true);
      expect(secondResult.message).toContain('updated successfully');
      expect(secondResult.backupPath).toBeDefined();

      // Verify new content was written
      const content = await fs.readFile(secondResult.installedPath!, 'utf-8');
      expect(content).toBe(secondScript);

      // Verify backup has old content
      const backupContent = await fs.readFile(secondResult.backupPath!, 'utf-8');
      expect(backupContent).toBe(firstScript);
    });

    it('should handle paths with spaces in .bashrc config', async () => {
      // Create a test home directory with spaces
      const testHomeDirWithSpaces = path.join(os.tmpdir(), `openspec bash test ${randomUUID()}`);
      await fs.mkdir(testHomeDirWithSpaces, { recursive: true });
      const installerWithSpaces = new BashInstaller(testHomeDirWithSpaces);

      try {
        const result = await installerWithSpaces.install(testScript);
        expect(result.success).toBe(true);

        // Check if .bashrc was created (when auto-config is enabled)
        const bashrcPath = path.join(testHomeDirWithSpaces, '.bashrc');
        try {
          const bashrcContent = await fs.readFile(bashrcPath, 'utf-8');
          // Verify the path is quoted in config
          const completionsDir = path.dirname(result.installedPath!);
          expect(bashrcContent).toContain(completionsDir);
        } catch {
          // .bashrc might not exist if auto-config was disabled
        }
      } finally {
        // Clean up
        await fs.rm(testHomeDirWithSpaces, { recursive: true, force: true });
      }
    });
  });

  describe('uninstall', () => {
    const testScript = '# Bash completion script\n_openspec_completion() {}\n';

    it('should remove installed completion script', async () => {
      // Install first
      await installer.install(testScript);

      // Uninstall
      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toContain('uninstalled successfully');

      // Verify file is gone
      const targetPath = await installer.getInstallationPath();
      const exists = await fs.access(targetPath).then(() => true).catch(() => false);
      expect(exists).toBe(false);
    });

    it('should return failure when not installed', async () => {
      const result = await installer.uninstall();

      expect(result.success).toBe(false);
      expect(result.message).toContain('not installed');
    });

    it('should remove .bashrc configuration', async () => {
      await installer.install(testScript);

      const result = await installer.uninstall();

      expect(result.success).toBe(true);

      // Verify .bashrc markers are removed
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const exists = await fs.access(bashrcPath).then(() => true).catch(() => false);

      if (exists) {
        const content = await fs.readFile(bashrcPath, 'utf-8');
        expect(content).not.toContain('# OPENSPEC:START');
        expect(content).not.toContain('# OPENSPEC:END');
      }
    });
  });

  describe('configureBashrc', () => {
    const completionsDir = '/test/.local/share/bash-completion/completions';

    it('should create .bashrc with markers and config when file does not exist', async () => {
      const result = await installer.configureBashrc(completionsDir);

      expect(result).toBe(true);

      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const content = await fs.readFile(bashrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain('# OpenSpec shell completions configuration');
      expect(content).toContain(completionsDir);
    });

    it('should prepend markers and config when .bashrc exists without markers', async () => {
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      await fs.writeFile(bashrcPath, '# My custom bash config\nalias ll="ls -la"\n');

      const result = await installer.configureBashrc(completionsDir);

      expect(result).toBe(true);

      const content = await fs.readFile(bashrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain('# My custom bash config');
      expect(content).toContain('alias ll="ls -la"');

      // Config should be before existing content
      const configIndex = content.indexOf('# OPENSPEC:START');
      const aliasIndex = content.indexOf('alias ll');
      expect(configIndex).toBeLessThan(aliasIndex);
    });

    it('should update config between markers when .bashrc has existing markers', async () => {
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const initialContent = [
        '# OPENSPEC:START',
        '# Old config',
        'if [ -d "/old/path" ]; then',
        '  . "/old/path"',
        'fi',
        '# OPENSPEC:END',
        '',
        '# My custom config',
      ].join('\n');

      await fs.writeFile(bashrcPath, initialContent);

      const result = await installer.configureBashrc(completionsDir);

      expect(result).toBe(true);

      const content = await fs.readFile(bashrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain(completionsDir);
      expect(content).not.toContain('# Old config');
      expect(content).not.toContain('/old/path');
      expect(content).toContain('# My custom config');
    });

    it('should preserve user content outside markers', async () => {
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const userContent = [
        '# My bash config',
        'export PATH="/custom/path:$PATH"',
        '',
        '# OPENSPEC:START',
        '# Old OpenSpec config',
        '# OPENSPEC:END',
        '',
        'alias ls="ls -G"',
      ].join('\n');

      await fs.writeFile(bashrcPath, userContent);

      const result = await installer.configureBashrc(completionsDir);

      expect(result).toBe(true);

      const content = await fs.readFile(bashrcPath, 'utf-8');

      expect(content).toContain('# My bash config');
      expect(content).toContain('export PATH="/custom/path:$PATH"');
      expect(content).toContain('alias ls="ls -G"');
      expect(content).toContain(completionsDir);
      expect(content).not.toContain('# Old OpenSpec config');
    });

    it('should return false when OPENSPEC_NO_AUTO_CONFIG is set', async () => {
      const originalEnv = process.env.OPENSPEC_NO_AUTO_CONFIG;
      process.env.OPENSPEC_NO_AUTO_CONFIG = '1';

      const result = await installer.configureBashrc(completionsDir);

      expect(result).toBe(false);

      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const exists = await fs.access(bashrcPath).then(() => true).catch(() => false);
      expect(exists).toBe(false);

      // Restore env
      if (originalEnv === undefined) {
        delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      } else {
        process.env.OPENSPEC_NO_AUTO_CONFIG = originalEnv;
      }
    });

    it('should handle write permission errors gracefully', async () => {
      // Create a temporary file and use its path as homeDir
      // This guarantees ENOTDIR when trying to write .bashrc (cross-platform)
      const blockingFile = path.join(testHomeDir, 'blocking-file');
      await fs.writeFile(blockingFile, 'blocking content');
      const invalidInstaller = new BashInstaller(blockingFile);

      const result = await invalidInstaller.configureBashrc(completionsDir);

      expect(result).toBe(false);
    });
  });

  describe('removeBashrcConfig', () => {
    it('should return true when .bashrc does not exist', async () => {
      const result = await installer.removeBashrcConfig();
      expect(result).toBe(true);
    });

    it('should return true when .bashrc exists but has no markers', async () => {
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      await fs.writeFile(bashrcPath, '# My custom config\nalias ll="ls -la"\n');

      const result = await installer.removeBashrcConfig();

      expect(result).toBe(true);

      // Content should be unchanged
      const content = await fs.readFile(bashrcPath, 'utf-8');
      expect(content).toBe('# My custom config\nalias ll="ls -la"\n');
    });

    it('should remove markers and config when present', async () => {
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const content = [
        '# My config',
        '',
        '# OPENSPEC:START',
        '# OpenSpec shell completions configuration',
        'if [ -d ~/.local/share/bash-completion/completions ]; then',
        '  . ~/.local/share/bash-completion/completions/openspec',
        'fi',
        '# OPENSPEC:END',
        '',
        'alias ll="ls -la"',
      ].join('\n');

      await fs.writeFile(bashrcPath, content);

      const result = await installer.removeBashrcConfig();

      expect(result).toBe(true);

      const newContent = await fs.readFile(bashrcPath, 'utf-8');

      expect(newContent).not.toContain('# OPENSPEC:START');
      expect(newContent).not.toContain('# OPENSPEC:END');
      expect(newContent).not.toContain('OpenSpec shell completions configuration');
      expect(newContent).toContain('# My config');
      expect(newContent).toContain('alias ll="ls -la"');
    });

    it('should preserve user content when removing markers', async () => {
      const bashrcPath = path.join(testHomeDir, '.bashrc');
      const content = [
        'export PATH="/custom:$PATH"',
        '',
        '# OPENSPEC:START',
        '# Config',
        '# OPENSPEC:END',
        '',
        'alias g="git"',
      ].join('\n');

      await fs.writeFile(bashrcPath, content);

      const result = await installer.removeBashrcConfig();

      expect(result).toBe(true);

      const newContent = await fs.readFile(bashrcPath, 'utf-8');

      expect(newContent).toContain('export PATH="/custom:$PATH"');
      expect(newContent).toContain('alias g="git"');
      expect(newContent).not.toContain('# OPENSPEC:START');
    });

    it('should handle permission errors gracefully', async () => {
      const invalidInstaller = new BashInstaller('/root/invalid/path');
      const result = await invalidInstaller.removeBashrcConfig();

      expect(result).toBe(true);
    });
  });

  describe('constructor', () => {
    it('should use provided home directory', () => {
      const customInstaller = new BashInstaller('/custom/home');
      expect(customInstaller).toBeDefined();
    });

    it('should use os.homedir() by default', () => {
      const defaultInstaller = new BashInstaller();
      expect(defaultInstaller).toBeDefined();
    });
  });
});



================================================
FILE: test/core/completions/installers/fish-installer.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { FishInstaller } from '../../../../src/core/completions/installers/fish-installer.js';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';

describe('FishInstaller', () => {
  let testHomeDir: string;
  let installer: FishInstaller;

  beforeEach(async () => {
    testHomeDir = path.join(os.tmpdir(), `openspec-fish-test-${randomUUID()}`);
    await fs.mkdir(testHomeDir, { recursive: true });
    installer = new FishInstaller(testHomeDir);
  });

  afterEach(async () => {
    await fs.rm(testHomeDir, { recursive: true, force: true });
  });

  describe('getInstallationPath', () => {
    it('should return standard fish completions path', () => {
      const result = installer.getInstallationPath();
      expect(result).toBe(path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish'));
    });

    it('should use homeDir from constructor', () => {
      const customHome = '/custom/home';
      const customInstaller = new FishInstaller(customHome);
      const result = customInstaller.getInstallationPath();
      expect(result).toBe(path.join(customHome, '.config', 'fish', 'completions', 'openspec.fish'));
    });
  });

  describe('backupExistingFile', () => {
    it('should return undefined when file does not exist', async () => {
      const nonExistentPath = path.join(testHomeDir, 'does-not-exist.fish');
      const backupPath = await installer.backupExistingFile(nonExistentPath);
      expect(backupPath).toBeUndefined();
    });

    it('should create backup with timestamp in filename', async () => {
      const filePath = path.join(testHomeDir, 'test.fish');
      await fs.writeFile(filePath, 'test content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      expect(backupPath).toMatch(/\.backup-\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}/);
    });

    it('should copy file content to backup', async () => {
      const filePath = path.join(testHomeDir, 'test.fish');
      const originalContent = '# Original fish completion script\nfunction test_func\nend';
      await fs.writeFile(filePath, originalContent);

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      const backupContent = await fs.readFile(backupPath!, 'utf-8');
      expect(backupContent).toBe(originalContent);
    });

    it('should create backup next to original file', async () => {
      const filePath = path.join(testHomeDir, 'subdir', 'test.fish');
      await fs.mkdir(path.dirname(filePath), { recursive: true });
      await fs.writeFile(filePath, 'content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      expect(path.dirname(backupPath!)).toBe(path.dirname(filePath));
    });
  });

  describe('install', () => {
    const mockCompletionScript = `# Fish completion script for OpenSpec CLI
function __fish_openspec
    echo "test"
end

complete -c openspec -a 'init' -d 'Initialize OpenSpec'
`;

    it('should install completion script for the first time', async () => {
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script installed successfully for Fish');
      expect(result.installedPath).toBe(path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish'));
      expect(result.backupPath).toBeUndefined();
      expect(result.instructions).toHaveLength(2);
      expect(result.instructions![0]).toContain('Fish automatically loads completions');
      expect(result.instructions![1]).toContain('Completions are available immediately');
    });

    it('should create parent directories if they do not exist', async () => {
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');
      const dirExists = await fs.access(path.dirname(targetPath)).then(() => true).catch(() => false);
      expect(dirExists).toBe(true);
    });

    it('should write completion script content correctly', async () => {
      await installer.install(mockCompletionScript);

      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');
      const content = await fs.readFile(targetPath, 'utf-8');
      expect(content).toBe(mockCompletionScript);
    });

    it('should detect when already installed with same content', async () => {
      // First installation
      await installer.install(mockCompletionScript);

      // Second installation with same content
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script is already installed (up to date)');
      expect(result.instructions![0]).toContain('already installed and up to date');
      expect(result.backupPath).toBeUndefined();
    });

    it('should update when content is different', async () => {
      // Initial installation
      await installer.install(mockCompletionScript);

      // Update with different content
      const updatedScript = `# Fish completion script for OpenSpec CLI
function __fish_openspec_new
    echo "updated"
end

complete -c openspec -a 'init' -d 'Initialize OpenSpec'
complete -c openspec -a 'validate' -d 'Validate specs'
`;

      const result = await installer.install(updatedScript);

      expect(result.success).toBe(true);
      expect(result.message).toContain('updated successfully');
      expect(result.backupPath).toBeDefined();
      expect(result.backupPath).toMatch(/\.backup-\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}/);
    });

    it('should create backup when updating existing installation', async () => {
      const originalScript = mockCompletionScript;
      await installer.install(originalScript);

      const updatedScript = originalScript + '\n# Updated version';
      const result = await installer.install(updatedScript);

      expect(result.success).toBe(true);
      expect(result.backupPath).toBeDefined();

      // Verify backup contains original content
      const backupContent = await fs.readFile(result.backupPath!, 'utf-8');
      expect(backupContent).toBe(originalScript);

      // Verify current file has updated content
      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');
      const currentContent = await fs.readFile(targetPath, 'utf-8');
      expect(currentContent).toBe(updatedScript);
    });

    it('should include backup path in message when updating', async () => {
      await installer.install(mockCompletionScript);

      const updatedScript = mockCompletionScript + '\n# Updated';
      const result = await installer.install(updatedScript);

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script updated successfully (previous version backed up)');
      expect(result.backupPath).toBeDefined();
    });

    it('should handle installation with paths containing spaces', async () => {
      const spacedHomeDir = path.join(os.tmpdir(), `openspec fish test ${randomUUID()}`);
      await fs.mkdir(spacedHomeDir, { recursive: true });

      const spacedInstaller = new FishInstaller(spacedHomeDir);
      const result = await spacedInstaller.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.installedPath).toContain('openspec fish test');

      // Cleanup
      await fs.rm(spacedHomeDir, { recursive: true, force: true });
    });

    // Skip on Windows: fs.chmod() on directories doesn't restrict write access on Windows
    // Windows uses ACLs which Node.js chmod doesn't control
    it.skipIf(process.platform === 'win32')('should return failure on permission error', async () => {
      // Create a read-only directory to simulate permission error
      const restrictedDir = path.join(testHomeDir, '.config', 'fish', 'completions');
      await fs.mkdir(restrictedDir, { recursive: true });
      await fs.chmod(restrictedDir, 0o444); // Read-only

      const result = await installer.install(mockCompletionScript);

      // Cleanup - restore permissions before asserting
      await fs.chmod(restrictedDir, 0o755);

      expect(result.success).toBe(false);
      expect(result.message).toContain('Failed to install completion script');
    });

    it('should provide appropriate instructions for Fish', async () => {
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.instructions).toBeDefined();
      expect(result.instructions).toHaveLength(2);
      expect(result.instructions![0]).toContain('~/.config/fish/completions/');
      expect(result.instructions![1]).toContain('no shell restart needed');
    });

    it('should handle empty completion script', async () => {
      const result = await installer.install('');

      expect(result.success).toBe(true);
      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');
      const content = await fs.readFile(targetPath, 'utf-8');
      expect(content).toBe('');
    });

    it('should handle completion script with special characters', async () => {
      const specialScript = `# Fish completion script with special chars: ' " \` $ \\
function __fish_openspec
    echo "test's \\"quoted\\" text"
end
`;

      const result = await installer.install(specialScript);

      expect(result.success).toBe(true);
      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');
      const content = await fs.readFile(targetPath, 'utf-8');
      expect(content).toBe(specialScript);
    });
  });

  describe('uninstall', () => {
    const mockCompletionScript = `# Fish completion script
complete -c openspec -a 'init'
`;

    it('should successfully uninstall when completion script exists', async () => {
      // First install
      await installer.install(mockCompletionScript);

      // Then uninstall
      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script uninstalled successfully');
    });

    it('should remove the completion file', async () => {
      await installer.install(mockCompletionScript);
      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');

      await installer.uninstall();

      const fileExists = await fs.access(targetPath).then(() => true).catch(() => false);
      expect(fileExists).toBe(false);
    });

    it('should return failure when completion script is not installed', async () => {
      const result = await installer.uninstall();

      expect(result.success).toBe(false);
      expect(result.message).toBe('Completion script is not installed');
    });

    it('should accept yes option parameter', async () => {
      await installer.install(mockCompletionScript);

      const result = await installer.uninstall({ yes: true });

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script uninstalled successfully');
    });

    // Skip on Windows: fs.chmod() on directories doesn't restrict write access on Windows
    // Windows uses ACLs which Node.js chmod doesn't control
    it.skipIf(process.platform === 'win32')('should return failure on permission error', async () => {
      await installer.install(mockCompletionScript);
      const targetPath = path.join(testHomeDir, '.config', 'fish', 'completions', 'openspec.fish');
      const parentDir = path.dirname(targetPath);

      // Make parent directory read-only to simulate permission error
      await fs.chmod(parentDir, 0o444);
      const result = await installer.uninstall();

      // Restore permissions for cleanup
      await fs.chmod(parentDir, 0o755);

      // On some systems, the access check fails with permission error
      // which returns "not installed" rather than "failed to uninstall"
      expect(result.success).toBe(false);
      expect(
        result.message === 'Completion script is not installed' ||
        result.message.includes('Failed to uninstall completion script')
      ).toBe(true);
    });

    it('should handle uninstall when parent directory does not exist', async () => {
      // Don't install anything, so directory doesn't exist
      const result = await installer.uninstall();

      expect(result.success).toBe(false);
      expect(result.message).toBe('Completion script is not installed');
    });
  });

});



================================================
FILE: test/core/completions/installers/powershell-installer.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { PowerShellInstaller } from '../../../../src/core/completions/installers/powershell-installer.js';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';

describe('PowerShellInstaller', () => {
  let testHomeDir: string;
  let installer: PowerShellInstaller;
  let originalPlatform: NodeJS.Platform;
  let originalEnv: NodeJS.ProcessEnv;

  beforeEach(async () => {
    testHomeDir = path.join(os.tmpdir(), `openspec-powershell-test-${randomUUID()}`);
    await fs.mkdir(testHomeDir, { recursive: true });
    installer = new PowerShellInstaller(testHomeDir);
    originalPlatform = process.platform;
    originalEnv = { ...process.env };
  });

  afterEach(async () => {
    await fs.rm(testHomeDir, { recursive: true, force: true });
    // Restore platform and environment
    Object.defineProperty(process, 'platform', {
      value: originalPlatform,
    });
    process.env = originalEnv;
  });

  describe('getProfilePath', () => {
    it('should prefer PROFILE environment variable when set', () => {
      process.env.PROFILE = '/custom/profile/path.ps1';
      const result = installer.getProfilePath();
      expect(result).toBe('/custom/profile/path.ps1');
    });

    it('should return Windows default path when on win32 platform', () => {
      delete process.env.PROFILE;
      Object.defineProperty(process, 'platform', {
        value: 'win32',
      });

      const result = installer.getProfilePath();
      expect(result).toBe(path.join(testHomeDir, 'Documents', 'PowerShell', 'Microsoft.PowerShell_profile.ps1'));
    });

    it('should return Unix default path when on darwin platform', () => {
      delete process.env.PROFILE;
      Object.defineProperty(process, 'platform', {
        value: 'darwin',
      });

      const result = installer.getProfilePath();
      expect(result).toBe(path.join(testHomeDir, '.config', 'powershell', 'Microsoft.PowerShell_profile.ps1'));
    });

    it('should return Unix default path when on linux platform', () => {
      delete process.env.PROFILE;
      Object.defineProperty(process, 'platform', {
        value: 'linux',
      });

      const result = installer.getProfilePath();
      expect(result).toBe(path.join(testHomeDir, '.config', 'powershell', 'Microsoft.PowerShell_profile.ps1'));
    });
  });

  describe('getInstallationPath', () => {
    it('should return path relative to profile directory', () => {
      delete process.env.PROFILE;
      Object.defineProperty(process, 'platform', {
        value: 'darwin',
      });

      const result = installer.getInstallationPath();
      expect(result).toBe(path.join(testHomeDir, '.config', 'powershell', 'OpenSpecCompletion.ps1'));
    });

    it('should work with custom PROFILE environment variable', () => {
      process.env.PROFILE = path.join(testHomeDir, 'custom', 'profile.ps1');
      const result = installer.getInstallationPath();
      expect(result).toBe(path.join(testHomeDir, 'custom', 'OpenSpecCompletion.ps1'));
    });

    it('should return Windows path when on Windows platform', () => {
      delete process.env.PROFILE;
      Object.defineProperty(process, 'platform', {
        value: 'win32',
      });

      const result = installer.getInstallationPath();
      expect(result).toBe(path.join(testHomeDir, 'Documents', 'PowerShell', 'OpenSpecCompletion.ps1'));
    });
  });

  describe('backupExistingFile', () => {
    it('should return undefined when file does not exist', async () => {
      const nonExistentPath = path.join(testHomeDir, 'does-not-exist.ps1');
      const backupPath = await installer.backupExistingFile(nonExistentPath);
      expect(backupPath).toBeUndefined();
    });

    it('should create backup with timestamp in filename', async () => {
      const filePath = path.join(testHomeDir, 'test.ps1');
      await fs.writeFile(filePath, 'test content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      expect(backupPath).toMatch(/\.backup-\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}/);
    });

    it('should copy file content to backup', async () => {
      const filePath = path.join(testHomeDir, 'test.ps1');
      const originalContent = '# Original PowerShell completion script\n$completer = {}';
      await fs.writeFile(filePath, originalContent);

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      const backupContent = await fs.readFile(backupPath!, 'utf-8');
      expect(backupContent).toBe(originalContent);
    });

    it('should create backup next to original file', async () => {
      const filePath = path.join(testHomeDir, 'subdir', 'test.ps1');
      await fs.mkdir(path.dirname(filePath), { recursive: true });
      await fs.writeFile(filePath, 'content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      expect(path.dirname(backupPath!)).toBe(path.dirname(filePath));
    });
  });

  describe('configureProfile', () => {
    const mockScriptPath = '/path/to/OpenSpecCompletion.ps1';

    // Note: OPENSPEC_NO_AUTO_CONFIG check is now handled in the install() method,
    // not in configureProfile() itself

    it('should create profile with markers when file does not exist', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const profilePath = installer.getProfilePath();

      const result = await installer.configureProfile(mockScriptPath);

      expect(result).toBe(true);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain(`. "${mockScriptPath}"`);
    });

    it('should prepend markers and config when file exists without markers', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });
      await fs.writeFile(profilePath, '# My custom PowerShell config\nWrite-Host "Hello"');

      const result = await installer.configureProfile(mockScriptPath);

      expect(result).toBe(true);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain(mockScriptPath);
      expect(content).toContain('# My custom PowerShell config');
      expect(content).toContain('Write-Host "Hello"');
    });

    // Skip on Windows: Windows has dual profile paths (PowerShell Core + Windows PowerShell 5.1),
    // so even if one profile is already configured, the second one will be configured and return true
    it.skipIf(process.platform === 'win32')('should skip configuration when script line already exists', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });

      const initialContent = [
        '# OPENSPEC:START - OpenSpec completion (managed block, do not edit manually)',
        `. "${mockScriptPath}"`,
        '# OPENSPEC:END',
        '',
        '# My custom config',
        'Write-Host "Custom"',
      ].join('\n');

      await fs.writeFile(profilePath, initialContent);

      const result = await installer.configureProfile(mockScriptPath);

      // Should return false because already configured (anyConfigured = false)
      expect(result).toBe(false);
      const content = await fs.readFile(profilePath, 'utf-8');
      // Content should be unchanged
      expect(content).toBe(initialContent);
    });

    it('should preserve user content outside markers', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });

      const initialContent = [
        '# User config before',
        'Set-Variable -Name "test" -Value "before"',
        '',
        '# OPENSPEC:START',
        '# Old config',
        '# OPENSPEC:END',
        '',
        '# User config after',
        'Set-Variable -Name "test" -Value "after"',
      ].join('\n');

      await fs.writeFile(profilePath, initialContent);

      const result = await installer.configureProfile(mockScriptPath);

      expect(result).toBe(true);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toContain('# User config before');
      expect(content).toContain('Set-Variable -Name "test" -Value "before"');
      expect(content).toContain('# User config after');
      expect(content).toContain('Set-Variable -Name "test" -Value "after"');
    });

    it('should generate correct PowerShell syntax in config', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const profilePath = installer.getProfilePath();

      await installer.configureProfile(mockScriptPath);

      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain(`. "${mockScriptPath}"`);
      expect(content).toContain('# OPENSPEC:END');
    });

    // Skip on Windows: fs.chmod() doesn't reliably restrict write access on Windows
    // (admin users can bypass read-only attribute, and CI runners often have elevated privileges)
    it.skipIf(process.platform === 'win32')('should return false on write permission error', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });
      await fs.writeFile(profilePath, '# Test');

      // Make file read-only
      await fs.chmod(profilePath, 0o444);

      const result = await installer.configureProfile(mockScriptPath);

      // Restore permissions for cleanup
      await fs.chmod(profilePath, 0o644);

      expect(result).toBe(false);
    });
  });

  describe('removeProfileConfig', () => {
    it('should return false when profile does not exist', async () => {
      const result = await installer.removeProfileConfig();
      expect(result).toBe(false);
    });

    it('should return false when profile exists but has no markers', async () => {
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });
      await fs.writeFile(profilePath, '# My custom config\nWrite-Host "Hello"');

      const result = await installer.removeProfileConfig();

      expect(result).toBe(false);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toBe('# My custom config\nWrite-Host "Hello"');
    });

    it('should remove content between markers', async () => {
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });

      const initialContent = [
        '# OPENSPEC:START',
        '# OpenSpec completions',
        'if (Test-Path "/path") {',
        '    . "/path"',
        '}',
        '# OPENSPEC:END',
        '',
        '# My config',
      ].join('\n');

      await fs.writeFile(profilePath, initialContent);

      const result = await installer.removeProfileConfig();

      expect(result).toBe(true);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).not.toContain('# OPENSPEC:START');
      expect(content).not.toContain('# OPENSPEC:END');
      expect(content).not.toContain('# OpenSpec completions');
      expect(content).toContain('# My config');
    });

    it('should remove trailing empty lines after removal', async () => {
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });

      const initialContent = [
        '# User config',
        '# OPENSPEC:START',
        '# Config',
        '# OPENSPEC:END',
        '',
        '',
      ].join('\n');

      await fs.writeFile(profilePath, initialContent);

      const result = await installer.removeProfileConfig();

      expect(result).toBe(true);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toBe('# User config\n');
    });

    it('should preserve user content outside markers', async () => {
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });

      const initialContent = [
        '# Before',
        '# OPENSPEC:START',
        '# OpenSpec',
        '# OPENSPEC:END',
        '# After',
      ].join('\n');

      await fs.writeFile(profilePath, initialContent);

      const result = await installer.removeProfileConfig();

      expect(result).toBe(true);
      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).toContain('# Before');
      expect(content).toContain('# After');
    });

    it('should return false on invalid marker placement', async () => {
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });

      const initialContent = [
        '# OPENSPEC:END',
        '# Config',
        '# OPENSPEC:START',
      ].join('\n');

      await fs.writeFile(profilePath, initialContent);

      const result = await installer.removeProfileConfig();

      expect(result).toBe(false);
    });
  });

  describe('install', () => {
    const mockCompletionScript = `# PowerShell completion script for OpenSpec
$openspecCompleter = {
    param($wordToComplete, $commandAst, $cursorPosition)
    # Completion logic here
}
Register-ArgumentCompleter -CommandName openspec -ScriptBlock $openspecCompleter
`;

    it('should install completion script for the first time', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.message).toContain('installed');
      expect(result.installedPath).toContain('OpenSpecCompletion.ps1');
      expect(result.backupPath).toBeUndefined();
    });

    it('should create parent directories if they do not exist', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      const targetPath = installer.getInstallationPath();
      const fileExists = await fs.access(targetPath).then(() => true).catch(() => false);
      expect(fileExists).toBe(true);
    });

    it('should write completion script content correctly', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const targetPath = installer.getInstallationPath();
      const content = await fs.readFile(targetPath, 'utf-8');
      expect(content).toBe(mockCompletionScript);
    });

    it('should detect when already installed with same content', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script is already installed (up to date)');
      expect(result.backupPath).toBeUndefined();
    });

    it('should update when content is different', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const updatedScript = mockCompletionScript + '\n# Updated version';
      const result = await installer.install(updatedScript);

      expect(result.success).toBe(true);
      expect(result.message).toContain('updated successfully');
      expect(result.backupPath).toBeDefined();
    });

    it('should create backup when updating existing installation', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const updatedScript = mockCompletionScript + '\n# Updated';
      const result = await installer.install(updatedScript);

      expect(result.success).toBe(true);
      expect(result.backupPath).toBeDefined();

      // Verify backup contains original content
      const backupContent = await fs.readFile(result.backupPath!, 'utf-8');
      expect(backupContent).toBe(mockCompletionScript);
    });

    it('should configure PowerShell profile when not disabled', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const result = await installer.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.profileConfigured).toBe(true);
      expect(result.message).toContain('profile configured');
      expect(result.instructions).toBeUndefined();
    });

    // Note: OPENSPEC_NO_AUTO_CONFIG support was removed from PowerShell installer
    // Profile is now always auto-configured if possible

    // Skip on Windows: fs.chmod() doesn't reliably restrict write access on Windows
    // (admin users can bypass read-only attribute, and CI runners often have elevated privileges)
    it.skipIf(process.platform === 'win32')('should provide instructions when profile cannot be configured', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      // Make profile directory read-only to prevent configuration
      const profilePath = installer.getProfilePath();
      await fs.mkdir(path.dirname(profilePath), { recursive: true });
      await fs.writeFile(profilePath, '# Test');
      await fs.chmod(profilePath, 0o444);

      const result = await installer.install(mockCompletionScript);

      // Restore permissions
      await fs.chmod(profilePath, 0o644);

      expect(result.success).toBe(true);
      expect(result.profileConfigured).toBe(false);
      expect(result.instructions).toBeDefined();
      expect(result.instructions!.some(i => i.includes('Test-Path'))).toBe(true);
    });

    it('should include backup path in message when updating', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const updatedScript = mockCompletionScript + '\n# Updated';
      const result = await installer.install(updatedScript);

      expect(result.success).toBe(true);
      expect(result.message).toContain('backed up');
      expect(result.backupPath).toBeDefined();
    });

    it('should handle installation with paths containing spaces', async () => {
      const spacedHomeDir = path.join(os.tmpdir(), `openspec powershell test ${randomUUID()}`);
      await fs.mkdir(spacedHomeDir, { recursive: true });

      const spacedInstaller = new PowerShellInstaller(spacedHomeDir);
      const result = await spacedInstaller.install(mockCompletionScript);

      expect(result.success).toBe(true);
      expect(result.installedPath).toContain('openspec powershell test');

      // Cleanup
      await fs.rm(spacedHomeDir, { recursive: true, force: true });
    });

    // Skip on Windows: fs.chmod() on directories doesn't restrict write access on Windows
    // Windows uses ACLs which Node.js chmod doesn't control
    it.skipIf(process.platform === 'win32')('should return failure on permission error', async () => {
      const targetPath = installer.getInstallationPath();
      const targetDir = path.dirname(targetPath);
      await fs.mkdir(targetDir, { recursive: true });

      // Make target directory read-only to simulate permission error
      await fs.chmod(targetDir, 0o444);

      const result = await installer.install(mockCompletionScript);

      // Restore permissions for cleanup
      await fs.chmod(targetDir, 0o755);

      expect(result.success).toBe(false);
      expect(result.message).toContain('Failed to install completion script');
    });

    it('should handle empty completion script', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const result = await installer.install('');

      expect(result.success).toBe(true);
      const targetPath = installer.getInstallationPath();
      const content = await fs.readFile(targetPath, 'utf-8');
      expect(content).toBe('');
    });

    it('should handle completion script with special characters', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      const specialScript = `# PowerShell with special chars: ' " \` $ @\n$test = "value"`;

      const result = await installer.install(specialScript);

      expect(result.success).toBe(true);
      const targetPath = installer.getInstallationPath();
      const content = await fs.readFile(targetPath, 'utf-8');
      expect(content).toBe(specialScript);
    });
  });

  describe('uninstall', () => {
    const mockCompletionScript = `# PowerShell completion script
$openspecCompleter = {}
Register-ArgumentCompleter -CommandName openspec -ScriptBlock $openspecCompleter
`;

    it('should successfully uninstall when completion script exists', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script uninstalled successfully');
    });

    it('should remove the completion file', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);
      const targetPath = installer.getInstallationPath();

      await installer.uninstall();

      const fileExists = await fs.access(targetPath).then(() => true).catch(() => false);
      expect(fileExists).toBe(false);
    });

    it('should remove profile configuration', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);
      const profilePath = installer.getProfilePath();

      await installer.uninstall();

      const content = await fs.readFile(profilePath, 'utf-8');
      expect(content).not.toContain('# OPENSPEC:START');
      expect(content).not.toContain('# OPENSPEC:END');
    });

    it('should return failure when completion script is not installed', async () => {
      const result = await installer.uninstall();

      expect(result.success).toBe(false);
      expect(result.message).toBe('Completion script is not installed');
    });

    it('should accept yes option parameter', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const result = await installer.uninstall({ yes: true });

      expect(result.success).toBe(true);
      expect(result.message).toBe('Completion script uninstalled successfully');
    });

    it('should handle both script and config removal', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);

      const targetPath = installer.getInstallationPath();
      const profilePath = installer.getProfilePath();

      // Verify both exist
      const scriptExists = await fs.access(targetPath).then(() => true).catch(() => false);
      const profileContent = await fs.readFile(profilePath, 'utf-8');
      expect(scriptExists).toBe(true);
      expect(profileContent).toContain('# OPENSPEC:START');

      await installer.uninstall();

      // Verify both are removed/cleaned
      const scriptExistsAfter = await fs.access(targetPath).then(() => true).catch(() => false);
      const profileContentAfter = await fs.readFile(profilePath, 'utf-8');
      expect(scriptExistsAfter).toBe(false);
      expect(profileContentAfter).not.toContain('# OPENSPEC:START');
    });

    // Skip on Windows: fs.chmod() on directories doesn't restrict write access on Windows
    // Windows uses ACLs which Node.js chmod doesn't control
    it.skipIf(process.platform === 'win32')('should return failure on permission error', async () => {
      delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      await installer.install(mockCompletionScript);
      const targetPath = installer.getInstallationPath();
      const parentDir = path.dirname(targetPath);

      // Make parent directory read-only
      await fs.chmod(parentDir, 0o444);
      const result = await installer.uninstall();

      // Restore permissions
      await fs.chmod(parentDir, 0o755);

      // On some systems, the access check fails which returns "not installed"
      // On others, the unlink fails which returns "Failed to uninstall"
      expect(result.success).toBe(false);
      expect(
        result.message === 'Completion script is not installed' ||
        result.message.includes('Failed to uninstall completion script')
      ).toBe(true);
    });

    it('should handle uninstall when parent directory does not exist', async () => {
      const result = await installer.uninstall();

      expect(result.success).toBe(false);
      expect(result.message).toBe('Completion script is not installed');
    });
  });

});



================================================
FILE: test/core/completions/installers/zsh-installer.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';
import { ZshInstaller } from '../../../../src/core/completions/installers/zsh-installer.js';

describe('ZshInstaller', () => {
  let testHomeDir: string;
  let installer: ZshInstaller;

  beforeEach(async () => {
    // Create a temporary home directory for testing
    testHomeDir = path.join(os.tmpdir(), `openspec-zsh-test-${randomUUID()}`);
    await fs.mkdir(testHomeDir, { recursive: true });
    installer = new ZshInstaller(testHomeDir);
  });

  afterEach(async () => {
    // Clean up test directory
    await fs.rm(testHomeDir, { recursive: true, force: true });
  });

  describe('isOhMyZshInstalled', () => {
    it('should return false when Oh My Zsh is not installed', async () => {
      const isInstalled = await installer.isOhMyZshInstalled();
      expect(isInstalled).toBe(false);
    });

    it('should return true when Oh My Zsh directory exists', async () => {
      // Create .oh-my-zsh directory
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      const isInstalled = await installer.isOhMyZshInstalled();
      expect(isInstalled).toBe(true);
    });

    it('should return false when .oh-my-zsh exists but is a file', async () => {
      // Create .oh-my-zsh as a file instead of directory
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.writeFile(ohMyZshPath, 'not a directory');

      const isInstalled = await installer.isOhMyZshInstalled();
      expect(isInstalled).toBe(false);
    });
  });

  describe('getInstallationPath', () => {
    it('should return Oh My Zsh path when Oh My Zsh is installed', async () => {
      // Create .oh-my-zsh directory
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      const result = await installer.getInstallationPath();

      expect(result.isOhMyZsh).toBe(true);
      expect(result.path).toBe(path.join(testHomeDir, '.oh-my-zsh', 'custom', 'completions', '_openspec'));
    });

    it('should return standard Zsh path when Oh My Zsh is not installed', async () => {
      const result = await installer.getInstallationPath();

      expect(result.isOhMyZsh).toBe(false);
      expect(result.path).toBe(path.join(testHomeDir, '.zsh', 'completions', '_openspec'));
    });
  });

  describe('backupExistingFile', () => {
    it('should return undefined when file does not exist', async () => {
      const nonExistentPath = path.join(testHomeDir, 'nonexistent.txt');
      const backupPath = await installer.backupExistingFile(nonExistentPath);

      expect(backupPath).toBeUndefined();
    });

    it('should create backup when file exists', async () => {
      const filePath = path.join(testHomeDir, 'test.txt');
      await fs.writeFile(filePath, 'original content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toBeDefined();
      expect(backupPath).toContain('.backup-');

      // Verify backup file exists and has correct content
      const backupContent = await fs.readFile(backupPath!, 'utf-8');
      expect(backupContent).toBe('original content');
    });

    it('should create backup with timestamp in filename', async () => {
      const filePath = path.join(testHomeDir, 'test.txt');
      await fs.writeFile(filePath, 'content');

      const backupPath = await installer.backupExistingFile(filePath);

      expect(backupPath).toMatch(/\.backup-\d{4}-\d{2}-\d{2}T\d{2}-\d{2}-\d{2}/);
    });
  });

  describe('install', () => {
    const testScript = '#compdef openspec\n_openspec() {\n  echo "test"\n}\n';

    it('should install to Oh My Zsh path when Oh My Zsh is present', async () => {
      // Create .oh-my-zsh directory
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.isOhMyZsh).toBe(true);
      expect(result.installedPath).toBe(path.join(ohMyZshPath, 'custom', 'completions', '_openspec'));
      expect(result.message).toContain('Oh My Zsh');

      // Verify file was created with correct content
      const content = await fs.readFile(result.installedPath!, 'utf-8');
      expect(content).toBe(testScript);
    });

    it('should install to standard Zsh path when Oh My Zsh is not present', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.isOhMyZsh).toBe(false);
      expect(result.installedPath).toBe(path.join(testHomeDir, '.zsh', 'completions', '_openspec'));

      // Verify file was created
      const content = await fs.readFile(result.installedPath!, 'utf-8');
      expect(content).toBe(testScript);
    });

    it('should create necessary directories if they do not exist', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);

      // Verify directory structure was created
      const completionsDir = path.dirname(result.installedPath!);
      const stat = await fs.stat(completionsDir);
      expect(stat.isDirectory()).toBe(true);
    });

    it('should backup existing file before overwriting', async () => {
      const targetPath = path.join(testHomeDir, '.zsh', 'completions', '_openspec');
      await fs.mkdir(path.dirname(targetPath), { recursive: true });
      await fs.writeFile(targetPath, 'old script');

      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.backupPath).toBeDefined();
      expect(result.backupPath).toContain('.backup-');

      // Verify backup has old content
      const backupContent = await fs.readFile(result.backupPath!, 'utf-8');
      expect(backupContent).toBe('old script');

      // Verify new file has new content
      const newContent = await fs.readFile(targetPath, 'utf-8');
      expect(newContent).toBe(testScript);
    });

    it('should include fpath verification guidance for Oh My Zsh', async () => {
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      const result = await installer.install(testScript);

      expect(result.instructions).toBeDefined();
      expect(result.instructions!.length).toBeGreaterThan(0);
      // Should include guidance about verifying fpath for Oh My Zsh
      expect(result.instructions!.join(' ')).toContain('fpath');
      expect(result.instructions!.join(' ')).toContain('custom/completions');
    });

    it('should include fpath instructions for standard Zsh when auto-config is disabled', async () => {
      const originalEnv = process.env.OPENSPEC_NO_AUTO_CONFIG;
      process.env.OPENSPEC_NO_AUTO_CONFIG = '1';

      const result = await installer.install(testScript);

      expect(result.instructions).toBeDefined();
      expect(result.instructions!.join('\n')).toContain('fpath');
      expect(result.instructions!.join('\n')).toContain('.zshrc');
      expect(result.instructions!.join('\n')).toContain('compinit');

      // Restore env
      if (originalEnv === undefined) {
        delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      } else {
        process.env.OPENSPEC_NO_AUTO_CONFIG = originalEnv;
      }
    });

    it('should handle installation errors gracefully', async () => {
      // Create installer with non-existent/invalid home directory
      // Use a path that will fail on both Unix and Windows
      const invalidPath = process.platform === 'win32'
        ? 'Z:\\nonexistent\\invalid\\path'  // Non-existent drive letter on Windows
        : '/root/invalid/nonexistent/path';  // Permission-denied path on Unix
      const invalidInstaller = new ZshInstaller(invalidPath);

      const result = await invalidInstaller.install(testScript);

      expect(result.success).toBe(false);
      expect(result.message).toContain('Failed to install');
    });

    it('should detect already-installed completion with identical content', async () => {
      // First installation
      const firstResult = await installer.install(testScript);
      expect(firstResult.success).toBe(true);

      // Second installation with same script
      const secondResult = await installer.install(testScript);

      expect(secondResult.success).toBe(true);
      expect(secondResult.message).toContain('already installed');
      expect(secondResult.message).toContain('up to date');
      expect(secondResult.backupPath).toBeUndefined();
      expect(secondResult.instructions).toBeDefined();
      expect(secondResult.instructions!.join(' ')).toContain('already installed');
    });

    it('should update completion when content differs', async () => {
      // First installation
      const firstScript = '#compdef openspec\n_openspec() {\n  echo "version 1"\n}\n';
      const firstResult = await installer.install(firstScript);
      expect(firstResult.success).toBe(true);

      // Second installation with different script
      const secondScript = '#compdef openspec\n_openspec() {\n  echo "version 2"\n}\n';
      const secondResult = await installer.install(secondScript);

      expect(secondResult.success).toBe(true);
      expect(secondResult.message).toContain('updated successfully');
      expect(secondResult.message).toContain('backed up');
      expect(secondResult.backupPath).toBeDefined();

      // Verify new content was written
      const content = await fs.readFile(secondResult.installedPath!, 'utf-8');
      expect(content).toBe(secondScript);

      // Verify backup has old content
      const backupContent = await fs.readFile(secondResult.backupPath!, 'utf-8');
      expect(backupContent).toBe(firstScript);
    });

    it('should handle paths with spaces in .zshrc config', async () => {
      // Create a test home directory with spaces
      const testHomeDirWithSpaces = path.join(os.tmpdir(), `openspec zsh test ${randomUUID()}`);
      await fs.mkdir(testHomeDirWithSpaces, { recursive: true });
      const installerWithSpaces = new ZshInstaller(testHomeDirWithSpaces);

      try {
        const result = await installerWithSpaces.install(testScript);
        expect(result.success).toBe(true);

        // Check if .zshrc was created (when auto-config is enabled)
        const zshrcPath = path.join(testHomeDirWithSpaces, '.zshrc');
        try {
          const zshrcContent = await fs.readFile(zshrcPath, 'utf-8');
          // Verify the path is quoted in fpath
          expect(zshrcContent).toContain(`fpath=("${path.dirname(result.installedPath!)}" $fpath)`);
        } catch {
          // .zshrc might not exist if auto-config was disabled
        }
      } finally {
        // Clean up
        await fs.rm(testHomeDirWithSpaces, { recursive: true, force: true });
      }
    });
  });

  describe('uninstall', () => {
    const testScript = '#compdef openspec\n_openspec() {}\n';

    it('should remove installed completion script', async () => {
      // Install first
      await installer.install(testScript);

      // Verify it's installed
      const beforeUninstall = await installer.isInstalled();
      expect(beforeUninstall).toBe(true);

      // Uninstall
      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toContain('removed');

      // Verify it's gone
      const afterUninstall = await installer.isInstalled();
      expect(afterUninstall).toBe(false);
    });

    it('should return failure when script and .zshrc config are not installed', async () => {
      // Don't create .zshrc or completion script - nothing to remove
      const result = await installer.uninstall();

      expect(result.success).toBe(false);
      expect(result.message).toContain('not installed');
    });

    it('should remove from correct location for Oh My Zsh', async () => {
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      await installer.install(testScript);

      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toContain(path.join('.oh-my-zsh', 'custom', 'completions', '_openspec'));
    });
  });

  describe('isInstalled', () => {
    const testScript = '#compdef openspec\n_openspec() {}\n';

    it('should return false when not installed', async () => {
      const isInstalled = await installer.isInstalled();
      expect(isInstalled).toBe(false);
    });

    it('should return true when installed', async () => {
      await installer.install(testScript);

      const isInstalled = await installer.isInstalled();
      expect(isInstalled).toBe(true);
    });

    it('should check correct location for Oh My Zsh', async () => {
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      await installer.install(testScript);

      const isInstalled = await installer.isInstalled();
      expect(isInstalled).toBe(true);
    });
  });

  describe('getInstallationInfo', () => {
    const testScript = '#compdef openspec\n_openspec() {}\n';

    it('should return not installed when script does not exist', async () => {
      const info = await installer.getInstallationInfo();

      expect(info.installed).toBe(false);
      expect(info.path).toBeUndefined();
      expect(info.isOhMyZsh).toBeUndefined();
    });

    it('should return installation info when installed', async () => {
      await installer.install(testScript);

      const info = await installer.getInstallationInfo();

      expect(info.installed).toBe(true);
      expect(info.path).toBeDefined();
      expect(info.path).toContain('_openspec');
      expect(info.isOhMyZsh).toBe(false);
    });

    it('should indicate Oh My Zsh when installed there', async () => {
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      await installer.install(testScript);

      const info = await installer.getInstallationInfo();

      expect(info.installed).toBe(true);
      expect(info.isOhMyZsh).toBe(true);
      expect(info.path).toContain('.oh-my-zsh');
    });
  });

  describe('constructor', () => {
    it('should use provided home directory', () => {
      const customInstaller = new ZshInstaller('/custom/home');
      expect(customInstaller).toBeDefined();
    });

    it('should use os.homedir() by default', () => {
      const defaultInstaller = new ZshInstaller();
      expect(defaultInstaller).toBeDefined();
    });
  });

  describe('configureZshrc', () => {
    const completionsDir = '/test/.zsh/completions';

    it('should create .zshrc with markers and config when file does not exist', async () => {
      const result = await installer.configureZshrc(completionsDir);

      expect(result).toBe(true);

      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const content = await fs.readFile(zshrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain('# OpenSpec shell completions configuration');
      expect(content).toContain(`fpath=("${completionsDir}" $fpath)`);
      expect(content).toContain('autoload -Uz compinit');
      expect(content).toContain('compinit');
    });

    it('should prepend markers and config when .zshrc exists without markers', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      await fs.writeFile(zshrcPath, '# My custom zsh config\nalias ll="ls -la"\n');

      const result = await installer.configureZshrc(completionsDir);

      expect(result).toBe(true);

      const content = await fs.readFile(zshrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain('# My custom zsh config');
      expect(content).toContain('alias ll="ls -la"');

      // Config should be before existing content
      const configIndex = content.indexOf('# OPENSPEC:START');
      const aliasIndex = content.indexOf('alias ll');
      expect(configIndex).toBeLessThan(aliasIndex);
    });

    it('should update config between markers when .zshrc has existing markers', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const initialContent = [
        '# OPENSPEC:START',
        '# Old config',
        'fpath=(/old/path $fpath)',
        '# OPENSPEC:END',
        '',
        '# My custom config',
      ].join('\n');

      await fs.writeFile(zshrcPath, initialContent);

      const result = await installer.configureZshrc(completionsDir);

      expect(result).toBe(true);

      const content = await fs.readFile(zshrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('# OPENSPEC:END');
      expect(content).toContain(`fpath=("${completionsDir}" $fpath)`);
      expect(content).not.toContain('# Old config');
      expect(content).not.toContain('/old/path');
      expect(content).toContain('# My custom config');
    });

    it('should preserve user content outside markers', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const userContent = [
        '# My zsh config',
        'export PATH="/custom/path:$PATH"',
        '',
        '# OPENSPEC:START',
        '# Old OpenSpec config',
        '# OPENSPEC:END',
        '',
        'alias ls="ls -G"',
      ].join('\n');

      await fs.writeFile(zshrcPath, userContent);

      const result = await installer.configureZshrc(completionsDir);

      expect(result).toBe(true);

      const content = await fs.readFile(zshrcPath, 'utf-8');

      expect(content).toContain('# My zsh config');
      expect(content).toContain('export PATH="/custom/path:$PATH"');
      expect(content).toContain('alias ls="ls -G"');
      expect(content).toContain(`fpath=("${completionsDir}" $fpath)`);
      expect(content).not.toContain('# Old OpenSpec config');
    });

    it('should return false when OPENSPEC_NO_AUTO_CONFIG is set', async () => {
      const originalEnv = process.env.OPENSPEC_NO_AUTO_CONFIG;
      process.env.OPENSPEC_NO_AUTO_CONFIG = '1';

      const result = await installer.configureZshrc(completionsDir);

      expect(result).toBe(false);

      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const exists = await fs.access(zshrcPath).then(() => true).catch(() => false);
      expect(exists).toBe(false);

      // Restore env
      if (originalEnv === undefined) {
        delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      } else {
        process.env.OPENSPEC_NO_AUTO_CONFIG = originalEnv;
      }
    });

    it('should handle write permission errors gracefully', async () => {
      // Create installer with path that can't be written
      // Use a path that will fail on both Unix and Windows
      const invalidPath = process.platform === 'win32'
        ? 'Z:\\nonexistent\\invalid\\path'  // Non-existent drive letter on Windows
        : '/root/invalid/path';  // Permission-denied path on Unix
      const invalidInstaller = new ZshInstaller(invalidPath);

      const result = await invalidInstaller.configureZshrc(completionsDir);

      expect(result).toBe(false);
    });
  });

  describe('removeZshrcConfig', () => {
    it('should return true when .zshrc does not exist', async () => {
      const result = await installer.removeZshrcConfig();
      expect(result).toBe(true);
    });

    it('should return true when .zshrc exists but has no markers', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      await fs.writeFile(zshrcPath, '# My custom config\nalias ll="ls -la"\n');

      const result = await installer.removeZshrcConfig();

      expect(result).toBe(true);

      // Content should be unchanged
      const content = await fs.readFile(zshrcPath, 'utf-8');
      expect(content).toBe('# My custom config\nalias ll="ls -la"\n');
    });

    it('should remove markers and config when present', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const content = [
        '# My config',
        '',
        '# OPENSPEC:START',
        '# OpenSpec shell completions configuration',
        'fpath=(~/.zsh/completions $fpath)',
        'autoload -Uz compinit',
        'compinit',
        '# OPENSPEC:END',
        '',
        'alias ll="ls -la"',
      ].join('\n');

      await fs.writeFile(zshrcPath, content);

      const result = await installer.removeZshrcConfig();

      expect(result).toBe(true);

      const newContent = await fs.readFile(zshrcPath, 'utf-8');

      expect(newContent).not.toContain('# OPENSPEC:START');
      expect(newContent).not.toContain('# OPENSPEC:END');
      expect(newContent).not.toContain('OpenSpec shell completions');
      expect(newContent).toContain('# My config');
      expect(newContent).toContain('alias ll="ls -la"');
    });

    it('should remove leading empty lines when markers were at top', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const content = [
        '# OPENSPEC:START',
        '# OpenSpec config',
        '# OPENSPEC:END',
        '',
        '# User config below',
      ].join('\n');

      await fs.writeFile(zshrcPath, content);

      const result = await installer.removeZshrcConfig();

      expect(result).toBe(true);

      const newContent = await fs.readFile(zshrcPath, 'utf-8');

      // Should not start with empty lines
      expect(newContent).toBe('# User config below');
    });

    it('should handle invalid marker placement gracefully', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');

      // End marker before start marker
      await fs.writeFile(zshrcPath, '# OPENSPEC:END\n# OPENSPEC:START\n');

      const result = await installer.removeZshrcConfig();

      expect(result).toBe(false);
    });

    it('should return true when only one marker is present', async () => {
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      await fs.writeFile(zshrcPath, '# OPENSPEC:START\nsome config\n');

      const result = await installer.removeZshrcConfig();

      // Should return true (markers don't exist as a pair)
      expect(result).toBe(true);
    });
  });

  describe('install with .zshrc auto-configuration', () => {
    const testScript = '#compdef openspec\n_openspec() {}\n';

    it('should auto-configure .zshrc for standard Zsh', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.zshrcConfigured).toBe(true);

      // Verify .zshrc was created
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const content = await fs.readFile(zshrcPath, 'utf-8');

      expect(content).toContain('# OPENSPEC:START');
      expect(content).toContain('fpath=');
      expect(content).toContain('compinit');
    });

    it('should configure .zshrc for Oh My Zsh when fpath is missing', async () => {
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.isOhMyZsh).toBe(true);
      // Should configure .zshrc if fpath doesn't already include the directory
      expect(result.zshrcConfigured).toBe(true);

      // Verify .zshrc was created with fpath configuration
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      const exists = await fs.access(zshrcPath).then(() => true).catch(() => false);
      expect(exists).toBe(true);

      if (exists) {
        const content = await fs.readFile(zshrcPath, 'utf-8');
        expect(content).toContain('fpath=');
        // Check for custom/completions or custom\completions (Windows path separator)
        expect(content).toMatch(/custom[/\\]completions/);
      }
    });

    it('should not include manual instructions when .zshrc was auto-configured', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.zshrcConfigured).toBe(true);
      expect(result.instructions).toBeUndefined();
    });

    it('should include instructions when .zshrc auto-config fails', async () => {
      const originalEnv = process.env.OPENSPEC_NO_AUTO_CONFIG;
      process.env.OPENSPEC_NO_AUTO_CONFIG = '1';

      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.zshrcConfigured).toBe(false);
      expect(result.instructions).toBeDefined();
      expect(result.instructions!.join('\n')).toContain('fpath');

      // Restore env
      if (originalEnv === undefined) {
        delete process.env.OPENSPEC_NO_AUTO_CONFIG;
      } else {
        process.env.OPENSPEC_NO_AUTO_CONFIG = originalEnv;
      }
    });

    it('should update success message when .zshrc is configured', async () => {
      const result = await installer.install(testScript);

      expect(result.success).toBe(true);
      expect(result.message).toContain('.zshrc configured');
    });
  });

  describe('uninstall with .zshrc cleanup', () => {
    const testScript = '#compdef openspec\n_openspec() {}\n';

    it('should remove .zshrc config when uninstalling', async () => {
      // Install first (which creates .zshrc config)
      await installer.install(testScript);

      // Verify .zshrc was configured
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      let content = await fs.readFile(zshrcPath, 'utf-8');
      expect(content).toContain('# OPENSPEC:START');

      // Uninstall
      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toContain('Removed OpenSpec configuration from ~/.zshrc');

      // Verify .zshrc config was removed
      content = await fs.readFile(zshrcPath, 'utf-8');
      expect(content).not.toContain('# OPENSPEC:START');
    });

    it('should not remove .zshrc config for Oh My Zsh users', async () => {
      const ohMyZshPath = path.join(testHomeDir, '.oh-my-zsh');
      await fs.mkdir(ohMyZshPath, { recursive: true });

      await installer.install(testScript);

      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).not.toContain('.zshrc');
    });

    it('should succeed even if only .zshrc config is removed', async () => {
      // Manually create .zshrc config without installing completion script
      const zshrcPath = path.join(testHomeDir, '.zshrc');
      await fs.writeFile(zshrcPath, '# OPENSPEC:START\nconfig\n# OPENSPEC:END\n');

      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toContain('Removed OpenSpec configuration from ~/.zshrc');
    });

    it('should include both messages when removing script and .zshrc', async () => {
      await installer.install(testScript);

      const result = await installer.uninstall();

      expect(result.success).toBe(true);
      expect(result.message).toContain('Completion script removed');
      expect(result.message).toContain('Removed OpenSpec configuration from ~/.zshrc');
    });
  });
});



================================================
FILE: test/core/converters/json-converter.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import { JsonConverter } from '../../../src/core/converters/json-converter.js';

describe('JsonConverter', () => {
  const testDir = path.join(process.cwd(), 'test-json-converter-tmp');
  const converter = new JsonConverter();
  
  beforeEach(async () => {
    await fs.mkdir(testDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('convertSpecToJson', () => {
    it('should convert a spec to JSON format', async () => {
      const specContent = `# User Authentication Spec

## Purpose
This specification defines the requirements for user authentication.

## Requirements

### The system SHALL provide secure user authentication
Users need to be able to log in securely.

#### Scenario: Successful login
Given a user with valid credentials
When they submit the login form
Then they are authenticated`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);
      
      const json = converter.convertSpecToJson(specPath);
      const parsed = JSON.parse(json);
      
      expect(parsed.name).toBe('spec');
      expect(parsed.overview).toContain('user authentication');
      expect(parsed.requirements).toHaveLength(1);
      expect(parsed.requirements[0].scenarios).toHaveLength(1);
      expect(parsed.metadata).toBeDefined();
      expect(parsed.metadata.format).toBe('openspec');
      expect(parsed.metadata.sourcePath).toBe(specPath);
    });

    it('should extract spec name from directory structure', async () => {
      const specsDir = path.join(testDir, 'specs', 'user-auth');
      await fs.mkdir(specsDir, { recursive: true });
      
      const specContent = `# User Auth

## Purpose
Auth spec overview

## Requirements

### The system SHALL authenticate users

#### Scenario: Login
Given a user
When they login
Then authenticated`;

      const specPath = path.join(specsDir, 'spec.md');
      await fs.writeFile(specPath, specContent);
      
      const json = converter.convertSpecToJson(specPath);
      const parsed = JSON.parse(json);
      
      expect(parsed.name).toBe('user-auth');
    });
  });

  describe('convertChangeToJson', () => {
    it('should convert a change to JSON format', async () => {
      const changeContent = `# Add User Authentication

## Why
We need to implement user authentication to secure the application and protect user data from unauthorized access.

## What Changes
- **user-auth:** Add new user authentication specification
- **api-endpoints:** Modify to include authentication endpoints`;

      const changePath = path.join(testDir, 'change.md');
      await fs.writeFile(changePath, changeContent);
      
      const json = await converter.convertChangeToJson(changePath);
      const parsed = JSON.parse(json);
      
      expect(parsed.name).toBe('change');
      expect(parsed.why).toContain('secure the application');
      expect(parsed.deltas).toHaveLength(2);
      expect(parsed.deltas[0].spec).toBe('user-auth');
      expect(parsed.deltas[0].operation).toBe('ADDED');
      expect(parsed.metadata).toBeDefined();
      expect(parsed.metadata.format).toBe('openspec-change');
      expect(parsed.metadata.sourcePath).toBe(changePath);
    });

    it('should extract change name from directory structure', async () => {
      const changesDir = path.join(testDir, 'changes', 'add-auth');
      await fs.mkdir(changesDir, { recursive: true });
      
      const changeContent = `# Add Auth

## Why
We need authentication for security reasons and to protect user data properly.

## What Changes
- **auth:** Add authentication`;

      const changePath = path.join(changesDir, 'proposal.md');
      await fs.writeFile(changePath, changeContent);
      
      const json = await converter.convertChangeToJson(changePath);
      const parsed = JSON.parse(json);
      
      expect(parsed.name).toBe('add-auth');
    });
  });

  describe('JSON formatting', () => {
    it('should produce properly formatted JSON with indentation', async () => {
      const specContent = `# Test

## Purpose
Test overview

## Requirements

### The system SHALL test

#### Scenario: Test
Given test
When action
Then result`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);
      
      const json = converter.convertSpecToJson(specPath);
      
      // Check for proper indentation (2 spaces)
      expect(json).toContain('  "name"');
      expect(json).toContain('  "overview"');
      expect(json).toContain('  "requirements"');
      
      // Check it's valid JSON
      expect(() => JSON.parse(json)).not.toThrow();
    });

    it('should handle special characters in content', async () => {
      const specContent = `# Test

## Purpose
This has "quotes" and \\ backslashes and
newlines

## Requirements

### The system SHALL handle "special" characters

#### Scenario: Special chars
Given a string with "quotes"
When processing \\ backslash
Then handle correctly`;

      const specPath = path.join(testDir, 'spec.md');
      await fs.writeFile(specPath, specContent);
      
      const json = converter.convertSpecToJson(specPath);
      const parsed = JSON.parse(json);
      
      expect(parsed.overview).toContain('"quotes"');
      expect(parsed.overview).toContain('\\');
      expect(parsed.requirements[0].text).toContain('"special"');
    });
  });
});


================================================
FILE: test/core/parsers/change-parser.test.ts
================================================
import { describe, it, expect } from 'vitest';
import path from 'path';
import { promises as fs } from 'fs';
import os from 'os';
import { ChangeParser } from '../../../src/core/parsers/change-parser.js';

async function withTempDir(run: (dir: string) => Promise<void>) {
  const dir = await fs.mkdtemp(path.join(os.tmpdir(), 'openspec-change-parser-'));
  try {
    await run(dir);
  } finally {
    // Best-effort cleanup
    try { await fs.rm(dir, { recursive: true, force: true }); } catch {}
  }
}

describe('ChangeParser', () => {
  it('parses simple What Changes bullet list', async () => {
    const content = `# Test Change\n\n## Why\nWe need it because reasons that are sufficiently long.\n\n## What Changes\n- **spec-a:** Add a new requirement to A\n- **spec-b:** Rename requirement X to Y\n- **spec-c:** Remove obsolete requirement`;

    const parser = new ChangeParser(content, process.cwd());
    const change = await parser.parseChangeWithDeltas('test-change');

    expect(change.name).toBe('test-change');
    expect(change.deltas.length).toBe(3);
    expect(change.deltas[0].spec).toBe('spec-a');
    expect(['ADDED', 'MODIFIED', 'REMOVED', 'RENAMED']).toContain(change.deltas[1].operation);
  });

  it('prefers delta-format specs over simple bullets when both exist', async () => {
    await withTempDir(async (dir) => {
      const changeDir = dir;
      const specsDir = path.join(changeDir, 'specs', 'foo');
      await fs.mkdir(specsDir, { recursive: true });

      const content = `# Test Change\n\n## Why\nWe need it because reasons that are sufficiently long.\n\n## What Changes\n- **foo:** Add something via bullets (should be overridden)`;
      const deltaSpec = `# Delta for Foo\n\n## ADDED Requirements\n\n### Requirement: New thing\n\n#### Scenario: basic\nGiven X\nWhen Y\nThen Z`;

      await fs.writeFile(path.join(specsDir, 'spec.md'), deltaSpec, 'utf8');

      const parser = new ChangeParser(content, changeDir);
      const change = await parser.parseChangeWithDeltas('test-change');

      expect(change.deltas.length).toBeGreaterThan(0);
      // Since delta spec exists, the description should reflect delta-derived entries
      expect(change.deltas[0].spec).toBe('foo');
      expect(change.deltas[0].description).toContain('Add requirement:');
      expect(change.deltas[0].operation).toBe('ADDED');
      expect(change.deltas[0].requirement).toBeDefined();
    });
  });
});



================================================
FILE: test/core/parsers/markdown-parser.test.ts
================================================
import { describe, it, expect } from 'vitest';
import { MarkdownParser } from '../../../src/core/parsers/markdown-parser.js';

describe('MarkdownParser', () => {
  describe('parseSpec', () => {
    it('should parse a valid spec', () => {
      const content = `# User Authentication Spec

## Purpose
This specification defines the requirements for user authentication.

## Requirements

### The system SHALL provide secure user authentication
Users need to be able to log in securely.

#### Scenario: Successful login
Given a user with valid credentials
When they submit the login form
Then they are authenticated

### The system SHALL handle invalid login attempts
The system must handle incorrect credentials.

#### Scenario: Invalid credentials
Given a user with invalid credentials
When they submit the login form
Then they see an error message`;

      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec('user-auth');
      
      expect(spec.name).toBe('user-auth');
      expect(spec.overview).toContain('requirements for user authentication');
      expect(spec.requirements).toHaveLength(2);
      
      const firstReq = spec.requirements[0];
      expect(firstReq.text).toBe('Users need to be able to log in securely.');
      expect(firstReq.scenarios).toHaveLength(1);
      
      const scenario = firstReq.scenarios[0];
      expect(scenario.rawText).toContain('Given a user with valid credentials');
      expect(scenario.rawText).toContain('When they submit the login form');
      expect(scenario.rawText).toContain('Then they are authenticated');
    });

    it('should handle multi-line scenarios', () => {
      const content = `# Test Spec

## Purpose
Test overview

## Requirements

### The system SHALL handle complex scenarios
This requirement has content.

#### Scenario: Multi-line scenario
Given a user with valid credentials
  and the user has admin privileges
  and the system is in maintenance mode
When they attempt to login
  and provide their MFA token
Then they are authenticated
  and redirected to admin dashboard
  and see a maintenance warning`;

      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec('test');
      
      const scenario = spec.requirements[0].scenarios[0];
      expect(scenario.rawText).toContain('Given a user with valid credentials');
      expect(scenario.rawText).toContain('and the user has admin privileges');
      expect(scenario.rawText).toContain('When they attempt to login');
      expect(scenario.rawText).toContain('and provide their MFA token');
      expect(scenario.rawText).toContain('Then they are authenticated');
      expect(scenario.rawText).toContain('and see a maintenance warning');
    });

    it('should throw error for missing overview', () => {
      const content = `# Test Spec

## Requirements

### The system SHALL do something

#### Scenario: Test
Given test
When action
Then result`;

      const parser = new MarkdownParser(content);
      expect(() => parser.parseSpec('test')).toThrow('must have a Purpose section');
    });

    it('should throw error for missing requirements', () => {
      const content = `# Test Spec

## Purpose
This is a test spec`;

      const parser = new MarkdownParser(content);
      expect(() => parser.parseSpec('test')).toThrow('must have a Requirements section');
    });
  });

  describe('parseChange', () => {
    it('should parse a valid change', () => {
      const content = `# Add User Authentication

## Why
We need to implement user authentication to secure the application and protect user data from unauthorized access.

## What Changes
- **user-auth:** Add new user authentication specification
- **api-endpoints:** Modify to include authentication endpoints
- **database:** Remove old session management tables`;

      const parser = new MarkdownParser(content);
      const change = parser.parseChange('add-user-auth');
      
      expect(change.name).toBe('add-user-auth');
      expect(change.why).toContain('secure the application');
      expect(change.whatChanges).toContain('user-auth');
      expect(change.deltas).toHaveLength(3);
      
      expect(change.deltas[0].spec).toBe('user-auth');
      expect(change.deltas[0].operation).toBe('ADDED');
      expect(change.deltas[0].description).toContain('Add new user authentication');
      
      expect(change.deltas[1].spec).toBe('api-endpoints');
      expect(change.deltas[1].operation).toBe('MODIFIED');
      
      expect(change.deltas[2].spec).toBe('database');
      expect(change.deltas[2].operation).toBe('REMOVED');
    });

    it('should throw error for missing why section', () => {
      const content = `# Test Change

## What Changes
- **test:** Add test`;

      const parser = new MarkdownParser(content);
      expect(() => parser.parseChange('test')).toThrow('must have a Why section');
    });

    it('should throw error for missing what changes section', () => {
      const content = `# Test Change

## Why
Because we need it`;

      const parser = new MarkdownParser(content);
      expect(() => parser.parseChange('test')).toThrow('must have a What Changes section');
    });

    it('should handle changes without deltas', () => {
      const content = `# Test Change

## Why
We need to make some changes for important reasons that justify this work.

## What Changes
Some general description of changes without specific deltas`;

      const parser = new MarkdownParser(content);
      const change = parser.parseChange('test');
      
      expect(change.deltas).toHaveLength(0);
    });

    it('parses change documents saved with CRLF line endings', () => {
      const crlfContent = [
        '# CRLF Change',
        '',
        '## Why',
        'Reasons on Windows editors should parse like POSIX environments.',
        '',
        '## What Changes',
        '- **alpha:** Add cross-platform parsing coverage',
      ].join('\r\n');

      const parser = new MarkdownParser(crlfContent);
      const change = parser.parseChange('crlf-change');

      expect(change.why).toContain('Windows editors should parse');
      expect(change.deltas).toHaveLength(1);
      expect(change.deltas[0].spec).toBe('alpha');
    });
  });

  describe('section parsing', () => {
    it('should handle nested sections correctly', () => {
      const content = `# Test Spec

## Purpose
This is the overview section for testing nested sections.

## Requirements

### The system SHALL handle nested sections

#### Scenario: Test nested
Given a nested structure
When parsing sections
Then handle correctly

### Another requirement SHALL work

#### Scenario: Another test
Given another test
When running
Then success`;

      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec('test');
      
      // Should find the correct sections at different levels
      expect(spec).toBeDefined();
      expect(spec.overview).toContain('testing nested sections');
      expect(spec.requirements).toHaveLength(2);
    });

    it('should preserve content between headers', () => {
      const content = `# Test

## Purpose
This is the overview.
It has multiple lines.

Some more content here.

## Requirements

### Requirement 1
Content for requirement 1`;

      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec('test');
      
      expect(spec.overview).toContain('multiple lines');
      expect(spec.overview).toContain('more content');
    });

    it('should use requirement heading as fallback when no content is provided', () => {
      const content = `# Test Spec

## Purpose
Test overview

## Requirements

### The system SHALL use heading text when no content

#### Scenario: Test
Given test
When action
Then result`;

      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec('test');
      
      expect(spec.requirements[0].text).toBe('The system SHALL use heading text when no content');
    });

    it('should extract requirement text from first non-empty content line', () => {
      const content = `# Test Spec

## Purpose
Test overview

## Requirements

### Requirement heading

This is the actual requirement text.
This is additional description.

#### Scenario: Test
Given test
When action
Then result`;

      const parser = new MarkdownParser(content);
      const spec = parser.parseSpec('test');
      
      expect(spec.requirements[0].text).toBe('This is the actual requirement text.');
    });
  });
});


================================================
FILE: test/fixtures/tmp-init/openspec/changes/c1/proposal.md
================================================
# Test Change

## Why
Because reasons that are sufficiently long for validation.

## What Changes
- **alpha:** Add something



================================================
FILE: test/fixtures/tmp-init/openspec/changes/c1/specs/alpha/spec.md
================================================
## ADDED Requirements
### Requirement: Parser SHALL accept CRLF change proposals
The parser SHALL accept CRLF change proposals without manual edits.

#### Scenario: Validate CRLF change
- **GIVEN** a change proposal saved with CRLF line endings
- **WHEN** a developer runs openspec validate on the proposal
- **THEN** validation succeeds without section errors



================================================
FILE: test/fixtures/tmp-init/openspec/specs/alpha/spec.md
================================================
## Purpose
This spec ensures the validation harness exercises a deterministic alpha module for automated tests.

## Requirements

### Requirement: Alpha module SHALL produce deterministic output
The alpha module SHALL produce a deterministic response for validation.

#### Scenario: Deterministic alpha run
- **GIVEN** a configured alpha module
- **WHEN** the module runs the default flow
- **THEN** the output matches the expected fixture result



================================================
FILE: test/helpers/run-cli.ts
================================================
import { spawn } from 'child_process';
import { existsSync } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const projectRoot = path.resolve(__dirname, '..', '..');
const cliEntry = path.join(projectRoot, 'dist', 'cli', 'index.js');

let buildPromise: Promise<void> | undefined;

interface RunCommandOptions {
  cwd?: string;
  env?: NodeJS.ProcessEnv;
}

interface RunCLIOptions {
  cwd?: string;
  env?: NodeJS.ProcessEnv;
  input?: string;
  timeoutMs?: number;
}

export interface RunCLIResult {
  exitCode: number | null;
  signal: NodeJS.Signals | null;
  stdout: string;
  stderr: string;
  timedOut: boolean;
  command: string;
}

function runCommand(command: string, args: string[], options: RunCommandOptions = {}) {
  return new Promise<void>((resolve, reject) => {
    const child = spawn(command, args, {
      cwd: options.cwd ?? projectRoot,
      env: { ...process.env, ...options.env },
      stdio: 'inherit',
      shell: process.platform === 'win32',
    });

    child.on('error', (error) => reject(error));
    child.on('close', (code, signal) => {
      if (code === 0) {
        resolve();
      } else {
        const reason = signal ? `signal ${signal}` : `exit code ${code}`;
        reject(new Error(`Command failed (${reason}): ${command} ${args.join(' ')}`));
      }
    });
  });
}

export async function ensureCliBuilt() {
  if (existsSync(cliEntry)) {
    return;
  }

  if (!buildPromise) {
    buildPromise = runCommand('pnpm', ['run', 'build']).catch((error) => {
      buildPromise = undefined;
      throw error;
    });
  }

  await buildPromise;

  if (!existsSync(cliEntry)) {
    throw new Error('CLI entry point missing after build. Expected dist/cli/index.js');
  }
}

export async function runCLI(args: string[] = [], options: RunCLIOptions = {}): Promise<RunCLIResult> {
  await ensureCliBuilt();

  const finalArgs = Array.isArray(args) ? args : [args];
  const invocation = [cliEntry, ...finalArgs].join(' ');

  return new Promise<RunCLIResult>((resolve, reject) => {
    const child = spawn(process.execPath, [cliEntry, ...finalArgs], {
      cwd: options.cwd ?? projectRoot,
      env: {
        ...process.env,
        OPEN_SPEC_INTERACTIVE: '0',
        ...options.env,
      },
      stdio: ['pipe', 'pipe', 'pipe'],
      windowsHide: true,
    });

    // Prevent child process from keeping the event loop alive
    child.unref();

    let stdout = '';
    let stderr = '';
    let timedOut = false;

    const timeout = options.timeoutMs
      ? setTimeout(() => {
          timedOut = true;
          child.kill('SIGKILL');
        }, options.timeoutMs)
      : undefined;

    child.stdout?.setEncoding('utf-8');
    child.stdout?.on('data', (chunk) => {
      stdout += chunk;
    });

    child.stderr?.setEncoding('utf-8');
    child.stderr?.on('data', (chunk) => {
      stderr += chunk;
    });

    child.on('error', (error) => {
      if (timeout) clearTimeout(timeout);
      // Explicitly destroy streams to prevent hanging handles
      child.stdout?.destroy();
      child.stderr?.destroy();
      child.stdin?.destroy();
      reject(error);
    });

    child.on('close', (code, signal) => {
      if (timeout) clearTimeout(timeout);
      // Explicitly destroy streams to prevent hanging handles
      child.stdout?.destroy();
      child.stderr?.destroy();
      child.stdin?.destroy();
      resolve({
        exitCode: code,
        signal,
        stdout,
        stderr,
        timedOut,
        command: `node ${invocation}`,
      });
    });

    if (options.input && child.stdin) {
      child.stdin.end(options.input);
    } else if (child.stdin) {
      child.stdin.end();
    }
  });
}

export const cliProjectRoot = projectRoot;



================================================
FILE: test/telemetry/config.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';

import {
  getConfigPath,
  readConfig,
  writeConfig,
  getTelemetryConfig,
  updateTelemetryConfig,
} from '../../src/telemetry/config.js';

describe('telemetry/config', () => {
  let tempDir: string;
  let originalHome: string | undefined;
  let originalUserProfile: string | undefined;

  beforeEach(() => {
    // Create temp directory for tests
    tempDir = path.join(os.tmpdir(), `openspec-telemetry-test-${Date.now()}`);
    fs.mkdirSync(tempDir, { recursive: true });

    // Mock HOME/USERPROFILE to point to temp dir
    // On POSIX, os.homedir() uses HOME; on Windows it uses USERPROFILE
    originalHome = process.env.HOME;
    originalUserProfile = process.env.USERPROFILE;
    process.env.HOME = tempDir;
    process.env.USERPROFILE = tempDir;
  });

  afterEach(() => {
    // Restore HOME/USERPROFILE
    process.env.HOME = originalHome;
    process.env.USERPROFILE = originalUserProfile;

    // Clean up temp directory
    fs.rmSync(tempDir, { recursive: true, force: true });
  });

  describe('getConfigPath', () => {
    it('should return path to config.json in .config/openspec', () => {
      const result = getConfigPath();
      expect(result).toBe(path.join(tempDir, '.config', 'openspec', 'config.json'));
    });
  });

  describe('readConfig', () => {
    it('should return empty object when config file does not exist', async () => {
      const config = await readConfig();
      expect(config).toEqual({});
    });

    it('should load valid config from file', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        telemetry: { anonymousId: 'test-id', noticeSeen: true }
      }));

      const config = await readConfig();
      expect(config.telemetry).toEqual({ anonymousId: 'test-id', noticeSeen: true });
    });

    it('should return empty object for invalid JSON', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, '{ invalid json }');

      const config = await readConfig();
      expect(config).toEqual({});
    });
  });

  describe('writeConfig', () => {
    it('should create directory if it does not exist', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');

      await writeConfig({ telemetry: { noticeSeen: true } });

      expect(fs.existsSync(configDir)).toBe(true);
    });

    it('should write config to file', async () => {
      const configPath = path.join(tempDir, '.config', 'openspec', 'config.json');

      await writeConfig({ telemetry: { anonymousId: 'test-123' } });

      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.telemetry.anonymousId).toBe('test-123');
    });

    it('should preserve existing fields when updating', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');
      const configPath = path.join(configDir, 'config.json');

      // Create initial config with other fields
      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        existingField: 'preserved',
        telemetry: { anonymousId: 'old-id' }
      }));

      // Update telemetry
      await writeConfig({ telemetry: { noticeSeen: true } });

      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.existingField).toBe('preserved');
      expect(parsed.telemetry.noticeSeen).toBe(true);
    });

    it('should deep merge telemetry fields', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');
      const configPath = path.join(configDir, 'config.json');

      // Create initial config
      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        telemetry: { anonymousId: 'existing-id' }
      }));

      // Update with noticeSeen only
      await writeConfig({ telemetry: { noticeSeen: true } });

      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.telemetry.anonymousId).toBe('existing-id');
      expect(parsed.telemetry.noticeSeen).toBe(true);
    });
  });

  describe('getTelemetryConfig', () => {
    it('should return empty object when no config exists', async () => {
      const config = await getTelemetryConfig();
      expect(config).toEqual({});
    });

    it('should return telemetry section from config', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        telemetry: { anonymousId: 'my-id', noticeSeen: false }
      }));

      const config = await getTelemetryConfig();
      expect(config).toEqual({ anonymousId: 'my-id', noticeSeen: false });
    });
  });

  describe('updateTelemetryConfig', () => {
    it('should create telemetry config when none exists', async () => {
      await updateTelemetryConfig({ anonymousId: 'new-id' });

      const configPath = path.join(tempDir, '.config', 'openspec', 'config.json');
      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.telemetry.anonymousId).toBe('new-id');
    });

    it('should merge with existing telemetry config', async () => {
      const configDir = path.join(tempDir, '.config', 'openspec');
      const configPath = path.join(configDir, 'config.json');

      fs.mkdirSync(configDir, { recursive: true });
      fs.writeFileSync(configPath, JSON.stringify({
        telemetry: { anonymousId: 'existing-id' }
      }));

      await updateTelemetryConfig({ noticeSeen: true });

      const content = fs.readFileSync(configPath, 'utf-8');
      const parsed = JSON.parse(content);
      expect(parsed.telemetry.anonymousId).toBe('existing-id');
      expect(parsed.telemetry.noticeSeen).toBe(true);
    });
  });
});



================================================
FILE: test/telemetry/index.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import { randomUUID } from 'node:crypto';

// Mock posthog-node before importing the module
vi.mock('posthog-node', () => {
  return {
    PostHog: vi.fn().mockImplementation(() => ({
      capture: vi.fn(),
      shutdown: vi.fn().mockResolvedValue(undefined),
    })),
  };
});

// Import after mocking
import { isTelemetryEnabled, maybeShowTelemetryNotice, shutdown, trackCommand } from '../../src/telemetry/index.js';
import { PostHog } from 'posthog-node';

describe('telemetry/index', () => {
  let tempDir: string;
  let originalEnv: NodeJS.ProcessEnv;
  let consoleLogSpy: ReturnType<typeof vi.spyOn>;

  beforeEach(() => {
    // Create unique temp directory for each test using UUID
    tempDir = path.join(os.tmpdir(), `openspec-telemetry-test-${randomUUID()}`);
    fs.mkdirSync(tempDir, { recursive: true });

    // Save original env
    originalEnv = { ...process.env };

    // Mock HOME to point to temp dir
    process.env.HOME = tempDir;

    // Clear all mocks
    vi.clearAllMocks();

    // Spy on console.log for notice tests
    consoleLogSpy = vi.spyOn(console, 'log').mockImplementation(() => {});
  });

  afterEach(() => {
    // Restore original env
    process.env = originalEnv;

    // Clean up temp directory
    try {
      fs.rmSync(tempDir, { recursive: true, force: true });
    } catch {
      // Ignore cleanup errors
    }

    // Restore all mocks
    vi.restoreAllMocks();
  });

  describe('isTelemetryEnabled', () => {
    it('should return false when OPENSPEC_TELEMETRY=0', () => {
      process.env.OPENSPEC_TELEMETRY = '0';
      expect(isTelemetryEnabled()).toBe(false);
    });

    it('should return false when DO_NOT_TRACK=1', () => {
      process.env.DO_NOT_TRACK = '1';
      expect(isTelemetryEnabled()).toBe(false);
    });

    it('should return false when CI=true', () => {
      process.env.CI = 'true';
      expect(isTelemetryEnabled()).toBe(false);
    });

    it('should return true when no opt-out is set', () => {
      delete process.env.OPENSPEC_TELEMETRY;
      delete process.env.DO_NOT_TRACK;
      delete process.env.CI;
      expect(isTelemetryEnabled()).toBe(true);
    });

    it('should prioritize OPENSPEC_TELEMETRY=0 over other settings', () => {
      process.env.OPENSPEC_TELEMETRY = '0';
      delete process.env.DO_NOT_TRACK;
      delete process.env.CI;
      expect(isTelemetryEnabled()).toBe(false);
    });
  });

  describe('maybeShowTelemetryNotice', () => {
    it('should not show notice when telemetry is disabled', async () => {
      process.env.OPENSPEC_TELEMETRY = '0';

      await maybeShowTelemetryNotice();

      expect(consoleLogSpy).not.toHaveBeenCalled();
    });
  });

  describe('trackCommand', () => {
    it('should not track when telemetry is disabled', async () => {
      process.env.OPENSPEC_TELEMETRY = '0';

      await trackCommand('test', '1.0.0');

      expect(PostHog).not.toHaveBeenCalled();
    });

    it('should track when telemetry is enabled', async () => {
      delete process.env.OPENSPEC_TELEMETRY;
      delete process.env.DO_NOT_TRACK;
      delete process.env.CI;

      await trackCommand('test', '1.0.0');

      expect(PostHog).toHaveBeenCalled();
    });
  });

  describe('shutdown', () => {
    it('should not throw when no client exists', async () => {
      await expect(shutdown()).resolves.not.toThrow();
    });

    it('should handle shutdown errors silently', async () => {
      const mockPostHog = {
        capture: vi.fn(),
        shutdown: vi.fn().mockRejectedValue(new Error('Network error')),
      };
      (PostHog as any).mockImplementation(() => mockPostHog);

      await expect(shutdown()).resolves.not.toThrow();
    });
  });
});



================================================
FILE: test/utils/change-metadata.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';
import {
  writeChangeMetadata,
  readChangeMetadata,
  resolveSchemaForChange,
  validateSchemaName,
  ChangeMetadataError,
} from '../../src/utils/change-metadata.js';
import { ChangeMetadataSchema } from '../../src/core/artifact-graph/types.js';

describe('ChangeMetadataSchema', () => {
  describe('valid metadata', () => {
    it('should accept valid schema with created date', () => {
      const result = ChangeMetadataSchema.safeParse({
        schema: 'spec-driven',
        created: '2025-01-05',
      });
      expect(result.success).toBe(true);
      if (result.success) {
        expect(result.data.schema).toBe('spec-driven');
        expect(result.data.created).toBe('2025-01-05');
      }
    });

    it('should accept valid schema without created date', () => {
      const result = ChangeMetadataSchema.safeParse({
        schema: 'tdd',
      });
      expect(result.success).toBe(true);
      if (result.success) {
        expect(result.data.schema).toBe('tdd');
        expect(result.data.created).toBeUndefined();
      }
    });
  });

  describe('invalid metadata', () => {
    it('should reject empty schema', () => {
      const result = ChangeMetadataSchema.safeParse({
        schema: '',
      });
      expect(result.success).toBe(false);
    });

    it('should reject missing schema', () => {
      const result = ChangeMetadataSchema.safeParse({
        created: '2025-01-05',
      });
      expect(result.success).toBe(false);
    });

    it('should reject invalid date format', () => {
      const result = ChangeMetadataSchema.safeParse({
        schema: 'spec-driven',
        created: '01/05/2025', // Wrong format
      });
      expect(result.success).toBe(false);
    });

    it('should reject non-ISO date format', () => {
      const result = ChangeMetadataSchema.safeParse({
        schema: 'spec-driven',
        created: '2025-1-5', // Missing leading zeros
      });
      expect(result.success).toBe(false);
    });
  });
});

describe('writeChangeMetadata', () => {
  let testDir: string;
  let changeDir: string;

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-test-${randomUUID()}`);
    changeDir = path.join(testDir, 'openspec', 'changes', 'test-change');
    await fs.mkdir(changeDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('should write valid YAML metadata file', async () => {
    writeChangeMetadata(changeDir, {
      schema: 'spec-driven',
      created: '2025-01-05',
    });

    const metaPath = path.join(changeDir, '.openspec.yaml');
    const content = await fs.readFile(metaPath, 'utf-8');

    expect(content).toContain('schema: spec-driven');
    expect(content).toContain('created: 2025-01-05');
  });

  it('should throw error for unknown schema', () => {
    expect(() =>
      writeChangeMetadata(changeDir, {
        schema: 'unknown-schema',
        created: '2025-01-05',
      })
    ).toThrow(/Unknown schema 'unknown-schema'/);
  });
});

describe('readChangeMetadata', () => {
  let testDir: string;
  let changeDir: string;

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-test-${randomUUID()}`);
    changeDir = path.join(testDir, 'openspec', 'changes', 'test-change');
    await fs.mkdir(changeDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('should return null when no metadata file exists', () => {
    const result = readChangeMetadata(changeDir);
    expect(result).toBeNull();
  });

  it('should read valid metadata', async () => {
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(
      metaPath,
      'schema: spec-driven\ncreated: "2025-01-05"\n',
      'utf-8'
    );

    const result = readChangeMetadata(changeDir);
    expect(result).toEqual({
      schema: 'spec-driven',
      created: '2025-01-05',
    });
  });

  it('should throw ChangeMetadataError for invalid YAML', async () => {
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, '{ invalid yaml', 'utf-8');

    expect(() => readChangeMetadata(changeDir)).toThrow(ChangeMetadataError);
  });

  it('should throw ChangeMetadataError for missing schema field', async () => {
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'created: "2025-01-05"\n', 'utf-8');

    expect(() => readChangeMetadata(changeDir)).toThrow(ChangeMetadataError);
  });

  it('should throw ChangeMetadataError for unknown schema', async () => {
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'schema: unknown-schema\n', 'utf-8');

    expect(() => readChangeMetadata(changeDir)).toThrow(/Unknown schema/);
  });
});

describe('resolveSchemaForChange', () => {
  let testDir: string;
  let changeDir: string;

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-test-${randomUUID()}`);
    changeDir = path.join(testDir, 'openspec', 'changes', 'test-change');
    await fs.mkdir(changeDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  it('should return explicit schema when provided', async () => {
    // Even with metadata file, explicit schema wins
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'schema: spec-driven\n', 'utf-8');

    const result = resolveSchemaForChange(changeDir, 'tdd');
    expect(result).toBe('tdd');
  });

  it('should return schema from metadata when no explicit schema', async () => {
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'schema: spec-driven\n', 'utf-8');

    const result = resolveSchemaForChange(changeDir);
    expect(result).toBe('spec-driven');
  });

  it('should return default when no metadata and no explicit schema', () => {
    const result = resolveSchemaForChange(changeDir);
    expect(result).toBe('spec-driven');
  });

  it('should return default when metadata read fails', async () => {
    // Create an invalid metadata file
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, '{ invalid yaml', 'utf-8');

    // Should fall back to default, not throw
    const result = resolveSchemaForChange(changeDir);
    expect(result).toBe('spec-driven');
  });

  it('should use project config schema when no metadata exists', async () => {
    // Create project config
    const configDir = path.join(testDir, 'openspec');
    await fs.mkdir(configDir, { recursive: true });
    await fs.writeFile(
      path.join(configDir, 'config.yaml'),
      'schema: tdd\n',
      'utf-8'
    );

    const result = resolveSchemaForChange(changeDir);
    expect(result).toBe('tdd');
  });

  it('should prefer change metadata over project config', async () => {
    // Create project config
    const configDir = path.join(testDir, 'openspec');
    await fs.mkdir(configDir, { recursive: true });
    await fs.writeFile(
      path.join(configDir, 'config.yaml'),
      'schema: tdd\n',
      'utf-8'
    );

    // Create change metadata with different schema
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'schema: spec-driven\n', 'utf-8');

    const result = resolveSchemaForChange(changeDir);
    expect(result).toBe('spec-driven'); // Change metadata wins
  });

  it('should prefer explicit schema over all config sources', async () => {
    // Create project config
    const configDir = path.join(testDir, 'openspec');
    await fs.mkdir(configDir, { recursive: true });
    await fs.writeFile(
      path.join(configDir, 'config.yaml'),
      'schema: tdd\n',
      'utf-8'
    );

    // Create change metadata
    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'schema: spec-driven\n', 'utf-8');

    // Explicit schema should win
    const result = resolveSchemaForChange(changeDir, 'tdd');
    expect(result).toBe('tdd');
  });

  it('should test full precedence order: CLI > metadata > config > default', async () => {
    // Setup all levels
    const configDir = path.join(testDir, 'openspec');
    await fs.mkdir(configDir, { recursive: true });
    await fs.writeFile(
      path.join(configDir, 'config.yaml'),
      'schema: tdd\n',
      'utf-8'
    );

    const metaPath = path.join(changeDir, '.openspec.yaml');
    await fs.writeFile(metaPath, 'schema: spec-driven\n', 'utf-8');

    // Test each level
    expect(resolveSchemaForChange(changeDir, 'tdd')).toBe('tdd'); // CLI wins
    expect(resolveSchemaForChange(changeDir)).toBe('spec-driven'); // Metadata wins when no CLI

    // Remove metadata, config should win
    await fs.unlink(metaPath);
    expect(resolveSchemaForChange(changeDir)).toBe('tdd'); // Config wins

    // Remove config, default should win
    await fs.unlink(path.join(configDir, 'config.yaml'));
    expect(resolveSchemaForChange(changeDir)).toBe('spec-driven'); // Default wins
  });
});

describe('validateSchemaName', () => {
  it('should accept valid schema name', () => {
    expect(() => validateSchemaName('spec-driven')).not.toThrow();
  });

  it('should throw for unknown schema', () => {
    expect(() => validateSchemaName('unknown-schema')).toThrow(
      /Unknown schema 'unknown-schema'/
    );
  });
});



================================================
FILE: test/utils/change-utils.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';
import { validateChangeName, createChange } from '../../src/utils/change-utils.js';

describe('validateChangeName', () => {
  describe('valid names', () => {
    it('should accept simple kebab-case name', () => {
      const result = validateChangeName('add-auth');
      expect(result).toEqual({ valid: true });
    });

    it('should accept name with multiple segments', () => {
      const result = validateChangeName('add-user-auth');
      expect(result).toEqual({ valid: true });
    });

    it('should accept name with numeric suffix', () => {
      const result = validateChangeName('add-feature-2');
      expect(result).toEqual({ valid: true });
    });

    it('should accept single word name', () => {
      const result = validateChangeName('refactor');
      expect(result).toEqual({ valid: true });
    });

    it('should accept name with numbers in segments', () => {
      const result = validateChangeName('upgrade-to-v2');
      expect(result).toEqual({ valid: true });
    });
  });

  describe('invalid names - uppercase rejected', () => {
    it('should reject name with uppercase letters', () => {
      const result = validateChangeName('Add-Auth');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('lowercase');
    });

    it('should reject fully uppercase name', () => {
      const result = validateChangeName('ADD-AUTH');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('lowercase');
    });
  });

  describe('invalid names - spaces rejected', () => {
    it('should reject name with spaces', () => {
      const result = validateChangeName('add auth');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('spaces');
    });
  });

  describe('invalid names - underscores rejected', () => {
    it('should reject name with underscores', () => {
      const result = validateChangeName('add_auth');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('underscores');
    });
  });

  describe('invalid names - special characters rejected', () => {
    it('should reject name with exclamation mark', () => {
      const result = validateChangeName('add-auth!');
      expect(result.valid).toBe(false);
      expect(result.error).toBeDefined();
    });

    it('should reject name with @ symbol', () => {
      const result = validateChangeName('add@auth');
      expect(result.valid).toBe(false);
      expect(result.error).toBeDefined();
    });
  });

  describe('invalid names - leading/trailing hyphens rejected', () => {
    it('should reject name with leading hyphen', () => {
      const result = validateChangeName('-add-auth');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('start with a hyphen');
    });

    it('should reject name with trailing hyphen', () => {
      const result = validateChangeName('add-auth-');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('end with a hyphen');
    });
  });

  describe('invalid names - consecutive hyphens rejected', () => {
    it('should reject name with double hyphens', () => {
      const result = validateChangeName('add--auth');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('consecutive hyphens');
    });
  });

  describe('invalid names - empty name rejected', () => {
    it('should reject empty string', () => {
      const result = validateChangeName('');
      expect(result.valid).toBe(false);
      expect(result.error).toContain('empty');
    });
  });
});

describe('createChange', () => {
  let testDir: string;

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-test-${randomUUID()}`);
    await fs.mkdir(testDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('creates directory', () => {
    it('should create change directory', async () => {
      await createChange(testDir, 'add-auth');

      const changeDir = path.join(testDir, 'openspec', 'changes', 'add-auth');
      const stats = await fs.stat(changeDir);
      expect(stats.isDirectory()).toBe(true);
    });

    it('should create .openspec.yaml metadata file with default schema', async () => {
      await createChange(testDir, 'add-auth');

      const metaPath = path.join(testDir, 'openspec', 'changes', 'add-auth', '.openspec.yaml');
      const content = await fs.readFile(metaPath, 'utf-8');
      expect(content).toContain('schema: spec-driven');
      expect(content).toMatch(/created: \d{4}-\d{2}-\d{2}/);
    });

    it('should create .openspec.yaml with custom schema', async () => {
      await createChange(testDir, 'add-auth', { schema: 'tdd' });

      const metaPath = path.join(testDir, 'openspec', 'changes', 'add-auth', '.openspec.yaml');
      const content = await fs.readFile(metaPath, 'utf-8');
      expect(content).toContain('schema: tdd');
    });
  });

  describe('schema validation', () => {
    it('should throw error for unknown schema', async () => {
      await expect(createChange(testDir, 'add-auth', { schema: 'unknown-schema' })).rejects.toThrow(
        /Unknown schema/
      );
    });
  });

  describe('duplicate change throws error', () => {
    it('should throw error if change already exists', async () => {
      await createChange(testDir, 'add-auth');

      await expect(createChange(testDir, 'add-auth')).rejects.toThrow(
        /already exists/
      );
    });
  });

  describe('invalid name throws validation error', () => {
    it('should throw error for uppercase name', async () => {
      await expect(createChange(testDir, 'Add-Auth')).rejects.toThrow(
        /lowercase/
      );
    });

    it('should throw error for name with spaces', async () => {
      await expect(createChange(testDir, 'add auth')).rejects.toThrow(
        /spaces/
      );
    });

    it('should throw error for empty name', async () => {
      await expect(createChange(testDir, '')).rejects.toThrow(
        /empty/
      );
    });
  });

  describe('creates parent directories if needed', () => {
    it('should create openspec/changes/ directories if they do not exist', async () => {
      const newProjectDir = path.join(testDir, 'new-project');
      await fs.mkdir(newProjectDir);

      // openspec/changes/ does not exist yet
      await createChange(newProjectDir, 'add-auth');

      const changeDir = path.join(newProjectDir, 'openspec', 'changes', 'add-auth');
      const stats = await fs.stat(changeDir);
      expect(stats.isDirectory()).toBe(true);
    });
  });
});



================================================
FILE: test/utils/file-system.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { randomUUID } from 'crypto';
import { FileSystemUtils } from '../../src/utils/file-system.js';

describe('FileSystemUtils', () => {
  let testDir: string;

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-test-${randomUUID()}`);
    await fs.mkdir(testDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('createDirectory', () => {
    it('should create a directory', async () => {
      const dirPath = path.join(testDir, 'new-dir');
      await FileSystemUtils.createDirectory(dirPath);
      
      const stats = await fs.stat(dirPath);
      expect(stats.isDirectory()).toBe(true);
    });

    it('should create nested directories', async () => {
      const dirPath = path.join(testDir, 'nested', 'deep', 'dir');
      await FileSystemUtils.createDirectory(dirPath);
      
      const stats = await fs.stat(dirPath);
      expect(stats.isDirectory()).toBe(true);
    });

    it('should not throw if directory already exists', async () => {
      const dirPath = path.join(testDir, 'existing-dir');
      await fs.mkdir(dirPath);
      
      await expect(FileSystemUtils.createDirectory(dirPath)).resolves.not.toThrow();
    });
  });

  describe('fileExists', () => {
    it('should return true for existing file', async () => {
      const filePath = path.join(testDir, 'test.txt');
      await fs.writeFile(filePath, 'test content');
      
      const exists = await FileSystemUtils.fileExists(filePath);
      expect(exists).toBe(true);
    });

    it('should return false for non-existing file', async () => {
      const filePath = path.join(testDir, 'non-existent.txt');
      
      const exists = await FileSystemUtils.fileExists(filePath);
      expect(exists).toBe(false);
    });

    it('should return false for directory path', async () => {
      const dirPath = path.join(testDir, 'dir');
      await fs.mkdir(dirPath);
      
      const exists = await FileSystemUtils.fileExists(dirPath);
      expect(exists).toBe(true); // fs.access doesn't distinguish between files and directories
    });
  });

  describe('directoryExists', () => {
    it('should return true for existing directory', async () => {
      const dirPath = path.join(testDir, 'test-dir');
      await fs.mkdir(dirPath);
      
      const exists = await FileSystemUtils.directoryExists(dirPath);
      expect(exists).toBe(true);
    });

    it('should return false for non-existing directory', async () => {
      const dirPath = path.join(testDir, 'non-existent-dir');
      
      const exists = await FileSystemUtils.directoryExists(dirPath);
      expect(exists).toBe(false);
    });

    it('should return false for file path', async () => {
      const filePath = path.join(testDir, 'file.txt');
      await fs.writeFile(filePath, 'content');
      
      const exists = await FileSystemUtils.directoryExists(filePath);
      expect(exists).toBe(false);
    });
  });

  describe('writeFile', () => {
    it('should write content to file', async () => {
      const filePath = path.join(testDir, 'output.txt');
      const content = 'Hello, World!';
      
      await FileSystemUtils.writeFile(filePath, content);
      
      const readContent = await fs.readFile(filePath, 'utf-8');
      expect(readContent).toBe(content);
    });

    it('should create directory if it does not exist', async () => {
      const filePath = path.join(testDir, 'nested', 'dir', 'output.txt');
      const content = 'Nested content';
      
      await FileSystemUtils.writeFile(filePath, content);
      
      const readContent = await fs.readFile(filePath, 'utf-8');
      expect(readContent).toBe(content);
    });

    it('should overwrite existing file', async () => {
      const filePath = path.join(testDir, 'existing.txt');
      await fs.writeFile(filePath, 'old content');
      
      const newContent = 'new content';
      await FileSystemUtils.writeFile(filePath, newContent);
      
      const readContent = await fs.readFile(filePath, 'utf-8');
      expect(readContent).toBe(newContent);
    });
  });

  describe('readFile', () => {
    it('should read file content', async () => {
      const filePath = path.join(testDir, 'input.txt');
      const content = 'Test content';
      await fs.writeFile(filePath, content);
      
      const readContent = await FileSystemUtils.readFile(filePath);
      expect(readContent).toBe(content);
    });

    it('should throw for non-existing file', async () => {
      const filePath = path.join(testDir, 'non-existent.txt');
      
      await expect(FileSystemUtils.readFile(filePath)).rejects.toThrow();
    });
  });

  describe('ensureWritePermissions', () => {
    it('should return true for writable directory', async () => {
      const hasPermission = await FileSystemUtils.ensureWritePermissions(testDir);
      expect(hasPermission).toBe(true);
    });

    it('should return true for non-existing directory with writable parent', async () => {
      const dirPath = path.join(testDir, 'new-dir');
      const hasPermission = await FileSystemUtils.ensureWritePermissions(dirPath);
      expect(hasPermission).toBe(true);
    });

    it('should handle deeply nested non-existing directories', async () => {
      const dirPath = path.join(testDir, 'a', 'b', 'c', 'd');
      const hasPermission = await FileSystemUtils.ensureWritePermissions(dirPath);
      expect(hasPermission).toBe(true);
    });
  });

  describe('canWriteFile', () => {
    it('should return true for existing writable file', async () => {
      const filePath = path.join(testDir, 'writable.txt');
      await fs.writeFile(filePath, 'content');

      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(true);
    });

    it('should return false for existing read-only file', async () => {
      const filePath = path.join(testDir, 'readonly.txt');
      await fs.writeFile(filePath, 'content');
      await fs.chmod(filePath, 0o444); // Read-only

      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(false);

      // Cleanup: restore permissions so afterEach can delete
      await fs.chmod(filePath, 0o644);
    });

    it('should return true for non-existent file in writable directory', async () => {
      const filePath = path.join(testDir, 'new-file.txt');

      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(true);
    });

    it('should return true for non-existent file in non-existent nested directories', async () => {
      const filePath = path.join(testDir, 'deep', 'nested', 'path', 'file.txt');

      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(true);
    });

    // Skip on Windows: fs.chmod() on directories doesn't restrict write access on Windows
    // Windows uses ACLs which Node.js chmod doesn't control
    it.skipIf(process.platform === 'win32')('should return false for non-existent file in read-only directory', async () => {
      const readOnlyDir = path.join(testDir, 'readonly-dir');
      await fs.mkdir(readOnlyDir);
      await fs.chmod(readOnlyDir, 0o555); // Read-only + execute

      const filePath = path.join(readOnlyDir, 'file.txt');
      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(false);

      // Cleanup
      await fs.chmod(readOnlyDir, 0o755);
    });

    it('should return true when path points to existing directory', async () => {
      const dirPath = path.join(testDir, 'some-dir');
      await fs.mkdir(dirPath);

      const canWrite = await FileSystemUtils.canWriteFile(dirPath);
      expect(canWrite).toBe(true);
    });

    it('should traverse multiple non-existent parent directories', async () => {
      const filePath = path.join(testDir, 'a', 'b', 'c', 'd', 'e', 'file.txt');

      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(true);
    });

    it('should return false when intermediate path component is a file', async () => {
      // Create a file where a directory should be
      const fileInPath = path.join(testDir, 'blocking-file.txt');
      await fs.writeFile(fileInPath, 'content');

      // Try to check a path that goes "through" this file
      const filePath = path.join(fileInPath, 'nested', 'file.txt');
      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(false);
    });

    it('should follow symbolic links to files', async () => {
      const realFile = path.join(testDir, 'real-file.txt');
      const linkFile = path.join(testDir, 'link-file.txt');
      await fs.writeFile(realFile, 'content');
      await fs.symlink(realFile, linkFile);

      const canWrite = await FileSystemUtils.canWriteFile(linkFile);
      expect(canWrite).toBe(true);
    });

    it('should handle platform-specific path separators', async () => {
      const filePath = FileSystemUtils.joinPath(testDir, 'subdir', 'file.txt');
      const canWrite = await FileSystemUtils.canWriteFile(filePath);
      expect(canWrite).toBe(true);
    });
  });

  describe('joinPath', () => {
    it('should join POSIX-style paths', () => {
      const result = FileSystemUtils.joinPath(
        '/tmp/project',
        '.claude/commands/openspec/proposal.md'
      );
      expect(result).toBe('/tmp/project/.claude/commands/openspec/proposal.md');
    });

    it('should join Linux home directory paths', () => {
      const result = FileSystemUtils.joinPath(
        '/home/dev/workspace/openspec',
        '.cursor/commands/install.md'
      );
      expect(result).toBe('/home/dev/workspace/openspec/.cursor/commands/install.md');
    });

    it('should join Windows drive-letter paths with backslashes', () => {
      const result = FileSystemUtils.joinPath(
        'C:\\Users\\dev\\project',
        '.claude/commands/openspec/proposal.md'
      );
      expect(result).toBe(
        'C:\\Users\\dev\\project\\.claude\\commands\\openspec\\proposal.md'
      );
    });

    it('should join Windows paths that use forward slashes', () => {
      const result = FileSystemUtils.joinPath(
        'D:/workspace/app',
        '.cursor/commands/openspec-apply.md'
      );
      expect(result).toBe(
        'D:\\workspace\\app\\.cursor\\commands\\openspec-apply.md'
      );
    });

    it('should join UNC-style Windows paths', () => {
      const result = FileSystemUtils.joinPath(
        '\\server\\share\\repo',
        '.windsurf/workflows/openspec-archive.md'
      );
      expect(result).toBe(
        '\\server\\share\\repo\\.windsurf\\workflows\\openspec-archive.md'
      );
    });
  });
});



================================================
FILE: test/utils/interactive.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { isInteractive, resolveNoInteractive, InteractiveOptions } from '../../src/utils/interactive.js';

describe('interactive utilities', () => {
  let originalOpenSpecInteractive: string | undefined;
  let originalCI: string | undefined;
  let originalStdinIsTTY: boolean | undefined;

  beforeEach(() => {
    // Save original environment
    originalOpenSpecInteractive = process.env.OPEN_SPEC_INTERACTIVE;
    originalCI = process.env.CI;
    originalStdinIsTTY = process.stdin.isTTY;

    // Clear environment for clean testing
    delete process.env.OPEN_SPEC_INTERACTIVE;
    delete process.env.CI;
  });

  afterEach(() => {
    // Restore original environment
    if (originalOpenSpecInteractive !== undefined) {
      process.env.OPEN_SPEC_INTERACTIVE = originalOpenSpecInteractive;
    } else {
      delete process.env.OPEN_SPEC_INTERACTIVE;
    }
    if (originalCI !== undefined) {
      process.env.CI = originalCI;
    } else {
      delete process.env.CI;
    }
    // Restore stdin.isTTY
    Object.defineProperty(process.stdin, 'isTTY', {
      value: originalStdinIsTTY,
      writable: true,
      configurable: true,
    });
  });

  describe('resolveNoInteractive', () => {
    it('should return true when noInteractive is true', () => {
      expect(resolveNoInteractive({ noInteractive: true })).toBe(true);
    });

    it('should return true when interactive is false (Commander.js style)', () => {
      // This is how Commander.js handles --no-interactive flag
      expect(resolveNoInteractive({ interactive: false })).toBe(true);
    });

    it('should return false when noInteractive is false', () => {
      expect(resolveNoInteractive({ noInteractive: false })).toBe(false);
    });

    it('should return false when interactive is true', () => {
      expect(resolveNoInteractive({ interactive: true })).toBe(false);
    });

    it('should return false for empty options object', () => {
      expect(resolveNoInteractive({})).toBe(false);
    });

    it('should return false for undefined', () => {
      expect(resolveNoInteractive(undefined)).toBe(false);
    });

    it('should handle boolean value true', () => {
      expect(resolveNoInteractive(true)).toBe(true);
    });

    it('should handle boolean value false', () => {
      expect(resolveNoInteractive(false)).toBe(false);
    });

    it('should prioritize noInteractive over interactive when both set', () => {
      // noInteractive: true should win
      expect(resolveNoInteractive({ noInteractive: true, interactive: true })).toBe(true);
      // If noInteractive is false, check interactive
      expect(resolveNoInteractive({ noInteractive: false, interactive: false })).toBe(true);
    });
  });

  describe('isInteractive', () => {
    it('should return false when noInteractive is true', () => {
      expect(isInteractive({ noInteractive: true })).toBe(false);
    });

    it('should return false when interactive is false (Commander.js --no-interactive)', () => {
      expect(isInteractive({ interactive: false })).toBe(false);
    });

    it('should return false when OPEN_SPEC_INTERACTIVE env var is 0', () => {
      process.env.OPEN_SPEC_INTERACTIVE = '0';
      Object.defineProperty(process.stdin, 'isTTY', { value: true, writable: true, configurable: true });
      expect(isInteractive({})).toBe(false);
    });

    it('should return false when CI env var is set', () => {
      process.env.CI = 'true';
      Object.defineProperty(process.stdin, 'isTTY', { value: true, writable: true, configurable: true });
      expect(isInteractive({})).toBe(false);
    });

    it('should return false when CI env var is set to any value', () => {
      // CI can be set to any value, not just "true"
      process.env.CI = '1';
      Object.defineProperty(process.stdin, 'isTTY', { value: true, writable: true, configurable: true });
      expect(isInteractive({})).toBe(false);
    });

    it('should return false when stdin is not a TTY', () => {
      Object.defineProperty(process.stdin, 'isTTY', { value: false, writable: true, configurable: true });
      expect(isInteractive({})).toBe(false);
    });

    it('should return true when stdin is TTY and no flags disable it', () => {
      Object.defineProperty(process.stdin, 'isTTY', { value: true, writable: true, configurable: true });
      expect(isInteractive({})).toBe(true);
    });

    it('should return true when stdin is TTY and options are undefined', () => {
      Object.defineProperty(process.stdin, 'isTTY', { value: true, writable: true, configurable: true });
      expect(isInteractive(undefined)).toBe(true);
    });
  });
});



================================================
FILE: test/utils/marker-updates.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { FileSystemUtils } from '../../src/utils/file-system.js';

describe('FileSystemUtils.updateFileWithMarkers', () => {
  let testDir: string;
  const START_MARKER = '<!-- OPENSPEC:START -->';
  const END_MARKER = '<!-- OPENSPEC:END -->';

  beforeEach(async () => {
    testDir = path.join(os.tmpdir(), `openspec-marker-test-${Date.now()}`);
    await fs.mkdir(testDir, { recursive: true });
  });

  afterEach(async () => {
    await fs.rm(testDir, { recursive: true, force: true });
  });

  describe('new file creation', () => {
    it('should create new file with markers and content', async () => {
      const filePath = path.join(testDir, 'new-file.md');
      const content = 'OpenSpec content';
      
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        content,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toBe(`${START_MARKER}\n${content}\n${END_MARKER}`);
    });
  });

  describe('existing file without markers', () => {
    it('should prepend markers and content to existing file', async () => {
      const filePath = path.join(testDir, 'existing.md');
      const existingContent = '# Existing Content\nUser content here';
      await fs.writeFile(filePath, existingContent);
      
      const newContent = 'OpenSpec content';
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        newContent,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toBe(
        `${START_MARKER}\n${newContent}\n${END_MARKER}\n\n${existingContent}`
      );
    });
  });

  describe('existing file with markers', () => {
    it('should replace content between markers', async () => {
      const filePath = path.join(testDir, 'with-markers.md');
      const beforeContent = '# Before\nSome content before';
      const oldManagedContent = 'Old OpenSpec content';
      const afterContent = '# After\nSome content after';
      
      const existingFile = `${beforeContent}\n${START_MARKER}\n${oldManagedContent}\n${END_MARKER}\n${afterContent}`;
      await fs.writeFile(filePath, existingFile);
      
      const newContent = 'New OpenSpec content';
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        newContent,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toBe(
        `${beforeContent}\n${START_MARKER}\n${newContent}\n${END_MARKER}\n${afterContent}`
      );
    });

    it('should preserve content before and after markers', async () => {
      const filePath = path.join(testDir, 'preserve.md');
      const userContentBefore = '# User Content Before\nImportant user notes';
      const userContentAfter = '## User Content After\nMore user notes';
      
      const existingFile = `${userContentBefore}\n${START_MARKER}\nOld content\n${END_MARKER}\n${userContentAfter}`;
      await fs.writeFile(filePath, existingFile);
      
      const newContent = 'Updated content';
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        newContent,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toContain(userContentBefore);
      expect(result).toContain(userContentAfter);
      expect(result).toContain(newContent);
      expect(result).not.toContain('Old content');
    });

    it('should handle markers at the beginning of file', async () => {
      const filePath = path.join(testDir, 'markers-at-start.md');
      const afterContent = 'User content after markers';
      
      const existingFile = `${START_MARKER}\nOld content\n${END_MARKER}\n${afterContent}`;
      await fs.writeFile(filePath, existingFile);
      
      const newContent = 'New content';
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        newContent,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toBe(`${START_MARKER}\n${newContent}\n${END_MARKER}\n${afterContent}`);
    });

    it('should handle markers at the end of file', async () => {
      const filePath = path.join(testDir, 'markers-at-end.md');
      const beforeContent = 'User content before markers';
      
      const existingFile = `${beforeContent}\n${START_MARKER}\nOld content\n${END_MARKER}`;
      await fs.writeFile(filePath, existingFile);
      
      const newContent = 'New content';
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        newContent,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toBe(`${beforeContent}\n${START_MARKER}\n${newContent}\n${END_MARKER}`);
    });
  });

  describe('invalid marker states', () => {
    it('should throw error if only start marker exists', async () => {
      const filePath = path.join(testDir, 'invalid-start.md');
      const existingFile = `Some content\n${START_MARKER}\nManaged content\nNo end marker`;
      await fs.writeFile(filePath, existingFile);
      
      await expect(
        FileSystemUtils.updateFileWithMarkers(
          filePath,
          'New content',
          START_MARKER,
          END_MARKER
        )
      ).rejects.toThrow(/Invalid marker state/);
    });

    it('should throw error if only end marker exists', async () => {
      const filePath = path.join(testDir, 'invalid-end.md');
      const existingFile = `Some content\nNo start marker\nManaged content\n${END_MARKER}`;
      await fs.writeFile(filePath, existingFile);
      
      await expect(
        FileSystemUtils.updateFileWithMarkers(
          filePath,
          'New content',
          START_MARKER,
          END_MARKER
        )
      ).rejects.toThrow(/Invalid marker state/);
    });
  });

  describe('idempotency', () => {
    it('should produce same result when called multiple times with same content', async () => {
      const filePath = path.join(testDir, 'idempotent.md');
      const content = 'Consistent content';
      
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        content,
        START_MARKER,
        END_MARKER
      );
      
      const firstResult = await fs.readFile(filePath, 'utf-8');
      
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        content,
        START_MARKER,
        END_MARKER
      );
      
      const secondResult = await fs.readFile(filePath, 'utf-8');
      expect(secondResult).toBe(firstResult);
    });
  });

  describe('edge cases', () => {
    it('should handle empty content', async () => {
      const filePath = path.join(testDir, 'empty-content.md');
      
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        '',
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toBe(`${START_MARKER}\n\n${END_MARKER}`);
    });

    it('should handle content with special characters', async () => {
      const filePath = path.join(testDir, 'special-chars.md');
      const content = '# Special chars: ${}[]()<>|\\`*_~';
      
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        content,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toContain(content);
    });

    it('should handle multi-line content', async () => {
      const filePath = path.join(testDir, 'multi-line.md');
      const content = `Line 1
Line 2
Line 3

Line 5 with gap`;
      
      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        content,
        START_MARKER,
        END_MARKER
      );
      
      const result = await fs.readFile(filePath, 'utf-8');
      expect(result).toContain(content);
    });

    it('should ignore inline mentions of markers when updating content', async () => {
      const filePath = path.join(testDir, 'inline-mentions.md');
      const existingFile = `Intro referencing markers like ${START_MARKER} and ${END_MARKER} inside text.

${START_MARKER}
Original content
${END_MARKER}
`;

      await fs.writeFile(filePath, existingFile);

      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        'Updated content',
        START_MARKER,
        END_MARKER
      );

      const firstResult = await fs.readFile(filePath, 'utf-8');
      expect(firstResult).toContain('Intro referencing markers like');
      expect(firstResult).toContain('Updated content');
      expect(firstResult.match(new RegExp(START_MARKER, 'g'))?.length).toBe(2);
      expect(firstResult.match(new RegExp(END_MARKER, 'g'))?.length).toBe(2);

      await FileSystemUtils.updateFileWithMarkers(
        filePath,
        'Updated content',
        START_MARKER,
        END_MARKER
      );

      const secondResult = await fs.readFile(filePath, 'utf-8');
      expect(secondResult).toBe(firstResult);
    });
  });
});



================================================
FILE: test/utils/shell-detection.test.ts
================================================
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { detectShell, SupportedShell } from '../../src/utils/shell-detection.js';

describe('shell-detection', () => {
  let originalShell: string | undefined;
  let originalPSModulePath: string | undefined;
  let originalComspec: string | undefined;
  let originalPlatform: NodeJS.Platform;

  beforeEach(() => {
    // Save original environment
    originalShell = process.env.SHELL;
    originalPSModulePath = process.env.PSModulePath;
    originalComspec = process.env.COMSPEC;
    originalPlatform = process.platform;

    // Clear environment for clean testing
    delete process.env.SHELL;
    delete process.env.PSModulePath;
    delete process.env.COMSPEC;
  });

  afterEach(() => {
    // Restore original environment
    if (originalShell !== undefined) {
      process.env.SHELL = originalShell;
    } else {
      delete process.env.SHELL;
    }
    if (originalPSModulePath !== undefined) {
      process.env.PSModulePath = originalPSModulePath;
    } else {
      delete process.env.PSModulePath;
    }
    if (originalComspec !== undefined) {
      process.env.COMSPEC = originalComspec;
    } else {
      delete process.env.COMSPEC;
    }
    Object.defineProperty(process, 'platform', {
      value: originalPlatform,
    });
  });

  describe('detectShell', () => {
    it('should detect zsh from SHELL environment variable', () => {
      process.env.SHELL = '/bin/zsh';
      const result = detectShell();
      expect(result.shell).toBe('zsh');
      expect(result.detected).toBe('zsh');
    });

    it('should detect zsh from various zsh paths', () => {
      const zshPaths = [
        '/usr/bin/zsh',
        '/usr/local/bin/zsh',
        '/opt/homebrew/bin/zsh',
        '/home/user/.local/bin/zsh',
      ];

      for (const path of zshPaths) {
        process.env.SHELL = path;
        const result = detectShell();
        expect(result.shell).toBe('zsh');
        expect(result.detected).toBe('zsh');
      }
    });

    it('should detect bash from SHELL environment variable', () => {
      process.env.SHELL = '/bin/bash';
      const result = detectShell();
      expect(result.shell).toBe('bash');
      expect(result.detected).toBe('bash');
    });

    it('should detect bash from various bash paths', () => {
      const bashPaths = [
        '/usr/bin/bash',
        '/usr/local/bin/bash',
        '/opt/homebrew/bin/bash',
        '/home/user/.local/bin/bash',
      ];

      for (const path of bashPaths) {
        process.env.SHELL = path;
        const result = detectShell();
        expect(result.shell).toBe('bash');
        expect(result.detected).toBe('bash');
      }
    });

    it('should detect fish from SHELL environment variable', () => {
      process.env.SHELL = '/usr/bin/fish';
      const result = detectShell();
      expect(result.shell).toBe('fish');
      expect(result.detected).toBe('fish');
    });

    it('should detect fish from various fish paths', () => {
      const fishPaths = [
        '/bin/fish',
        '/usr/local/bin/fish',
        '/opt/homebrew/bin/fish',
        '/home/user/.local/bin/fish',
      ];

      for (const path of fishPaths) {
        process.env.SHELL = path;
        const result = detectShell();
        expect(result.shell).toBe('fish');
        expect(result.detected).toBe('fish');
      }
    });

    it('should be case-insensitive when detecting shell', () => {
      process.env.SHELL = '/BIN/ZSH';
      let result = detectShell();
      expect(result.shell).toBe('zsh');

      process.env.SHELL = '/USR/BIN/BASH';
      result = detectShell();
      expect(result.shell).toBe('bash');

      process.env.SHELL = '/USR/BIN/FISH';
      result = detectShell();
      expect(result.shell).toBe('fish');
    });

    it('should detect PowerShell from PSModulePath environment variable', () => {
      process.env.PSModulePath = 'C:\\Program Files\\PowerShell\\Modules';
      const result = detectShell();
      expect(result.shell).toBe('powershell');
      expect(result.detected).toBe('powershell');
    });

    it('should detect PowerShell on Windows platform with PSModulePath', () => {
      Object.defineProperty(process, 'platform', {
        value: 'win32',
      });
      process.env.PSModulePath = 'C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\Modules';
      const result = detectShell();
      expect(result.shell).toBe('powershell');
      expect(result.detected).toBe('powershell');
    });

    it('should return detected name for unsupported shell', () => {
      process.env.SHELL = '/bin/tcsh';
      const result = detectShell();
      expect(result.shell).toBeUndefined();
      expect(result.detected).toBe('tcsh');
    });

    it('should return undefined when SHELL is not set and not on Windows', () => {
      Object.defineProperty(process, 'platform', {
        value: 'linux',
      });
      const result = detectShell();
      expect(result.shell).toBeUndefined();
      expect(result.detected).toBeUndefined();
    });

    it('should return detected name for cmd.exe on Windows', () => {
      Object.defineProperty(process, 'platform', {
        value: 'win32',
      });
      process.env.COMSPEC = 'C:\\Windows\\System32\\cmd.exe';
      const result = detectShell();
      expect(result.shell).toBeUndefined();
      expect(result.detected).toBe('cmd.exe');
    });

    it('should return undefined when no shell information is available', () => {
      const result = detectShell();
      expect(result.shell).toBeUndefined();
      expect(result.detected).toBeUndefined();
    });
  });

  describe('SupportedShell type', () => {
    it('should accept valid shell types', () => {
      const shells: SupportedShell[] = ['zsh', 'bash', 'fish', 'powershell'];
      expect(shells).toHaveLength(4);
    });
  });
});



================================================
FILE: .changeset/README.md
================================================
# Changesets

This directory is managed by [Changesets](https://github.com/changesets/changesets).

## Quick Start

```bash
pnpm changeset
```

Follow the prompts to select version bump type and describe your changes.

## Workflow

1. **Add a changeset** â€” Run `pnpm changeset` locally before or after your PR
2. **Version PR** â€” CI opens/updates a "Version Packages" PR when changesets merge to main
3. **Release** â€” Merging the Version PR triggers npm publish and GitHub Release

> **Note:** Contributors only need to run `pnpm changeset`. Versioning (`changeset version`) and publishing happen automatically in CI.

## Template

Use this structure for your changeset content:

```markdown
---
"@fission-ai/openspec": patch
---

### New Features

- **Feature name** â€” What users can now do

### Bug Fixes

- Fixed issue where X happened when Y

### Breaking Changes

- `oldMethod()` has been removed, use `newMethod()` instead

### Deprecations

- `legacyOption` is deprecated and will be removed in v2.0

### Other

- Internal refactoring of X for better performance
```

Include only the sections relevant to your change.

## Version Bump Guide

| Type | When to use | Example |
|------|-------------|---------|
| `patch` | Bug fixes, small improvements | Fixed crash when config missing |
| `minor` | New features, non-breaking additions | Added `--verbose` flag |
| `major` | Breaking changes, removed features | Renamed `init` to `setup` |

## When to Create a Changeset

**Create one for:**
- New features or commands
- Bug fixes that affect users
- Breaking changes or deprecations
- Performance improvements users would notice

**Skip for:**
- Documentation-only changes
- Test additions/fixes
- Internal refactoring with no user impact
- CI/tooling changes

## Writing Good Descriptions

**Do:** Write for users, not developers
```markdown
- **Shell completions** â€” Tab completion now available for Bash, Fish, and PowerShell
```

**Don't:** Write implementation details
```markdown
- Added ShellCompletionGenerator class with Bash/Fish/PowerShell subclasses
```

**Do:** Explain the impact
```markdown
- Fixed config loading to respect `XDG_CONFIG_HOME` on Linux
```

**Don't:** Just reference the fix
```markdown
- Fixed #123
```



================================================
FILE: .changeset/config.json
================================================
{
  "$schema": "https://unpkg.com/@changesets/config/schema.json",
  "changelog": [
    "@changesets/changelog-github",
    { "repo": "Fission-AI/OpenSpec" }
  ],
  "commit": false,
  "fixed": [],
  "linked": [],
  "access": "public",
  "baseBranch": "main",
  "updateInternalDependencies": "patch",
  "ignore": []
}




================================================
FILE: .devcontainer/README.md
================================================
# Dev Container Setup

This directory contains the VS Code dev container configuration for OpenSpec development.

## What's Included

- **Node.js 20 LTS** (>=20.19.0) - TypeScript/JavaScript runtime
- **pnpm** - Fast, disk space efficient package manager
- **Git + GitHub CLI** - Version control tools
- **VS Code Extensions**:
  - ESLint & Prettier for code quality
  - Vitest Explorer for running tests
  - GitLens for enhanced git integration
  - Error Lens for inline error highlighting
  - Code Spell Checker
  - Path IntelliSense

## How to Use

### First Time Setup

1. **Install Prerequisites** (on your local machine):
   - [VS Code](https://code.visualstudio.com/)
   - [Docker Desktop](https://www.docker.com/products/docker-desktop)
   - [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)

2. **Open in Container**:
   - Open this project in VS Code
   - You'll see a notification: "Folder contains a Dev Container configuration file"
   - Click "Reopen in Container"

   OR

   - Open Command Palette (`Cmd/Ctrl+Shift+P`)
   - Type "Dev Containers: Reopen in Container"
   - Press Enter

3. **Wait for Setup**:
   - The container will build (first time takes a few minutes)
   - `pnpm install` runs automatically via `postCreateCommand`
   - All extensions install automatically

### Daily Development

Once set up, the container preserves your development environment:

```bash
# Run development build
pnpm run dev

# Run CLI in development
pnpm run dev:cli

# Run tests
pnpm test

# Run tests in watch mode
pnpm test:watch

# Build the project
pnpm run build
```

### SSH Keys

Your SSH keys are mounted read-only from `~/.ssh`, so git operations work seamlessly with GitHub/GitLab.

### Rebuilding the Container

If you modify `.devcontainer/devcontainer.json`:
- Command Palette â†’ "Dev Containers: Rebuild Container"

## Benefits

- No need to install Node.js or pnpm on your local machine
- Consistent development environment across team members
- Isolated from other Node.js projects on your machine
- All dependencies and tools containerized
- Easy onboarding for new developers

## Troubleshooting

**Container won't build:**
- Ensure Docker Desktop is running
- Check Docker has enough memory allocated (recommend 4GB+)

**Extensions not appearing:**
- Rebuild the container: "Dev Containers: Rebuild Container"

**Permission issues:**
- The container runs as the `node` user (non-root)
- Files created in the container are owned by this user



================================================
FILE: .devcontainer/devcontainer.json
================================================
{
  "name": "OpenSpec Development",
  "image": "mcr.microsoft.com/devcontainers/typescript-node:1-20-bookworm",

  // Additional tools and features
  "features": {
    "ghcr.io/devcontainers/features/git:1": {
      "version": "latest",
      "ppa": true
    },
    "ghcr.io/devcontainers/features/github-cli:1": {
      "version": "latest"
    }
  },

  // Configure tool-specific properties
  "customizations": {
    "vscode": {
      // Set default container specific settings
      "settings": {
        "typescript.tsdk": "node_modules/typescript/lib",
        "typescript.enablePromptUseWorkspaceTsdk": true,
        "editor.formatOnSave": true,
        "editor.defaultFormatter": "esbenp.prettier-vscode",
        "editor.codeActionsOnSave": {
          "source.fixAll": "explicit"
        },
        "files.eol": "\n",
        "terminal.integrated.defaultProfile.linux": "bash"
      },

      // Add extensions you want installed when the container is created
      "extensions": [
        // TypeScript/JavaScript essentials
        "dbaeumer.vscode-eslint",
        "esbenp.prettier-vscode",

        // Testing
        "vitest.explorer",

        // Git
        "eamodio.gitlens",

        // Utilities
        "streetsidesoftware.code-spell-checker",
        "usernamehw.errorlens",
        "christian-kohler.path-intellisense"
      ]
    }
  },

  // Use 'forwardPorts' to make a list of ports inside the container available locally
  // "forwardPorts": [],

  // Use 'postCreateCommand' to run commands after the container is created
  "postCreateCommand": "corepack enable && corepack prepare pnpm@latest --activate && pnpm install",

  // Configure mounts to preserve SSH keys for git operations
  "mounts": [
    "source=${localEnv:HOME}${localEnv:USERPROFILE}/.ssh,target=/home/node/.ssh,readonly,type=bind,consistency=cached"
  ],

  // Set the default user to 'node' (non-root user)
  "remoteUser": "node",

  // Ensure git is properly configured
  "initializeCommand": "echo 'Initializing dev container...'"
}



================================================
FILE: .github/CODEOWNERS
================================================
# Default code ownership
* @TabishB



================================================
FILE: .github/workflows/README.md
================================================
# Github Workflows

## Testing CI Locally

Test GitHub Actions workflows locally using [act](https://nektosact.com/):

```bash
# Test all PR checks
act pull_request

# Test specific job
act pull_request -j nix-flake-validate

# Dry run to see what would execute
act pull_request --dryrun
```

The `.actrc` file configures act to use the appropriate Docker image.





================================================
FILE: .github/workflows/ci.yml
================================================
name: CI

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Detect which files changed to enable path-based filtering
  changes:
    name: Detect changes
    runs-on: ubuntu-latest
    outputs:
      nix: ${{ steps.filter.outputs.nix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for Nix-related changes
        uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            nix:
              - 'flake.nix'
              - 'flake.lock'
              - 'package.json'
              - 'pnpm-lock.yaml'
              - 'scripts/update-flake.sh'
              - '.github/workflows/ci.yml'

  test_pr:
    name: Test
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build project
        run: pnpm run build

      - name: Run tests
        run: pnpm test

      - name: Upload test coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-pr
          path: coverage/
          retention-days: 7

  test_matrix:
    name: Test (${{ matrix.label }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    if: github.event_name != 'pull_request'
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            shell: bash
            label: linux-bash
          - os: macos-latest
            shell: bash
            label: macos-bash
          - os: windows-latest
            shell: pwsh
            label: windows-pwsh

    defaults:
      run:
        shell: ${{ matrix.shell }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Print environment diagnostics
        run: |
          node -p "JSON.stringify({ platform: process.platform, arch: process.arch, shell: process.env.SHELL || process.env.ComSpec || '' })"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build project
        run: pnpm run build

      - name: Run tests
        run: pnpm test

      - name: Upload test coverage
        if: matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-main
          path: coverage/
          retention-days: 7

  lint:
    name: Lint & Type Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build project
        run: pnpm run build

      - name: Type check
        run: pnpm exec tsc --noEmit

      - name: Lint
        run: pnpm lint

      - name: Check for build artifacts
        run: |
          if [ ! -d "dist" ]; then
            echo "Error: dist directory not found after build"
            exit 1
          fi
          if [ ! -f "dist/cli/index.js" ]; then
            echo "Error: CLI entry point not found"
            exit 1
          fi

  nix-flake-validate:
    name: Nix Flake Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: changes
    if: needs.changes.outputs.nix == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Nix
        uses: DeterminateSystems/nix-installer-action@v13

      - name: Setup Nix cache
        uses: DeterminateSystems/magic-nix-cache-action@v8

      - name: Build with Nix
        run: nix build

      - name: Verify build output
        run: |
          if [ ! -e "result" ]; then
            echo "Error: Nix build output 'result' symlink not found"
            exit 1
          fi
          if [ ! -f "result/bin/openspec" ]; then
            echo "Error: openspec binary not found in build output"
            exit 1
          fi
          echo "âœ… Build output verified"

      - name: Test binary execution
        run: |
          VERSION=$(nix run . -- --version)
          echo "OpenSpec version: $VERSION"
          if [ -z "$VERSION" ]; then
            echo "Error: Version command returned empty output"
            exit 1
          fi
          echo "âœ… Binary execution successful"

      - name: Validate update script
        run: |
          echo "Testing update-flake.sh script..."
          bash scripts/update-flake.sh
          echo "âœ… Update script executed successfully"

      - name: Check flake.nix modifications
        run: |
          if git diff --quiet flake.nix; then
            echo "âš ï¸  Warning: flake.nix was not modified by update script"
          else
            echo "âœ… flake.nix was updated by script"
            git diff flake.nix
          fi

      - name: Restore flake.nix
        if: always()
        run: git checkout -- flake.nix || true

  validate-changesets:
    name: Validate Changesets
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Validate changesets
        run: |
          if command -v changeset &> /dev/null; then
            pnpm exec changeset status --since=origin/main
          else
            echo "Changesets not configured, skipping validation"
          fi

  required-checks-pr:
    name: All checks passed
    runs-on: ubuntu-latest
    needs: [test_pr, lint, nix-flake-validate]
    if: always() && github.event_name == 'pull_request'
    steps:
      - name: Verify all checks passed
        run: |
          if [[ "${{ needs.test_pr.result }}" != "success" ]]; then
            echo "Test job failed"
            exit 1
          fi
          if [[ "${{ needs.lint.result }}" != "success" ]]; then
            echo "Lint job failed"
            exit 1
          fi
          # Nix validation may be skipped if no Nix-related files changed
          if [[ "${{ needs.nix-flake-validate.result }}" != "success" && "${{ needs.nix-flake-validate.result }}" != "skipped" ]]; then
            echo "Nix flake validation job failed"
            exit 1
          fi
          if [[ "${{ needs.nix-flake-validate.result }}" == "skipped" ]]; then
            echo "Nix flake validation skipped (no Nix-related changes)"
          fi
          echo "All required checks passed!"

  required-checks-main:
    name: All checks passed
    runs-on: ubuntu-latest
    needs: [test_matrix, lint, nix-flake-validate]
    if: always() && github.event_name != 'pull_request'
    steps:
      - name: Verify all checks passed
        run: |
          if [[ "${{ needs.test_matrix.result }}" != "success" ]]; then
            echo "Matrix test job failed"
            exit 1
          fi
          if [[ "${{ needs.lint.result }}" != "success" ]]; then
            echo "Lint job failed"
            exit 1
          fi
          # Nix validation may be skipped if no Nix-related files changed
          if [[ "${{ needs.nix-flake-validate.result }}" != "success" && "${{ needs.nix-flake-validate.result }}" != "skipped" ]]; then
            echo "Nix flake validation job failed"
            exit 1
          fi
          if [[ "${{ needs.nix-flake-validate.result }}" == "skipped" ]]; then
            echo "Nix flake validation skipped (no Nix-related changes)"
          fi
          echo "All required checks passed!"



================================================
FILE: .github/workflows/polish-release-notes.yml
================================================
name: Polish Release Notes

# Uses Claude to transform raw changelog into polished release notes.
# Triggered automatically by release-prepare after publishing, or manually.
on:
  repository_dispatch:
    types: [polish-release-notes]
  workflow_dispatch:
    inputs:
      tag_name:
        description: 'Release tag to polish (e.g., v0.18.0)'
        required: true
        type: string

env:
  # repository_dispatch passes tag via client_payload, workflow_dispatch via inputs
  TAG_NAME: ${{ github.event.client_payload.tag_name || inputs.tag_name }}

permissions:
  contents: write

jobs:
  polish:
    # Only run on the main repo, not forks
    if: github.repository == 'Fission-AI/OpenSpec'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Get current release body
        id: get-release
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh release view "${{ env.TAG_NAME }}" --json body -q '.body' > current-notes.md
          echo "Fetched release notes for ${{ env.TAG_NAME }}"

      - name: Transform release notes with Claude
        uses: anthropics/claude-code-action@v1
        id: claude
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          claude_args: "--allowedTools Write,Read"
          prompt: |
            Transform the changelog in `current-notes.md` into release notes for OpenSpec ${{ env.TAG_NAME }}.

            ## Voice

            OpenSpec is a developer tool. Write like you're talking to a peer:
            - Direct and practical, not marketing copy
            - Focus on what changed and why it matters
            - Skip the hype, keep it real

            ## Output

            Create two files:

            ### 1. `release-title.txt`

            A short title in this format:
            ```
            ${{ env.TAG_NAME }} - [1-4 words describing the release]
            ```

            Examples:
            - `v0.18.0 - OPSX Experimental Workflow`
            - `v0.16.0 - Antigravity, iFlow Support`
            - `v0.15.0 - Gemini CLI, RooCode`

            Rules for title:
            - Lead with the most notable addition
            - 1-4 words after the dash, no fluff
            - If multiple features, comma-separate the top 2
            - For bugfix-only releases, use something like `v0.17.2 - Pre-commit Hook Fix`

            ### 2. `polished-notes.md`

            ```markdown
            ## What's New in ${{ env.TAG_NAME }}

            [One sentence: what's the theme of this release?]

            ### New

            - **Feature name** - What it does and why you'd use it

            ### Improved

            - **Area** - What got better

            ### Fixed

            - What was broken, now works
            ```

            Omit empty sections.

            ## Rules

            1. Write for developers using OpenSpec with AI coding assistants
            2. Remove commit hashes (like `eb152eb:`), PR numbers, and changesets wrappers (`### Minor Changes`)
            3. Lead with what users can do, not implementation details
            4. One to two sentences per item, max
            5. Use **bold** for feature/area names
            6. Skip internal changes (CI, refactors, tests) unless they affect users
            7. If the input is already well-formatted, just clean up structure and remove noise

            ## Example

            Before:
            ```
            ### Minor Changes
            - 8dfd824: Add OPSX experimental workflow commands and enhanced artifact system
              **New Commands:**
              - `/opsx:ff` - Fast-forward through artifact creation
            ```

            After (polished-notes.md):
            ```
            ### New

            - **Fast-forward mode** - Generate all planning artifacts at once with `/opsx:ff`. Useful when you already know what you're building.
            ```

            After (release-title.txt):
            ```
            v0.18.0 - OPSX Experimental Workflow
            ```

            Write both files. No other output.

      - name: Update release
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          TAG="${{ env.TAG_NAME }}"

          if [ -f "polished-notes.md" ] && [ -f "release-title.txt" ]; then
            TITLE=$(cat release-title.txt)
            gh release edit "$TAG" --title "$TITLE" --notes-file polished-notes.md
            echo "Updated: $TITLE"
          elif [ -f "polished-notes.md" ]; then
            gh release edit "$TAG" --notes-file polished-notes.md
            echo "Updated notes (title unchanged)"
          else
            echo "No changes generated, keeping original"
          fi



================================================
FILE: .github/workflows/release-prepare.yml
================================================
name: Release (prepare)

on:
  push:
    branches: [main]

permissions:
  contents: write
  pull-requests: write
  id-token: write # Required for npm OIDC trusted publishing

concurrency:
  group: release-${{ github.ref }}
  cancel-in-progress: false

jobs:
  prepare:
    if: github.repository == 'Fission-AI/OpenSpec'
    runs-on: ubuntu-latest
    steps:
      # Generate GitHub App token first - used for checkout and changesets
      # This allows git operations to trigger CI workflows on the version PR
      # (GITHUB_TOKEN cannot trigger workflows by design)
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ vars.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ steps.app-token.outputs.token }}

      - uses: pnpm/action-setup@v4
        with:
          version: 9

      - uses: actions/setup-node@v4
        with:
          node-version: '24' # Node 24 includes npm 11.5.1+ required for OIDC
          cache: 'pnpm'
          registry-url: 'https://registry.npmjs.org'

      - run: pnpm install --frozen-lockfile

      # Opens/updates the Version Packages PR; publishes when the Version PR merges
      - name: Create/Update Version PR
        id: changesets
        uses: changesets/action@v1
        with:
          title: 'chore(release): version packages'
          createGithubReleases: true
          # Use CI-specific release script: relies on version PR having been merged
          # so package.json already contains the bumped version.
          publish: pnpm run release:ci
        env:
          GITHUB_TOKEN: ${{ steps.app-token.outputs.token }}
          # npm authentication handled via OIDC trusted publishing (no token needed)

      # Trigger release notes polishing after a release is published
      # Uses repository_dispatch instead of workflow_dispatch because:
      # - workflow_dispatch requires actions:write permission (GitHub App doesn't have it)
      # - repository_dispatch works with contents:write (which we already have)
      - name: Polish release notes
        if: steps.changesets.outputs.published == 'true'
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          # Get version from package.json (just bumped by changesets)
          TAG="v$(jq -r .version package.json)"
          echo "Triggering polish workflow for $TAG"
          gh api repos/${{ github.repository }}/dispatches \
            --method POST \
            --input - <<< "{\"event_type\":\"polish-release-notes\",\"client_payload\":{\"tag_name\":\"$TAG\"}}"


